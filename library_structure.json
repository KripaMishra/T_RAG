{
  "id": 1,
  "title": "Library",
  "type": "library",
  "children": [
    {
      "id": 2,
      "title": "Book 1",
      "type": "book",
      "children": [
        {
          "id": 3,
          "title": "Abstract",
          "type": "section",
          "children": [
            {
              "id": 4,
              "title": "Abstract - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Abstract\nLarge      language      models      (LLMs)      have      shown exceptional      performance      as      general-purpose      as- sistants,      excelling      across   \n \na      variety      of      reasoning arXiv:2407.14562v1      [cs.Al]      18      Jul      2024 tasks. This      achievement      represents   \n \na      signifi- cant      step      toward      achieving      artificial      general      in- telligence      (AGI)."
            },
            {
              "id": 5,
              "title": "Abstract - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Despite      these      advancements, the      effectiveness      of      LLMs      often      hinges      on      the specific      prompting      strategies      employed,      and there      remains   \n \na      lack      of   \n \na      robust      framework      to facilitate      learning      and      generalization      across      di- verse      reasoning      tasks."
            },
            {
              "id": 6,
              "title": "Abstract - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "To      address      these      chal- lenges,      we      introduce   \n \na      novel      learning      frame- work,      THOUGHT-LIKE-PRO. In      this      frame- work,      we      utilize      imitation      learning      to      imitate the      Chain-of-Thought      (CoT)      process      which      is verified      and      translated      from      reasoning      trajec- tories      generated      by   \n \na      symbolic      Prolog      logic engine."
            },
            {
              "id": 7,
              "title": "Abstract - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      framework      proceeds      in   \n \na      self- driven      manner,      that      enables      LLMs      to      formu- late      rules      and      statements      from      given      instruc- tions      and      leverage      the      symbolic      Prolog      engine to      derive      results."
            },
            {
              "id": 8,
              "title": "Abstract - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Subsequently,      LLMs      con- vert      Prolog-derived      successive      reasoning      tra- jectories      into      natural      language      CoT      for      imi- tation      learning. Our      empirical      findings      indi- cate      that      our      proposed      approach      substantially enhances      the      reasoning      abilities      of      LLMs      and demonstrates      robust      generalization      across      out- of-distribution      reasoning      tasks."
            },
            {
              "id": 9,
              "title": "Abstract - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "1\n \n   Introduction Recent      advancements      in      large      language      models (LLMs)      have      positioned      them      as      versatile      tools for   \n \na      variety      of      tasks,      achieved      through   \n \na      struc- tured      training      process      that      includes      pre-training      on large      text      corpora,      supervised      fine-tuning,      and      rein- forcement      learning      from      human      feedback      (RLHF) (Casper      et      al.,      2023)."
            },
            {
              "id": 10,
              "title": "Abstract - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "These      phases      equip      LLMs with      extensive      knowledge,      the      ability      to      generate context-specific      responses,      and      alignment      with      hu- man      values. One      of      the      key      factors      contributing to      the      perception      of      LLMs      as   \n \na      precursor      to      arti- et      al.,      2024)      have      been      introduced."
            },
            {
              "id": 11,
              "title": "Abstract - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "These      meth-  \n \n  ods      aim      to      formalize      the      reasoning      architecture ficial      general      intelligence      (AGI)      is      their      scalable  \n \n  and      explainable      reasoning      capabilities      (Zhao      et      al., 2023),      which      have      demonstrated      potential      to      solve multiple      types      of      real-world      complex      logic      reason- ing      problems,      including      natural      language      logical reasoning      and      arithmetic      reasoning."
            },
            {
              "id": 12,
              "title": "Abstract - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "General      logic      reasoning      tasks      continue      to      present substantial      challenges      for      LLMs. These      challenges primarily      emerge      during      the      LLMs’      reasoning      pro- cesses      (Ribeiro      et      al.,      2023;      Zhou      et      al.,      2024)."
            },
            {
              "id": 13,
              "title": "Abstract - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "At the      semantic      level,      the      generation      of      accurate      multi- hop      inferential      pathways      and      the      assurance      of      va- lidity      at      each      reasoning      step      remain      significant      ob- stacles      (Creswell      et      al.,      2023;      Kazemi      et      al.,      2023)."
            },
            {
              "id": 14,
              "title": "Abstract - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "LLMs      function      in   \n \na      self-regressive      manner      at      the      to- ken      level,      processing      information      sequentially      from left      to      right,      one      token      at   \n \na      time."
            },
            {
              "id": 15,
              "title": "Abstract - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "This      method      can amplify      errors:      an      inaccurate      token      prediction      may negatively      impact      all      subsequent      tokens,      leading to      escalating      inaccuracies      and      false      reasoning      out- comes."
            },
            {
              "id": 16,
              "title": "Abstract - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Interestingly,      some      studies      (Ye      and      Durrett, 2022;      Saparov      and      He,      2023;      Ribeiro      et      al.,      2023) have      observed      instances      where      LLMs      deliver      cor- rect      answers      despite      erroneous      internal      reasoning processes."
            },
            {
              "id": 17,
              "title": "Abstract - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "This      phenomenon      highlights   \n \na      mis- alignment      between      the      reasoning      processes      and outcomes      of      LLMs,      suggesting   \n \na      weak      causal relationship      and      underdeveloped      implicit      rea- soning      connections      within      the      LLMs."
            },
            {
              "id": 18,
              "title": "Abstract - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "To      address      the      challenges      associated      with      gener- ating      reasoning      trajectories      in      LLMs,      several      strate- gies      have      been      developed      to      enhance      cognitive alignment      and      logical      coherence."
            },
            {
              "id": 19,
              "title": "Abstract - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "The      Chain-of- Thought      (CoT)      approach      (Wei      et      al.,      2022;      Ko- jima      et      al.,      2022;      Zhang      et      al.,      2022),      for      instance, enhances      LLMs’      reasoning      abilities      by      crafting instructions      and      few-shot      examples      that      promote sequential      reasoning."
            },
            {
              "id": 20,
              "title": "Abstract - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Building      on      the      CoT      frame- work,      other      methodologies      like      Tree-of-Thoughts (Yao      et      al.,      2024;      Long,      2023;      Hulbert,      2023) and      Graph-of-Thoughts      (Besta      et      al.,      2024;      Zhang of      LLMs      through      in-context      learning      (Dong      et      al., 2022;      Work)      and      guide      model      output."
            },
            {
              "id": 21,
              "title": "Abstract - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "While      these prompt-based      techniques      have      proven      effective      in specific      tasks,      they      require      precise,      task-specific modifications      and      may      not      be      broadly      applicable across      different      domains      (Creswell      et      al.,      2023;\nKazemi      et      al.,      2023)."
            },
            {
              "id": 22,
              "title": "Abstract - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Alternative      approaches      have sought      to      augment      the      reasoning      capabilities      of LLMs      by      conceptualizing      them      as      agents      that      can employ      various      logical      reasoning      tools      (Lyu      et      al., 2023;      Pan      et      al.,      2023a)."
            },
            {
              "id": 23,
              "title": "Abstract - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "This      strategy      simplifies complex      reasoning      tasks      into      more      manageable components      such      as      tool      utilization      and      question definition."
            },
            {
              "id": 24,
              "title": "Abstract - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "One      particularly      effective      method      in- volves      the      use      of      symbolic      logic      engines,      such      as Prolog      (Bowen,      1979),      to      conduct      symbolic      infer- ence,      thereby      ensuring      the      correctness      of      the      rea- soning      trajectory."
            },
            {
              "id": 25,
              "title": "Abstract - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "However,      this      approach      does      not inherently      enhance      the      LLM’s      reasoning      capabili- ties      and      fails      to      provide   \n \na      generalized      improvement in      the      model’s      ability      to      follow      general      instructions across      diverse      tasks. Pro!,   \n \na      novel      framework      designed      to      enhance      the"
            }
          ],
          "content": ""
        },
        {
          "id": 26,
          "title": "In      this      paper,      we      introduce      THOUGHT-LIKE-",
          "type": "section",
          "children": [
            {
              "id": 27,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "In      this      paper,      we      introduce      THOUGHT-LIKE-\nlogical      reasoning      capabilities      of      LLMs      by      imitating the      verified      reasoning      processes      of      the      Prolog      logic engine."
            },
            {
              "id": 28,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      begin      by      utilizing      open-source      chat LLMs,      such      as      Llama3-8B-Instruct      (AI@      Meta, 2024),      to      generate      rules,      facts,      and      queries      follow- ing      specific      instructions      and      demonstrations. Sub- sequently,      we      employ      the      Prolog      engine      to      perform logical      reasoning,      verifying      the      outcomes      against established      truths."
            },
            {
              "id": 29,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Only      the      verified      reasoning      pro- cesses      are      selected,      which      we      then      translate      into CoT-like      natural      language      reasoning      trajectories. These      trajectories      serve      as      the      basis      for      supervised fine-tuning      (SFT),      aimed      at      teaching      LLMs      to      im- itate   \n \na      strictly      logical      reasoning      process."
            },
            {
              "id": 30,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "To      ad- dress      the      issue      of      catastrophic      forgetting      during domain-specific      fine-tuning,      we      implement   \n \na      model averaging      technique."
            },
            {
              "id": 31,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Empirical      experiments      con- firm      that      the      THOUGHT-LIKE-PRO      framework      sig- nificantly      improves      the      reasoning      capabilities      of LLMs      and      extends      their      generalization      to      Out-of- Distribution      (OOD)      reasoning      benchmarks."
            },
            {
              "id": 32,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "The contributions      of      our      study      are      detailed      as      follows:\n \n \n  We      offer   \n \na      demo      of      the      dataset      automatically      generated      by  \n \n  the      THOUGHT-LIKE-PRO      framework      for      reference. Avail-  \n \n  able      at:      https:      //anonymous.4open.science/r/Prolog_  \n \n  datasets-9875. \\\\\\'The      code      will      be      fully      released      due      to      the      acceptance."
            },
            {
              "id": 33,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "¢\n \n   We      propose      THOUGHT-LIKE-PRO      framework designed      to      enhance      the      general      reasoning      ca- pabilities      of      LLMs      in   \n \na      self-driven      way. This framework      is      straightforward      to      implement and      replicate."
            },
            {
              "id": 34,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "¢\n \n   Our      results      show      that      performing      imitation learning      on      strictly      logical      and      diverse      rea- soning      trajectories      for   \n \na      single      instruction leads      to      improved      and      consistent      reasoning performance. ¢\n \n   The      framework      is      simple,      straightforward, and      highly      effective."
            },
            {
              "id": 35,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "It      demonstrates      robust OOD      reasoning      performance      across      multiple logic      tasks      and      general      benchmarks,      making it      applicable      in      various      industrial      domains. 2\n \n   Methods\n2.1      Preliminary:      Supervised      Fine-tuning,\ning, Chain-of-Thought,      and      Prolog Consider   \n \na      LLM,      denoted      by      pg,      which      is      param- eterized      by      @."
            },
            {
              "id": 36,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Given      an      instruction      dataset      Dy      pr consisting      of      question      and      answer      pairs      (x,y),   \n \na highly      effective      method      for      aligning   \n \n6      with      the      tar- get      output   \n \ny      given   \n \nx      is      to      minimize      the      negative log-likelihood      of   \n \ny      conditioned      on   \n \nx      (Gunel      et      al., 2020;      Dong      et      al.,      2023)."
            },
            {
              "id": 37,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "This      can      be      formulated autoregressively      as:\nmin      —E(xy)~Dyp   \n \n>      ert)   \n \n,      Q) k\n6\n     ;\ni=1 where      k      is      the      number      of      tokens      in      y."
            },
            {
              "id": 38,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "To      enhance      reasoning      performance      on      com- plex      logical      and      algorithmic      tasks,      one      effective approach      involves      using   \n \na      specialized      prompt, promptcor,      to      initiate   \n \na      step-by-step      reasoning trajectory      prior      to      generating      the      final      output:\n(y,c)   \n \n~      po(-|x,      promptcor)."
            },
            {
              "id": 39,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Here,      c      represents   \n \na CoT      reasoning      process      (Wei      et      al.,      2022;      Kojima et      al.,      2022;      Zhang      et      al.,      2022). Typically,      this process      decomposes      complex,      multi-step      reason- ing      tasks      into      simpler,      intermediate      steps,      thereby directing      the      LLM      toward      the      correct      answer."
            },
            {
              "id": 40,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Nev- ertheless,      several      studies      (Ye      and      Durrett,      2022;\nSaparov      and      He,      2023;      Ribeiro      et      al.,      2023)      have indicated      that      c      may      sometimes      exhibit      disorga- nized      patterns      that      do      not      adhere      strictly      to      logical reasoning      processes."
            },
            {
              "id": 41,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "This      inconsistency      can      ad- versely      affect      the      LLM’s      reasoning      performance across      diverse      tasks."
            },
            {
              "id": 42,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Step.1      Generate      Rules,      Facts,  \n \n  Step.3      Translate      Prolog-based      Trajectories      to      CoT\nreasoning      Prolog      code:   \n \n>      by      Prolog      engine:      ire      ro  \n \n  (Re,      Fx;      Ty)   \n \n~      pol:   \n \n|      prompt,      4,      x,      y)      O(ay)   \n \n=      Prolog(Rz,      Fz;      Ty)      cy      ~~      po(-|prompte:      ,X,¥,0i),      01   \n \n€      O(e,y);\nand      Targets      Reasoning      Trajectories  \n \n  fo}      Preparing      the   \n \na      Reasoning      trajectories      fe}      Constructing      the      new      dataset      Drzz:\nZ=1,,n  \n \n  Datasets      Drr      fo      prompt,      ¢,  \n \n  cot  \n \n  SFT      for      imitation      learning:  \n \n  ming      —E(x,c2,y)~Darp      [log      Po      (y,      cP?"
            },
            {
              "id": 43,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "lx)\nProlog      is   \n \na      high-level      symbolic      language      system This      is      designed      to      guide      the      model      pg      in      generat- designed      for      rule-based      reasoning      (Andreas      et      al., ing      relevant      rules      R,,      facts      F,,      and      deriving      the 2016;      Neelakantan      et      al.,      2017),      fundamentally      op- reasoning      target      Ty:\nerating      within   \n \na      subset      of      predicate      logic      known as      Horn      Clause      logic      (Hudson      and      Manning,      2019; (Re,      Fx,Ty)   \n \n~      po(-   \n \n|      prompt,      x,y)."
            },
            {
              "id": 44,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "(3)"
            }
          ],
          "content": ""
        },
        {
          "id": 45,
          "title": "2.1      Preliminary:      Supervised      Fine-tuning,",
          "type": "section",
          "children": [
            {
              "id": 46,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "2.1      Preliminary:      Supervised      Fine-tuning,\ning, Chain-of-Thought,      and      Prolog Consider   \n \na      LLM,      denoted      by      pg,      which      is      param- eterized      by      @."
            },
            {
              "id": 47,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Given      an      instruction      dataset      Dy      pr consisting      of      question      and      answer      pairs      (x,y),   \n \na highly      effective      method      for      aligning   \n \n6      with      the      tar- get      output   \n \ny      given   \n \nx      is      to      minimize      the      negative log-likelihood      of   \n \ny      conditioned      on   \n \nx      (Gunel      et      al., 2020;      Dong      et      al.,      2023)."
            },
            {
              "id": 48,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "This      can      be      formulated autoregressively      as:\nmin      —E(xy)~Dyp   \n \n>      ert)   \n \n,      Q) k\n6\n     ;\ni=1 where      k      is      the      number      of      tokens      in      y."
            },
            {
              "id": 49,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "To      enhance      reasoning      performance      on      com- plex      logical      and      algorithmic      tasks,      one      effective approach      involves      using   \n \na      specialized      prompt, promptcor,      to      initiate   \n \na      step-by-step      reasoning trajectory      prior      to      generating      the      final      output:\n(y,c)   \n \n~      po(-|x,      promptcor)."
            },
            {
              "id": 50,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Here,      c      represents   \n \na CoT      reasoning      process      (Wei      et      al.,      2022;      Kojima et      al.,      2022;      Zhang      et      al.,      2022). Typically,      this process      decomposes      complex,      multi-step      reason- ing      tasks      into      simpler,      intermediate      steps,      thereby directing      the      LLM      toward      the      correct      answer."
            },
            {
              "id": 51,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Nev- ertheless,      several      studies      (Ye      and      Durrett,      2022;\nSaparov      and      He,      2023;      Ribeiro      et      al.,      2023)      have indicated      that      c      may      sometimes      exhibit      disorga- nized      patterns      that      do      not      adhere      strictly      to      logical reasoning      processes."
            },
            {
              "id": 52,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "This      inconsistency      can      ad- versely      affect      the      LLM’s      reasoning      performance across      diverse      tasks."
            },
            {
              "id": 53,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Step.1      Generate      Rules,      Facts,  \n \n  Step.3      Translate      Prolog-based      Trajectories      to      CoT\nreasoning      Prolog      code:   \n \n>      by      Prolog      engine:      ire      ro  \n \n  (Re,      Fx;      Ty)   \n \n~      pol:   \n \n|      prompt,      4,      x,      y)      O(ay)   \n \n=      Prolog(Rz,      Fz;      Ty)      cy      ~~      po(-|prompte:      ,X,¥,0i),      01   \n \n€      O(e,y);\nand      Targets      Reasoning      Trajectories  \n \n  fo}      Preparing      the   \n \na      Reasoning      trajectories      fe}      Constructing      the      new      dataset      Drzz:\nZ=1,,n  \n \n  Datasets      Drr      fo      prompt,      ¢,  \n \n  cot  \n \n  SFT      for      imitation      learning:  \n \n  ming      —E(x,c2,y)~Darp      [log      Po      (y,      cP?"
            },
            {
              "id": 54,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "lx)\nProlog      is   \n \na      high-level      symbolic      language      system This      is      designed      to      guide      the      model      pg      in      generat- designed      for      rule-based      reasoning      (Andreas      et      al., ing      relevant      rules      R,,      facts      F,,      and      deriving      the 2016;      Neelakantan      et      al.,      2017),      fundamentally      op- reasoning      target      Ty:\nerating      within   \n \na      subset      of      predicate      logic      known as      Horn      Clause      logic      (Hudson      and      Manning,      2019; (Re,      Fx,Ty)   \n \n~      po(-   \n \n|      prompt,      x,y)."
            },
            {
              "id": 55,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "(3)"
            }
          ],
          "content": ""
        },
        {
          "id": 56,
          "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de-",
          "type": "section",
          "children": [
            {
              "id": 57,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Bowen,      1979). It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de-\nimperative      approach      by      emphasizing      relations      over duce the set of reasoning trajectories O(,,), which the      sequence      of      actions."
            },
            {
              "id": 58,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "In      Prolog,      the      logic      of      com- encompasses      all      logical      paths      leading      to      the      target\n |       putation      is      articulated      through      relations,      denoted | Ty. This      process      is      formalized      as:\n |       as      facts      F      and      rules      R."
            },
            {
              "id": 59,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Typically,      Prolog      utilizes      a | Oy)   \n \n=      Prolog(Re,      Fx;      Ty):      (4)\n |       depth-first      search      strategy      (Wielemaker      et      al.,      2012)       sired      conclusion,      yet      it      is      also      equipped      to      delineate | reasoning      trajectories      that      conclusively      reach      the\n | all      possible      logical      inference      paths      leading      to      the target      7,,      excluding      any      data      that      result      from      er-\n |       target      results      7."
            },
            {
              "id": 60,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      entire      logical      inference      pro-       cess      within      the      Prolog      engine,      denoted      as      Prolog, | delineated      in      Equation      3."
            },
            {
              "id": 61,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "To      ensure      the      acquisition\n |       can      be      represented      by      the      following      equation: | of      high-quality      and      interpretable      reasoning      trajec-\n | O = Prolog(R, F, T), {01, 02, | -; On} € O, (2)  \n \n  tories      via      Prolog,      we      implement   \n \na      meta-solver      de-  \n \n  veloped      by      (Yang      et      al.,      2023),      which      retrieves      all\n |       where      O      encompasses      n      valid      logical      inference | feasible      reasoning      paths."
            },
            {
              "id": 62,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "|       trajectories      toward      the      target      T. | After      acquiring      the      set      O(z,),      we      design   \n \na      novel  \n \n  few-shot      prompt,      prompt®”? (Listing      2),      to      trans-\n\n2.2      THOUGHT-LIKE-PRO late      existing      reasoning      trajectories      into      CoT-like\nHere,      we      introduce      THOUGHT-LIKE-PRO,   \n \na      novel reasoning      processes      expressed      in      natural      language."
            },
            {
              "id": 63,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "framework      designed      to      enhance      the      general      log- This      transformation      aids      in      constructing      the      new\n\n |       ical      reasoning      capabilities      of      LLMs      across      vari- |       dataset      Darr:\n |       ous      logical      tasks. As      suggested      by      the      name,      our |       cP”?"
            },
            {
              "id": 64,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "~      py(-|prompt?”?,      x,      ¥,0;),0;      €      Oury):\n |       framework      enables      LLMs      to      imitate      strictly      logical       reasoning      trajectories      that      are      generated      and      val- |       (x,      cre a=1,,n. )      y)      €      Dri      F;      for\n |       idated      by      the      Prolog      engine."
            },
            {
              "id": 65,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "The      architecture      of |       (5)\n |       THOUGHT-LIKE-PRO      is      organized      in      a      self-driven |       It      is      important      to      note      that      this      new      dataset,      Dry      pr,\n |       manner,      eliminating      the      requirement      for      auxiliary |       encompasses      all      n      available      reasoning      trajectories\n |       services      from      other      advanced      LLMs,      such      as      GPT- |       for      each      instruction      x."
            },
            {
              "id": 66,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Subsequently,      we      optimize\n | 4      (Achiam      et      al.,      2023)      and      Claude      2      (Wu      et      al., the      model      using      SFT      as      outlined      in      Equation      1,\n |       2023)."
            },
            {
              "id": 67,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "It      solely      relies      on      the      utilization      of      effi- |       aligning      both      the      CoT-like      reasoning      trajectories\n |       cient,      open-source      LLMs      (i.e.,      Llama3-8B-Instruct |       and      the      target      outputs      conditioned      on      x      autoregres-\n |       (AI@Meta,      2024)),      fostering      accessibility      and      ease |       sively:\n |       of      replication."
            },
            {
              "id": 68,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "|       min      E(x,      cP°¢,y)~Darr      [log      po(y,c””°|x)],      (6)\n | To      employ      the      Prolog      engine      Prolog      for      logical reasoning,      we      initiate      the      process      by      constructing resulting      in      a      trained      model      parameterized      by      6’. | This      entire      learning      process      parallels      imitation       Acc a      few-shot      demonstration      prompt,.-,      (Listing      1)."
            },
            {
              "id": 69,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "| Datasets      Prompt      Thought-Like-Pro(ours)       Lama3-8B-Instruct      MA+single      MA+multiple      single      multiple      CARING       GSM8K      8-shot,CoT      79.6      80.7      85.32      83.4      87.81      98.1       ProofWriter      3-shot,CoT      53.7      72.13      97.25      73.91      98.19      100       PrOntoQA      2-shot      53.6      90.4      94.3      95.3      100      100       MMLU      5-shot      68.4      68.2      67.9      65.4      64.3      -       GPQA      0-shot      34.2      34.2      33.8      32.8      31.9      -       HumanEval      0-shot      62.2      62.1      61.9      60.2      60      -       MATH      4-shot,CoT      30      29.3      30.2      29.2      30.1      -\n | and      are      not      included      in      the      accuracy      rankings."
            },
            {
              "id": 70,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "| learning      algorithms      (Hussein      et      al.,      2017;      Osa      et      al., 2018)      that      select      “optimal”      trajectories      (here      veri- fied      by      the      Prolog      engine)      and      implement      behavior cloning      to      directly      imitate      these      trajectories."
            },
            {
              "id": 71,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Af- ter      training      according      to      Equation      6,      the      model pe      is      tailored      to      perform      domain-specific      tasks present      in      Dgrr."
            },
            {
              "id": 72,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "However,      if      the      task      distribution of      Drir      significantly      diverges      from      that      of      Dyr, catastrophic      forgetting      (CF)      may      occur      (Chen      et      al., 2023;      Zhai      et      al.,      2023;      Shi      et      al.,      2024),      potentially compromising      the      model’s      generality      across      other reasoning      and      general      tasks."
            },
            {
              "id": 73,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "To      address      this,      we employ      a      model      averaging      technique      (Lin      et      al., 2023)      to      derive      a      new      model      pg      parameterized      by      0:\n | 6      =      a0      +      (1      —a)6’,      where      a      is      a      hyper-parameter that      balances      specialization      and      generalization."
            },
            {
              "id": 74,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "| 3      Experiment In      our      preliminary      experiments,      we      continually trained      the      Llama3-8B-Instruct      model,      using      it as      a      baseline      to      evaluate      the      effectiveness      of      the THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 75,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "We      also      imple- ment      CARING      (Yang      et      al.,      2023)      under      the      experi- mental      setup      as      our      baseline      method      which      utilizes the      Prolog      engine      to      derive      the      final      results      without training      LLMs. Hence,      the      performance      of      CAR- ING      in      reasoning      tasks      should      be      the      upper      limit of      THOUGHT-LIKE-PRO."
            },
            {
              "id": 76,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "We      trained      the      model and      evaluated      its      reasoning      capabilities      across      three datasets:      GSM8K      (Cobbe      et      al.,      2021),      ProofWriter (Tafjord      et      al.,      2020),      and      PrOntoQA      (Saparov      and He,      2022)."
            },
            {
              "id": 77,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Additionally,      we      assessed      OOD      general task      performance      using      the      MMLU      (Hendrycks et      al.,      2020),      GPQA      (Rein      et      al.,      2023),      HumanEval (Chen      et      al.,      2021),      and      MATH      (Hendrycks      et      al., 2021)      datasets."
            },
            {
              "id": 78,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Our      experimental      framework      com- prises      four      configurations      to      explore      the      impact      of model      averaging      and      training      with      multiple      reason- future      works. | ing      trajectories."
            },
            {
              "id": 79,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "The      configurations      are:      1)      full       implementation      with      model      averaging      and      mul- tiple      trajectories      (MA+multiple),      2)      model      aver- aging      with      a      single      trajectory      for      each      instruc- tion      (MA+single),      3)      multiple      trajectories      without model      averaging      (multiple),      and      4)      a      single      trajec- tory      without      model      averaging      (single)."
            },
            {
              "id": 80,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "We      refer the      readers      to      Appendix      A      for      more      details      about the      experiment. | The      results,      as      detailed      in      Table      1,      reveal      that the      THOUGHT-LIKE-PRO      framework      significantly enhances      reasoning      capabilities      through      continu- ous      training      on      the      Llama3-8B-Instruct      model."
            },
            {
              "id": 81,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "By incorporating      multiple      reasoning      trajectories,      this approach      leads      to      superior      outcomes      compared      to training      with      a      single      trajectory."
            },
            {
              "id": 82,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      the application      of      the      model      averaging      technique      has proven      effective      in      exploiting      the      trade-off      between specialty      and      generality,      addressing      the      issue      of      CF, and      yielding      performance      on      OOD      generalization tasks      that      are      not      included      in      the      continual      learn- ing."
            },
            {
              "id": 83,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "The      results      show      that      the      OOD      performance is      comparable      to      Llama3-8B-Instruct      itself      and      sig- nificantly      exceeds      that      of      methods      not      employing model      averaging. See      Appendix      B      for      a      compre- hensive      discussion      of      the      experimental      results."
            },
            {
              "id": 84,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "| 4      Conclusion In      this      paper,      we      introduce      THOUGHT-LIKE-PRO, a      framework      designed      to      enhance      the      logical      rea- soning      of      LLMs      by      imitating      Prolog-based      strictly logical      reasoning      trajectories      in      a      self-driven      man- ner."
            },
            {
              "id": 85,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "The      design      is      simple,      straightforward,      and effective,      ensuring      ease      of      use      in      industrial      appli- cations. Our      initial      findings      show      improved      task performance      on      both      specialized      reasoning      and      gen- eral      benchmarks."
            },
            {
              "id": 86,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "This      foundational      framework will      be      further      developed      and      extensively      evaluated across      various      tasks      to      refine      its      methodology      in 5      Limitations\n | Our      comparison      of      Llama3-8B-Instruct      and THOUGHT-LIKE-PRO      is      constrained      to      moderate- scale      language      modeling      tasks      due      to      limited      com- putational      resources."
            },
            {
              "id": 87,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      to      comprehen- sively      evaluate      and      better      understand      the      perfor- mance      potential      of      THOUGHT-LIKE-PRO,      it      may be      beneficial      to      explore      the      generation      of      multiple reasoning      paths      for      more      challenging      datasets."
            },
            {
              "id": 88,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "Intu- itively,      while      the      complexity      of      reasoning      paths      for more      complex      problems      increases      exponentially, the      difficulty      of      describing      these      problems      in      code only      increases      linearly."
            },
            {
              "id": 89,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Additionally,      we      did      not explore      the      performance      of      models      under      differ- ent      a      values      when      applying      the      model      averaging technique,      nor      did      we      balance      the      performance      of the      models      on      specialized      versus      generalized      tasks. | These      considerations      are      scenario-specific      and      left for      future      research."
            },
            {
              "id": 90,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "| References\n |       Josh      Achiam,      Steven      Adler,      Sandhini      Agarwal,      Lama       Ahmad,      Ilge      Akkaya,      Florencia      Leoni      Aleman,       Diogo      Almeida,      Janko      Altenschmidt,      Sam      Altman,       Shyamal      Anadkat,      et      al. 2023. Gpt-4      technical      report. |       arXiv      preprint      arXiv:2303.08774. | AI@      Meta. 2024. Llama      3      model      card."
            },
            {
              "id": 91,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "|       Jacob      Andreas,      Marcus      Rohrbach,      Trevor      Darrell,      and       Dan      Klein. 2016. Neural      module      networks. In      2016       IEEE      Conference      on      Computer      Vision      and      Pattern       Recognition      (CVPR),      pages      39-48."
            },
            {
              "id": 92,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "|       Maciej      Besta,      Nils      Blach,      Ales      Kubicek,      Robert      Gersten-       berger,      Michal      Podstawski,      Lukas      Gianinazzi,      Joanna       Gajda,      Tomasz      Lehmann,      Hubert      Niewiadomski,      Pi-       otr      Nyczyk,      et      al. 2024. Graph      of      thoughts:      Solving       elaborate      problems      with      large      language      models."
            },
            {
              "id": 93,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "In       Proceedings      of      the      AAAI      Conference      on      Artificial       Intelligence,      volume      38,      pages      17682-17690. | Kenneth      A      Bowen. 1979. Prolog. In      Proceedings      of      the       1979      annual      conference,      pages      14-23."
            },
            {
              "id": 94,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "|       Stephen      Casper,      Xander      Davies,      Claudia      Shi,       Thomas      Krendl      Gilbert,      Jérémy      Scheurer,      Javier       Rando,      Rachel      Freedman,      Tomasz      Korbak,      David       Lindner,      Pedro      Freire,      et      al. 2023. Open      problems       and      fundamental      limitations      of      reinforcement       learning      from      human      feedback. arXiv      preprint       arXiv:2307.15217."
            },
            {
              "id": 95,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "|       Mark      Chen,      Jerry      Tworek,      Heewoo      Jun,      Qiming       Yuan,      Henrique      Ponde      de      Oliveira      Pinto,      Jared      Ka-       plan,      Harri      Edwards,      Yuri      Burda,      Nicholas      Joseph,       Greg      Brockman,      et      al. 2021. Evaluating      large       language      models      trained      on      code. arXiv      preprint       arXiv:2107.03374."
            },
            {
              "id": 96,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "|       Xiaoliang      Chen,      Liangbin      Li,      Le      Chang,      Yunhe      Huang,       Yuxuan      Zhao,      Yuxiao      Zhang,      and      Dinuo      Li. 2023. Challenges      and      contributing      factors      in      the      utiliza-       tion      of      large      language      models      (IIms). arXiv      preprint       arXiv:2310.13343."
            },
            {
              "id": 97,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "|       Karl      Cobbe,      Vineet      Kosaraju,      Mohammad      Bavarian,       Mark      Chen,      Heewoo      Jun,      Lukasz      Kaiser,      Matthias       Plappert,      Jerry      Tworek,      Jacob      Hilton,      Reiichiro       Nakano,      et      al. 2021. Training      verifiers      to      solve      math       word      problems. arXiv      preprint      arXiv:2110.14168. |       Antonia      Creswell,      Murray      Shanahan,      and      Irina      Higgins. 2023."
            },
            {
              "id": 98,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Selection-inference:      Exploiting      large      language       models      for      interpretable      logical      reasoning. In      The       Eleventh      International      Conference      on      Learning      Rep- resentations. |       Guanting      Dong,      Hongyi      Yuan,      Keming      Lu,      Cheng-       peng      Li,      Mingfeng      Xue,      Dayiheng      Liu,      Wei      Wang,       Zheng      Yuan,      Chang      Zhou,      and      Jingren      Zhou. 2023."
            },
            {
              "id": 99,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "How      abilities      in      large      language      models      are      affected       by      supervised      fine-tuning      data      composition. arXiv       preprint      arXiv:2310.05492. |       Qingxiu      Dong,      Lei      Li,      Damai      Dai,      Ce      Zheng,      Zhiy-       ong      Wu,      Baobao      Chang,      Xu      Sun,      Jingjing      Xu,      and       Zhifang      Sui. 2022. A      survey      on      in-context      learning."
            },
            {
              "id": 100,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "|       arXiv      preprint      arXiv:2301.00234. |       Beliz      Gunel,      Jingfei      Du,      Alexis      Conneau,      and      Ves      Stoy-       anov. 2020. Supervised      contrastive      learning      for      pre-       trained      language      model      fine-tuning. arXiv      preprint       arXiv:2011.01403."
            },
            {
              "id": 101,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "|       Dan      Hendrycks,      Collin      Burns,      Steven      Basart,      Andy      Zou,       Mantas      Mazeika,      Dawn      Song,      and      Jacob      Steinhardt. |       2020. Measuring      massive      multitask      language      under-       standing. arXiv      preprint      arXiv:2009.03300."
            },
            {
              "id": 102,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "|       Dan      Hendrycks,      Collin      Burns,      Saurav      Kadavath,      Akul       Arora,      Steven      Basart,      Eric      Tang,      Dawn      Song,      and      Ja-       cob      Steinhardt. 2021. Measuring      mathematical      prob-       lem      solving      with      the      math      dataset. arXiv      preprint       arXiv:2103.03874. |       Drew      Hudson      and      Christopher      D      Manning. 2019."
            },
            {
              "id": 103,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Learn-       ing      by      abstraction:      The      neural      state      machine. In      Ad-       vances      in      Neural      Information      Processing      Systems,       volume      32. Curran      Associates,      Inc. Dave      Hulbert. 2023. Using      tree-of-thought      prompt-       ing      to      boost      chatgpt’s      reasoning. https://github. |       com/dave1010/tree-of-thought-prompting."
            },
            {
              "id": 104,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "|       Ahmed      Hussein,      Mohamed      Medhat      Gaber,      Eyad      Elyan,       and      Chrisina      Jayne. 2017. Imitation      learning:      A      sur-       vey      of      learning      methods. ACM      Computing      Surveys       (CSUR),      50(2):1-35. |       Mehran      Kazemi,      Najoung      Kim,      Deepti      Bhatia,      Xin       Xu,      and      Deepak      Ramachandran. 2023."
            },
            {
              "id": 105,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "LAMBADA:\n |       Backward      chaining      for      automated      reasoning      in      nat-       ural      language. In      Proceedings      of      the      61st      Annual       Meeting      of      the      Association      for      Computational      Lin-       guistics      (Volume      1:      Long      Papers),      pages      6547-6568,\n |       Toronto,      Canada. Association      for      Computational      Lin-       guistics."
            },
            {
              "id": 106,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "Takeshi      Kojima,      Shixiang      Shane      Gu,      Machel      Reid,      Yu-       taka      Matsuo,      and      Yusuke      Iwasawa. 2022. Large      lan-       guage      models      are      zero-shot      reasoners. Advances      in       neural      information      processing      systems,      35:22199-       22213. | Takeshi      Kojima,      Shixiang      Shane      Gu,      Machel      Reid,      Yu-  \n \n  taka      Matsuo,      and      Yusuke      Iwasawa. 2022."
            },
            {
              "id": 107,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Large      lan-  \n \n  guage      models      are      zero-shot      reasoners. Advances      in  \n \n  neural      information      processing      systems,      35:22199-  \n \n  22213. Abulhair      Saparov      and      He      He. 2022. Language      models  \n \n  are      greedy      reasoners:   \n \nA      systematic      formal      analysis      of  \n \n  chain-of-thought. arXiv      preprint      arXiv:2210.01240. Abulhair      Saparov      and      He      He. 2023."
            },
            {
              "id": 108,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Language      models  \n \n  are      greedy      reasoners:   \n \nA      systematic      formal      analysis  \n \n  of      chain-of-thought. In      The      Eleventh      International  \n \n  Conference      on      Learning      Representations. |       Yong      Lin,      Lu      Tan,      Hangyu      Lin,      Zeming      Zheng,      Renjie       Pi,      Jipeng      Zhang,      Shizhe      Diao,      Haoxiang      Wang,      Han       Zhao,      Yuan      Yao,      et      al. 2023."
            },
            {
              "id": 109,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Speciality      vs      gener-       ality:      An      empirical      study      on      catastrophic      forgetting       in      fine-tuning      foundation      models. arXiv      preprint       arXiv:2309.06256. | Haizhou      Shi,      Zihao      Xu,      Hengyi      Wang,      Weiyi      Qin,  \n \n  Wenyuan      Wang,      Yibin      Wang,      and      Hao      Wang. 2024. Continual      learning      of      large      language      models:   \n \nA      com-  \n \n  prehensive      survey."
            },
            {
              "id": 110,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:2404.16789. |       Jieyi      Long. 2023. Large      language      model      guided      tree-of-       thought. arXiv      preprint      arXiv:2305.08291. | Oyvind      Tafjord,      Bhavana      Dalvi      Mishra,      and      Peter  \n \n  Clark. 2020. Proofwriter:      Generating      implications,  \n \n  proofs,      and      abductive      statements      over      natural      lan-  \n \n  guage. arXiv      preprint      arXiv:2012.13048."
            },
            {
              "id": 111,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "|       Qing      Lyu,      Shreya      Havaldar,      Adam      Stein,      Li      Zhang,       Delip      Rao,      Eric      Wong,      Marianna      Apidianaki,      and       Chris      Callison-Burch. 2023. Faithful      chain-of-       thought      reasoning. Preprint,      arXiv:2301.13379. | Jason      Wei,      Xuezhi      Wang,      Dale      Schuurmans,      Maarten  \n \n  Bosma,      Fei      Xia,      Ed      Chi,      Quoc      V      Le,      Denny      Zhou,  \n \n  et      al."
            },
            {
              "id": 112,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "2022. Chain-of-thought      prompting      elicits      rea-  \n \n  soning      in      large      language      models. Advances      in      neural  \n \n  information      processing      systems,      35:24824—24837. |       Arvind      Neelakantan,      Quoc      V. Le,      Martin      Abadi,      An-       drew      McCallum,      and      Dario      Amodei. 2017. Learning       a      natural      language      interface      with      neural      programmer."
            },
            {
              "id": 113,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "In      International      Conference      on      Learning      Representa- | Jan      Wielemaker,      Tom      Schrijvers,      Markus      Triska,      and       Torbjérn      Lager. 2012. Swi-prolog. Theory      and      Prac-  \n \n  tice      of      Logic      Programming,      12(1-2):67-96. |       tions. NVIDIA      Corporation. 2023. Nvidia      a800. https:      //www.nvidia.com/en-us/geforce/       design-visualization/a800/. Accessed: | NVIDIA      Corporation. 2023."
            },
            {
              "id": 114,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "Nvidia      a800. https:      //www.nvidia.com/en-us/geforce/  \n \n  design-visualization/a800/. Accessed:  \n \n  What      Makes      In-Context      Learning      Work. Rethinking  \n \n  the      role      of      demonstrations:      What      makes      in-context  \n \n  learning      work? |       2024-04-30. Takayuki      Osa,      Joni      Pajarinen,      Gerhard      Neumann,      J      An-       drew      Bagnell,      Pieter      Abbeel,      Jan      Peters,      et      al. 2018."
            },
            {
              "id": 115,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Foundations      and      Trends®      in      Robotics,      7(1-2):1-179. | Takayuki      Osa,      Joni      Pajarinen,      Gerhard      Neumann,   \n \nJ      An-  \n \n  drew      Bagnell,      Pieter      Abbeel,      Jan      Peters,      et      al. 2018. Foundations      and      Trends®      in      Robotics,      7(1-2):1-179. Sean      Wu,      Michael      Koo,      Lesley      Blum,      Andy      Black,      Liyo  \n \n  Kao,      Fabien      Scalzo,      and      Ira      Kurtz. 2023."
            },
            {
              "id": 116,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "A      compar-  \n \n  ative      study      of      open-source      large      language      models,  \n \n  gpt-4      and      claude      2:      Multiple-choice      test      taking      in  \n \n  nephrology. arXiv      preprint      arXiv:2308.04709. |       An      algorithmic      perspective      on      imitation      learning. Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023a."
            },
            {
              "id": 117,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Logic-lm:      Em-       powering      large      language      models      with      symbolic       solvers      for      faithful      logical      reasoning. Preprint,       arXiv:2305.12295. | Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023a. Logic-lm:      Em-  \n \n  powering      large      language      models      with      symbolic  \n \n  solvers      for      faithful      logical      reasoning."
            },
            {
              "id": 118,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "Preprint,  \n \n  arXiv:2305.12295. Sen      Yang,      Xin      Li,      Leyang      Cui,      Lidong      Bing,      and       Wai      Lam. 2023. Neuro-symbolic      integration      brings  \n \n  causal      and      reliable      reasoning      proofs. arXiv      preprint  \n \n  arXiv:2311.09802. Shunyu      Yao,      Dian      Yu,      Jeffrey      Zhao,      Izhak      Shafran,  \n \n  Tom      Griffiths,      Yuan      Cao,      and      Karthik      Narasimhan."
            },
            {
              "id": 119,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "|       Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023b. Logic-lm:      Empow-       ering      large      language      models      with      symbolic      solvers       for      faithful      logical      reasoning. arXiv      preprint       arXiv:2305.12295. | 2024. Tree      of      thoughts:      Deliberate      problem      solving  \n \n  with      large      language      models."
            },
            {
              "id": 120,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "Advances      in      Neural  \n \n  Information      Processing      Systems,      36. Xi      Ye      and      Greg      Durrett. 2022. The      unreliability      of      ex-  \n \n  planations      in      few-shot      prompting      for      textual      reason-  \n \n  ing."
            },
            {
              "id": 121,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "In      Advances      in      Neural      Information      Processing\n |       David      Rein,      Betty      Li      Hou,      Asa      Cooper      Stickland,      Jack-       son      Petty,      Richard      Yuanzhe      Pang,      Julien      Dirani,      Ju-       lian      Michael,      and      Samuel      R      Bowman. 2023. Gpqa:      A       graduate-level      google-proof      q&a      benchmark. arXiv       preprint      arXiv:2311.12022. |       Systems."
            },
            {
              "id": 122,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "Yuexiang      Zhai,      Shengbang      Tong,      Xiao      Li,      Mu      Cai,      Qing       Qu,      Yong      Jae      Lee,      and      Yi      Ma. 2023. Investigating      the       catastrophic      forgetting      in      multimodal      large      language       models. arXiv      preprint      arXiv:2309. 10313."
            },
            {
              "id": 123,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "|       Danilo      Neves      Ribeiro,      Shen      Wang,      Xiaofei      Ma,       Henghui      Zhu,      Rui      Dong,      Deguang      Kong,      Juli-       ette      Burger,      Anjelica      Ramos,      zhiheng      huang,       William      Yang      Wang,      George      Karypis,      Bing      Xiang,       and      Dan      Roth. 2023. STREET:      A      MULTI-TASK       STRUCTURED      REASONING      AND      EXPLANA-       TION      BENCHMARK."
            },
            {
              "id": 124,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "In      The      Eleventh      Interna-       tional      Conference      on      Learning      Representations. | Yifan      Zhang,      Jingqin      Yang,      Yang      Yuan,      and      Andrew  \n \n  Chi-Chih      Yao. 2024. Cumulative      reasoning      with  \n \n  large      language      models. Preprint,      arXiv:2308.04371. Zhuosheng      Zhang,      Aston      Zhang,      Mu      Li,      and      Alex  \n \n  Smola. 2022."
            },
            {
              "id": 125,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "Automatic      chain      of      thought      prompt-  \n \n  ing      in      large      language      models. arXiv      preprint  \n \n  arXiv:2210.03493. Wayne      Xin      Zhao,      Kun      Zhou,      Junyi      Li,      Tianyi      Tang,  \n \n  Xiaolei      Wang,      Yupeng      Hou,      Yinggian      Min,      Beichen  \n \n  Zhang,      Junjie      Zhang,      Zican      Dong,      et      al. 2023. A       survey      of      large      language      models."
            },
            {
              "id": 126,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint  \n \n  arXiv:2303.18223. Zixuan      Zhou,      Xuefei      Ning,      Ke      Hong,      Tianyu      Fu,      Ji-  \n \n  aming      Xu,      Shiyao      Li,      Yuming      Lou,      Luning      Wang,  \n \n  Zhihang      Yuan,      Xiuhong      Li,      et      al. 2024. A      survey      on  \n \n  efficient      inference      for      large      language      models. arXiv  \n \n  preprint      arXiv:2404. 14294."
            }
          ],
          "content": ""
        },
        {
          "id": 127,
          "title": "A      Experimental      Details",
          "type": "section",
          "children": [
            {
              "id": 128,
              "title": "A      Experimental      Details - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A      Experimental      Details\nIn      this      subsection,      we      will      provide      detailed      infor- mation      on      the      equipment,      models,      datasets,      fine- tuning      methods,      and      hyperparameter      settings      used in      our      experiment."
            },
            {
              "id": 129,
              "title": "A      Experimental      Details - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "A.1_      Baseline,      Model,      and      Equipment Throughout      the      entire      process,      we   \n \n_      utilized two      A800-80GB      (NVIDIA      Corporation,      2023) GPUs      for      inference,      fine-tuning,      and      evaluation tasks."
            },
            {
              "id": 130,
              "title": "A      Experimental      Details - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "We      applied      our      THOUGHT-LIKE-PRO framework      by      continually      fine-tuning      the Llama3-8B-Instruct      model      which      can      be      accessed in      https:      //huggingface.co/meta-llama/ Meta-Llama-3-8B-Instruct. Our      baseline      was      established      by      assessing      the      un- trained      Llama3-8B-Instruct      model’s      performance on      various      datasets."
            },
            {
              "id": 131,
              "title": "A      Experimental      Details - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      initial      evaluation      gave      us a\n \n   benchmark      to      demonstrate      the      enhancements      our framework      could      provide. Additionally,      we      imple- mented      the      CARING      (Yang      et      al.,      2023)      method to      generate      Prolog      code      with      Llama3-8B-Instruct, assessing      the      correctness      of      solutions      this      code      pro- duced      to      problems."
            }
          ],
          "content": ""
        },
        {
          "id": 132,
          "title": "A.2.      Datasets",
          "type": "section",
          "children": [
            {
              "id": 133,
              "title": "A.2.      Datasets - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A.2. Datasets\nWe      evaluated      THOUGHT-LIKE-PRO      across      seven prominent      LLM      benchmark      datasets:      two      fo- cused      on      mathematical      reasoning      (GSM8K      and MATH),      two      on      knowledge-based      question      answer- ing      (MMLU      and      GPQA),      two      on      logical      reasoning (ProofWriter      and      PrOntoQA),      and      one      on      code      gen- eration      (HumanEval)."
            }
          ],
          "content": ""
        },
        {
          "id": 134,
          "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com-",
          "type": "section",
          "children": [
            {
              "id": 135,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com-\nprises      8,500      high-quality,      linguistically      diverse grade      school      math      word      problems      created      by      hu- man      experts."
            },
            {
              "id": 136,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      randomly      selected      2,000      entries from      this      dataset      to      generate      reasoning      trajectories and      used      the      balance      to      gauge      the      effectiveness      of our      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 137,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Given      that the      number      of      reasoning      trajectories      generated      by the      Prolog      engine      is      variable,      we      capped      the      trajec- tories      for      each      problem      at      10      to      mitigate      data      dis- tribution      bias. Consequently,      we      produced      20,000 pieces      of      training      data      for      the      LLM."
            },
            {
              "id": 138,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "MATH:      MATH      (Hendrycks      et      al.,      2021)      en- compasses   \n \na      collection      of      12,500      challenging competition-level      mathematics      problems,      each accompanied      by      detailed      step-by-step      solutions."
            },
            {
              "id": 139,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "These      solutions      facilitate      training      models      to      gen- most      demanding      subset      (Pan      et      al.,      2023b),      “Fic-  \n \n  tional      Characters”,      with   \n \na      depth      level      of      5,      com- erate      complete      derivations      and      explanations."
            },
            {
              "id": 140,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  leveraged      this      difficult      dataset      to      assess      the      OOD performance      of      our      THOUGHT-LIKE-PRO      frame- work,      noting      that      the      LLM      was      not      previously trained      on      it."
            },
            {
              "id": 141,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "MMLU:      MMLU      (Hendrycks      et      al.,      2020)      bench- mark      is      designed      to      gauge      the      knowledge      ac- quired      during      pretraining      by      assessing      models in      exclusively      zero-shot      and      few-shot      scenarios, which      closely      aligns      with      methods      used      to      evalu- ate      human      capabilities."
            },
            {
              "id": 142,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "It      encompasses      57      sub- jects,      spanning      STEM,      the      humanities,      and      the social      sciences,      among      others. Given      its      wide content      range      and      varying      difficulty,      we      utilize the      entire      dataset      to      evaluate      the      THOUGHT-LIKE- PRO      framework’s      generalization      abilities."
            },
            {
              "id": 143,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Notably, within      the      THOUGHT-LIKE-PRO      framework,      the LLM      does      not      have      exposure      to      MMLU      during      the training      phase. GPQA:      GPQA      (Rein      et      al.,      2023)      represents   \n \na formidable      dataset      aimed      at      testing      the      capabilities of      LLMs      alongside      scalable      oversight      mechanisms."
            },
            {
              "id": 144,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "The      dataset      comprises      448      multiple-choice      ques- tions      crafted      by      domain      experts      in      disciplines      such as      biology,      physics,      and      chemistry. We      employ this      complete      set      to      determine      the      generalization capacity      of      the      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 145,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "ProofWriter:      ProofWriter      (Tafjord      et      al.,      2020) is   \n \na      widely      utilized      logical      reasoning      dataset      com- prising      many      small-scale      knowledge      bases      ex- pressed      in      English,      each      containing      facts      and      rules."
            },
            {
              "id": 146,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Each      knowledge      base      is      paired      with   \n \na      set      of      ques- tions,      also      in      English,      which      can      be      definitively proven      as      true      or      false      via      proofs      of      varying      depths, or      the      answer      may      be      categorized      as      “unknown” under      an      open-world      assumption      (OWA)      or      pre- sumed      negative      under   \n \na      closed-world      assumption (CWA)."
            },
            {
              "id": 147,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "This      dataset      contains      subsets      of      varying difficulty,      we      have      selected      the      most      challenging subset      within      the      OWA      setting,      which      includes      482 knowledge      bases      and      10,190      questions. We      initially randomly      sampled      100      knowledge      bases      and      their corresponding      questions      to      create      reasoning      trajec- tories."
            },
            {
              "id": 148,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "We      restricted      the      number      of      allowed      reason- ing      trajectories      per      question      to      five. Ultimately,      we utilized      all      remaining      data      to      evaluate      the      perfor- mance      of      our      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 149,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "PrOntoQA:      PrOntoQA      (Saparov      and      He,      2022) is   \n \na      synthetic      question-and-answer      dataset      designed to      test      the      logical      reasoning      capabilities      of      LLMs. Each      instance      is      structured      to      verify      the      validity      of a\n \n   statement      within   \n \na      specific      context. We      chose      the prising      500      statement-context      pairs."
            },
            {
              "id": 150,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "We      randomly selected      100      statement-context      pairs      to      generate reasoning      trajectories      and      employed      the      remain- ing      data      for      assessing      the      THOUGHT-LIKE-PRO framework’s      capabilities. The      maximum      number of      reasoning      trajectories      per      question      was      set      to      5."
            },
            {
              "id": 151,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "HumanEval:      HumanEval      (Chen      et      al.,      2021) comprises      164      unique      programming      problems designed      to      evaluate      language      comprehension, algorithmic      proficiency,      and      elementary      mathe- matics,      some      of      which      are      akin      to      basic      soft- ware      interview      questions."
            },
            {
              "id": 152,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "This      dataset      is      em- ployed      to      assess      the      functional      correctness      of      pro- grams      synthesized      from      documentation      strings."
            },
            {
              "id": 153,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Given      that      HumanEval      is      unrelated      to      the      two      do- mains—mathematical      reasoning      and      logical      rea- soning—used      for      training      the      LLM,      we      employ      the entire      dataset      to      assess      the      THOUGHT-LIKE-PRO framework’s      performance      on      general      tasks      follow- ing      specialized      training."
            },
            {
              "id": 154,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "A.3      Fine-Tuning      Method      and Hyperparameter      Settings We      perform      typical      continual      supervised      fine- tuning      based      on      the      checkpoint      of      Llama3-8B- Instruct. Our      training      framework      follows      the      im- plementation      of      https:      //github.com/hiyouga/ LLaMA-Factory      using      the      LLaMA-Factory."
            },
            {
              "id": 155,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "we employed      the      Adam      optimizer      in      the      training      pro- cess      and      selected   \n \na      consistent      learning      rate      of      le—6 for   \n \n3      epochs      of      training. To      ensure      comparability between      the      single      trajectory      and      multiple      trajec- tory      datasets,      despite      their      differing      data      volumes, we      have      adjusted      the      training      regimen."
            },
            {
              "id": 156,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Specifi- cally,      the      model      trained      on      the      single      trajectory dataset      undergoes      an      equivalent      number      of      train- ing      steps      as      the      model      trained      on      the      multiple      tra- jectory      dataset      for   \n \n3      epochs."
            },
            {
              "id": 157,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "During      model      in- ference      and      evaluation,      we      configured      the      sam- pling      settings      with   \n \na      temperature      of      0.6      and   \n \na top_p      value      of      0.9,      based      on      the      default      recom- mended      parameters      from      https:      //huggingface. co/blog/1lama3."
            },
            {
              "id": 158,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "For      model      averaging,      we      imple- ment   \n \na   \n \n=      0.5      for   \n \na      balanced      averaging      between the      base      model      and      the      fine-tuned      model."
            }
          ],
          "content": ""
        },
        {
          "id": 159,
          "title": "B_      Analysis      of      Experimental      Results",
          "type": "section",
          "children": [
            {
              "id": 160,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "B_      Analysis      of      Experimental      Results\nIn      our      study,      we      assessed      the      performance      of      both the      baseline      model,      Llama3-8B-Instruct,      and      our PrOntoQA. However,      the      improvements      in      algo-  \n \n  rithmic      reasoning      tasks      are      comparatively      modest."
            },
            {
              "id": 161,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "proposed      framework,      which      was      tested      under      four  \n \n  distinct      configurations:      1)      Full      implementation      fea- turing      both      model      averaging      and      multiple      trajecto- ries      (MA+multiple),      2)      Model      averaging      applied to   \n \na      single      trajectory      per      instruction      (MA+single), 3)      Multiple      trajectories      without      model      averaging\n(multiple),      and      4)   \n \nA      single      trajectory      without      model averaging      (single)."
            },
            {
              "id": 162,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "This      comparison      allows      us      to discern      the      contributions      of      key      components      within our      framework,      particularly      the      impact      of      model averaging      and      the      learning      of      multiple      reasoning trajectories      for      the      same      instruction. Additionally, we      incorporated      the      CARING      method      (Yang      et      al., 2023)      within      our      experimental      setup."
            },
            {
              "id": 163,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      was utilized      to      evaluate      the      final      reasoning      accuracy, relying      solely      on      Prolog      engine      inferences,      without the      requirement      for      training      LLMs      or      using      them to      derive      final      answers. All      experiment      results      are      presented      in      Table      1. We      report      the      CARING      results      across      three      reason- ing      tasks."
            },
            {
              "id": 164,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "The      Prolog      engine      delivered      completely accurate      reasoning      outputs      for      the      ProofWriter and      PrOntoQA      tasks      and      achieved      an      accuracy      of 98.19%      for      the      GSM8K      task."
            },
            {
              "id": 165,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "The      slightly      lower accuracy      in      GSM8K      can      be      attributed      to      errors in      the      translation      of      facts      or      rules      and      formatting- related      issues,      although      the      reasoning      trajectories are      correct."
            },
            {
              "id": 166,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Consequently,      we      posit      that      the      per- formance      of      CARING      represents      the      practical      up- per      limit      for      the      proposed      THOUGHT-LIKE-PRO framework. Across      all      tasks,      our      framework,      con- figured      in      four      distinct      ways,      demonstrated      sub- stantial      performance      improvements      over      the      base- line      model."
            },
            {
              "id": 167,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Notably,      the      configuration      employing the      ’multiple’      method      without      model      averaging recorded      the      highest      performance,      consistent      with our      expectations,      as      performing      domain-specific fine-tuning      and      forgoing      model      averaging      tend      to enhance      domain-specific      expertise."
            },
            {
              "id": 168,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "In      the      GSM8K task,      the      Llama3-8B-Instruct      model      achieved      an accuracy      rate      of      79.6%. In      contrast,      our      frame- work      marked   \n \na      significant      improvement,      attaining an      accuracy      of      87.81%."
            },
            {
              "id": 169,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "This      improvement      was particularly      pronounced      in      datasets      requiring      log- ical      reasoning,      especially      in      the      ProofWriter      and PrOntoQA      datasets,      where      the      model      utilizing      mul- tiple      reasoning      paths      achieved      98.19%      and      100% accuracy,      respectively."
            },
            {
              "id": 170,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "The      experimental      results      for      reasoning      tasks      also suggest      that      imitating      strictly      logical      reasoning      tra- jectories      can      significantly      enhance      performance      in logical      reasoning      tasks,      such      as      ProofWriter      and These      findings      not      only      confirm      the      efficacy      of imitating      strictly      correct      logical      reasoning      trajecto- ries      in      aligning      the      reasoning      capabilities      of      LLMs, but      also      suggest      that      LLMs      may      be      better      suited to      modeling      natural      language      problems      using      the relatively      straightforward      Prolog      language,      rather than      translating      these      problems      into      more      complex mainstream      programming      languages      like      Python."
            },
            {
              "id": 171,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "We      can      assess      the      performance      differences      be- tween      the      ‘single’      and      ‘multiple’      training      ap- proaches      to      validate      the      effectiveness      of      utilizing multiple      reasoning      paths      in      training."
            },
            {
              "id": 172,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Across      all three      reasoning      tasks,      it      is      evident      that      training      with a\n \n   single      reasoning      path      can      enhance      performance relative      to      baseline      methods."
            },
            {
              "id": 173,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "However,      there      ex- ists   \n \na      significant      performance      disparity      between      the ‘multiple’      and      ‘single’      approaches,      underscoring the      importance      of      training      with      multiple      reasoning trajectories      for      each      instruction. This      performance gap      may      be      attributed      to      the      inherent      multi-modal nature      of      LLMs."
            },
            {
              "id": 174,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Training      on      multiple      correct      tra- jectories      toward      the      same      target      could      promote robust      learning      of      multi-modal      distributions      and significantly      improve      the      robustness      of      LLM’s      rea- soning."
            }
          ],
          "content": ""
        },
        {
          "id": 175,
          "title": "To      evaluate      the      performance      of      THOUGHT-LIKE-",
          "type": "section",
          "children": [
            {
              "id": 176,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "To      evaluate      the      performance      of      THOUGHT-LIKE-\nPRO      on      general      OOD      tasks,      we      selected      four      bench- marks      commonly      employed      to      assess      the      com- mon      knowledge      and      abilities      of      LLMs:      MMLU (Hendrycks      et      al.,      2020),      GPQA      (Rein      et      al., 2023),      HumanEval      (Chen      et      al.,      2021),      and      MATH (Hendrycks      et      al.,      2021)."
            },
            {
              "id": 177,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "These      benchmarks      were chosen      to      measure      the      impacts      of      continual      fine- tuning      on      three      distinct      reasoning      tasks. Our      obser- vations      indicate      that      Llama3-8B-Instruct      achieves almost      the      highest      performance      across      these      tasks, and      exhibits      signs      of      catastrophic      forgetting      of      con- tinual      training."
            },
            {
              "id": 178,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "However,      the      implementation      of model      averaging      in      THOUGHT-LIKE-PRO      effec- tively      navigates      the      trade-off      between      specializa- tion      and      generalization,      significantly      enhancing the      OOD      performance."
            },
            {
              "id": 179,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      results      show      results of      67.9%      on      MMLU      and      33.8%      on      GPQA      with MA+multiple,      compared      to      domain-specific      train- ing,      with      only   \n \na      slight      decrease      in      performance on      the      reasoning      tasks."
            },
            {
              "id": 180,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Thus,      model      averaging serves      as   \n \na      viable      strategy      to      mitigate      catastrophic forgetting,      enhancing      both      the      robustness      and      gen- eralizability      of      our      approach."
            },
            {
              "id": 181,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "While      we      observe   \n \na      decline      in      performance      on the      MMLU,      GPQA,      and      HumanEval      datasets,      the  \n \n  performance      on      the      MATH      dataset      intriguingly      re- mains      consistent      with      the      base      model."
            },
            {
              "id": 182,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "This      sta- bility      may      be      attributed      to      the      inherent      nature      of the      MATH      tasks,      which      are      graduate-level      prob- lems      requiring      arithmetic      and      logical      reasoning skills. These      skills      have      been      effectively      cultivated through      the      THOUGHT-LIKE-PRO      approach      ap- plied      within      the      GSM8K,      ProofWriter,      and      PrOn- toQA      datasets."
            },
            {
              "id": 183,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "This      approach      appears      to      success- fully      generalize      to      MATH      tasks      and      mitigate      the negative      impacts      of      catastrophic      forgetting. More- over,      these      results      suggest      that      the      THOUGHT- LIKE-PRO      strategy      possesses   \n \na      potential      broad      gen- eralization      capability      for      OOD      reasoning      tasks."
            },
            {
              "id": 184,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "C      Prompt      demo In      this      section,      we      present      the      few-shot      demonstra- tion      prompt      utilized."
            },
            {
              "id": 185,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "It      should      be      noted      that      due to      space      constraints,      all      prompts      are      displayed      in their      1-shot      condition,      with      the      black      text      denoting the      prompt      sent      to      the      LLM      and      the      red      text      indi- cating      the      model’s      response. For      more      demonstra- tions,      we      refer      the      readers      to      https:      //anonymous. 4open."
            },
            {
              "id": 186,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "science/r/Prolog_datasets-9875. Listing      1:      Construct   \n \na      prompt      prompt,.-,      to      guide      the LLM      to      generate      Prolog      code      contains      rules      7,      facts      F, and      targets   \n \n7      based      on      the      problem."
            },
            {
              "id": 187,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      assistant      who      xx  \n \n  produces      Prolog      codex*      to      solve  \n \n  problems. <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>\n \n \n  Could      you      please      help      me      write      Prolog  \n \n  code      to      solve      the      following  \n \n  arithmetic      reasoning      problem?"
            },
            {
              "id": 188,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "You  \n \n  should      use      consistent      variable      names  \n \n  for      coreferent      entities      or  \n \n  attributes      throughout      the      code. Start      by      coding      the      given      context  \n \n  after      the      \"/x      Context      */”      comment. Then      code      the      query      that      represents  \n \n  the      question      after      the      \"/x      Query      x/”  \n \n  comment."
            },
            {
              "id": 189,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 190,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 191,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  7x      Context      */ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 192,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  Eis   \n \n8   \n \nx      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 193,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is   \n \nH   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular),  \n \n  overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 194,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. 7*      Query      x/  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total). <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 195,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 196,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 197,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 198,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  /*x      Context      */  \n \n  %      facts  \n \n  sentences_per_minute      (6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536). %      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \nx      SessionMinutes."
            },
            {
              "id": 199,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n’       erased_sentences      (Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 200,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday)   \n \n,       total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      x*/  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences). <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>  \n \n  Excellent      work!"
            },
            {
              "id": 201,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race. sent-2:      They      have      one      week      to      run      30  \n \n  miles."
            },
            {
              "id": 202,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days. sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days?"
            },
            {
              "id": 203,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>assistant      <|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem. Here      is      the  \n \n  Prolog      code:\n \n \n  ~*~      prolog  \n \n  7x      Context      x*/  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg(2/3). jesse_day_four(10). mia_first_four_days_avg      (3)."
            },
            {
              "id": 204,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total(Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 205,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg      (DayAvg)   \n \n,       Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 206,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance);\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 207,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages   \n \n(      Average)."
            },
            {
              "id": 208,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "pro  \n \n  Listing      2:      Construct   \n \na      prompt      prompt’,      to      guide      the LLM      to      generate   \n \na      natural      language      CoT-like      reasoning logic      chain      based      on      the      problem,      Prolog      code,      and reasoning      tree."
            },
            {
              "id": 209,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      and      smart      assistant  \n \n  that      helps      people      solve      problems. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>\n \n \n \nI      need      assistance      in      translating   \n \na       reasoning      tree      generated      by   \n \na      Prolog  \n \n  engine      into   \n \na      natural      language  \n \n  description."
            },
            {
              "id": 210,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "To      facilitate      this,   \n \nI       am      providing      the      original      problem,  \n \n  the      relevant      Prolog      code,      and      the  \n \n  reasoning      tree      itself. Please      review  \n \n  these      carefully      and      provide   \n \na       fluent      and      accurate      narrative      of      the  \n \n  reasoning      process. Thanks      for      your  \n \n  help!"
            },
            {
              "id": 211,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "xxkInstructions      Startx*  \n \n  Translate      the      provided      reasoning      tree  \n \n  into   \n \na      clear      and      logical      natural  \n \n  language      explanation. Many      thanks      for      your      help! I      am      looking  \n \n  forward      to      your      response! *xkInstructions      End**\nHere      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour."
            },
            {
              "id": 212,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage. sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make?"
            },
            {
              "id": 213,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog_code:\n/*      Context      x*/ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 214,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  E      is   \n \n8   \n \n*      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 215,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is   \n \nH   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular), overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 216,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. /*      Query      */  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total)."
            },
            {
              "id": 217,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog      reasoning      tree:\n \n \n  =>(=>(,      (=>(,      (=>(,      (=>      C(builtin(true),      wage  \n \n  (18.0)),      =>Cbuiltin(is(144.0,      x*(8,  \n \n  18.0))),      is(144.0,      *(8,      18.0)))),  \n \n  regular_earning_for_day(144.0)),  \n \n  ,(=>(,      (=>(=>(builtin(is(2,      -(10,      8))  \n \n  ),      is(2,      -(1@,      8))),      overtime_hours  \n \n  (2)),      ,C=>Cbuiltin(,      (g(wage(18.0)),  \n \n  g(is(27.0,      *(1.5,      18.0))))),  \n \n  overtime_wage(27.0)),      =>(Cbuiltin(is  \n \n  (54.0,      *(2,      27.0))),      is(54.0,      *(2,  \n \n  27.0))))),      overtime_earning_for_day  \n \n  (54.0)),      =>(Cbuiltin(is(198.0,  \n \n  +(144.0,      54.0))),      i18(198.0,      +(144.0,  \n \n  54.0))))),      total_earning_for_day  \n \n  (198.0)),      =>Cbuiltin(is(990.0,      x*(5,  \n \n  198.0))),      18(990.0,      *(5,      198.0)))),  \n \n  total_earning_for_5_days(990.0)),  \n \n  solve      (990.0)   \n \n)       <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 218,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Tina      earns      $18.00      per      hour      according      to  \n \n  the      information      provided."
            },
            {
              "id": 219,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "She      has  \n \n  shifts      where,      if      she      works      more      than  \n \n  8      hours,      the      additional      hours      are  \n \n  considered      overtime. Overtime      pay      is  \n \n  calculated      at      one      and   \n \na      half      times  \n \n  her      regular      hourly      wage."
            },
            {
              "id": 220,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "On   \n \na      typical      day,      if      Tina      works      10      hours  \n \n  ,      this      includes   \n \n2      hours      of      overtime  \n \n  since      she      exceeds      the      8-hour      regular  \n \n  work      period. Her      regular      earnings  \n \n  for      working   \n \n8      hours   \n \na      day      at      $18.00  \n \n  per      hour      amounts      to      $144.00      per      day."
            },
            {
              "id": 221,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "For      the   \n \n2      hours      of      overtime,      since  \n \n  the      overtime      rate      is      $27.00      per      hour  \n \n  (1.5      times      her      regular      hourly      wage)  \n \n  ,      she      earns      $54.00      from      overtime  \n \n  work      per      day. Therefore,      her      total      earnings      for   \n \na       single      day,      combining      her      regular  \n \n  and      overtime      earnings,      are      $198.00."
            },
            {
              "id": 222,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Over      the      course      of   \n \n5      days,      working  \n \n  the      same      hours      daily,      Tina      makes   \n \na       total      of      $990.00,      factoring      in      all  \n \n  regular      pay      and      overtime      across      the  \n \n  five      days. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 223,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 224,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 225,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? Prolog      code:  \n \n  /*      Context      x*/  \n \n  %      facts  \n \n  sentences_per_minute(6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536)."
            },
            {
              "id": 226,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \n*      SessionMinutes."
            },
            {
              "id": 227,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n,       erased_sentences(Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 228,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday),  \n \n  total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      */  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences)."
            },
            {
              "id": 229,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(builtin(true),  \n \n  total_end_sentences      (536)),  \n \n  ,(=>(,      (=>(Cbuiltin(true),  \n \n  typing_sessions([20,      15,      18])),  \n \n  builtin(,      (g(maplist(sentences_typed,  \n \n  [20,      15,      18],      [120,      90,      108])),      ,Cg  \n \n  (sum_list([120,      90,      108],      318)),      ,(g  \n \n  (erased_sentences(40)),      g(is(278,  \n \n  ~(318,      40)))))))),  \n \n  total_sentences_typed_today      (278)),  \n \n  =>(builtin(is(258,      -(536,      278))),      is  \n \n  (258,      -(536,      278))))),  \n \n  start_sentences(258)),      solve(258))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 230,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Janice\\\\\\'s      typing      speed      is   \n \n6      sentences      per  \n \n  minute."
            },
            {
              "id": 231,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Today,      she      had      three  \n \n  separate      typing      sessions:      the      first  \n \n  lasted      for      20      minutes,      the      second  \n \n  for      15      minutes,      and      the      third      for      18  \n \n  minutes. Over      these      sessions,      she  \n \n  initially      typed   \n \na      total      of      318  \n \n  sentences."
            },
            {
              "id": 232,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "However,      she      made   \n \na       mistake      and      had      to      erase      40  \n \n  sentences,      leaving      her      with      278  \n \n  sentences      typed      effectively      today. By      the      end      of      the      day,      the      total  \n \n  number      of      sentences      on      her      paper      was  \n \n  536."
            },
            {
              "id": 233,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "To      find      out      how      many      sentences  \n \n  were      on      the      paper      at      the      beginning  \n \n  of      the      day,      we      subtract      the  \n \n  sentences      typed      today      (278)      from      the  \n \n  total      at      the      end      of      the      day      (536). Hence,      Janice      started      the      day      with  \n \n  258      sentences      already      on      her      paper."
            },
            {
              "id": 234,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race."
            },
            {
              "id": 235,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      They      have      one      week      to      run      30  \n \n  miles. sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days."
            },
            {
              "id": 236,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days? Prolog      code:  \n \n  7*      Context      */  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg      (2/3). jesse_day_four(10). mia_first_four_days_avg(3)."
            },
            {
              "id": 237,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total      (Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 238,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg(DayAvg),  \n \n  Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 239,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance)      ;\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 240,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages(      Average)."
            },
            {
              "id": 241,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(,      (=>Cbuiltin(;      (->(=(jesse,  \n \n  jesse),      jesse_first_four_days_total  \n \n  (12.0)),      ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ;(->(=(jesse,      jesse),  \n \n  jesse_first_four_days_total(12.0)),  \n \n  ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ,(=>(      true,      total_distance(30)),  \n \n  ,(=>(builtin(is(18.0,      -(30,      12.0))),  \n \n  is(18.0,      -(30,      12.0))),      =>(Cbuiltin(      is(6.0,      /(18.0,      3))),      is(6.0,  \n \n  /(18.@,      3)))))),      remaining_avg      (jesse  \n \n  ,      6.0)),      ,(C=>C,      (=>Cbuiltin(;      (->(=¢  \n \n  mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ;(->(=(mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ,(=>(builtin(true),      total_distance  \n \n  (30)),      builtin(,(gCis(18,      -(30,      12))  \n \n  ),      gCis(6,      /(18,      3))))))),  \n \n  remaining_avg(mia,      6)),      =>(Cbuiltin(      is(6.0,      /(+(6.0,      6),      2))),      is(6.@,  \n \n  /(+(6.0,      6),      2))))),  \n \n  average_of_averages(6.0)),      solve  \n \n  (6.0))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 242,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Jesse      and      Mia      are      competing      in   \n \na      week-  \n \n  long      race      where      each      needs      to      run   \n \na       total      of      30      miles."
            },
            {
              "id": 243,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "Jesse      averages   \n \n(      \\\\\\\\frac{2}{3}   \n \n)      mile      each      day      for      the  \n \n  first      three      days,      totaling   \n \n2      miles,  \n \n  and      then      runs      10      miles      on      the      fourth  \n \n  day,      making      it   \n \na      total      of      12      miles  \n \n  in      the      first      four      days."
            },
            {
              "id": 244,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "Mia      averages  \n \n  3      miles      per      day      over      the      first      four  \n \n  days,      totaling      12      miles      as      well. Given      that      they      both      need      to      complete      30  \n \n  miles      by      the      end      of      the      week,      both  \n \n  Jesse      and      Mia      have      18      miles      left      to  \n \n  run      over      the      final      three      days      after  \n \n  the      first      four      days."
            },
            {
              "id": 245,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "This      results      in  \n \n  each      needing      to      run      an      average      of   \n \n6       miles      per      day      over      the      last      three  \n \n  days. To      find      the      average      of      their      averages  \n \n  over      these      remaining      three      days,      we  \n \n  calculate   \n \n(      \\\\\\\\frac{(6+6)}{2}      ),      which  \n \n  remains   \n \n6      miles      per      day."
            },
            {
              "id": 246,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "Therefore,  \n \n  the      average      of      their      average      daily  \n \n  miles      over      the      final      three      days      that  \n \n  they      need      to      run      is   \n \n6      miles."
            }
          ],
          "content": ""
        },
        {
          "id": 247,
          "title": "Here      is      the      problem:",
          "type": "section",
          "children": [
            {
              "id": 248,
              "title": "Here      is      the      problem: - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 249,
              "title": "Here      is      the      problem: - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 250,
              "title": "Here      is      the      problem: - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  7x      Context      */ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 251,
              "title": "Here      is      the      problem: - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  Eis   \n \n8   \n \nx      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 252,
              "title": "Here      is      the      problem: - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is   \n \nH   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular),  \n \n  overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 253,
              "title": "Here      is      the      problem: - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. 7*      Query      x/  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total). <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 254,
              "title": "Here      is      the      problem: - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 255,
              "title": "Here      is      the      problem: - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 256,
              "title": "Here      is      the      problem: - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 257,
              "title": "Here      is      the      problem: - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  /*x      Context      */  \n \n  %      facts  \n \n  sentences_per_minute      (6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536). %      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \nx      SessionMinutes."
            },
            {
              "id": 258,
              "title": "Here      is      the      problem: - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n’       erased_sentences      (Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 259,
              "title": "Here      is      the      problem: - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday)   \n \n,       total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      x*/  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences). <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>  \n \n  Excellent      work!"
            },
            {
              "id": 260,
              "title": "Here      is      the      problem: - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race. sent-2:      They      have      one      week      to      run      30  \n \n  miles."
            },
            {
              "id": 261,
              "title": "Here      is      the      problem: - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days. sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days?"
            },
            {
              "id": 262,
              "title": "Here      is      the      problem: - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>assistant      <|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem. Here      is      the  \n \n  Prolog      code:\n \n \n  ~*~      prolog  \n \n  7x      Context      x*/  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg(2/3). jesse_day_four(10). mia_first_four_days_avg      (3)."
            },
            {
              "id": 263,
              "title": "Here      is      the      problem: - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total(Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 264,
              "title": "Here      is      the      problem: - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg      (DayAvg)   \n \n,       Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 265,
              "title": "Here      is      the      problem: - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance);\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 266,
              "title": "Here      is      the      problem: - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages   \n \n(      Average)."
            },
            {
              "id": 267,
              "title": "Here      is      the      problem: - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "pro  \n \n  Listing      2:      Construct   \n \na      prompt      prompt’,      to      guide      the LLM      to      generate   \n \na      natural      language      CoT-like      reasoning logic      chain      based      on      the      problem,      Prolog      code,      and reasoning      tree."
            },
            {
              "id": 268,
              "title": "Here      is      the      problem: - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      and      smart      assistant  \n \n  that      helps      people      solve      problems. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>\n \n \n \nI      need      assistance      in      translating   \n \na       reasoning      tree      generated      by   \n \na      Prolog  \n \n  engine      into   \n \na      natural      language  \n \n  description."
            },
            {
              "id": 269,
              "title": "Here      is      the      problem: - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "To      facilitate      this,   \n \nI       am      providing      the      original      problem,  \n \n  the      relevant      Prolog      code,      and      the  \n \n  reasoning      tree      itself. Please      review  \n \n  these      carefully      and      provide   \n \na       fluent      and      accurate      narrative      of      the  \n \n  reasoning      process. Thanks      for      your  \n \n  help!"
            },
            {
              "id": 270,
              "title": "Here      is      the      problem: - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "xxkInstructions      Startx*  \n \n  Translate      the      provided      reasoning      tree  \n \n  into   \n \na      clear      and      logical      natural  \n \n  language      explanation. Many      thanks      for      your      help! I      am      looking  \n \n  forward      to      your      response! *xkInstructions      End**"
            }
          ],
          "content": ""
        },
        {
          "id": 271,
          "title": "Here      is      the      problem:",
          "type": "section",
          "children": [
            {
              "id": 272,
              "title": "Here      is      the      problem: - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 273,
              "title": "Here      is      the      problem: - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? Here      is      the      prolog_code:\n/*      Context      x*/ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00)."
            },
            {
              "id": 274,
              "title": "Here      is      the      problem: - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "%      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage. overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1."
            },
            {
              "id": 275,
              "title": "Here      is      the      problem: - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "%      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  E      is   \n \n8   \n \n*      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 276,
              "title": "Here      is      the      problem: - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is   \n \nH   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular), overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 277,
              "title": "Here      is      the      problem: - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. /*      Query      */  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total)."
            },
            {
              "id": 278,
              "title": "Here      is      the      problem: - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog      reasoning      tree:\n \n \n  =>(=>(,      (=>(,      (=>(,      (=>      C(builtin(true),      wage  \n \n  (18.0)),      =>Cbuiltin(is(144.0,      x*(8,  \n \n  18.0))),      is(144.0,      *(8,      18.0)))),  \n \n  regular_earning_for_day(144.0)),  \n \n  ,(=>(,      (=>(=>(builtin(is(2,      -(10,      8))  \n \n  ),      is(2,      -(1@,      8))),      overtime_hours  \n \n  (2)),      ,C=>Cbuiltin(,      (g(wage(18.0)),  \n \n  g(is(27.0,      *(1.5,      18.0))))),  \n \n  overtime_wage(27.0)),      =>(Cbuiltin(is  \n \n  (54.0,      *(2,      27.0))),      is(54.0,      *(2,  \n \n  27.0))))),      overtime_earning_for_day  \n \n  (54.0)),      =>(Cbuiltin(is(198.0,  \n \n  +(144.0,      54.0))),      i18(198.0,      +(144.0,  \n \n  54.0))))),      total_earning_for_day  \n \n  (198.0)),      =>Cbuiltin(is(990.0,      x*(5,  \n \n  198.0))),      18(990.0,      *(5,      198.0)))),  \n \n  total_earning_for_5_days(990.0)),  \n \n  solve      (990.0)   \n \n)       <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 279,
              "title": "Here      is      the      problem: - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Tina      earns      $18.00      per      hour      according      to  \n \n  the      information      provided."
            },
            {
              "id": 280,
              "title": "Here      is      the      problem: - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "She      has  \n \n  shifts      where,      if      she      works      more      than  \n \n  8      hours,      the      additional      hours      are  \n \n  considered      overtime. Overtime      pay      is  \n \n  calculated      at      one      and   \n \na      half      times  \n \n  her      regular      hourly      wage."
            },
            {
              "id": 281,
              "title": "Here      is      the      problem: - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "On   \n \na      typical      day,      if      Tina      works      10      hours  \n \n  ,      this      includes   \n \n2      hours      of      overtime  \n \n  since      she      exceeds      the      8-hour      regular  \n \n  work      period. Her      regular      earnings  \n \n  for      working   \n \n8      hours   \n \na      day      at      $18.00  \n \n  per      hour      amounts      to      $144.00      per      day."
            },
            {
              "id": 282,
              "title": "Here      is      the      problem: - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "For      the   \n \n2      hours      of      overtime,      since  \n \n  the      overtime      rate      is      $27.00      per      hour  \n \n  (1.5      times      her      regular      hourly      wage)  \n \n  ,      she      earns      $54.00      from      overtime  \n \n  work      per      day. Therefore,      her      total      earnings      for   \n \na       single      day,      combining      her      regular  \n \n  and      overtime      earnings,      are      $198.00."
            },
            {
              "id": 283,
              "title": "Here      is      the      problem: - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Over      the      course      of   \n \n5      days,      working  \n \n  the      same      hours      daily,      Tina      makes   \n \na       total      of      $990.00,      factoring      in      all  \n \n  regular      pay      and      overtime      across      the  \n \n  five      days. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 284,
              "title": "Here      is      the      problem: - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 285,
              "title": "Here      is      the      problem: - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 286,
              "title": "Here      is      the      problem: - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? Prolog      code:  \n \n  /*      Context      x*/  \n \n  %      facts  \n \n  sentences_per_minute(6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536)."
            },
            {
              "id": 287,
              "title": "Here      is      the      problem: - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \n*      SessionMinutes."
            },
            {
              "id": 288,
              "title": "Here      is      the      problem: - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n,       erased_sentences(Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 289,
              "title": "Here      is      the      problem: - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday),  \n \n  total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      */  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences)."
            },
            {
              "id": 290,
              "title": "Here      is      the      problem: - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(builtin(true),  \n \n  total_end_sentences      (536)),  \n \n  ,(=>(,      (=>(Cbuiltin(true),  \n \n  typing_sessions([20,      15,      18])),  \n \n  builtin(,      (g(maplist(sentences_typed,  \n \n  [20,      15,      18],      [120,      90,      108])),      ,Cg  \n \n  (sum_list([120,      90,      108],      318)),      ,(g  \n \n  (erased_sentences(40)),      g(is(278,  \n \n  ~(318,      40)))))))),  \n \n  total_sentences_typed_today      (278)),  \n \n  =>(builtin(is(258,      -(536,      278))),      is  \n \n  (258,      -(536,      278))))),  \n \n  start_sentences(258)),      solve(258))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 291,
              "title": "Here      is      the      problem: - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Janice\\\\\\'s      typing      speed      is   \n \n6      sentences      per  \n \n  minute."
            },
            {
              "id": 292,
              "title": "Here      is      the      problem: - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Today,      she      had      three  \n \n  separate      typing      sessions:      the      first  \n \n  lasted      for      20      minutes,      the      second  \n \n  for      15      minutes,      and      the      third      for      18  \n \n  minutes. Over      these      sessions,      she  \n \n  initially      typed   \n \na      total      of      318  \n \n  sentences."
            },
            {
              "id": 293,
              "title": "Here      is      the      problem: - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "However,      she      made   \n \na       mistake      and      had      to      erase      40  \n \n  sentences,      leaving      her      with      278  \n \n  sentences      typed      effectively      today. By      the      end      of      the      day,      the      total  \n \n  number      of      sentences      on      her      paper      was  \n \n  536."
            },
            {
              "id": 294,
              "title": "Here      is      the      problem: - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "To      find      out      how      many      sentences  \n \n  were      on      the      paper      at      the      beginning  \n \n  of      the      day,      we      subtract      the  \n \n  sentences      typed      today      (278)      from      the  \n \n  total      at      the      end      of      the      day      (536). Hence,      Janice      started      the      day      with  \n \n  258      sentences      already      on      her      paper."
            },
            {
              "id": 295,
              "title": "Here      is      the      problem: - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race."
            },
            {
              "id": 296,
              "title": "Here      is      the      problem: - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      They      have      one      week      to      run      30  \n \n  miles. sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days."
            },
            {
              "id": 297,
              "title": "Here      is      the      problem: - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days? Prolog      code:  \n \n  7*      Context      */  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg      (2/3). jesse_day_four(10). mia_first_four_days_avg(3)."
            },
            {
              "id": 298,
              "title": "Here      is      the      problem: - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total      (Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 299,
              "title": "Here      is      the      problem: - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg(DayAvg),  \n \n  Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 300,
              "title": "Here      is      the      problem: - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance)      ;\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 301,
              "title": "Here      is      the      problem: - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages(      Average)."
            },
            {
              "id": 302,
              "title": "Here      is      the      problem: - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(,      (=>Cbuiltin(;      (->(=(jesse,  \n \n  jesse),      jesse_first_four_days_total  \n \n  (12.0)),      ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ;(->(=(jesse,      jesse),  \n \n  jesse_first_four_days_total(12.0)),  \n \n  ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ,(=>(      true,      total_distance(30)),  \n \n  ,(=>(builtin(is(18.0,      -(30,      12.0))),  \n \n  is(18.0,      -(30,      12.0))),      =>(Cbuiltin(      is(6.0,      /(18.0,      3))),      is(6.0,  \n \n  /(18.@,      3)))))),      remaining_avg      (jesse  \n \n  ,      6.0)),      ,(C=>C,      (=>Cbuiltin(;      (->(=¢  \n \n  mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ;(->(=(mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ,(=>(builtin(true),      total_distance  \n \n  (30)),      builtin(,(gCis(18,      -(30,      12))  \n \n  ),      gCis(6,      /(18,      3))))))),  \n \n  remaining_avg(mia,      6)),      =>(Cbuiltin(      is(6.0,      /(+(6.0,      6),      2))),      is(6.@,  \n \n  /(+(6.0,      6),      2))))),  \n \n  average_of_averages(6.0)),      solve  \n \n  (6.0))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 303,
              "title": "Here      is      the      problem: - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Jesse      and      Mia      are      competing      in   \n \na      week-  \n \n  long      race      where      each      needs      to      run   \n \na       total      of      30      miles."
            },
            {
              "id": 304,
              "title": "Here      is      the      problem: - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Jesse      averages   \n \n(      \\\\\\\\frac{2}{3}   \n \n)      mile      each      day      for      the  \n \n  first      three      days,      totaling   \n \n2      miles,  \n \n  and      then      runs      10      miles      on      the      fourth  \n \n  day,      making      it   \n \na      total      of      12      miles  \n \n  in      the      first      four      days."
            },
            {
              "id": 305,
              "title": "Here      is      the      problem: - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Mia      averages  \n \n  3      miles      per      day      over      the      first      four  \n \n  days,      totaling      12      miles      as      well. Given      that      they      both      need      to      complete      30  \n \n  miles      by      the      end      of      the      week,      both  \n \n  Jesse      and      Mia      have      18      miles      left      to  \n \n  run      over      the      final      three      days      after  \n \n  the      first      four      days."
            },
            {
              "id": 306,
              "title": "Here      is      the      problem: - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "This      results      in  \n \n  each      needing      to      run      an      average      of   \n \n6       miles      per      day      over      the      last      three  \n \n  days. To      find      the      average      of      their      averages  \n \n  over      these      remaining      three      days,      we  \n \n  calculate   \n \n(      \\\\\\\\frac{(6+6)}{2}      ),      which  \n \n  remains   \n \n6      miles      per      day."
            },
            {
              "id": 307,
              "title": "Here      is      the      problem: - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Therefore,  \n \n  the      average      of      their      average      daily  \n \n  miles      over      the      final      three      days      that  \n \n  they      need      to      run      is   \n \n6      miles."
            }
          ],
          "content": ""
        }
      ],
      "content": ""
    }
  ],
  "content": ""
}