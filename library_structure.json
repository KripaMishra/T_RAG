{
  "id": 1,
  "title": "Library",
  "type": "library",
  "children": [
    {
      "id": 2,
      "title": "Book 1",
      "type": "book",
      "children": [
        {
          "id": 3,
          "title": "Abstract",
          "type": "section",
          "children": [
            {
              "id": 4,
              "title": "Abstract - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Abstract\nLarge      language      models      (LLMs)      have      shown exceptional      performance      as      general-purpose      as- sistants,      excelling      across   \n \na      variety      of      reasoning arXiv:2407.14562v1      [cs.Al]      18      Jul      2024 tasks. This      achievement      represents   \n \na      signifi- cant      step      toward      achieving      artificial      general      in- telligence      (AGI)."
            },
            {
              "id": 5,
              "title": "Abstract - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Despite      these      advancements, the      effectiveness      of      LLMs      often      hinges      on      the specific      prompting      strategies      employed,      and there      remains   \n \na      lack      of   \n \na      robust      framework      to facilitate      learning      and      generalization      across      di- verse      reasoning      tasks."
            },
            {
              "id": 6,
              "title": "Abstract - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "To      address      these      chal- lenges,      we      introduce   \n \na      novel      learning      frame- work,      THOUGHT-LIKE-PRO. In      this      frame- work,      we      utilize      imitation      learning      to      imitate the      Chain-of-Thought      (CoT)      process      which      is verified      and      translated      from      reasoning      trajec- tories      generated      by   \n \na      symbolic      Prolog      logic engine."
            },
            {
              "id": 7,
              "title": "Abstract - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      framework      proceeds      in   \n \na      self- driven      manner,      that      enables      LLMs      to      formu- late      rules      and      statements      from      given      instruc- tions      and      leverage      the      symbolic      Prolog      engine to      derive      results."
            },
            {
              "id": 8,
              "title": "Abstract - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Subsequently,      LLMs      con- vert      Prolog-derived      successive      reasoning      tra- jectories      into      natural      language      CoT      for      imi- tation      learning. Our      empirical      findings      indi- cate      that      our      proposed      approach      substantially enhances      the      reasoning      abilities      of      LLMs      and demonstrates      robust      generalization      across      out- of-distribution      reasoning      tasks."
            },
            {
              "id": 9,
              "title": "Abstract - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "1\n \n   Introduction Recent      advancements      in      large      language      models (LLMs)      have      positioned      them      as      versatile      tools for   \n \na      variety      of      tasks,      achieved      through   \n \na      struc- tured      training      process      that      includes      pre-training      on large      text      corpora,      supervised      fine-tuning,      and      rein- forcement      learning      from      human      feedback      (RLHF) (Casper      et      al.,      2023)."
            },
            {
              "id": 10,
              "title": "Abstract - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "These      phases      equip      LLMs with      extensive      knowledge,      the      ability      to      generate context-specific      responses,      and      alignment      with      hu- man      values. One      of      the      key      factors      contributing to      the      perception      of      LLMs      as   \n \na      precursor      to      arti- et      al.,      2024)      have      been      introduced."
            },
            {
              "id": 11,
              "title": "Abstract - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "These      meth-  \n \n  ods      aim      to      formalize      the      reasoning      architecture ficial      general      intelligence      (AGI)      is      their      scalable  \n \n  and      explainable      reasoning      capabilities      (Zhao      et      al., 2023),      which      have      demonstrated      potential      to      solve multiple      types      of      real-world      complex      logic      reason- ing      problems,      including      natural      language      logical reasoning      and      arithmetic      reasoning."
            },
            {
              "id": 12,
              "title": "Abstract - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "General      logic      reasoning      tasks      continue      to      present substantial      challenges      for      LLMs. These      challenges primarily      emerge      during      the      LLMs’      reasoning      pro- cesses      (Ribeiro      et      al.,      2023;      Zhou      et      al.,      2024)."
            },
            {
              "id": 13,
              "title": "Abstract - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "At the      semantic      level,      the      generation      of      accurate      multi- hop      inferential      pathways      and      the      assurance      of      va- lidity      at      each      reasoning      step      remain      significant      ob- stacles      (Creswell      et      al.,      2023;      Kazemi      et      al.,      2023)."
            },
            {
              "id": 14,
              "title": "Abstract - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "LLMs      function      in   \n \na      self-regressive      manner      at      the      to- ken      level,      processing      information      sequentially      from left      to      right,      one      token      at   \n \na      time."
            },
            {
              "id": 15,
              "title": "Abstract - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "This      method      can amplify      errors:      an      inaccurate      token      prediction      may negatively      impact      all      subsequent      tokens,      leading to      escalating      inaccuracies      and      false      reasoning      out- comes."
            },
            {
              "id": 16,
              "title": "Abstract - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Interestingly,      some      studies      (Ye      and      Durrett, 2022;      Saparov      and      He,      2023;      Ribeiro      et      al.,      2023) have      observed      instances      where      LLMs      deliver      cor- rect      answers      despite      erroneous      internal      reasoning processes."
            },
            {
              "id": 17,
              "title": "Abstract - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "This      phenomenon      highlights   \n \na      mis- alignment      between      the      reasoning      processes      and outcomes      of      LLMs,      suggesting   \n \na      weak      causal relationship      and      underdeveloped      implicit      rea- soning      connections      within      the      LLMs."
            },
            {
              "id": 18,
              "title": "Abstract - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "To      address      the      challenges      associated      with      gener- ating      reasoning      trajectories      in      LLMs,      several      strate- gies      have      been      developed      to      enhance      cognitive alignment      and      logical      coherence."
            },
            {
              "id": 19,
              "title": "Abstract - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "The      Chain-of- Thought      (CoT)      approach      (Wei      et      al.,      2022;      Ko- jima      et      al.,      2022;      Zhang      et      al.,      2022),      for      instance, enhances      LLMs’      reasoning      abilities      by      crafting instructions      and      few-shot      examples      that      promote sequential      reasoning."
            },
            {
              "id": 20,
              "title": "Abstract - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Building      on      the      CoT      frame- work,      other      methodologies      like      Tree-of-Thoughts (Yao      et      al.,      2024;      Long,      2023;      Hulbert,      2023) and      Graph-of-Thoughts      (Besta      et      al.,      2024;      Zhang of      LLMs      through      in-context      learning      (Dong      et      al., 2022;      Work)      and      guide      model      output."
            },
            {
              "id": 21,
              "title": "Abstract - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "While      these prompt-based      techniques      have      proven      effective      in specific      tasks,      they      require      precise,      task-specific modifications      and      may      not      be      broadly      applicable across      different      domains      (Creswell      et      al.,      2023;\nKazemi      et      al.,      2023)."
            },
            {
              "id": 22,
              "title": "Abstract - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Alternative      approaches      have sought      to      augment      the      reasoning      capabilities      of LLMs      by      conceptualizing      them      as      agents      that      can employ      various      logical      reasoning      tools      (Lyu      et      al., 2023;      Pan      et      al.,      2023a)."
            },
            {
              "id": 23,
              "title": "Abstract - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "This      strategy      simplifies complex      reasoning      tasks      into      more      manageable components      such      as      tool      utilization      and      question definition."
            },
            {
              "id": 24,
              "title": "Abstract - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "One      particularly      effective      method      in- volves      the      use      of      symbolic      logic      engines,      such      as Prolog      (Bowen,      1979),      to      conduct      symbolic      infer- ence,      thereby      ensuring      the      correctness      of      the      rea- soning      trajectory."
            },
            {
              "id": 25,
              "title": "Abstract - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "However,      this      approach      does      not inherently      enhance      the      LLM’s      reasoning      capabili- ties      and      fails      to      provide   \n \na      generalized      improvement in      the      model’s      ability      to      follow      general      instructions across      diverse      tasks. Pro!,   \n \na      novel      framework      designed      to      enhance      the"
            }
          ],
          "content": ""
        },
        {
          "id": 26,
          "title": "In      this      paper,      we      introduce      THOUGHT-LIKE-",
          "type": "section",
          "children": [
            {
              "id": 27,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "In      this      paper,      we      introduce      THOUGHT-LIKE-\nlogical      reasoning      capabilities      of      LLMs      by      imitating the      verified      reasoning      processes      of      the      Prolog      logic engine."
            },
            {
              "id": 28,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      begin      by      utilizing      open-source      chat LLMs,      such      as      Llama3-8B-Instruct      (AI@      Meta, 2024),      to      generate      rules,      facts,      and      queries      follow- ing      specific      instructions      and      demonstrations. Sub- sequently,      we      employ      the      Prolog      engine      to      perform logical      reasoning,      verifying      the      outcomes      against established      truths."
            },
            {
              "id": 29,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Only      the      verified      reasoning      pro- cesses      are      selected,      which      we      then      translate      into CoT-like      natural      language      reasoning      trajectories. These      trajectories      serve      as      the      basis      for      supervised fine-tuning      (SFT),      aimed      at      teaching      LLMs      to      im- itate   \n \na      strictly      logical      reasoning      process."
            },
            {
              "id": 30,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "To      ad- dress      the      issue      of      catastrophic      forgetting      during domain-specific      fine-tuning,      we      implement   \n \na      model averaging      technique."
            },
            {
              "id": 31,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Empirical      experiments      con- firm      that      the      THOUGHT-LIKE-PRO      framework      sig- nificantly      improves      the      reasoning      capabilities      of LLMs      and      extends      their      generalization      to      Out-of- Distribution      (OOD)      reasoning      benchmarks."
            },
            {
              "id": 32,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "The contributions      of      our      study      are      detailed      as      follows:\n \n \n  We      offer   \n \na      demo      of      the      dataset      automatically      generated      by  \n \n  the      THOUGHT-LIKE-PRO      framework      for      reference. Avail-  \n \n  able      at:      https:      //anonymous.4open.science/r/Prolog_  \n \n  datasets-9875. \\\\\\'The      code      will      be      fully      released      due      to      the      acceptance."
            },
            {
              "id": 33,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "¢\n \n   We      propose      THOUGHT-LIKE-PRO      framework designed      to      enhance      the      general      reasoning      ca- pabilities      of      LLMs      in   \n \na      self-driven      way. This framework      is      straightforward      to      implement and      replicate."
            },
            {
              "id": 34,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "¢\n \n   Our      results      show      that      performing      imitation learning      on      strictly      logical      and      diverse      rea- soning      trajectories      for   \n \na      single      instruction leads      to      improved      and      consistent      reasoning performance. ¢\n \n   The      framework      is      simple,      straightforward, and      highly      effective."
            },
            {
              "id": 35,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "It      demonstrates      robust OOD      reasoning      performance      across      multiple logic      tasks      and      general      benchmarks,      making it      applicable      in      various      industrial      domains. 2\n \n   Methods\n2.1      Preliminary:      Supervised      Fine-tuning,\ning, Chain-of-Thought,      and      Prolog Consider   \n \na      LLM,      denoted      by      pg,      which      is      param- eterized      by      @."
            },
            {
              "id": 36,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Given      an      instruction      dataset      Dy      pr consisting      of      question      and      answer      pairs      (x,y),   \n \na highly      effective      method      for      aligning   \n \n6      with      the      tar- get      output   \n \ny      given   \n \nx      is      to      minimize      the      negative log-likelihood      of   \n \ny      conditioned      on   \n \nx      (Gunel      et      al., 2020;      Dong      et      al.,      2023)."
            },
            {
              "id": 37,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "This      can      be      formulated autoregressively      as:\nmin      —E(xy)~Dyp   \n \n>      ert)   \n \n,      Q) k\n6\n     ;\ni=1 where   \n \nk      is      the      number      of      tokens      in      y."
            },
            {
              "id": 38,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "To      enhance      reasoning      performance      on      com- plex      logical      and      algorithmic      tasks,      one      effective approach      involves      using   \n \na      specialized      prompt, promptcor,      to      initiate   \n \na      step-by-step      reasoning trajectory      prior      to      generating      the      final      output:\n(y,c)   \n \n~      po(-|x,      promptcor)."
            },
            {
              "id": 39,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Here,      c      represents   \n \na CoT      reasoning      process      (Wei      et      al.,      2022;      Kojima et      al.,      2022;      Zhang      et      al.,      2022). Typically,      this process      decomposes      complex,      multi-step      reason- ing      tasks      into      simpler,      intermediate      steps,      thereby directing      the      LLM      toward      the      correct      answer."
            },
            {
              "id": 40,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Nev- ertheless,      several      studies      (Ye      and      Durrett,      2022;\nSaparov      and      He,      2023;      Ribeiro      et      al.,      2023)      have indicated      that      c      may      sometimes      exhibit      disorga- nized      patterns      that      do      not      adhere      strictly      to      logical reasoning      processes."
            },
            {
              "id": 41,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "This      inconsistency      can      ad- versely      affect      the      LLM’s      reasoning      performance across      diverse      tasks."
            },
            {
              "id": 42,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Step.1      Generate      Rules,      Facts,  \n \n  Step.3      Translate      Prolog-based      Trajectories      to      CoT\nreasoning      Prolog      code:   \n \n>      by      Prolog      engine:      ire      ro  \n \n  (Re,      Fx;      Ty)   \n \n~      pol:   \n \n|      prompt,      4,      x,      y)      O(ay)   \n \n=      Prolog(Rz,      Fz;      Ty)      cy      ~~      po(-|prompte:      ,X,¥,0i),      01   \n \n€      O(e,y);\nand      Targets      Reasoning      Trajectories  \n \n  fo}      Preparing      the   \n \na      Reasoning      trajectories      fe}      Constructing      the      new      dataset      Drzz:\nZ=1,,n  \n \n  Datasets      Drr      fo      prompt,      ¢,  \n \n  cot  \n \n  SFT      for      imitation      learning:  \n \n  ming      —E(x,c2,y)~Darp      [log      Po      (y,      cP?"
            },
            {
              "id": 43,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "lx)\nProlog      is   \n \na      high-level      symbolic      language      system This      is      designed      to      guide      the      model      pg      in      generat- designed      for      rule-based      reasoning      (Andreas      et      al., ing      relevant      rules      R,,      facts      F,,      and      deriving      the 2016;      Neelakantan      et      al.,      2017),      fundamentally      op- reasoning      target      Ty:\nerating      within   \n \na      subset      of      predicate      logic      known as      Horn      Clause      logic      (Hudson      and      Manning,      2019; (Re,      Fx,Ty)   \n \n~      po(-   \n \n|      prompt,      x,y)."
            },
            {
              "id": 44,
              "title": "In      this      paper,      we      introduce      THOUGHT-LIKE- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "(3)"
            }
          ],
          "content": ""
        },
        {
          "id": 45,
          "title": "2.1      Preliminary:      Supervised      Fine-tuning,",
          "type": "section",
          "children": [
            {
              "id": 46,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "2.1      Preliminary:      Supervised      Fine-tuning,\ning, Chain-of-Thought,      and      Prolog Consider   \n \na      LLM,      denoted      by      pg,      which      is      param- eterized      by      @."
            },
            {
              "id": 47,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Given      an      instruction      dataset      Dy      pr consisting      of      question      and      answer      pairs      (x,y),   \n \na highly      effective      method      for      aligning   \n \n6      with      the      tar- get      output   \n \ny      given   \n \nx      is      to      minimize      the      negative log-likelihood      of   \n \ny      conditioned      on   \n \nx      (Gunel      et      al., 2020;      Dong      et      al.,      2023)."
            },
            {
              "id": 48,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "This      can      be      formulated autoregressively      as:\nmin      —E(xy)~Dyp   \n \n>      ert)   \n \n,      Q) k\n6\n     ;\ni=1 where   \n \nk      is      the      number      of      tokens      in      y."
            },
            {
              "id": 49,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "To      enhance      reasoning      performance      on      com- plex      logical      and      algorithmic      tasks,      one      effective approach      involves      using   \n \na      specialized      prompt, promptcor,      to      initiate   \n \na      step-by-step      reasoning trajectory      prior      to      generating      the      final      output:\n(y,c)   \n \n~      po(-|x,      promptcor)."
            },
            {
              "id": 50,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Here,      c      represents   \n \na CoT      reasoning      process      (Wei      et      al.,      2022;      Kojima et      al.,      2022;      Zhang      et      al.,      2022). Typically,      this process      decomposes      complex,      multi-step      reason- ing      tasks      into      simpler,      intermediate      steps,      thereby directing      the      LLM      toward      the      correct      answer."
            },
            {
              "id": 51,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Nev- ertheless,      several      studies      (Ye      and      Durrett,      2022;\nSaparov      and      He,      2023;      Ribeiro      et      al.,      2023)      have indicated      that      c      may      sometimes      exhibit      disorga- nized      patterns      that      do      not      adhere      strictly      to      logical reasoning      processes."
            },
            {
              "id": 52,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "This      inconsistency      can      ad- versely      affect      the      LLM’s      reasoning      performance across      diverse      tasks."
            },
            {
              "id": 53,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Step.1      Generate      Rules,      Facts,  \n \n  Step.3      Translate      Prolog-based      Trajectories      to      CoT\nreasoning      Prolog      code:   \n \n>      by      Prolog      engine:      ire      ro  \n \n  (Re,      Fx;      Ty)   \n \n~      pol:   \n \n|      prompt,      4,      x,      y)      O(ay)   \n \n=      Prolog(Rz,      Fz;      Ty)      cy      ~~      po(-|prompte:      ,X,¥,0i),      01   \n \n€      O(e,y);\nand      Targets      Reasoning      Trajectories  \n \n  fo}      Preparing      the   \n \na      Reasoning      trajectories      fe}      Constructing      the      new      dataset      Drzz:\nZ=1,,n  \n \n  Datasets      Drr      fo      prompt,      ¢,  \n \n  cot  \n \n  SFT      for      imitation      learning:  \n \n  ming      —E(x,c2,y)~Darp      [log      Po      (y,      cP?"
            },
            {
              "id": 54,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "lx)\nProlog      is   \n \na      high-level      symbolic      language      system This      is      designed      to      guide      the      model      pg      in      generat- designed      for      rule-based      reasoning      (Andreas      et      al., ing      relevant      rules      R,,      facts      F,,      and      deriving      the 2016;      Neelakantan      et      al.,      2017),      fundamentally      op- reasoning      target      Ty:\nerating      within   \n \na      subset      of      predicate      logic      known as      Horn      Clause      logic      (Hudson      and      Manning,      2019; (Re,      Fx,Ty)   \n \n~      po(-   \n \n|      prompt,      x,y)."
            },
            {
              "id": 55,
              "title": "2.1      Preliminary:      Supervised      Fine-tuning, - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "(3)"
            }
          ],
          "content": ""
        },
        {
          "id": 56,
          "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de-",
          "type": "section",
          "children": [
            {
              "id": 57,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Bowen,      1979). It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de-\nimperative      approach      by      emphasizing      relations      over duce the set of reasoning trajectories O(,,), which the      sequence      of      actions."
            },
            {
              "id": 58,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "In      Prolog,      the      logic      of      com- encompasses      all      logical      paths      leading      to      the      target\n |       putation      is      articulated      through      relations,      denoted | Ty. This      process      is      formalized      as:\n |       as      facts      F      and      rules      R."
            },
            {
              "id": 59,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Typically,      Prolog      utilizes      a | Oy)   \n \n=      Prolog(Re,      Fx;      Ty):      (4)\n |       depth-first      search      strategy      (Wielemaker      et      al.,      2012)       sired      conclusion,      yet      it      is      also      equipped      to      delineate | reasoning      trajectories      that      conclusively      reach      the\n | all      possible      logical      inference      paths      leading      to      the target      7,,      excluding      any      data      that      result      from      er-\n |       target      results      7."
            },
            {
              "id": 60,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      entire      logical      inference      pro-       cess      within      the      Prolog      engine,      denoted      as      Prolog, | delineated      in      Equation      3."
            },
            {
              "id": 61,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "To      ensure      the      acquisition\n |       can      be      represented      by      the      following      equation: | of      high-quality      and      interpretable      reasoning      trajec-\n | O = Prolog(R, F, T), {01, 02, | -; On} € O, (2)  \n \n  tories      via      Prolog,      we      implement   \n \na      meta-solver      de-  \n \n  veloped      by      (Yang      et      al.,      2023),      which      retrieves      all\n |       where      O      encompasses      n      valid      logical      inference | feasible      reasoning      paths."
            },
            {
              "id": 62,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "|       trajectories      toward      the      target      T. | After      acquiring      the      set      O(z,),      we      design   \n \na      novel  \n \n  few-shot      prompt,      prompt®”? (Listing      2),      to      trans-\n\n2.2      THOUGHT-LIKE-PRO late      existing      reasoning      trajectories      into      CoT-like\nHere,      we      introduce      THOUGHT-LIKE-PRO,   \n \na      novel reasoning      processes      expressed      in      natural      language."
            },
            {
              "id": 63,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "framework      designed      to      enhance      the      general      log- This      transformation      aids      in      constructing      the      new\n\n |       ical      reasoning      capabilities      of      LLMs      across      vari- |       dataset      Darr:\n |       ous      logical      tasks. As      suggested      by      the      name,      our |       cP”?"
            },
            {
              "id": 64,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "~      py(-|prompt?”?,      x,      ¥,0;),0;      €      Oury):\n |       framework      enables      LLMs      to      imitate      strictly      logical       reasoning      trajectories      that      are      generated      and      val- |       (x,      cre a=1,,n. )      y)      €      Dri      F;      for\n |       idated      by      the      Prolog      engine."
            },
            {
              "id": 65,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "The      architecture      of |       (5)\n |       THOUGHT-LIKE-PRO      is      organized      in      a      self-driven |       It      is      important      to      note      that      this      new      dataset,      Dry      pr,\n |       manner,      eliminating      the      requirement      for      auxiliary |       encompasses      all      n      available      reasoning      trajectories\n |       services      from      other      advanced      LLMs,      such      as      GPT- |       for      each      instruction      x."
            },
            {
              "id": 66,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Subsequently,      we      optimize\n | 4      (Achiam      et      al.,      2023)      and      Claude      2      (Wu      et      al., the      model      using      SFT      as      outlined      in      Equation      1,\n |       2023)."
            },
            {
              "id": 67,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "It      solely      relies      on      the      utilization      of      effi- |       aligning      both      the      CoT-like      reasoning      trajectories\n |       cient,      open-source      LLMs      (i.e.,      Llama3-8B-Instruct |       and      the      target      outputs      conditioned      on      x      autoregres-\n |       (AI@Meta,      2024)),      fostering      accessibility      and      ease |       sively:\n |       of      replication."
            },
            {
              "id": 68,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "|       min      E(x,      cP°¢,y)~Darr      [log      po(y,c””°|x)],      (6)\n | To      employ      the      Prolog      engine      Prolog      for      logical reasoning,      we      initiate      the      process      by      constructing resulting      in      a      trained      model      parameterized      by      6’. | This      entire      learning      process      parallels      imitation       Acc a      few-shot      demonstration      prompt,.-,      (Listing      1)."
            },
            {
              "id": 69,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "| Datasets      Prompt      Thought-Like-Pro(ours)       Lama3-8B-Instruct      MA+single      MA+multiple      single      multiple      CARING       GSM8K      8-shot,CoT      79.6      80.7      85.32      83.4      87.81      98.1       ProofWriter      3-shot,CoT      53.7      72.13      97.25      73.91      98.19      100       PrOntoQA      2-shot      53.6      90.4      94.3      95.3      100      100       MMLU      5-shot      68.4      68.2      67.9      65.4      64.3      -       GPQA      0-shot      34.2      34.2      33.8      32.8      31.9      -       HumanEval      0-shot      62.2      62.1      61.9      60.2      60      -       MATH      4-shot,CoT      30      29.3      30.2      29.2      30.1      -\n | and      are      not      included      in      the      accuracy      rankings."
            },
            {
              "id": 70,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "| learning      algorithms      (Hussein      et      al.,      2017;      Osa      et      al., 2018)      that      select      “optimal”      trajectories      (here      veri- fied      by      the      Prolog      engine)      and      implement      behavior cloning      to      directly      imitate      these      trajectories."
            },
            {
              "id": 71,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Af- ter      training      according      to      Equation      6,      the      model pe      is      tailored      to      perform      domain-specific      tasks present      in      Dgrr."
            },
            {
              "id": 72,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "However,      if      the      task      distribution of      Drir      significantly      diverges      from      that      of      Dyr, catastrophic      forgetting      (CF)      may      occur      (Chen      et      al., 2023;      Zhai      et      al.,      2023;      Shi      et      al.,      2024),      potentially compromising      the      model’s      generality      across      other reasoning      and      general      tasks."
            },
            {
              "id": 73,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "To      address      this,      we employ      a      model      averaging      technique      (Lin      et      al., 2023)      to      derive      a      new      model      pg      parameterized      by      0:\n | 6      =      a0      +      (1      —a)6’,      where      a      is      a      hyper-parameter that      balances      specialization      and      generalization."
            },
            {
              "id": 74,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "| 3      Experiment In      our      preliminary      experiments,      we      continually trained      the      Llama3-8B-Instruct      model,      using      it as      a      baseline      to      evaluate      the      effectiveness      of      the THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 75,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "We      also      imple- ment      CARING      (Yang      et      al.,      2023)      under      the      experi- mental      setup      as      our      baseline      method      which      utilizes the      Prolog      engine      to      derive      the      final      results      without training      LLMs. Hence,      the      performance      of      CAR- ING      in      reasoning      tasks      should      be      the      upper      limit of      THOUGHT-LIKE-PRO."
            },
            {
              "id": 76,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "We      trained      the      model and      evaluated      its      reasoning      capabilities      across      three datasets:      GSM8K      (Cobbe      et      al.,      2021),      ProofWriter (Tafjord      et      al.,      2020),      and      PrOntoQA      (Saparov      and He,      2022)."
            },
            {
              "id": 77,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Additionally,      we      assessed      OOD      general task      performance      using      the      MMLU      (Hendrycks et      al.,      2020),      GPQA      (Rein      et      al.,      2023),      HumanEval (Chen      et      al.,      2021),      and      MATH      (Hendrycks      et      al., 2021)      datasets."
            },
            {
              "id": 78,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Our      experimental      framework      com- prises      four      configurations      to      explore      the      impact      of model      averaging      and      training      with      multiple      reason- future      works. | ing      trajectories."
            },
            {
              "id": 79,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "The      configurations      are:      1)      full       implementation      with      model      averaging      and      mul- tiple      trajectories      (MA+multiple),      2)      model      aver- aging      with      a      single      trajectory      for      each      instruc- tion      (MA+single),      3)      multiple      trajectories      without model      averaging      (multiple),      and      4)      a      single      trajec- tory      without      model      averaging      (single)."
            },
            {
              "id": 80,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "We      refer the      readers      to      Appendix      A      for      more      details      about the      experiment. | The      results,      as      detailed      in      Table      1,      reveal      that the      THOUGHT-LIKE-PRO      framework      significantly enhances      reasoning      capabilities      through      continu- ous      training      on      the      Llama3-8B-Instruct      model."
            },
            {
              "id": 81,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "By incorporating      multiple      reasoning      trajectories,      this approach      leads      to      superior      outcomes      compared      to training      with      a      single      trajectory."
            },
            {
              "id": 82,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      the application      of      the      model      averaging      technique      has proven      effective      in      exploiting      the      trade-off      between specialty      and      generality,      addressing      the      issue      of      CF, and      yielding      performance      on      OOD      generalization tasks      that      are      not      included      in      the      continual      learn- ing."
            },
            {
              "id": 83,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "The      results      show      that      the      OOD      performance is      comparable      to      Llama3-8B-Instruct      itself      and      sig- nificantly      exceeds      that      of      methods      not      employing model      averaging. See      Appendix      B      for      a      compre- hensive      discussion      of      the      experimental      results."
            },
            {
              "id": 84,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "| 4      Conclusion In      this      paper,      we      introduce      THOUGHT-LIKE-PRO, a      framework      designed      to      enhance      the      logical      rea- soning      of      LLMs      by      imitating      Prolog-based      strictly logical      reasoning      trajectories      in      a      self-driven      man- ner."
            },
            {
              "id": 85,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "The      design      is      simple,      straightforward,      and effective,      ensuring      ease      of      use      in      industrial      appli- cations. Our      initial      findings      show      improved      task performance      on      both      specialized      reasoning      and      gen- eral      benchmarks."
            },
            {
              "id": 86,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "This      foundational      framework will      be      further      developed      and      extensively      evaluated across      various      tasks      to      refine      its      methodology      in 5      Limitations\n | Our      comparison      of      Llama3-8B-Instruct      and THOUGHT-LIKE-PRO      is      constrained      to      moderate- scale      language      modeling      tasks      due      to      limited      com- putational      resources."
            },
            {
              "id": 87,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      to      comprehen- sively      evaluate      and      better      understand      the      perfor- mance      potential      of      THOUGHT-LIKE-PRO,      it      may be      beneficial      to      explore      the      generation      of      multiple reasoning      paths      for      more      challenging      datasets."
            },
            {
              "id": 88,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "Intu- itively,      while      the      complexity      of      reasoning      paths      for more      complex      problems      increases      exponentially, the      difficulty      of      describing      these      problems      in      code only      increases      linearly."
            },
            {
              "id": 89,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Additionally,      we      did      not explore      the      performance      of      models      under      differ- ent      a      values      when      applying      the      model      averaging technique,      nor      did      we      balance      the      performance      of the      models      on      specialized      versus      generalized      tasks. | These      considerations      are      scenario-specific      and      left for      future      research."
            },
            {
              "id": 90,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "| References\n |       Josh      Achiam,      Steven      Adler,      Sandhini      Agarwal,      Lama       Ahmad,      Ilge      Akkaya,      Florencia      Leoni      Aleman,       Diogo      Almeida,      Janko      Altenschmidt,      Sam      Altman,       Shyamal      Anadkat,      et      al. 2023. Gpt-4      technical      report. |       arXiv      preprint      arXiv:2303.08774. | AI@      Meta. 2024. Llama      3      model      card."
            },
            {
              "id": 91,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "|       Jacob      Andreas,      Marcus      Rohrbach,      Trevor      Darrell,      and       Dan      Klein. 2016. Neural      module      networks. In      2016       IEEE      Conference      on      Computer      Vision      and      Pattern       Recognition      (CVPR),      pages      39-48."
            },
            {
              "id": 92,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "|       Maciej      Besta,      Nils      Blach,      Ales      Kubicek,      Robert      Gersten-       berger,      Michal      Podstawski,      Lukas      Gianinazzi,      Joanna       Gajda,      Tomasz      Lehmann,      Hubert      Niewiadomski,      Pi-       otr      Nyczyk,      et      al. 2024. Graph      of      thoughts:      Solving       elaborate      problems      with      large      language      models."
            },
            {
              "id": 93,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "In       Proceedings      of      the      AAAI      Conference      on      Artificial       Intelligence,      volume      38,      pages      17682-17690. | Kenneth      A      Bowen. 1979. Prolog. In      Proceedings      of      the       1979      annual      conference,      pages      14-23."
            },
            {
              "id": 94,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "|       Stephen      Casper,      Xander      Davies,      Claudia      Shi,       Thomas      Krendl      Gilbert,      Jérémy      Scheurer,      Javier       Rando,      Rachel      Freedman,      Tomasz      Korbak,      David       Lindner,      Pedro      Freire,      et      al. 2023. Open      problems       and      fundamental      limitations      of      reinforcement       learning      from      human      feedback. arXiv      preprint       arXiv:2307.15217."
            },
            {
              "id": 95,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "|       Mark      Chen,      Jerry      Tworek,      Heewoo      Jun,      Qiming       Yuan,      Henrique      Ponde      de      Oliveira      Pinto,      Jared      Ka-       plan,      Harri      Edwards,      Yuri      Burda,      Nicholas      Joseph,       Greg      Brockman,      et      al. 2021. Evaluating      large       language      models      trained      on      code. arXiv      preprint       arXiv:2107.03374."
            },
            {
              "id": 96,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "|       Xiaoliang      Chen,      Liangbin      Li,      Le      Chang,      Yunhe      Huang,       Yuxuan      Zhao,      Yuxiao      Zhang,      and      Dinuo      Li. 2023. Challenges      and      contributing      factors      in      the      utiliza-       tion      of      large      language      models      (IIms). arXiv      preprint       arXiv:2310.13343."
            },
            {
              "id": 97,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "|       Karl      Cobbe,      Vineet      Kosaraju,      Mohammad      Bavarian,       Mark      Chen,      Heewoo      Jun,      Lukasz      Kaiser,      Matthias       Plappert,      Jerry      Tworek,      Jacob      Hilton,      Reiichiro       Nakano,      et      al. 2021. Training      verifiers      to      solve      math       word      problems. arXiv      preprint      arXiv:2110.14168. |       Antonia      Creswell,      Murray      Shanahan,      and      Irina      Higgins. 2023."
            },
            {
              "id": 98,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Selection-inference:      Exploiting      large      language       models      for      interpretable      logical      reasoning. In      The       Eleventh      International      Conference      on      Learning      Rep- resentations. |       Guanting      Dong,      Hongyi      Yuan,      Keming      Lu,      Cheng-       peng      Li,      Mingfeng      Xue,      Dayiheng      Liu,      Wei      Wang,       Zheng      Yuan,      Chang      Zhou,      and      Jingren      Zhou. 2023."
            },
            {
              "id": 99,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "How      abilities      in      large      language      models      are      affected       by      supervised      fine-tuning      data      composition. arXiv       preprint      arXiv:2310.05492. |       Qingxiu      Dong,      Lei      Li,      Damai      Dai,      Ce      Zheng,      Zhiy-       ong      Wu,      Baobao      Chang,      Xu      Sun,      Jingjing      Xu,      and       Zhifang      Sui. 2022. A      survey      on      in-context      learning."
            },
            {
              "id": 100,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "|       arXiv      preprint      arXiv:2301.00234. |       Beliz      Gunel,      Jingfei      Du,      Alexis      Conneau,      and      Ves      Stoy-       anov. 2020. Supervised      contrastive      learning      for      pre-       trained      language      model      fine-tuning. arXiv      preprint       arXiv:2011.01403."
            },
            {
              "id": 101,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "|       Dan      Hendrycks,      Collin      Burns,      Steven      Basart,      Andy      Zou,       Mantas      Mazeika,      Dawn      Song,      and      Jacob      Steinhardt. |       2020. Measuring      massive      multitask      language      under-       standing. arXiv      preprint      arXiv:2009.03300."
            },
            {
              "id": 102,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "|       Dan      Hendrycks,      Collin      Burns,      Saurav      Kadavath,      Akul       Arora,      Steven      Basart,      Eric      Tang,      Dawn      Song,      and      Ja-       cob      Steinhardt. 2021. Measuring      mathematical      prob-       lem      solving      with      the      math      dataset. arXiv      preprint       arXiv:2103.03874. |       Drew      Hudson      and      Christopher      D      Manning. 2019."
            },
            {
              "id": 103,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Learn-       ing      by      abstraction:      The      neural      state      machine. In      Ad-       vances      in      Neural      Information      Processing      Systems,       volume      32. Curran      Associates,      Inc. Dave      Hulbert. 2023. Using      tree-of-thought      prompt-       ing      to      boost      chatgpt’s      reasoning. https://github. |       com/dave1010/tree-of-thought-prompting."
            },
            {
              "id": 104,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "|       Ahmed      Hussein,      Mohamed      Medhat      Gaber,      Eyad      Elyan,       and      Chrisina      Jayne. 2017. Imitation      learning:      A      sur-       vey      of      learning      methods. ACM      Computing      Surveys       (CSUR),      50(2):1-35. |       Mehran      Kazemi,      Najoung      Kim,      Deepti      Bhatia,      Xin       Xu,      and      Deepak      Ramachandran. 2023."
            },
            {
              "id": 105,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "LAMBADA:\n |       Backward      chaining      for      automated      reasoning      in      nat-       ural      language. In      Proceedings      of      the      61st      Annual       Meeting      of      the      Association      for      Computational      Lin-       guistics      (Volume      1:      Long      Papers),      pages      6547-6568,\n |       Toronto,      Canada. Association      for      Computational      Lin-       guistics."
            },
            {
              "id": 106,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "Takeshi      Kojima,      Shixiang      Shane      Gu,      Machel      Reid,      Yu-       taka      Matsuo,      and      Yusuke      Iwasawa. 2022. Large      lan-       guage      models      are      zero-shot      reasoners. Advances      in       neural      information      processing      systems,      35:22199-       22213. | Takeshi      Kojima,      Shixiang      Shane      Gu,      Machel      Reid,      Yu-  \n \n  taka      Matsuo,      and      Yusuke      Iwasawa. 2022."
            },
            {
              "id": 107,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Large      lan-  \n \n  guage      models      are      zero-shot      reasoners. Advances      in  \n \n  neural      information      processing      systems,      35:22199-  \n \n  22213. Abulhair      Saparov      and      He      He. 2022. Language      models  \n \n  are      greedy      reasoners:   \n \nA      systematic      formal      analysis      of  \n \n  chain-of-thought. arXiv      preprint      arXiv:2210.01240. Abulhair      Saparov      and      He      He. 2023."
            },
            {
              "id": 108,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Language      models  \n \n  are      greedy      reasoners:   \n \nA      systematic      formal      analysis  \n \n  of      chain-of-thought. In      The      Eleventh      International  \n \n  Conference      on      Learning      Representations. |       Yong      Lin,      Lu      Tan,      Hangyu      Lin,      Zeming      Zheng,      Renjie       Pi,      Jipeng      Zhang,      Shizhe      Diao,      Haoxiang      Wang,      Han       Zhao,      Yuan      Yao,      et      al. 2023."
            },
            {
              "id": 109,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Speciality      vs      gener-       ality:      An      empirical      study      on      catastrophic      forgetting       in      fine-tuning      foundation      models. arXiv      preprint       arXiv:2309.06256. | Haizhou      Shi,      Zihao      Xu,      Hengyi      Wang,      Weiyi      Qin,  \n \n  Wenyuan      Wang,      Yibin      Wang,      and      Hao      Wang. 2024. Continual      learning      of      large      language      models:   \n \nA      com-  \n \n  prehensive      survey."
            },
            {
              "id": 110,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:2404.16789. |       Jieyi      Long. 2023. Large      language      model      guided      tree-of-       thought. arXiv      preprint      arXiv:2305.08291. | Oyvind      Tafjord,      Bhavana      Dalvi      Mishra,      and      Peter  \n \n  Clark. 2020. Proofwriter:      Generating      implications,  \n \n  proofs,      and      abductive      statements      over      natural      lan-  \n \n  guage. arXiv      preprint      arXiv:2012.13048."
            },
            {
              "id": 111,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "|       Qing      Lyu,      Shreya      Havaldar,      Adam      Stein,      Li      Zhang,       Delip      Rao,      Eric      Wong,      Marianna      Apidianaki,      and       Chris      Callison-Burch. 2023. Faithful      chain-of-       thought      reasoning. Preprint,      arXiv:2301.13379. | Jason      Wei,      Xuezhi      Wang,      Dale      Schuurmans,      Maarten  \n \n  Bosma,      Fei      Xia,      Ed      Chi,      Quoc   \n \nV      Le,      Denny      Zhou,  \n \n  et      al."
            },
            {
              "id": 112,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "2022. Chain-of-thought      prompting      elicits      rea-  \n \n  soning      in      large      language      models. Advances      in      neural  \n \n  information      processing      systems,      35:24824—24837. |       Arvind      Neelakantan,      Quoc      V. Le,      Martin      Abadi,      An-       drew      McCallum,      and      Dario      Amodei. 2017. Learning       a      natural      language      interface      with      neural      programmer."
            },
            {
              "id": 113,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "In      International      Conference      on      Learning      Representa- | Jan      Wielemaker,      Tom      Schrijvers,      Markus      Triska,      and       Torbjérn      Lager. 2012. Swi-prolog. Theory      and      Prac-  \n \n  tice      of      Logic      Programming,      12(1-2):67-96. |       tions. NVIDIA      Corporation. 2023. Nvidia      a800. https:      //www.nvidia.com/en-us/geforce/       design-visualization/a800/. Accessed: | NVIDIA      Corporation. 2023."
            },
            {
              "id": 114,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "Nvidia      a800. https:      //www.nvidia.com/en-us/geforce/  \n \n  design-visualization/a800/. Accessed:  \n \n  What      Makes      In-Context      Learning      Work. Rethinking  \n \n  the      role      of      demonstrations:      What      makes      in-context  \n \n  learning      work? |       2024-04-30. Takayuki      Osa,      Joni      Pajarinen,      Gerhard      Neumann,      J      An-       drew      Bagnell,      Pieter      Abbeel,      Jan      Peters,      et      al. 2018."
            },
            {
              "id": 115,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Foundations      and      Trends®      in      Robotics,      7(1-2):1-179. | Takayuki      Osa,      Joni      Pajarinen,      Gerhard      Neumann,   \n \nJ      An-  \n \n  drew      Bagnell,      Pieter      Abbeel,      Jan      Peters,      et      al. 2018. Foundations      and      Trends®      in      Robotics,      7(1-2):1-179. Sean      Wu,      Michael      Koo,      Lesley      Blum,      Andy      Black,      Liyo  \n \n  Kao,      Fabien      Scalzo,      and      Ira      Kurtz. 2023."
            },
            {
              "id": 116,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "A      compar-  \n \n  ative      study      of      open-source      large      language      models,  \n \n  gpt-4      and      claude      2:      Multiple-choice      test      taking      in  \n \n  nephrology. arXiv      preprint      arXiv:2308.04709. |       An      algorithmic      perspective      on      imitation      learning. Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023a."
            },
            {
              "id": 117,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Logic-lm:      Em-       powering      large      language      models      with      symbolic       solvers      for      faithful      logical      reasoning. Preprint,       arXiv:2305.12295. | Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023a. Logic-lm:      Em-  \n \n  powering      large      language      models      with      symbolic  \n \n  solvers      for      faithful      logical      reasoning."
            },
            {
              "id": 118,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "Preprint,  \n \n  arXiv:2305.12295. Sen      Yang,      Xin      Li,      Leyang      Cui,      Lidong      Bing,      and       Wai      Lam. 2023. Neuro-symbolic      integration      brings  \n \n  causal      and      reliable      reasoning      proofs. arXiv      preprint  \n \n  arXiv:2311.09802. Shunyu      Yao,      Dian      Yu,      Jeffrey      Zhao,      Izhak      Shafran,  \n \n  Tom      Griffiths,      Yuan      Cao,      and      Karthik      Narasimhan."
            },
            {
              "id": 119,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "|       Liangming      Pan,      Alon      Albalak,      Xinyi      Wang,      and       William      Yang      Wang. 2023b. Logic-lm:      Empow-       ering      large      language      models      with      symbolic      solvers       for      faithful      logical      reasoning. arXiv      preprint       arXiv:2305.12295. | 2024. Tree      of      thoughts:      Deliberate      problem      solving  \n \n  with      large      language      models."
            },
            {
              "id": 120,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "Advances      in      Neural  \n \n  Information      Processing      Systems,      36. Xi      Ye      and      Greg      Durrett. 2022. The      unreliability      of      ex-  \n \n  planations      in      few-shot      prompting      for      textual      reason-  \n \n  ing."
            },
            {
              "id": 121,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "In      Advances      in      Neural      Information      Processing\n |       David      Rein,      Betty      Li      Hou,      Asa      Cooper      Stickland,      Jack-       son      Petty,      Richard      Yuanzhe      Pang,      Julien      Dirani,      Ju-       lian      Michael,      and      Samuel      R      Bowman. 2023. Gpqa:      A       graduate-level      google-proof      q&a      benchmark. arXiv       preprint      arXiv:2311.12022. |       Systems."
            },
            {
              "id": 122,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "Yuexiang      Zhai,      Shengbang      Tong,      Xiao      Li,      Mu      Cai,      Qing       Qu,      Yong      Jae      Lee,      and      Yi      Ma. 2023. Investigating      the       catastrophic      forgetting      in      multimodal      large      language       models. arXiv      preprint      arXiv:2309. 10313."
            },
            {
              "id": 123,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "|       Danilo      Neves      Ribeiro,      Shen      Wang,      Xiaofei      Ma,       Henghui      Zhu,      Rui      Dong,      Deguang      Kong,      Juli-       ette      Burger,      Anjelica      Ramos,      zhiheng      huang,       William      Yang      Wang,      George      Karypis,      Bing      Xiang,       and      Dan      Roth. 2023. STREET:      A      MULTI-TASK       STRUCTURED      REASONING      AND      EXPLANA-       TION      BENCHMARK."
            },
            {
              "id": 124,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "In      The      Eleventh      Interna-       tional      Conference      on      Learning      Representations. | Yifan      Zhang,      Jingqin      Yang,      Yang      Yuan,      and      Andrew  \n \n  Chi-Chih      Yao. 2024. Cumulative      reasoning      with  \n \n  large      language      models. Preprint,      arXiv:2308.04371. Zhuosheng      Zhang,      Aston      Zhang,      Mu      Li,      and      Alex  \n \n  Smola. 2022."
            },
            {
              "id": 125,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "Automatic      chain      of      thought      prompt-  \n \n  ing      in      large      language      models. arXiv      preprint  \n \n  arXiv:2210.03493. Wayne      Xin      Zhao,      Kun      Zhou,      Junyi      Li,      Tianyi      Tang,  \n \n  Xiaolei      Wang,      Yupeng      Hou,      Yinggian      Min,      Beichen  \n \n  Zhang,      Junjie      Zhang,      Zican      Dong,      et      al. 2023. A       survey      of      large      language      models."
            },
            {
              "id": 126,
              "title": "Bowen,      1979).      It      is      renowned      for      its      declarative programming      paradigm,      which      contrasts      with      the Subsequently,      the      Prolog      engine      is      employed      to      de- - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint  \n \n  arXiv:2303.18223. Zixuan      Zhou,      Xuefei      Ning,      Ke      Hong,      Tianyu      Fu,      Ji-  \n \n  aming      Xu,      Shiyao      Li,      Yuming      Lou,      Luning      Wang,  \n \n  Zhihang      Yuan,      Xiuhong      Li,      et      al. 2024. A      survey      on  \n \n  efficient      inference      for      large      language      models. arXiv  \n \n  preprint      arXiv:2404. 14294."
            }
          ],
          "content": ""
        },
        {
          "id": 127,
          "title": "A      Experimental      Details",
          "type": "section",
          "children": [
            {
              "id": 128,
              "title": "A      Experimental      Details - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A      Experimental      Details\nIn      this      subsection,      we      will      provide      detailed      infor- mation      on      the      equipment,      models,      datasets,      fine- tuning      methods,      and      hyperparameter      settings      used in      our      experiment."
            },
            {
              "id": 129,
              "title": "A      Experimental      Details - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "A.1_      Baseline,      Model,      and      Equipment Throughout      the      entire      process,      we   \n \n_      utilized two      A800-80GB      (NVIDIA      Corporation,      2023) GPUs      for      inference,      fine-tuning,      and      evaluation tasks."
            },
            {
              "id": 130,
              "title": "A      Experimental      Details - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "We      applied      our      THOUGHT-LIKE-PRO framework      by      continually      fine-tuning      the Llama3-8B-Instruct      model      which      can      be      accessed in      https:      //huggingface.co/meta-llama/ Meta-Llama-3-8B-Instruct. Our      baseline      was      established      by      assessing      the      un- trained      Llama3-8B-Instruct      model’s      performance on      various      datasets."
            },
            {
              "id": 131,
              "title": "A      Experimental      Details - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      initial      evaluation      gave      us a\n \n   benchmark      to      demonstrate      the      enhancements      our framework      could      provide. Additionally,      we      imple- mented      the      CARING      (Yang      et      al.,      2023)      method to      generate      Prolog      code      with      Llama3-8B-Instruct, assessing      the      correctness      of      solutions      this      code      pro- duced      to      problems."
            }
          ],
          "content": ""
        },
        {
          "id": 132,
          "title": "A.2.      Datasets",
          "type": "section",
          "children": [
            {
              "id": 133,
              "title": "A.2.      Datasets - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A.2. Datasets\nWe      evaluated      THOUGHT-LIKE-PRO      across      seven prominent      LLM      benchmark      datasets:      two      fo- cused      on      mathematical      reasoning      (GSM8K      and MATH),      two      on      knowledge-based      question      answer- ing      (MMLU      and      GPQA),      two      on      logical      reasoning (ProofWriter      and      PrOntoQA),      and      one      on      code      gen- eration      (HumanEval)."
            }
          ],
          "content": ""
        },
        {
          "id": 134,
          "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com-",
          "type": "section",
          "children": [
            {
              "id": 135,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com-\nprises      8,500      high-quality,      linguistically      diverse grade      school      math      word      problems      created      by      hu- man      experts."
            },
            {
              "id": 136,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      randomly      selected      2,000      entries from      this      dataset      to      generate      reasoning      trajectories and      used      the      balance      to      gauge      the      effectiveness      of our      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 137,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Given      that the      number      of      reasoning      trajectories      generated      by the      Prolog      engine      is      variable,      we      capped      the      trajec- tories      for      each      problem      at      10      to      mitigate      data      dis- tribution      bias. Consequently,      we      produced      20,000 pieces      of      training      data      for      the      LLM."
            },
            {
              "id": 138,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "MATH:      MATH      (Hendrycks      et      al.,      2021)      en- compasses   \n \na      collection      of      12,500      challenging competition-level      mathematics      problems,      each accompanied      by      detailed      step-by-step      solutions."
            },
            {
              "id": 139,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "These      solutions      facilitate      training      models      to      gen- most      demanding      subset      (Pan      et      al.,      2023b),      “Fic-  \n \n  tional      Characters”,      with   \n \na      depth      level      of      5,      com- erate      complete      derivations      and      explanations."
            },
            {
              "id": 140,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  leveraged      this      difficult      dataset      to      assess      the      OOD performance      of      our      THOUGHT-LIKE-PRO      frame- work,      noting      that      the      LLM      was      not      previously trained      on      it."
            },
            {
              "id": 141,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "MMLU:      MMLU      (Hendrycks      et      al.,      2020)      bench- mark      is      designed      to      gauge      the      knowledge      ac- quired      during      pretraining      by      assessing      models in      exclusively      zero-shot      and      few-shot      scenarios, which      closely      aligns      with      methods      used      to      evalu- ate      human      capabilities."
            },
            {
              "id": 142,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "It      encompasses      57      sub- jects,      spanning      STEM,      the      humanities,      and      the social      sciences,      among      others. Given      its      wide content      range      and      varying      difficulty,      we      utilize the      entire      dataset      to      evaluate      the      THOUGHT-LIKE- PRO      framework’s      generalization      abilities."
            },
            {
              "id": 143,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Notably, within      the      THOUGHT-LIKE-PRO      framework,      the LLM      does      not      have      exposure      to      MMLU      during      the training      phase. GPQA:      GPQA      (Rein      et      al.,      2023)      represents   \n \na formidable      dataset      aimed      at      testing      the      capabilities of      LLMs      alongside      scalable      oversight      mechanisms."
            },
            {
              "id": 144,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "The      dataset      comprises      448      multiple-choice      ques- tions      crafted      by      domain      experts      in      disciplines      such as      biology,      physics,      and      chemistry. We      employ this      complete      set      to      determine      the      generalization capacity      of      the      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 145,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "ProofWriter:      ProofWriter      (Tafjord      et      al.,      2020) is   \n \na      widely      utilized      logical      reasoning      dataset      com- prising      many      small-scale      knowledge      bases      ex- pressed      in      English,      each      containing      facts      and      rules."
            },
            {
              "id": 146,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Each      knowledge      base      is      paired      with   \n \na      set      of      ques- tions,      also      in      English,      which      can      be      definitively proven      as      true      or      false      via      proofs      of      varying      depths, or      the      answer      may      be      categorized      as      “unknown” under      an      open-world      assumption      (OWA)      or      pre- sumed      negative      under   \n \na      closed-world      assumption (CWA)."
            },
            {
              "id": 147,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "This      dataset      contains      subsets      of      varying difficulty,      we      have      selected      the      most      challenging subset      within      the      OWA      setting,      which      includes      482 knowledge      bases      and      10,190      questions. We      initially randomly      sampled      100      knowledge      bases      and      their corresponding      questions      to      create      reasoning      trajec- tories."
            },
            {
              "id": 148,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "We      restricted      the      number      of      allowed      reason- ing      trajectories      per      question      to      five. Ultimately,      we utilized      all      remaining      data      to      evaluate      the      perfor- mance      of      our      THOUGHT-LIKE-PRO      framework."
            },
            {
              "id": 149,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "PrOntoQA:      PrOntoQA      (Saparov      and      He,      2022) is   \n \na      synthetic      question-and-answer      dataset      designed to      test      the      logical      reasoning      capabilities      of      LLMs. Each      instance      is      structured      to      verify      the      validity      of a\n \n   statement      within   \n \na      specific      context. We      chose      the prising      500      statement-context      pairs."
            },
            {
              "id": 150,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "We      randomly selected      100      statement-context      pairs      to      generate reasoning      trajectories      and      employed      the      remain- ing      data      for      assessing      the      THOUGHT-LIKE-PRO framework’s      capabilities. The      maximum      number of      reasoning      trajectories      per      question      was      set      to      5."
            },
            {
              "id": 151,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "HumanEval:      HumanEval      (Chen      et      al.,      2021) comprises      164      unique      programming      problems designed      to      evaluate      language      comprehension, algorithmic      proficiency,      and      elementary      mathe- matics,      some      of      which      are      akin      to      basic      soft- ware      interview      questions."
            },
            {
              "id": 152,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "This      dataset      is      em- ployed      to      assess      the      functional      correctness      of      pro- grams      synthesized      from      documentation      strings."
            },
            {
              "id": 153,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Given      that      HumanEval      is      unrelated      to      the      two      do- mains—mathematical      reasoning      and      logical      rea- soning—used      for      training      the      LLM,      we      employ      the entire      dataset      to      assess      the      THOUGHT-LIKE-PRO framework’s      performance      on      general      tasks      follow- ing      specialized      training."
            },
            {
              "id": 154,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "A.3      Fine-Tuning      Method      and Hyperparameter      Settings We      perform      typical      continual      supervised      fine- tuning      based      on      the      checkpoint      of      Llama3-8B- Instruct. Our      training      framework      follows      the      im- plementation      of      https:      //github.com/hiyouga/ LLaMA-Factory      using      the      LLaMA-Factory."
            },
            {
              "id": 155,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "we employed      the      Adam      optimizer      in      the      training      pro- cess      and      selected   \n \na      consistent      learning      rate      of      le—6 for   \n \n3      epochs      of      training. To      ensure      comparability between      the      single      trajectory      and      multiple      trajec- tory      datasets,      despite      their      differing      data      volumes, we      have      adjusted      the      training      regimen."
            },
            {
              "id": 156,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Specifi- cally,      the      model      trained      on      the      single      trajectory dataset      undergoes      an      equivalent      number      of      train- ing      steps      as      the      model      trained      on      the      multiple      tra- jectory      dataset      for   \n \n3      epochs."
            },
            {
              "id": 157,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "During      model      in- ference      and      evaluation,      we      configured      the      sam- pling      settings      with   \n \na      temperature      of      0.6      and   \n \na top_p      value      of      0.9,      based      on      the      default      recom- mended      parameters      from      https:      //huggingface. co/blog/1lama3."
            },
            {
              "id": 158,
              "title": "GSM8K:      GSM8K      (Cobbe      et      al.,      2021)      com- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "For      model      averaging,      we      imple- ment   \n \na   \n \n=      0.5      for   \n \na      balanced      averaging      between the      base      model      and      the      fine-tuned      model."
            }
          ],
          "content": ""
        },
        {
          "id": 159,
          "title": "B_      Analysis      of      Experimental      Results",
          "type": "section",
          "children": [
            {
              "id": 160,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "B_      Analysis      of      Experimental      Results\nIn      our      study,      we      assessed      the      performance      of      both the      baseline      model,      Llama3-8B-Instruct,      and      our PrOntoQA. However,      the      improvements      in      algo-  \n \n  rithmic      reasoning      tasks      are      comparatively      modest."
            },
            {
              "id": 161,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "proposed      framework,      which      was      tested      under      four  \n \n  distinct      configurations:      1)      Full      implementation      fea- turing      both      model      averaging      and      multiple      trajecto- ries      (MA+multiple),      2)      Model      averaging      applied to   \n \na      single      trajectory      per      instruction      (MA+single), 3)      Multiple      trajectories      without      model      averaging\n(multiple),      and      4)   \n \nA      single      trajectory      without      model averaging      (single)."
            },
            {
              "id": 162,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "This      comparison      allows      us      to discern      the      contributions      of      key      components      within our      framework,      particularly      the      impact      of      model averaging      and      the      learning      of      multiple      reasoning trajectories      for      the      same      instruction. Additionally, we      incorporated      the      CARING      method      (Yang      et      al., 2023)      within      our      experimental      setup."
            },
            {
              "id": 163,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      was utilized      to      evaluate      the      final      reasoning      accuracy, relying      solely      on      Prolog      engine      inferences,      without the      requirement      for      training      LLMs      or      using      them to      derive      final      answers. All      experiment      results      are      presented      in      Table      1. We      report      the      CARING      results      across      three      reason- ing      tasks."
            },
            {
              "id": 164,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "The      Prolog      engine      delivered      completely accurate      reasoning      outputs      for      the      ProofWriter and      PrOntoQA      tasks      and      achieved      an      accuracy      of 98.19%      for      the      GSM8K      task."
            },
            {
              "id": 165,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "The      slightly      lower accuracy      in      GSM8K      can      be      attributed      to      errors in      the      translation      of      facts      or      rules      and      formatting- related      issues,      although      the      reasoning      trajectories are      correct."
            },
            {
              "id": 166,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Consequently,      we      posit      that      the      per- formance      of      CARING      represents      the      practical      up- per      limit      for      the      proposed      THOUGHT-LIKE-PRO framework. Across      all      tasks,      our      framework,      con- figured      in      four      distinct      ways,      demonstrated      sub- stantial      performance      improvements      over      the      base- line      model."
            },
            {
              "id": 167,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Notably,      the      configuration      employing the      ’multiple’      method      without      model      averaging recorded      the      highest      performance,      consistent      with our      expectations,      as      performing      domain-specific fine-tuning      and      forgoing      model      averaging      tend      to enhance      domain-specific      expertise."
            },
            {
              "id": 168,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "In      the      GSM8K task,      the      Llama3-8B-Instruct      model      achieved      an accuracy      rate      of      79.6%. In      contrast,      our      frame- work      marked   \n \na      significant      improvement,      attaining an      accuracy      of      87.81%."
            },
            {
              "id": 169,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "This      improvement      was particularly      pronounced      in      datasets      requiring      log- ical      reasoning,      especially      in      the      ProofWriter      and PrOntoQA      datasets,      where      the      model      utilizing      mul- tiple      reasoning      paths      achieved      98.19%      and      100% accuracy,      respectively."
            },
            {
              "id": 170,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "The      experimental      results      for      reasoning      tasks      also suggest      that      imitating      strictly      logical      reasoning      tra- jectories      can      significantly      enhance      performance      in logical      reasoning      tasks,      such      as      ProofWriter      and These      findings      not      only      confirm      the      efficacy      of imitating      strictly      correct      logical      reasoning      trajecto- ries      in      aligning      the      reasoning      capabilities      of      LLMs, but      also      suggest      that      LLMs      may      be      better      suited to      modeling      natural      language      problems      using      the relatively      straightforward      Prolog      language,      rather than      translating      these      problems      into      more      complex mainstream      programming      languages      like      Python."
            },
            {
              "id": 171,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "We      can      assess      the      performance      differences      be- tween      the      ‘single’      and      ‘multiple’      training      ap- proaches      to      validate      the      effectiveness      of      utilizing multiple      reasoning      paths      in      training."
            },
            {
              "id": 172,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Across      all three      reasoning      tasks,      it      is      evident      that      training      with a\n \n   single      reasoning      path      can      enhance      performance relative      to      baseline      methods."
            },
            {
              "id": 173,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "However,      there      ex- ists   \n \na      significant      performance      disparity      between      the ‘multiple’      and      ‘single’      approaches,      underscoring the      importance      of      training      with      multiple      reasoning trajectories      for      each      instruction. This      performance gap      may      be      attributed      to      the      inherent      multi-modal nature      of      LLMs."
            },
            {
              "id": 174,
              "title": "B_      Analysis      of      Experimental      Results - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Training      on      multiple      correct      tra- jectories      toward      the      same      target      could      promote robust      learning      of      multi-modal      distributions      and significantly      improve      the      robustness      of      LLM’s      rea- soning."
            }
          ],
          "content": ""
        },
        {
          "id": 175,
          "title": "To      evaluate      the      performance      of      THOUGHT-LIKE-",
          "type": "section",
          "children": [
            {
              "id": 176,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "To      evaluate      the      performance      of      THOUGHT-LIKE-\nPRO      on      general      OOD      tasks,      we      selected      four      bench- marks      commonly      employed      to      assess      the      com- mon      knowledge      and      abilities      of      LLMs:      MMLU (Hendrycks      et      al.,      2020),      GPQA      (Rein      et      al., 2023),      HumanEval      (Chen      et      al.,      2021),      and      MATH (Hendrycks      et      al.,      2021)."
            },
            {
              "id": 177,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "These      benchmarks      were chosen      to      measure      the      impacts      of      continual      fine- tuning      on      three      distinct      reasoning      tasks. Our      obser- vations      indicate      that      Llama3-8B-Instruct      achieves almost      the      highest      performance      across      these      tasks, and      exhibits      signs      of      catastrophic      forgetting      of      con- tinual      training."
            },
            {
              "id": 178,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "However,      the      implementation      of model      averaging      in      THOUGHT-LIKE-PRO      effec- tively      navigates      the      trade-off      between      specializa- tion      and      generalization,      significantly      enhancing the      OOD      performance."
            },
            {
              "id": 179,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      results      show      results of      67.9%      on      MMLU      and      33.8%      on      GPQA      with MA+multiple,      compared      to      domain-specific      train- ing,      with      only   \n \na      slight      decrease      in      performance on      the      reasoning      tasks."
            },
            {
              "id": 180,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Thus,      model      averaging serves      as   \n \na      viable      strategy      to      mitigate      catastrophic forgetting,      enhancing      both      the      robustness      and      gen- eralizability      of      our      approach."
            },
            {
              "id": 181,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "While      we      observe   \n \na      decline      in      performance      on the      MMLU,      GPQA,      and      HumanEval      datasets,      the  \n \n  performance      on      the      MATH      dataset      intriguingly      re- mains      consistent      with      the      base      model."
            },
            {
              "id": 182,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "This      sta- bility      may      be      attributed      to      the      inherent      nature      of the      MATH      tasks,      which      are      graduate-level      prob- lems      requiring      arithmetic      and      logical      reasoning skills. These      skills      have      been      effectively      cultivated through      the      THOUGHT-LIKE-PRO      approach      ap- plied      within      the      GSM8K,      ProofWriter,      and      PrOn- toQA      datasets."
            },
            {
              "id": 183,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "This      approach      appears      to      success- fully      generalize      to      MATH      tasks      and      mitigate      the negative      impacts      of      catastrophic      forgetting. More- over,      these      results      suggest      that      the      THOUGHT- LIKE-PRO      strategy      possesses   \n \na      potential      broad      gen- eralization      capability      for      OOD      reasoning      tasks."
            },
            {
              "id": 184,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "C      Prompt      demo In      this      section,      we      present      the      few-shot      demonstra- tion      prompt      utilized."
            },
            {
              "id": 185,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "It      should      be      noted      that      due to      space      constraints,      all      prompts      are      displayed      in their      1-shot      condition,      with      the      black      text      denoting the      prompt      sent      to      the      LLM      and      the      red      text      indi- cating      the      model’s      response. For      more      demonstra- tions,      we      refer      the      readers      to      https:      //anonymous. 4open."
            },
            {
              "id": 186,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "science/r/Prolog_datasets-9875. Listing      1:      Construct   \n \na      prompt      prompt,.-,      to      guide      the LLM      to      generate      Prolog      code      contains      rules      7,      facts      F, and      targets   \n \n7      based      on      the      problem."
            },
            {
              "id": 187,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      assistant      who      xx  \n \n  produces      Prolog      codex*      to      solve  \n \n  problems. <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>\n \n \n  Could      you      please      help      me      write      Prolog  \n \n  code      to      solve      the      following  \n \n  arithmetic      reasoning      problem?"
            },
            {
              "id": 188,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "You  \n \n  should      use      consistent      variable      names  \n \n  for      coreferent      entities      or  \n \n  attributes      throughout      the      code. Start      by      coding      the      given      context  \n \n  after      the      \"/x      Context      */”      comment. Then      code      the      query      that      represents  \n \n  the      question      after      the      \"/x      Query      x/”  \n \n  comment."
            },
            {
              "id": 189,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 190,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 191,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  7x      Context      */ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 192,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  Eis   \n \n8   \n \nx      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 193,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is      H   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular),  \n \n  overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 194,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. 7*      Query      x/  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total). <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 195,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 196,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 197,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 198,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  /*x      Context      */  \n \n  %      facts  \n \n  sentences_per_minute      (6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536). %      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \nx      SessionMinutes."
            },
            {
              "id": 199,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n’       erased_sentences      (Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 200,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday)   \n \n,       total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      x*/  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences). <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>  \n \n  Excellent      work!"
            },
            {
              "id": 201,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race. sent-2:      They      have      one      week      to      run      30  \n \n  miles."
            },
            {
              "id": 202,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days. sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days?"
            },
            {
              "id": 203,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>assistant      <|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem. Here      is      the  \n \n  Prolog      code:\n \n \n  ~*~      prolog  \n \n  7x      Context      x*/  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg(2/3). jesse_day_four(10). mia_first_four_days_avg      (3)."
            },
            {
              "id": 204,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total(Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 205,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg      (DayAvg)   \n \n,       Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 206,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance);\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 207,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages   \n \n(      Average)."
            },
            {
              "id": 208,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "pro       Listing      2:      Construct   \n \na      prompt      prompt’,      to      guide      the LLM      to      generate   \n \na      natural      language      CoT-like      reasoning logic      chain      based      on      the      problem,      Prolog      code,      and reasoning      tree."
            },
            {
              "id": 209,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      and      smart      assistant  \n \n  that      helps      people      solve      problems. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>\n \n \n \nI      need      assistance      in      translating   \n \na       reasoning      tree      generated      by   \n \na      Prolog  \n \n  engine      into   \n \na      natural      language  \n \n  description."
            },
            {
              "id": 210,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "To      facilitate      this,   \n \nI       am      providing      the      original      problem,  \n \n  the      relevant      Prolog      code,      and      the  \n \n  reasoning      tree      itself. Please      review  \n \n  these      carefully      and      provide   \n \na       fluent      and      accurate      narrative      of      the  \n \n  reasoning      process. Thanks      for      your  \n \n  help!"
            },
            {
              "id": 211,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "xxkInstructions      Startx*  \n \n  Translate      the      provided      reasoning      tree  \n \n  into   \n \na      clear      and      logical      natural  \n \n  language      explanation. Many      thanks      for      your      help! I      am      looking  \n \n  forward      to      your      response! *xkInstructions      End**\nHere      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour."
            },
            {
              "id": 212,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage. sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make?"
            },
            {
              "id": 213,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog_code:\n/*      Context      x*/ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 214,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  E      is   \n \n8   \n \n*      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 215,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is      H   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular), overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 216,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. /*      Query      */  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total)."
            },
            {
              "id": 217,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog      reasoning      tree:\n \n \n  =>(=>(,      (=>(,      (=>(,      (=>      C(builtin(true),      wage  \n \n  (18.0)),      =>Cbuiltin(is(144.0,      x*(8,  \n \n  18.0))),      is(144.0,      *(8,      18.0)))),  \n \n  regular_earning_for_day(144.0)),  \n \n  ,(=>(,      (=>(=>(builtin(is(2,      -(10,      8))  \n \n  ),      is(2,      -(1@,      8))),      overtime_hours  \n \n  (2)),      ,C=>Cbuiltin(,      (g(wage(18.0)),  \n \n  g(is(27.0,      *(1.5,      18.0))))),  \n \n  overtime_wage(27.0)),      =>(Cbuiltin(is  \n \n  (54.0,      *(2,      27.0))),      is(54.0,      *(2,  \n \n  27.0))))),      overtime_earning_for_day  \n \n  (54.0)),      =>(Cbuiltin(is(198.0,  \n \n  +(144.0,      54.0))),      i18(198.0,      +(144.0,  \n \n  54.0))))),      total_earning_for_day  \n \n  (198.0)),      =>Cbuiltin(is(990.0,      x*(5,  \n \n  198.0))),      18(990.0,      *(5,      198.0)))),  \n \n  total_earning_for_5_days(990.0)),  \n \n  solve      (990.0)   \n \n)       <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 218,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Tina      earns      $18.00      per      hour      according      to  \n \n  the      information      provided."
            },
            {
              "id": 219,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "She      has  \n \n  shifts      where,      if      she      works      more      than  \n \n  8      hours,      the      additional      hours      are  \n \n  considered      overtime. Overtime      pay      is  \n \n  calculated      at      one      and   \n \na      half      times  \n \n  her      regular      hourly      wage."
            },
            {
              "id": 220,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "On   \n \na      typical      day,      if      Tina      works      10      hours  \n \n  ,      this      includes   \n \n2      hours      of      overtime  \n \n  since      she      exceeds      the      8-hour      regular  \n \n  work      period. Her      regular      earnings  \n \n  for      working   \n \n8      hours   \n \na      day      at      $18.00  \n \n  per      hour      amounts      to      $144.00      per      day."
            },
            {
              "id": 221,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "For      the   \n \n2      hours      of      overtime,      since  \n \n  the      overtime      rate      is      $27.00      per      hour  \n \n  (1.5      times      her      regular      hourly      wage)  \n \n  ,      she      earns      $54.00      from      overtime  \n \n  work      per      day. Therefore,      her      total      earnings      for   \n \na       single      day,      combining      her      regular  \n \n  and      overtime      earnings,      are      $198.00."
            },
            {
              "id": 222,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Over      the      course      of   \n \n5      days,      working  \n \n  the      same      hours      daily,      Tina      makes   \n \na       total      of      $990.00,      factoring      in      all  \n \n  regular      pay      and      overtime      across      the  \n \n  five      days. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 223,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 224,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 225,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? Prolog      code:  \n \n  /*      Context      x*/  \n \n  %      facts  \n \n  sentences_per_minute(6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536)."
            },
            {
              "id": 226,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \n*      SessionMinutes."
            },
            {
              "id": 227,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n,       erased_sentences(Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 228,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday),  \n \n  total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      */  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences)."
            },
            {
              "id": 229,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(builtin(true),  \n \n  total_end_sentences      (536)),  \n \n  ,(=>(,      (=>(Cbuiltin(true),  \n \n  typing_sessions([20,      15,      18])),  \n \n  builtin(,      (g(maplist(sentences_typed,  \n \n  [20,      15,      18],      [120,      90,      108])),      ,Cg  \n \n  (sum_list([120,      90,      108],      318)),      ,(g  \n \n  (erased_sentences(40)),      g(is(278,  \n \n  ~(318,      40)))))))),  \n \n  total_sentences_typed_today      (278)),  \n \n  =>(builtin(is(258,      -(536,      278))),      is  \n \n  (258,      -(536,      278))))),  \n \n  start_sentences(258)),      solve(258))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 230,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Janice\\\\\\'s      typing      speed      is   \n \n6      sentences      per  \n \n  minute."
            },
            {
              "id": 231,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Today,      she      had      three  \n \n  separate      typing      sessions:      the      first  \n \n  lasted      for      20      minutes,      the      second  \n \n  for      15      minutes,      and      the      third      for      18  \n \n  minutes. Over      these      sessions,      she  \n \n  initially      typed   \n \na      total      of      318  \n \n  sentences."
            },
            {
              "id": 232,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "However,      she      made   \n \na       mistake      and      had      to      erase      40  \n \n  sentences,      leaving      her      with      278  \n \n  sentences      typed      effectively      today. By      the      end      of      the      day,      the      total  \n \n  number      of      sentences      on      her      paper      was  \n \n  536."
            },
            {
              "id": 233,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "To      find      out      how      many      sentences  \n \n  were      on      the      paper      at      the      beginning  \n \n  of      the      day,      we      subtract      the  \n \n  sentences      typed      today      (278)      from      the  \n \n  total      at      the      end      of      the      day      (536). Hence,      Janice      started      the      day      with  \n \n  258      sentences      already      on      her      paper."
            },
            {
              "id": 234,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race."
            },
            {
              "id": 235,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      They      have      one      week      to      run      30  \n \n  miles. sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days."
            },
            {
              "id": 236,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days? Prolog      code:  \n \n  7*      Context      */  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg      (2/3). jesse_day_four(10). mia_first_four_days_avg(3)."
            },
            {
              "id": 237,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total      (Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 238,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg(DayAvg),  \n \n  Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 239,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance)      ;\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 240,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages(      Average)."
            },
            {
              "id": 241,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(,      (=>Cbuiltin(;      (->(=(jesse,  \n \n  jesse),      jesse_first_four_days_total  \n \n  (12.0)),      ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ;(->(=(jesse,      jesse),  \n \n  jesse_first_four_days_total(12.0)),  \n \n  ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ,(=>(      true,      total_distance(30)),  \n \n  ,(=>(builtin(is(18.0,      -(30,      12.0))),  \n \n  is(18.0,      -(30,      12.0))),      =>(Cbuiltin(      is(6.0,      /(18.0,      3))),      is(6.0,  \n \n  /(18.@,      3)))))),      remaining_avg      (jesse  \n \n  ,      6.0)),      ,(C=>C,      (=>Cbuiltin(;      (->(=¢  \n \n  mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ;(->(=(mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ,(=>(builtin(true),      total_distance  \n \n  (30)),      builtin(,(gCis(18,      -(30,      12))  \n \n  ),      gCis(6,      /(18,      3))))))),  \n \n  remaining_avg(mia,      6)),      =>(Cbuiltin(      is(6.0,      /(+(6.0,      6),      2))),      is(6.@,  \n \n  /(+(6.0,      6),      2))))),  \n \n  average_of_averages(6.0)),      solve  \n \n  (6.0))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 242,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Jesse      and      Mia      are      competing      in   \n \na      week-  \n \n  long      race      where      each      needs      to      run   \n \na       total      of      30      miles."
            },
            {
              "id": 243,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "Jesse      averages   \n \n(      \\\\\\\\frac{2}{3}   \n \n)      mile      each      day      for      the  \n \n  first      three      days,      totaling   \n \n2      miles,  \n \n  and      then      runs      10      miles      on      the      fourth  \n \n  day,      making      it   \n \na      total      of      12      miles  \n \n  in      the      first      four      days."
            },
            {
              "id": 244,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "Mia      averages  \n \n  3      miles      per      day      over      the      first      four  \n \n  days,      totaling      12      miles      as      well. Given      that      they      both      need      to      complete      30  \n \n  miles      by      the      end      of      the      week,      both  \n \n  Jesse      and      Mia      have      18      miles      left      to  \n \n  run      over      the      final      three      days      after  \n \n  the      first      four      days."
            },
            {
              "id": 245,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "This      results      in  \n \n  each      needing      to      run      an      average      of   \n \n6       miles      per      day      over      the      last      three  \n \n  days. To      find      the      average      of      their      averages  \n \n  over      these      remaining      three      days,      we  \n \n  calculate   \n \n(      \\\\\\\\frac{(6+6)}{2}      ),      which  \n \n  remains   \n \n6      miles      per      day."
            },
            {
              "id": 246,
              "title": "To      evaluate      the      performance      of      THOUGHT-LIKE- - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "Therefore,  \n \n  the      average      of      their      average      daily  \n \n  miles      over      the      final      three      days      that  \n \n  they      need      to      run      is   \n \n6      miles."
            }
          ],
          "content": ""
        },
        {
          "id": 247,
          "title": "Here      is      the      problem:",
          "type": "section",
          "children": [
            {
              "id": 248,
              "title": "Here      is      the      problem: - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 249,
              "title": "Here      is      the      problem: - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 250,
              "title": "Here      is      the      problem: - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  7x      Context      */ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00). %      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 251,
              "title": "Here      is      the      problem: - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1. %      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  Eis   \n \n8   \n \nx      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 252,
              "title": "Here      is      the      problem: - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is      H   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular),  \n \n  overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 253,
              "title": "Here      is      the      problem: - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. 7*      Query      x/  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total). <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 254,
              "title": "Here      is      the      problem: - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 255,
              "title": "Here      is      the      problem: - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 256,
              "title": "Here      is      the      problem: - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem."
            },
            {
              "id": 257,
              "title": "Here      is      the      problem: - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the  \n \n  Prolog      code:\n \n \n  ~**prolog  \n \n  /*x      Context      */  \n \n  %      facts  \n \n  sentences_per_minute      (6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536). %      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \nx      SessionMinutes."
            },
            {
              "id": 258,
              "title": "Here      is      the      problem: - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n’       erased_sentences      (Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 259,
              "title": "Here      is      the      problem: - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday)   \n \n,       total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      x*/  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences). <|eot_id|><|start_header_id|>user<]|  \n \n  end_header_id|>  \n \n  Excellent      work!"
            },
            {
              "id": 260,
              "title": "Here      is      the      problem: - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race. sent-2:      They      have      one      week      to      run      30  \n \n  miles."
            },
            {
              "id": 261,
              "title": "Here      is      the      problem: - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days. sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days?"
            },
            {
              "id": 262,
              "title": "Here      is      the      problem: - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>assistant      <|  \n \n  end_header_id|>  \n \n  Sure! I      am      happy      to      help      you      write  \n \n  Prolog      code      to      solve      this      arithmetic  \n \n  reasoning      problem. Here      is      the  \n \n  Prolog      code:\n \n \n  ~*~      prolog  \n \n  7x      Context      x*/  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg(2/3). jesse_day_four(10). mia_first_four_days_avg      (3)."
            },
            {
              "id": 263,
              "title": "Here      is      the      problem: - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total(Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 264,
              "title": "Here      is      the      problem: - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg      (DayAvg)   \n \n,       Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 265,
              "title": "Here      is      the      problem: - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance);\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 266,
              "title": "Here      is      the      problem: - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages   \n \n(      Average)."
            },
            {
              "id": 267,
              "title": "Here      is      the      problem: - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "pro       Listing      2:      Construct   \n \na      prompt      prompt’,      to      guide      the LLM      to      generate   \n \na      natural      language      CoT-like      reasoning logic      chain      based      on      the      problem,      Prolog      code,      and reasoning      tree."
            },
            {
              "id": 268,
              "title": "Here      is      the      problem: - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "<|begin_of_text|><|start_header_id|>  \n \n  system<|end_header_id|>  \n \n  You      are   \n \na      helpful      and      smart      assistant  \n \n  that      helps      people      solve      problems. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>\n \n \n \nI      need      assistance      in      translating   \n \na       reasoning      tree      generated      by   \n \na      Prolog  \n \n  engine      into   \n \na      natural      language  \n \n  description."
            },
            {
              "id": 269,
              "title": "Here      is      the      problem: - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "To      facilitate      this,   \n \nI       am      providing      the      original      problem,  \n \n  the      relevant      Prolog      code,      and      the  \n \n  reasoning      tree      itself. Please      review  \n \n  these      carefully      and      provide   \n \na       fluent      and      accurate      narrative      of      the  \n \n  reasoning      process. Thanks      for      your  \n \n  help!"
            },
            {
              "id": 270,
              "title": "Here      is      the      problem: - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "xxkInstructions      Startx*  \n \n  Translate      the      provided      reasoning      tree  \n \n  into   \n \na      clear      and      logical      natural  \n \n  language      explanation. Many      thanks      for      your      help! I      am      looking  \n \n  forward      to      your      response! *xkInstructions      End**"
            }
          ],
          "content": ""
        },
        {
          "id": 271,
          "title": "Here      is      the      problem:",
          "type": "section",
          "children": [
            {
              "id": 272,
              "title": "Here      is      the      problem: - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      problem:\n \n \n  sent-1:      Tina      makes      $18.00      an      hour. sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  sent-3:      she      is      eligible      for      overtime,  \n \n  sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage."
            },
            {
              "id": 273,
              "title": "Here      is      the      problem: - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "sent-5:      If      she      works      10      hours      every      day  \n \n  for   \n \n5      days,  \n \n  sent-6:      how      much      money      does      she      make? Here      is      the      prolog_code:\n/*      Context      x*/ %\n \n   sent-1:      Tina      makes      $18.00      an      hour. wage(18.00)."
            },
            {
              "id": 274,
              "title": "Here      is      the      problem: - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "%      sent-2:      If      she      works      more      than   \n \n8      hours  \n \n  per      shift,  \n \n  %      sent-3:      she      is      eligible      for      overtime,  \n \n  %      sent-4:      which      is      paid      by      your      hourly  \n \n  wage   \n \n+      1/2      your      hourly      wage. overtime_wage(W)      :-  \n \n  wage(W1),  \n \n  Wis      1.5   \n \n*      W1."
            },
            {
              "id": 275,
              "title": "Here      is      the      problem: - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "%      earnings      without      overtime      for   \n \n1      day  \n \n  regular_earning_for_day(E)      :-  \n \n  wage(W),  \n \n  E      is   \n \n8   \n \n*      W. %      sent-5:      If      she      works      10      hours      every  \n \n  day      for   \n \n5      days,  \n \n  overtime_hours(H)      :-  \n \n  H      is      10   \n \n-      8."
            },
            {
              "id": 276,
              "title": "Here      is      the      problem: - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "%      overtime      earnings      for   \n \n1      day  \n \n  overtime_earning_for_day(E)      :-  \n \n  overtime_hours(H),  \n \n  overtime_wage(W),  \n \n  E      is      H   \n \n*      W. %      total      earnings      for   \n \n1      day  \n \n  total_earning_for_day(Total)      :-  \n \n  regular_earning_for_day      (Regular), overtime_earning_for_day      (Overtime),  \n \n  Total      is      Regular   \n \n+      Overtime."
            },
            {
              "id": 277,
              "title": "Here      is      the      problem: - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "%      total      earnings      for   \n \n5      days  \n \n  total_earning_for_5_days(Total)      :-  \n \n  total_earning_for_day(OneDay),  \n \n  Total      is   \n \n5   \n \n*      OneDay. /*      Query      */  \n \n  solve(Total)      :-      total_earning_for_5_days  \n \n  (Total)."
            },
            {
              "id": 278,
              "title": "Here      is      the      problem: - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Here      is      the      prolog      reasoning      tree:\n \n \n  =>(=>(,      (=>(,      (=>(,      (=>      C(builtin(true),      wage  \n \n  (18.0)),      =>Cbuiltin(is(144.0,      x*(8,  \n \n  18.0))),      is(144.0,      *(8,      18.0)))),  \n \n  regular_earning_for_day(144.0)),  \n \n  ,(=>(,      (=>(=>(builtin(is(2,      -(10,      8))  \n \n  ),      is(2,      -(1@,      8))),      overtime_hours  \n \n  (2)),      ,C=>Cbuiltin(,      (g(wage(18.0)),  \n \n  g(is(27.0,      *(1.5,      18.0))))),  \n \n  overtime_wage(27.0)),      =>(Cbuiltin(is  \n \n  (54.0,      *(2,      27.0))),      is(54.0,      *(2,  \n \n  27.0))))),      overtime_earning_for_day  \n \n  (54.0)),      =>(Cbuiltin(is(198.0,  \n \n  +(144.0,      54.0))),      i18(198.0,      +(144.0,  \n \n  54.0))))),      total_earning_for_day  \n \n  (198.0)),      =>Cbuiltin(is(990.0,      x*(5,  \n \n  198.0))),      18(990.0,      *(5,      198.0)))),  \n \n  total_earning_for_5_days(990.0)),  \n \n  solve      (990.0)   \n \n)       <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 279,
              "title": "Here      is      the      problem: - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Tina      earns      $18.00      per      hour      according      to  \n \n  the      information      provided."
            },
            {
              "id": 280,
              "title": "Here      is      the      problem: - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "She      has  \n \n  shifts      where,      if      she      works      more      than  \n \n  8      hours,      the      additional      hours      are  \n \n  considered      overtime. Overtime      pay      is  \n \n  calculated      at      one      and   \n \na      half      times  \n \n  her      regular      hourly      wage."
            },
            {
              "id": 281,
              "title": "Here      is      the      problem: - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "On   \n \na      typical      day,      if      Tina      works      10      hours  \n \n  ,      this      includes   \n \n2      hours      of      overtime  \n \n  since      she      exceeds      the      8-hour      regular  \n \n  work      period. Her      regular      earnings  \n \n  for      working   \n \n8      hours   \n \na      day      at      $18.00  \n \n  per      hour      amounts      to      $144.00      per      day."
            },
            {
              "id": 282,
              "title": "Here      is      the      problem: - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "For      the   \n \n2      hours      of      overtime,      since  \n \n  the      overtime      rate      is      $27.00      per      hour  \n \n  (1.5      times      her      regular      hourly      wage)  \n \n  ,      she      earns      $54.00      from      overtime  \n \n  work      per      day. Therefore,      her      total      earnings      for   \n \na       single      day,      combining      her      regular  \n \n  and      overtime      earnings,      are      $198.00."
            },
            {
              "id": 283,
              "title": "Here      is      the      problem: - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Over      the      course      of   \n \n5      days,      working  \n \n  the      same      hours      daily,      Tina      makes   \n \na       total      of      $990.00,      factoring      in      all  \n \n  regular      pay      and      overtime      across      the  \n \n  five      days. <|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve."
            },
            {
              "id": 284,
              "title": "Here      is      the      problem: - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Janice      can      type   \n \n6      sentences      per  \n \n  minute. sent-2:      Today      at      work,      Janice      continued  \n \n  working      on   \n \na      paper      she      started  \n \n  typing      yesterday."
            },
            {
              "id": 285,
              "title": "Here      is      the      problem: - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "sent-3:      She      typed      for      20      minutes,      took   \n \na       break,  \n \n  sent-4:      and      typed      15      minutes      longer. sent-5:      She      then      had      to      erase      40  \n \n  sentences      she      had      typed      incorrectly. sent-6:      After   \n \na      meeting,      she      typed      for  \n \n  18      minutes      more."
            },
            {
              "id": 286,
              "title": "Here      is      the      problem: - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "sent-7:      In      all,      the      paper      had      536  \n \n  sentences      by      the      end      of      today. sent-8:      How      many      sentences      did      she      start  \n \n  with      today? Prolog      code:  \n \n  /*      Context      x*/  \n \n  %      facts  \n \n  sentences_per_minute(6). typing_sessions([20,      15,      18]). erased_sentences      (40). total_end_sentences      (536)."
            },
            {
              "id": 287,
              "title": "Here      is      the      problem: - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      number      of      sentences  \n \n  typed      in   \n \na      session  \n \n  sentences_typed(SessionMinutes,      Typed) sentences_per_minute(SPM),  \n \n  Typed      is      SPM   \n \n*      SessionMinutes."
            },
            {
              "id": 288,
              "title": "Here      is      the      problem: - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      number      of  \n \n  sentences      typed      across      all      sessions  \n \n  today  \n \n  total_sentences_typed_today(Total)      :-  \n \n  typing_sessions(Sessions),  \n \n  maplist(sentences_typed,      Sessions,  \n \n  TypedPerSession),  \n \n  sum_list(TypedPerSession,      TotalTyped  \n \n  )   \n \n,       erased_sentences(Erased),  \n \n  Total      is      TotalTyped   \n \n-      Erased."
            },
            {
              "id": 289,
              "title": "Here      is      the      problem: - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      how      many      sentences      she  \n \n  started      with      today  \n \n  start_sentences(TodayStart)      :-  \n \n  total_end_sentences(EndToday),  \n \n  total_sentences_typed_today   \n \n(      TodayTyped),  \n \n  TodayStart      is      EndToday   \n \n-      TodayTyped. /*      Query      */  \n \n  solve(StartSentences)      :-      start_sentences  \n \n  (StartSentences)."
            },
            {
              "id": 290,
              "title": "Here      is      the      problem: - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(builtin(true),  \n \n  total_end_sentences      (536)),  \n \n  ,(=>(,      (=>(Cbuiltin(true),  \n \n  typing_sessions([20,      15,      18])),  \n \n  builtin(,      (g(maplist(sentences_typed,  \n \n  [20,      15,      18],      [120,      90,      108])),      ,Cg  \n \n  (sum_list([120,      90,      108],      318)),      ,(g  \n \n  (erased_sentences(40)),      g(is(278,  \n \n  ~(318,      40)))))))),  \n \n  total_sentences_typed_today      (278)),  \n \n  =>(builtin(is(258,      -(536,      278))),      is  \n \n  (258,      -(536,      278))))),  \n \n  start_sentences(258)),      solve(258))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 291,
              "title": "Here      is      the      problem: - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Janice\\\\\\'s      typing      speed      is   \n \n6      sentences      per  \n \n  minute."
            },
            {
              "id": 292,
              "title": "Here      is      the      problem: - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Today,      she      had      three  \n \n  separate      typing      sessions:      the      first  \n \n  lasted      for      20      minutes,      the      second  \n \n  for      15      minutes,      and      the      third      for      18  \n \n  minutes. Over      these      sessions,      she  \n \n  initially      typed   \n \na      total      of      318  \n \n  sentences."
            },
            {
              "id": 293,
              "title": "Here      is      the      problem: - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "However,      she      made   \n \na       mistake      and      had      to      erase      40  \n \n  sentences,      leaving      her      with      278  \n \n  sentences      typed      effectively      today. By      the      end      of      the      day,      the      total  \n \n  number      of      sentences      on      her      paper      was  \n \n  536."
            },
            {
              "id": 294,
              "title": "Here      is      the      problem: - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "To      find      out      how      many      sentences  \n \n  were      on      the      paper      at      the      beginning  \n \n  of      the      day,      we      subtract      the  \n \n  sentences      typed      today      (278)      from      the  \n \n  total      at      the      end      of      the      day      (536). Hence,      Janice      started      the      day      with  \n \n  258      sentences      already      on      her      paper."
            },
            {
              "id": 295,
              "title": "Here      is      the      problem: - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "<|eot_id|><|start_header_id|>user<|  \n \n  end_header_id|>  \n \n  Excellent      work! Here      is      another      problem  \n \n  for      you      to      solve. Please      apply      the  \n \n  same      approach      you      used      for      the  \n \n  previous      one(s)      to      tackle      this      new       one. Problem:  \n \n  sent-1:      Jesse      and      Mia      are      competing      in   \n \na       week      long      race."
            },
            {
              "id": 296,
              "title": "Here      is      the      problem: - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "sent-2:      They      have      one      week      to      run      30  \n \n  miles. sent-3:      On      the      first      three      days      Jesse  \n \n  averages      (2/3)      of   \n \na      mile. sent-4:      On      day      four      she      runs      10      miles. sent-5:      Mia      averages   \n \n3      miles   \n \na      day      over  \n \n  the      first   \n \n4      days."
            },
            {
              "id": 297,
              "title": "Here      is      the      problem: - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "sent-6:      What      is      the      average      of      their  \n \n  average      that      they      have      to      run      over  \n \n  the      final      three      days? Prolog      code:  \n \n  7*      Context      */  \n \n  %      facts  \n \n  total_distance      (30). jesse_first_three_days_avg      (2/3). jesse_day_four(10). mia_first_four_days_avg(3)."
            },
            {
              "id": 298,
              "title": "Here      is      the      problem: - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Jesse      ran  \n \n  over      the      first      four      days  \n \n  jesse_first_four_days_total      (Distance)      :-  \n \n  jesse_first_three_days_avg(DayAvg),  \n \n  jesse_day_four(DayFour),  \n \n  Distance      is   \n \n3   \n \n*      DayAvg   \n \n+      DayFour."
            },
            {
              "id": 299,
              "title": "Here      is      the      problem: - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      total      distance      Mia      ran  \n \n  over      the      first      four      days  \n \n  mia_first_four_days_total(Distance)      :-  \n \n  mia_first_four_days_avg(DayAvg),  \n \n  Distance      is   \n \n4   \n \n*      DayAvg."
            },
            {
              "id": 300,
              "title": "Here      is      the      problem: - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "%      calculate      the      average      miles      they      have  \n \n  to      run      over      the      final      three      days  \n \n  remaining_avg(Person,      Avg)      :-  \n \n  (Person   \n \n=      jesse      ->  \n \n  jesse_first_four_days_total   \n \n(      Distance)      ;\n \n \n  Person   \n \n=      mia      ->  \n \n  mia_first_four_days_total   \n \n(      Distance)),  \n \n  total_distance(Total),  \n \n  Remaining      is      Total   \n \n-      Distance,  \n \n  Avg      is      Remaining   \n \n/      3."
            },
            {
              "id": 301,
              "title": "Here      is      the      problem: - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "%      determine      the      average      of      their  \n \n  averages      over      the      final      three      days  \n \n  average_of_averages(Result)      :-  \n \n  remaining_avg(jesse,      JesseAvg),  \n \n  remaining_avg(mia,      MiaAvg),  \n \n  Result      is      (JesseAvg   \n \n+      MiaAvg)   \n \n/      2. /*      Query      x*/  \n \n  solve(Average)      :-      average_of_averages(      Average)."
            },
            {
              "id": 302,
              "title": "Here      is      the      problem: - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Prolog      reasoning      tree:  \n \n  =>(=>(,      (=>(,      (=>Cbuiltin(;      (->(=(jesse,  \n \n  jesse),      jesse_first_four_days_total  \n \n  (12.0)),      ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ;(->(=(jesse,      jesse),  \n \n  jesse_first_four_days_total(12.0)),  \n \n  ->(=(jesse,      mia),  \n \n  mia_first_four_days_total(12.0)))),  \n \n  ,(=>(      true,      total_distance(30)),  \n \n  ,(=>(builtin(is(18.0,      -(30,      12.0))),  \n \n  is(18.0,      -(30,      12.0))),      =>(Cbuiltin(      is(6.0,      /(18.0,      3))),      is(6.0,  \n \n  /(18.@,      3)))))),      remaining_avg      (jesse  \n \n  ,      6.0)),      ,(C=>C,      (=>Cbuiltin(;      (->(=¢  \n \n  mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ;(->(=(mia,      jesse),  \n \n  jesse_first_four_days_total(12)),  \n \n  ->(=(mia,      mia),  \n \n  mia_first_four_days_total(12)))),  \n \n  ,(=>(builtin(true),      total_distance  \n \n  (30)),      builtin(,(gCis(18,      -(30,      12))  \n \n  ),      gCis(6,      /(18,      3))))))),  \n \n  remaining_avg(mia,      6)),      =>(Cbuiltin(      is(6.0,      /(+(6.0,      6),      2))),      is(6.@,  \n \n  /(+(6.0,      6),      2))))),  \n \n  average_of_averages(6.0)),      solve  \n \n  (6.0))  \n \n  <|eot_id|><|start_header_id|>assistant<|  \n \n  end_header_id|>  \n \n  Sure!"
            },
            {
              "id": 303,
              "title": "Here      is      the      problem: - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "I      am      happy      to      help      you      convert      the  \n \n  Prolog-style      reasoning      tree      into   \n \na       natural      language      reasoning      chain. Here      is      the      reasoning      chain:  \n \n  Jesse      and      Mia      are      competing      in   \n \na      week-  \n \n  long      race      where      each      needs      to      run   \n \na       total      of      30      miles."
            },
            {
              "id": 304,
              "title": "Here      is      the      problem: - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Jesse      averages   \n \n(      \\\\\\\\frac{2}{3}   \n \n)      mile      each      day      for      the  \n \n  first      three      days,      totaling   \n \n2      miles,  \n \n  and      then      runs      10      miles      on      the      fourth  \n \n  day,      making      it   \n \na      total      of      12      miles  \n \n  in      the      first      four      days."
            },
            {
              "id": 305,
              "title": "Here      is      the      problem: - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Mia      averages  \n \n  3      miles      per      day      over      the      first      four  \n \n  days,      totaling      12      miles      as      well. Given      that      they      both      need      to      complete      30  \n \n  miles      by      the      end      of      the      week,      both  \n \n  Jesse      and      Mia      have      18      miles      left      to  \n \n  run      over      the      final      three      days      after  \n \n  the      first      four      days."
            },
            {
              "id": 306,
              "title": "Here      is      the      problem: - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "This      results      in  \n \n  each      needing      to      run      an      average      of   \n \n6       miles      per      day      over      the      last      three  \n \n  days. To      find      the      average      of      their      averages  \n \n  over      these      remaining      three      days,      we  \n \n  calculate   \n \n(      \\\\\\\\frac{(6+6)}{2}      ),      which  \n \n  remains   \n \n6      miles      per      day."
            },
            {
              "id": 307,
              "title": "Here      is      the      problem: - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Therefore,  \n \n  the      average      of      their      average      daily  \n \n  miles      over      the      final      three      days      that  \n \n  they      need      to      run      is   \n \n6      miles."
            }
          ],
          "content": ""
        }
      ],
      "content": ""
    },
    {
      "id": 308,
      "title": "Book 2",
      "type": "book",
      "children": [
        {
          "id": 309,
          "title": "Xinyu      Zhang      *",
          "type": "section",
          "children": [
            {
              "id": 310,
              "title": "Xinyu      Zhang      * - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Xinyu      Zhang      *\n |  |  |       Abstract\n | --- | --- | ---\n |  |       2407.14743v1      [cs.IR]      20      Jul      2024 |       User      interests      can      be      viewed      over      different      time      scales,       mainly      including      stable      long-term      preferences      and      chang-       ing      short-term      intentions,      and      their      combination      facilitates       the      comprehensive      sequential      recommendation."
            },
            {
              "id": 311,
              "title": "Xinyu      Zhang      * - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "However,       existing      work      that      focuses      on      different      time      scales      of      user       modeling      has      ignored      the      negative      effects      of      different      time-       scale      noise,      which      hinders      capturing      actual      user      interests       and      cannot      be      resolved      by      conventional      sequential      denoising       methods."
            },
            {
              "id": 312,
              "title": "Xinyu      Zhang      * - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "term      Interest      Denoising      Network      (LSIDN),      which      employs       In      this      paper,      we      propose      a      Long-      and      Short-       different      encoders      and      tailored      denoising      strategies      to      ex-       tract      long-      and      short-term      interests,      respectively,      achieving       both      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 313,
              "title": "Xinyu      Zhang      * - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Specifically,       we      employ      a      session-level      interest      extraction      and      evolution       strategy      to      avoid      introducing      inter-session      behavioral      noise       into      long-term      interest      modeling;      we      also      adopt      contrastive       learning      equipped      with      a      homogeneous      exchanging      augmen-       tation      to      alleviate      the      impact      of      unintentional      behavioral       noise      on      short-term      interest      modeling."
            },
            {
              "id": 314,
              "title": "Xinyu      Zhang      * - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Results      of      experi-       ments      on      two      public      datasets      show      that      LSIDN      consistently       outperforms      state-of-the-art      models      and      achieves      significant       robustness. Keywords:      recommender      systems,      sequential      recom-       mendation,      interest      modeling."
            },
            {
              "id": 315,
              "title": "Xinyu      Zhang      * - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "| 1      Introduction\n |       arXiv |  |       Sequential      Recommendation      (SR)      [I]      has      been      widely       used      in      various      platforms      to      alleviate      information      over-       load      and      provide      personalized      services      for      users."
            },
            {
              "id": 316,
              "title": "Xinyu      Zhang      * - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "The       task      of      SR      is      to      predict      the      next-item      that      a      user      will      be       interested      in,      given      his/her      behavior      sequence."
            },
            {
              "id": 317,
              "title": "Xinyu      Zhang      * - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "In      real-       world      scenarios,      the      user’s      interests      can      be      viewed      over       different      time      scales,      mainly      including      relatively      stable       long-term      user      preferences      and      more      variable      short-term       user      intentions,      each      of      which      reflects      the      different      time-       scale      dynamics      of      the      user      historical      sequence."
            },
            {
              "id": 318,
              "title": "Xinyu      Zhang      * - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Some\n\n \n \n  Institute      of      Software,      Chinese      Academy      of      Sciences. XinyuZhang0429@outlook.com. +College      of      Computer      Science,  \n \n  libeibei22Q@cqu.edu.cn. 8These      authors      are      co-first      authors."
            },
            {
              "id": 319,
              "title": "Xinyu      Zhang      * - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "(13)      (4)      [I5]      utilizes      the      sequence      context      as      more      reliable  \n \n  denoising      signals      to      filter      out      noisy      components      that  \n \n  are      inconsistent      with      the      sequence      semantics. However,  \n \n  these      methods      require      rich      within-sequence      information  \n \n  &\\\\\\\\      User   \n \n©      Item      Session      —At<w      At      >w      1.2\nChongqing      University."
            },
            {
              "id": 320,
              "title": "Xinyu      Zhang      * - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "tCorresponding      author. Institute      of      Software,      Chinese  \n \n  Academy      of      Sciences. University      of      Chinese      Academy      of      Sciences. Beihong@iscas.ac.cn."
            }
          ],
          "content": ""
        },
        {
          "id": 321,
          "title": "Beihong      Jin      **",
          "type": "section",
          "children": [
            {
              "id": 322,
              "title": "Beihong      Jin      ** - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Beihong      Jin      **\n \n \n  work      [2,      {3},      (4)      15)      (6)      [7]      has      modeled      both      long-      and      short-  \n \n  term      user      interests      separately      and      then      combined      them  \n \n  to      facilitate      more      comprehensive      user      modeling,      thereby  \n \n  improving      recommendation      performance."
            },
            {
              "id": 323,
              "title": "Beihong      Jin      ** - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "However,      existing      work      has      overlooked      some      non-  \n \n  trivial      issues      when      modeling      different      time-scale      user  \n \n  interests."
            },
            {
              "id": 324,
              "title": "Beihong      Jin      ** - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      most      of      these      studies      capture      user  \n \n  interests      via      ubiquitous      implicit      feedback,      which      is  \n \n  susceptible      to      various      factors,      such      as      position      bias      [8]  \n \n  and      caption      bias      [9],      leading      to      unintentional      behavioral  \n \n  noise."
            },
            {
              "id": 325,
              "title": "Beihong      Jin      ** - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "This      kind      of      noise      is      particularly      harmful      to      the  \n \n  extraction      of      short-term      user      interests,      which      are      usually  \n \n  extracted      from   \n \na      small      set      of      most      recent      behaviors,      thus  \n \n  making      short-term      interest      modeling      more      vulnerable  \n \n  to      unintentional      behavioral      noise."
            },
            {
              "id": 326,
              "title": "Beihong      Jin      ** - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      these  \n \n  studies      mostly      capture      long-term      user      interests      via  \n \n  historical      behaviors      spanning      several      sessions,      where   \n \na       session      is   \n \na      sequence      of      behaviors      in      close      temporal  \n \n  proximity      [I]. As      shown      in      Figs."
            },
            {
              "id": 327,
              "title": "Beihong      Jin      ** - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "fi(a)      and      [i(b),      we  \n \n  have      noticed      that      user      behaviors      are      highly      homogeneous  \n \n  within   \n \na      session      and      heterogeneous      across      sessions,  \n \n  which      implies      that      behaviors      occurring      in      different  \n \n  sessions      may      be      irrelevant      to      each      other."
            },
            {
              "id": 328,
              "title": "Beihong      Jin      ** - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Conventional  \n \n  long-term      interest      modeling      usually      ignores      the      multi-  \n \n  session      structure      of      the      historical      sequence,      so      even      if   \n \na       certain      behavior      is      not      unintentional      behavioral      noise,  \n \n  it      may      introduce      another      form      of      noise      by      executing  \n \n  numerous      ineffective      feature      interactions      with      behaviors  \n \n  in      other      sessions,      ultimately      impairing      the      mining      of  \n \n  long-term      user      interests."
            },
            {
              "id": 329,
              "title": "Beihong      Jin      ** - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "We      refer      to      this      kind      of      noise  \n \n  as      inter-session      behavioral      noise. There      are      several      studies      that      have      explored      the  \n \n  denoising      of      SR      models      to      alleviate      the      harmful      impact  \n \n  of      noise."
            },
            {
              "id": 330,
              "title": "Beihong      Jin      ** - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Some      early      attention-based      work      [I]      [12]      has  \n \n  utilized      item-level      relevance      to      the      target      item,      down-  \n \n  weighting      or      directly      removing      items      with      low      relevance."
            },
            {
              "id": 331,
              "title": "Beihong      Jin      ** - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "These      methods      solely      rely      on      the      target      item      as      the  \n \n  denoising      signals,      although      they      filter      out      unintentional  \n \n  behaviors,      they      also      unavoidably      discard      many      low-  \n \n  relevance      but      non-noisy      behaviors,      resulting      in      the      loss  \n \n  of      potentially      useful      information."
            },
            {
              "id": 332,
              "title": "Beihong      Jin      ** - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Another      line      of      work 1.0  \n \n  0.8]      le      eel   \n \n| Q. \\\\\\'      3633127      5."
            },
            {
              "id": 333,
              "title": "Beihong      Jin      ** - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "4826027      328600      4221084      2584047      3190578      5105730   \n \n|   \n \n—      =a  \n \n  215)      1\\\\\\\\      giias3   \n \n/      411153,   \n \n/      411153      2355072/      \\\\\\\\2355072/      \\\\\\\\2355072/      \\\\\\\\2355072      04   \n \n|   \n \n|   \n \n| 0.2   \n \n4       00      Gini  \n \n  3909570      2476988      3331977      2476988   \n \n|   \n \n|      3566708      2150755      4724845      3.0   \n \n|      index  \n \n  121)      |\\\\\\\\928278/      \\\\\\\\1928278/      \\\\\\\\200278/      \\\\\\\\1928278      \\\\\\\\g0s0007/      \\\\\\\\1050007/      \\\\\\\\g0s0007/   \n \nm _ =."
            },
            {
              "id": 334,
              "title": "Beihong      Jin      ** - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "I\n \n    15   \n \n—   \n \na 1.0   \n \n|      Entropy  \n \n  1640030,      2229795      2517769      1173209      3248616      1649596      577109   \n \n3   \n \n|      I\n92      \\\\\\\\2156574/      \\\\\\\\      2156574      \\\\\\\\      2156574, Session      Sessiong      Merged      Session\n(a) (b)\n \n \n  and      are      less      suitable      for      the      denoising      of      short-term  \n \n  interest      modeling,      which      relies      on   \n \na      few      recent      behaviors  \n \n  with      limited      information."
            },
            {
              "id": 335,
              "title": "Beihong      Jin      ** - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Besides,      they      cannot      deal  \n \n  with      inter-session      behavioral      noise      that      is      introduced  \n \n  by      conventional      long-term      interest      modeling."
            },
            {
              "id": 336,
              "title": "Beihong      Jin      ** - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "To      alleviate      the      negative      effects      of      different      time-  \n \n  scale      noise      when      modeling      different      time-scale      user      in-  \n \n  terests,      we      propose   \n \na      Long-      and      Short-term      Interest      De-  \n \n  noising      Network      (LSIDN),      which      employs      different      en-  \n \n  coders      and      tailored      denoising      strategies      to      extract      long-  \n \n  and      short-term      user      interests,      respectively,      achieving  \n \n  both      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 337,
              "title": "Beihong      Jin      ** - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Firstly,  \n \n  we      extract      long-term      user      interests      from      historical      be-  \n \n  haviors      spanning      several      sessions."
            },
            {
              "id": 338,
              "title": "Beihong      Jin      ** - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Due      to      the      multi-  \n \n  session      structure      of      the      history      sequence      and      the      het-  \n \n  erogeneity      of      inter-session      behaviors,      we      extract      intra-  \n \n  session      interests      separately      and      then      capture      the      evolu-  \n \n  tion      of      inter-session      interests,      thus      avoiding      the      intro-  \n \n  duction      of      inter-session      behavioral      noise      into      long-term  \n \n  interest      modeling."
            },
            {
              "id": 339,
              "title": "Beihong      Jin      ** - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      we      model      the      short-term  \n \n  user      interests      from      the      most      recent      behaviors."
            },
            {
              "id": 340,
              "title": "Beihong      Jin      ** - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  the      limited      length      of      the      current      session      and      the      ho-  \n \n  mogeneity      of      intra-session      behaviors,      we      resort      to      con-  \n \n  trastive      learning      [16]      with   \n \na      novel      data      augmentation  \n \n  tailored      for      short      sequences,      thus      alleviating      the      impact  \n \n  of      unintentional      behavioral      noise      on      short-term      interest  \n \n  modeling."
            },
            {
              "id": 341,
              "title": "Beihong      Jin      ** - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Our      homogeneous      exchanging      augmentation  \n \n  builds      more      informative      and      reliable      positive      pairs      by  \n \n  introducing      future      data      based      on      intra-session      seman-  \n \n  tic      consistency,      mitigating      data      sparsity      and      informa-  \n \n  tion      loss      caused      by      traditional      sequence-based      augmen-  \n \n  tations      [I7]."
            },
            {
              "id": 342,
              "title": "Beihong      Jin      ** - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Note      that      the      future      data      are      the      suffixed  \n \n  sub-sessions      of      the      original      current      session      and      can      only  \n \n  be      accessed      during      training. Finally,      we      combine      the  \n \n  long-      and      short-term      interests      in      an      adaptive      way      [4]  \n \n  for      joint      prediction. Our      contributions      are      summarized  \n \n  as      follows."
            },
            {
              "id": 343,
              "title": "Beihong      Jin      ** - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "e      We      are      the      first      to      indicate      the      negative      effects      of  \n \n  different      time-scale      noise      in      the      sequential      recom-  \n \n  mendation      and      propose   \n \na      Long-      and      Short-term      In-  \n \n  terest      Denoising      Network,      which      employs      distinct  \n \n  encoders      and      tailored      denoising      strategies      to      ex-  \n \n  tract      different      time-scale      user      interests,      thus      achiev-  \n \n  ing      both      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 344,
              "title": "Beihong      Jin      ** - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "e      We      design   \n \na      session-level      interest      extraction      and       evolution      strategy      to      avoid      introducing      inter-  \n \n  session      behavioral      noise      into      the      long-term      interest  \n \n  modeling,      and      we      also      resort      to      contrastive      learning  \n \n  equipped      with   \n \na      novel      augmentation      method      to      al-  \n \n  leviate      the      impact      of      unintentional      behavioral      noise  \n \n  on      short-term      interest      modeling."
            },
            {
              "id": 345,
              "title": "Beihong      Jin      ** - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "e      We      conduct      extensive      experiments      on      two      real-  \n \n  world      datasets      to      show      that      LSIDN      consistently  \n \n  outperforms      various      state-of-the-art      models,      and       release      the      code      at      https:      //github.com/zxyllq/  \n \n  LSIDN. git      for      reproducibility."
            },
            {
              "id": 346,
              "title": "Beihong      Jin      ** - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "2\n \n   Related      Work 2.1      Modeling      Long-      and      Short-term      Inter-  \n \n  ests      Early      deep      neural      network-based      recommendation  \n \n  methods      [18      [T9)      20)      21]      capture   \n \na      holistic      user      interest  \n \n  without      distinguishing      between      multiple      interests."
            },
            {
              "id": 347,
              "title": "Beihong      Jin      ** - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "In  \n \n  realistic      scenarios,      the      user’s      interests      can      be      viewed  \n \n  over      different      time      scales,      including      long-      and      short-  \n \n  term      interests,      and      their      combination      will      facilitate      com-  \n \n  prehensive      user      modeling      [2,      [3)      4)      {6)      5]."
            },
            {
              "id": 348,
              "title": "Beihong      Jin      ** - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "For      example,  \n \n  SHAN      [2]      employs   \n \na      novel      two-layer      hierarchical      atten-  \n \n  tion      network      to      learn      the      user’s      general      taste      and      re-  \n \n  cent      demand,      respectively."
            },
            {
              "id": 349,
              "title": "Beihong      Jin      ** - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "SLi-Rec      [4]      improves      the  \n \n  classical      LSTM      and      proposes      an      attention-based      fusion  \n \n  method      to      adaptively      combine      long-      and      short-term      in-  \n \n  terests. CLSR      [6]      adopts      contrastive      learning      to      disen-  \n \n  tangle      long-      and      short-term      user      interests."
            },
            {
              "id": 350,
              "title": "Beihong      Jin      ** - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "However,  \n \n  these      methods      ignore      the      negative      influence      of      noise  \n \n  when      modeling      different      time      scales      of      user      interests."
            },
            {
              "id": 351,
              "title": "Beihong      Jin      ** - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "2.2      Denoising      for      Sequential      Recommendation  \n \n  Previous      attention-based      work      [TI]      [T2]      has      utilized      item-  \n \n  level      relevance      to      the      target      item,      down-weighting      or  \n \n  directly      removing      items      with      low      relevance."
            },
            {
              "id": 352,
              "title": "Beihong      Jin      ** - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "However,  \n \n  these      methods      unavoidably      discard      many      low-relevance  \n \n  but      non-noisy      behaviors,      resulting      in      the      loss      of      po-  \n \n  tentially      useful      information."
            },
            {
              "id": 353,
              "title": "Beihong      Jin      ** - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "Recently,      another      line      of  \n \n  work      [I3}      14)      [[5]      has      made      further      progress      by      utiliz-  \n \n  ing      the      sequence      context      as      more      reliable      denoising      sig-  \n \n  nals      to      filter      out      noise. For      example,      STEAM      [13]      de-  \n \n  signs      an      item-wise      corrector      to      explicitly      correct      the      raw  \n \n  sequence."
            },
            {
              "id": 354,
              "title": "Beihong      Jin      ** - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "FMLP-Rec      [14]      introduces   \n \na      filter-enhanced  \n \n  MLP      to      filter      out      noise      components      from      the      item      rep-  \n \n  resentation. FEARec      [15]      captures      behavior      patterns      of  \n \n  different      frequency      bands      and      implicitly      removes      noise  \n \n  in      the      frequency      domain."
            },
            {
              "id": 355,
              "title": "Beihong      Jin      ** - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "However,      these      methods      fail  \n \n  to      alleviate      the      negative      effects      of      different      time-scale  \n \n  noise      in      the      sequential      recommendation."
            },
            {
              "id": 356,
              "title": "Beihong      Jin      ** - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "2.3      Contrastive      Learning      Contrastive      learning  \n \n  (1\\\\\\'7,      [22]      is   \n \na      branch      of      self-supervised      learning,      and      it  \n \n  adopts      data      augmentation      to      learn      high-quality      and       generalizable      representations."
            },
            {
              "id": 357,
              "title": "Beihong      Jin      ** - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "For      example,      S?-Rec  \n \n  [24]      uses      random      masks      of      attributes      and      sequences      to  \n \n  maximize      the      mutual      information      over      positive      pairs. CL4SRec      [25]      and      CLUE      [26]      perform      crop,      mask,      and       reorder      on   \n \na      sequence      to      obtain      multiple      views      of      the  \n \n  same      behavior      sequence."
            },
            {
              "id": 358,
              "title": "Beihong      Jin      ** - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "However,      these      traditional  \n \n  sequence-based      augmentations      may      break      essential      item  \n \n  relationships      or      lead      to      fewer      items,      yielding      less      confi-  \n \n  dent      positive      pairs,      especially      for      short      sequences."
            },
            {
              "id": 359,
              "title": "Beihong      Jin      ** - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "3.4      Long-term      Interest      Encoder      After      dividing  \n \n  the      sequence      into   \n \n&      (k      is   \n \na      dynamic      value)      sessions,      we  \n \n  feed      the      earlier   \n \nb      (b   \n \n<      k)      sessions      into      the      long-term  \n \n  interest      encoder      to      allow      instances      to      be      trained      in      mini-  \n \n  batches."
            },
            {
              "id": 360,
              "title": "Beihong      Jin      ** - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "Then      we      elaborate      on      the      technical      details      of  \n \n  the      long-term      interest      encoder      in      the      following. Intra-session      Interest      Extractor      Layer."
            },
            {
              "id": 361,
              "title": "Beihong      Jin      ** - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "We      adopt  \n \n  a      Transformer-based      encoder      [27]      to      extract      the      intra-  \n \n  session      interest      and      denote      it      as      SessEnc(-),      which      is  \n \n  shared      across   \n \n6      sessions,      i.e.,      [s,      SA,      sO),      Given the n-th historical session S‘, where n € [1,2,,0],  \n \n  Long-term      Interest      Encoder      Output\n3\n \n   Methodology 3.1      Problem      Formulation      We      denote      user      and       item      sets      as      U/      and      V,      respectively."
            },
            {
              "id": 362,
              "title": "Beihong      Jin      ** - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "For      each      user   \n \nu   \n \n€      U,  \n \n  we      have      his/her      temporally      ordered      behavior      sequence S = [U1, V2,,U4,---,U}s], Where v; € 8 is the t-th in-  \n \n  teracted      item      of      user      u. Given   \n \na      user’s      history      sequence  \n \n  with   \n \nT   \n \n—   \n \n1      time      steps,      our      model      aims      to      predict      the  \n \n  next-item      vp      that      the      user      will      interact      with."
            },
            {
              "id": 363,
              "title": "Beihong      Jin      ** - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "3.2      Overview      The      architecture      of      our      LSIDN      is  \n \n  shown      in      Fig. Firstly,      we      divide      the      user      behavior  \n \n  sequence      into      sessions      through      the      session      division      layer  \n \n  considering      the      multi-session      structure      of      the      historical  \n \n  sequence."
            },
            {
              "id": 364,
              "title": "Beihong      Jin      ** - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      we      use      long-term      and      short-term  \n \n  interest      encoders      to      model      different      time-scale      user      in-  \n \n  terests,      respectively. Finally,      we      aggregate      the      different  \n \n  time-scale      user      interests      through      the      fusion      prediction  \n \n  layer      and      then      calculate      the      interaction      probability      of  \n \n  the      target      item      vr."
            },
            {
              "id": 365,
              "title": "Beihong      Jin      ** - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Key      components      and      technical      de-  \n \n  tails      are      elaborated      below. 3.3."
            },
            {
              "id": 366,
              "title": "Beihong      Jin      ** - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Session      Division      Layer      User      historical      behav-  \n \n  iors      are      not      uniformly      distributed      over      timestamps,      and       behaviors      that      are      in      close      temporal      proximity      tend      to  \n \n  be      closely      related,      so      we      divide      the      historical      sequence  \n \n  into      multiple      sessions."
            },
            {
              "id": 367,
              "title": "Beihong      Jin      ** - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "Note      that,      unlike      session-based  \n \n  recommendation      models      [I]      that      focus      on      anonymous  \n \n  and      individual      sessions,      our      model      is      for      the      sequential  \n \n  recommendation      that      focuses      on      non-anonymous      and       cross-session      sequences,      where      sessions      are      merely      in-  \n \n  termediate      products      of      our      model."
            },
            {
              "id": 368,
              "title": "Beihong      Jin      ** - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      create      an      item      embedding      matrix      E   \n \n€       R\\\\\\'VIXx¢,      where      d      is      the      embedding      size,      and      then  \n \n  and      s      are      embedded      as      v;   \n \n€      R! *4      and      S      ¢€      RIs!X4,\n \n \n  Secondly,      we      adopt      the      session      division      layer,      denoted  \n \n  as      SessDiv(-),      to      divide      the      sequence      into      sessions."
            },
            {
              "id": 369,
              "title": "Beihong      Jin      ** - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Specifically,      given   \n \na      division      threshold      w,      for      Vu;   \n \n€      S,  \n \n  if      the      time      interval      At      between      v;_;      and      v;      is      less  \n \n  than      w,      then      vz_1      and      v;      belong      to      the      same      session,  \n \n  otherwise,      vz_1      and      v;      belong      to      two      successive      sessions,  \n \n  respectively."
            },
            {
              "id": 370,
              "title": "Beihong      Jin      ** - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "As   \n \na      result,      S      is      divided      as      follows. (3.1)      [s,      SA      GM,      s)]   \n \n=      SessDiv(S,w),\nwhere   \n \nk      is      the      number      of      sessions      contained      in      sequence  \n \n  s,      S\\\\\\\\™      e€      R! *4      is      the      n-th      session      embedding      matrix, and   \n \n|      denotes      the      maximum      session      length."
            },
            {
              "id": 371,
              "title": "Beihong      Jin      ** - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "Inter-session      Interest      a)   \n \n&      (k)      (k)      s      P   \n \n:       Evolution      Layer      s      an      s      ‘a      s   \n \n=      Sp   \n \n=      gm      Interest      Extraction   \n \n§    \n \n¥      Vv      Layer      ae  \n \n  h,      hy      Attention      Share      P       so”      NA      Session      Division      Layer  \n \n  Uw      vet   \n \nu      --      vr   \n \n=      S;   \n \n=      gH      Interest      Extraction   \n \n&    \n \n,   \n \n;      Long-term      Interest      Short-term      Interest      5)      oy   \n \n=   \n \ni      Layer  \n \n  hy   \n \n_      hy      Attention      Encoder      Encoder   \n \n=   \n \n~   \n \n2      Share      L       Rls   \n \n“   \n \n=      §®   \n \n©      Current      Session  \n \n  we   \n \nr      Fusion      Prediction      Layer      A,  \n \n  ~      5)   \n \n-      F      “Cc  \n \n  <5)      L      «®   \n \n|      =|      Current      Session      Us  \n \n  h      h\\\\\\'      =)      Q"
            }
          ],
          "content": ""
        },
        {
          "id": 372,
          "title": "Short-term      Interest      Encoder",
          "type": "section",
          "children": [
            {
              "id": 373,
              "title": "Short-term      Interest      Encoder - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Short-term      Interest      Encoder\nIntra-session      Interest      UT      si)   \n \n=      Cuca      Sesstan      gu  \n \n  Extraction      Layer      ee,   \n \n=      Interest      Extraction;   \n \nA      c"
            }
          ],
          "content": ""
        },
        {
          "id": 374,
          "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest",
          "type": "section",
          "children": [
            {
              "id": 375,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Se      SO      1      Embedding      Layer      . A”       =      =      UT      s      =      Recent      Interest\n |  |       Layer      Aa\n |       User      behavior      sequence |       vr      Evolution      Layer      u       :      8\n |       we      obtain      the      intra-session      interest      h,,      as      follows. (3.2)      h,      =      AvegPooling(SessEnc($“”)). Then we can get b intra-session interests [h1, ha,, ho]."
            },
            {
              "id": 376,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "By      extracting      session      interests      separately,      we      bypass      the       computation      of      self-attention      over      the      whole      sequence."
            },
            {
              "id": 377,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "It      can      be      viewed      as      a      form      of      local      self-attention      [28]      that       helps      to      avoid      inter-session      behavioral      noise,      i.e.,      inef-       fective      feature      interactions      between      irrelevant      behaviors       occurring      in      different      sessions,      and      thus      improves      both       the      efficiency      and      effectiveness      of      interest      modeling."
            },
            {
              "id": 378,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Inter-session      Interest      Evolution      Layer. We      adopt       GRU      [29],      a      variant      of      recurrent      neural      networks       (RNNs),      to      capture      the      evolution      of      historical      interest."
            },
            {
              "id": 379,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Although      RNNs      perform      well      at      capturing      temporal      dy-       namics,      they      suffer      from      inefficient      inference      time      due       to      their      low-parallelism      architectures      and      tend      to      forget       essential      information      when      processing      long      sequences. | (3.2)      h,   \n \n=      AvegPooling(SessEnc($“”)). Then we can get b intra-session interests [h1, ha,, ho]."
            },
            {
              "id": 380,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "By      extracting      session      interests      separately,      we      bypass      the  \n \n  computation      of      self-attention      over      the      whole      sequence."
            },
            {
              "id": 381,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "It      can      be      viewed      as   \n \na      form      of      local      self-attention      [28]      that  \n \n  helps      to      avoid      inter-session      behavioral      noise,      i.e.,      inef-  \n \n  fective      feature      interactions      between      irrelevant      behaviors  \n \n  occurring      in      different      sessions,      and      thus      improves      both  \n \n  the      efficiency      and      effectiveness      of      interest      modeling."
            },
            {
              "id": 382,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Inter-session      Interest      Evolution      Layer. We      adopt  \n \n  GRU      [29],   \n \na      variant      of      recurrent      neural      networks  \n \n  (RNNs),      to      capture      the      evolution      of      historical      interest."
            },
            {
              "id": 383,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Although      RNNs      perform      well      at      capturing      temporal      dy-  \n \n  namics,      they      suffer      from      inefficient      inference      time      due  \n \n  to      their      low-parallelism      architectures      and      tend      to      forget  \n \n  essential      information      when      processing      long      sequences."
            },
            {
              "id": 384,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "the      user’s      long-term      interest      can      be      expressed      as  \n \n  (3.5)      u’   \n \n=      Concat(u\",      uw\"). 3.5      Short-term      Interest      Encoder      We      use      the      cur-  \n \n  rent      session      S“*)      for      short-term      interest      modeling. How-  \n \n  ever,      some      current      sessions      contain      only      one      or      two      items  \n \n  and      thus      lack      clues      for      user      modeling."
            },
            {
              "id": 385,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Hence,      we      take  \n \n  the      latest   \n \nr      (r<T—1)      items,      i.e.,      the      recent      sub-sequence  \n \n  S”,      as      the      complementary      input. The      technical      details  \n \n  of      the      short-term      interest      encoder      are      described      below. Current      Session      Interest      Extractor      Layer."
            },
            {
              "id": 386,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  utilize      an      encoder      that      has      the      same      structure      as  \n \n  SessEnc(-)      in      Eq. B.2|and      denote      it      as      SessEnc’(-)."
            },
            {
              "id": 387,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Then\n |       Fortunately,      we      model      the      temporal      dynamics      be-       tween      sessions      rather      than      between      individual      items,      the       total      number      of      sessions      is      much      smaller      than      that      of       items,      thereby      significantly      reducing      inference      time      and       relieving      the      information      forgetting."
            },
            {
              "id": 388,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Besides,      a      coarse-       grained      session      representation      compresses      several      fine-       grained      item      representations,      so      that      taking      the      session-       level      representations      as      input      is      equivalent      to      enlarging       the      receptive      field      of      the      RNN      cell."
            },
            {
              "id": 389,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "We      formulate      inter-       session      interests      as      the      hidden      states      of      GRU      as      follows. | we      get      the      current      session      interest      u°      as      follows. (3.6)      us   \n \n=      AvePooling(SessEnc’(S)). | (3.3) hi] = GRU({hi, ho,       (hi,      byes | hol)."
            },
            {
              "id": 390,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "(hi,      byes\n |       Next,      we      adopt      an      attention      pooling      operation      to       conduct      a      soft      alignment      between      the      user’s      multiple       session-level      interests      and      the      target      item      v7. For      user’s intra-session interests, i.e., [hi,h2,, hy], we have ?"
            },
            {
              "id": 391,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "U7)      Ug)      Ug (3.4) wu” = AttnPool(vr, [hi, ho,,ho]) = — ahi, b       i=l       exp(hiWvr)       Dj=1      erP(hyWo7z)       ay=       where      W      €      R?@*¢      are      learnable      parameters."
            },
            {
              "id": 392,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Similarly,       we      also      perform      the      above      attention      pooling      operation on the user’s inter-session interests, i.e., [h),h5,, hi],       to      obtain      the      aggregated      representation      ul      Finally,       However,      the      limited      length      makes      the      current      session       more      sensitive      to      unintentional      behavior      noise,      so      we       adopt      contrastive      learning      to      enhance      the      robustness      of       the      representation."
            },
            {
              "id": 393,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "However,      as      shown      in      the      left      part       of      Fig."
            },
            {
              "id": 394,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "|3}      traditional      sequential      augmentations      [I7]      may       break      essential      item      relationships      or      lead      to      fewer      items       in      sequences,      thus      yielding      less      confident      positive      pairs       and      impairing      the      quality      of      the      learned      representation,       especially      for      short      sequences."
            },
            {
              "id": 395,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Considering      that      short-       term      interest      modeling      usually      relies      on      limited      recent       behaviors,      we      propose      a      new      data      augmentation      method       tailored      for      short      sequences,      which      uses      the      suffixes      of       the      original      current      session      as      additional      information      to       create      reliable      self-supervised      signals."
            },
            {
              "id": 396,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "|       As      shown      in      the      center      part      of      Fig."
            },
            {
              "id": 397,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "[3,      most       SR      methods      adopt      a      sequence      preprocessing      method       [30]      to      enhance      training      by      generating      a      collection      of       v1>(2)      (v3)      (v4)      (us)      (v6\n\n |  |       U7>\\\\\\\\Ug      V9      U1      U2,      U3,      V4      U5      Past\n |       Original      Sequence      V1      >      V2\\\\\\\\U3)\\\\\\\\      U4      U5,      UG |       Current      Session\n |       \\\\\\'       1       1      V1)>(U2)>(U3)>(U4)>\\\\\\\\U5)>UG |       U7)?\\\\\\\\Us)>      ?"
            },
            {
              "id": 398,
              "title": "Se      SO      1      Embedding      Layer      .      A”       =      =      UT      s      =      Recent      Interest - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "8       Target"
            }
          ],
          "content": ""
        },
        {
          "id": 399,
          "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future",
          "type": "section",
          "children": [
            {
              "id": 400,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "V2)      U3      U5      V7      V9       V7?)      (v9      Future\n \n  V7?)\n(v9      Future\nU1      v2      U4   \n \n1      ep      (Yp)>(¥9)>(v3)>(v4)>(05)>(U5  \n \n  1s   \n \n3       mW      G      1\\\\\\'s  \n \n  |  \n \n  8      SYS   \n \n|      Bi      @y)>@2)>@3)>@s)>5>@  \n \n  1   \n \n&   \n \n: U7)      (Ug)      ‘Ug      U4      OF\nU1)      \\\\\\\\U3)      V2)\\\\\\'\\\\\\\\VU4      U5      \\\\\\'  \n \n  1  \n \n  1  \n \n  1  \n \n  Traditional      augmentations U2      U3,      U5,      Us      U1      V4      U7)      Ug  \n \n  1  \n \n  1  \n \n  1  \n \n  1  \n \n  1  \n \n  1  \n \n  1  \n \n  1  \n \n  1      U1  \n \n  1  \n \n  1  \n \n  1  \n \n  U7      Us      Uy   \n \n1    \n \n1    \n \n1 Our      augmentation\n \n \n  prefixes      with      corresponding      new      targets      as      new      training  \n \n  instances,      while      discarding      the      suffixes,      i.e.,      future      data  \n \n  after      the      corresponding      new      targets."
            },
            {
              "id": 401,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "As      we      can      see,  \n \n  the      future      data      are      accessible      during      training      and      worth  \n \n  exploiting."
            },
            {
              "id": 402,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Therefore,      in      the      training      phase,      we      specify  \n \n  that      the      current      session      S$“)      contains   \n \na      past      sub-session  \n \n  gs      before      the      target      item      and   \n \na      future      sub-session Ss      after      it;      while      during      inference,      the      future      data      are inaccessible,      thus      S$      (k)   \n \n=      Ss),      Due      to      the      homogeneity  \n \n  of      intra-session      behaviors,      the      user’s      interests      in      the  \n \n  past      and      future      sub-sessions      are      highly      similar,      so      we  \n \n  randomly      exchange      items      from      the      two      sub-sessions      to  \n \n  build      positive      pairs."
            },
            {
              "id": 403,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "As      shown      in      the      right      part      of      Fig. 3}  \n \n  firstly,      we      randomly      select   \n \na      certain      proportion      of      items  \n \n  from      the      past      and      future      sub-sessions,      respectively. Secondly,      we      exchange      these      selected      items      and      merge  \n \n  them      with      the      reserved      items      of      the      other      side."
            },
            {
              "id": 404,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Finally,  \n \n  we      sort      the      two      merged      sessions      by      timestamp      to  \n \n  obtain      the      augmented      positive      pairs. This      homogeneous  \n \n  exchanging      augmentation      method      is      formulated      as se   \n \n=      Trctect      (SS,      7),      s)   \n \n=      Trcreor      (SY?"
            },
            {
              "id": 405,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "’      Y);\nSin   \n \n=      Tacierte(S$),      $0),      SM)   \n \n=      Tactere(SY,      SY), (k)  \n \n  a      alk (3.7)      S,   \n \n=      sort      (S$)   \n \n®      SU),   \n \n,   \n \n=    \n \nk      k\nSy   \n \n—      sort      (Sp,   \n \n©      S)),  \n \n  where   \n \ny      denotes      the      selection      ratio      and   \n \n©      denotes  \n \n  the      merge      operation."
            },
            {
              "id": 406,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "During      training,      let   \n \nB      denotes  \n \n  a      mini-batch      of      training      instances,      which      includes      |B|  \n \n  current      sessions,      each      session      containing   \n \na      past      and    \n \na      corresponding      future      sub-session."
            },
            {
              "id": 407,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Given      the      i-th  \n \n  current      session,      both      its      past      and      future      sub-sessions,  \n \n  ie,      S      (k)      and      se),      will      adopt      homogeneous      exchanging augmentation      method      to      obtain      positive      pairs,      i.e.,      Sh) and      sM),      which      are      then      fed      into      SessEnc’(-)      to      get  \n \n  the      representations,      ie.,      w,,      and      @%,."
            },
            {
              "id": 408,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Following      [16],  \n \n  (w,,,Us,)      is      treated      as   \n \na      positive      pair,      while      &,,      with  \n \n  the      other      2(|6|   \n \n—      1)      augmented      representations      are  \n \n  considered      as      negative      pairs      for      this      pair. We      adopt  \n \n  the      NT-Xent      loss      [I6]      for      optimization      as      follows."
            },
            {
              "id": 409,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Pe)      Yu,vlog(Gu,v      )+(1—Yyu,v      )log(1—Gu,v),  \n \n  where   \n \n©      denotes      the      set      of      trainable      parameters,      ||   \n \n-      ||2  \n \n  denotes      the      £2      regularization,   \n \n4      and   \n \n§      are      used      to  \n \n  control      the      strength      of      £,,;      and      [2      regularization."
            },
            {
              "id": 410,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "(3.8)  \n \n  exp(sim(é,,      @§,)/7)  \n \n  B   \n \n:      AC      AG   \n \n,       ah      Ij      zqexp(sim(@,,      U6;      )/T)  \n \n  Less      (tty,   \n \n,      &F,)   \n \n=      —log\n \n \n  where      I;      44   \n \n€      {0,1}      is      an      indicator      function,      sim(-)      is   \n \na       dot      product,   \n \n*      denotes      p      or      f,      and   \n \n7      is   \n \na      temperature  \n \n  index."
            },
            {
              "id": 411,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "It      is      worth      mentioning      that      we      only      calculate  \n \n  £551      for      training      instances      that      contain      both      past      and       future      sub-sessions. Recent      Interest      Evolution      Layer. We      take      the  \n \n  latest   \n \nr      (r<T      —1)      items      as      the      recent      sub-sequence,  \n \n  i.e.,      S”      [Up_r—1,      UT—r,+-;UT-1|."
            },
            {
              "id": 412,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "We      employ  \n \n  Time4LSTM      [4]      combined      with      the      attention      pooling  \n \n  in      Eq. 8.4]      to      obtain      recent      user      interest      u”      as      follows. (3.9)      u”   \n \n=      AttnPool(vr,      Time4LSTM(S\"))."
            },
            {
              "id": 413,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "We      set      the      recent      interest      evolution      layer      as      an      option  \n \n  to      be      used      only      when      the      current      session      is      extremely  \n \n  short,      and      also      set   \n \nr      as      small      as      possible      to      balance  \n \n  effectiveness      and      efficiency. Finally,      the      short-term      user  \n \n  interest      is      expressed      as:\n(3.10)      uw? =      Concat(u\",      u’)."
            },
            {
              "id": 414,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "3.6      Fusion      Prediction      Layer      Instead      of      using      sim-  \n \n  ple      aggregators      (e.g.,      summing      and      concatenation),      we  \n \n  adaptively      aggregate      long-      and      short-term      interests      for  \n \n  information      fusion,      considering      the      target      item      vr      and       the      trade-off      between      different      time-scale      interests      [4]."
            },
            {
              "id": 415,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "a\n \n   =\n \n   Sigmoid(W™      Concat(u”,      u°,      vr)   \n \n+      bm), LS      L      S       (3.11)      wu”      =au’+(l—-a)u’,  \n \n  where      W™      and      6b,      are      learnable      parameters. Finally,  \n \n  we      use      the      widely      adopted      two-layer      MLP      [6]      to      predict  \n \n  the      score      of      the      target      item      vr. (3.12)      Gu,»   \n \n=      Sigmoid(MLP(Concat(u’*,      vr)))."
            },
            {
              "id": 416,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "We      use      the      negative      log-likelihood      loss      [4]      {6}      as      follows. (3.13)       Lmain(Uu,      v)      =\n \n  Lmain(Uu,      v)   \n \n=    \n."
            },
            {
              "id": 417,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "N   \n \nv       where   \n \n©      is      the      set      of      training      instances,      containing   \n \na       positive      item      vr      that      the      user      has      interacted      with,      and       N   \n \n—   \n \n1      negative      items      that      are      sampled      within   \n \na      batch."
            },
            {
              "id": 418,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Finally,      we      use   \n \na      multi-task      strategy      to      optimize      the  \n \n  above      two      objectives:\n(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2,\nll2, 4\n \n   Experiments  \n \n  of      them      include      behaviors      such      as      click,      favorite,      add-  \n \n  to-cart,      and      purchase."
            },
            {
              "id": 419,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Details      of      the      datasets      are      listed  \n \n  in      Table      The      Taobao      dataset,      collected      from      the  \n \n  largest      online      shopping      platform      in      China,      includes  \n \n  user-item      interactions      from      25/11/2017      to      4/12/2017."
            },
            {
              "id": 420,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "We      use      interactions      before      1st      Dec      for      training      and       interactions      from      the      last   \n \n2      days      for      validation      and       testing,      respectively. The      Fliggy      dataset,      provided      by  \n \n  one      of      the      most      popular      online      travel      platforms      in  \n \n  China,      contains      user-item      interactions      from      3/6/2019  \n \n  to      3/6/2021."
            },
            {
              "id": 421,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "We      use      the      first      18      months      of      interactions  \n \n  for      training,      the      following   \n \n3      months      for      validation,      and       the      final   \n \n3      months      for      testing. We      leverage      the      same  \n \n  preprocessing      and      negative      sampling      methods      as      [6]. Baselines      and      Metrics."
            },
            {
              "id": 422,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "We      compare      LSIDN      with  \n \n  recommendation      models      of      various      research      lines:      (i)  \n \n  simple      holistic      interest      models      that      neither      distin-  \n \n  guish      between      different      time-scale      user      interests      nor      con-  \n \n  sider      denoising,      i.e.,      NCF      [18],      DIN      [19],      Caser      [20],      and       GRU4Rec      [21];      (ii)      long-      and      short-term      interest  \n \n  models      without      denoising      components,      i.e.,      SLi-Rec      [4]  \n \n  and      CLSR      [6];      (iii)      denoising      sequential      models      that  \n \n  do      not      distinguish      between      different      time-scale      user      in-  \n \n  terests,      i.e.,      FMLP-Rec      [14]      and      FEAR¢ec      [15]."
            },
            {
              "id": 423,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "We      eval-  \n \n  uate      these      models      with      two      accuracy      metrics,      i.e.,      AUC       and      GAUC,      and      two      ranking      metrics,      i.e.,      MRR      and       NDCGQK,      here   \n \nK   \n \n=      {5,10}. Implementation      Details."
            },
            {
              "id": 424,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      fair      comparison,      we  \n \n  implement      all      models      with      the      Microsoft      Recommenders  \n \n  framework      [31]      that      is      based      on      TensorFlow. We  \n \n  initialize      all      models      with   \n \na      normal      distribution      in      the  \n \n  range      [—0.01,0.01]      and      use      the      early      stopping      strategy  \n \n  of      [6]."
            },
            {
              "id": 425,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "We      set      the      embedding      size,      the      batch      size,      and       the      maximum      sequence      length      to      40,      500,      and      50      for  \n \n  all      models. Particularly      for      LSIDN,      we      set   \n \n6   \n \n=   \n \n5      and    \n \n1   \n \n=      10      for      both      datasets. We      use   \n \na      grid      search      to      find  \n \n  the      best      hyper-parameters."
            },
            {
              "id": 426,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Finally,      6,      A,      y,      and   \n \nr      are  \n \n  respectively      set      to      0.1,      0.1,      0.4,      and      30      for      Taobao      and       Fliggy;   \n \n7      is      0.2      for      Taobao      and      0.8      for      Fliggy,      w      is      360  \n \n  minutes      for      Taobao      and   \n \n5      days      for      Fliggy. 4.3."
            },
            {
              "id": 427,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Ablation      Study      To      demonstrate      how      each      key  \n \n  component      of      LSIDN      impacts      overall      performance,      we  \n \n  design      several      LSIDN      variants      by      removing      certain      com-  \n \n  ponents      for      comparisons,      including      (1)      w/o      LD:      re-  \n \n  moving      long-term      denoising      strategy      (i.e.,      directly      feed-  \n \n  ing      the      user      behavior      sequence      into      the      encoder      with-  \n \n  out      session      division),      (2)      w/o      SD:      removing      short-term  \n \n  denoising      components      (i.e.,      removing      the      contrastive  \n \n  learning),      (3)      w/o      RI:      without      the      recent      interest      evo-  \n \n  lution      layer   \n \n,      (4)      w/o      CI:      without      the      current      session  \n \n  interest      extraction      layer,      (5)      w/o      LI:      without      the      long-  \n \n  term      interest      encoder,      (6)      w/o      SI:      without      the      short-  \n \n  term      interest      encoder."
            },
            {
              "id": 428,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "From      Table      8}      we      find      that      removing      any      key      com-  \n \n  ponent      of      LSIDN      will      result      in      performance      degradation. Besides,      we      have      the      following      observations."
            },
            {
              "id": 429,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Firstly,  \n \n  the      short-term      interest      encoder      contributes      more      to      per-  \n \n  formance      than      the      long-term      interest      encoder,      mean-  \n \n  while,      for      the      two      components      of      the      short-term      inter-  \n \n  est      encoder,      i.e.,      current      session      interest      extraction      layer  \n \n  and      the      recent      interest      evolution      layer,      the      former      is  \n \n  more      important      than      the      latter."
            },
            {
              "id": 430,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "These      observations      are  \n \n  more      evident      in      Fliggy,      which      may      be      due      to      the      low-  \n \n  frequency      nature      of      the      travel      scenario,      making      user  \n \n  modeling      more      reliant      on      the      most      recent      behaviors. Secondly,      our      proposed      different      time-scale      denoising  \n \n  strategies      are      more      effective      in      Taobao."
            },
            {
              "id": 431,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "This      may      be  \n \n  because,      in      the      shopping      scenario,      the      goods      are      more  \n \n  abundant      and      diverse,      thus      user      behaviors      are      more      sus-  \n \n  ceptible      to      various      distractions      and      also      more      heteroge-  \n \n  neous      across      sessions,      which      exacerbates      the      noise      prob-  \n \n  lem      and      makes      our      denoising      strategies      more      useful."
            },
            {
              "id": 432,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "4.1      Experimental      Settings      We      elaborate      on      the  \n \n  details      of      experimental      setups      as      follows. Datasets. We      conduct      experiments      on      two      public      e-  \n \n  commerce      datasets,      i.e.,      Taobag\\\\\\'|      and      Fliggy||      Both\n*https://tianchi.aliyun.com/dataset/649  \n \n  thttps://tianchi.aliyun.com/dataset/113649  \n \n  Dataset      #Users      #Items      +#Interactions      Avg."
            },
            {
              "id": 433,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "length\nTaobao      —-36,915      64,138      1,471,155      39.85  \n \n  Fliggy      180,232      50,355      5,781,867      22.58 Table      1:      Statistics      of      Datasets 4.2      Performance      Comparison      We      list      the      perfor-  \n \n  mance      of      all      models      in      Table   \n \n|      and      obtain      the      following  \n \n  observation."
            },
            {
              "id": 434,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      the      long-      and      short-term      interest  \n \n  models,      i.e.,      SLi-Rec      and      CLSR,      outperform      the      simple  \n \n  holistic      interest      models      in      most      cases,      demonstrating      the  \n \n  superiority      of      jointly      modeling      different      time      scales      of  \n \n  user      interests."
            },
            {
              "id": 435,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      the      denoising      sequential      mod-  \n \n  els      outperform      the      above      non-denoising      models      in      most  \n \n  cases,      indicating      the      importance      of      denoising      compo-  \n \n  nents. Thirdly,      the      proposed      LSIDN      exceeds      all      base-  \n \n  lines      by   \n \na      large      margin      in      all      cases."
            },
            {
              "id": 436,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "This      is      attributed  \n \n  to      the      combination      of      different      time-scale      user      interests  \n \n  and      the      implementation      of      corresponding      time-scale      de-  \n \n  noising      strategies,      allowing      for      more      comprehensive      and       robust      user      modeling."
            },
            {
              "id": 437,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Taobao      Fliggy       Model      AUC      GAUC      MRR      NDCG@5      NDCG@10}      AUC      GAUC      MRR      NDCG@5      NDCG@10\n \n \n  NCF      0.7159      0.7196      0.1405      0.1231      0.1625      0.6622      0.6837      0.115      0.0951      0.1311  \n \n  DIN      0.7572      0.8552      0.3250      0.3355      0.3840      0.7695      0.8434      0.2898      0.2945      0.3444  \n \n  Caser      0.8538      0.8607      0.3944      0.4055      0.4440      0.8075      0.8516      0.2910      0.3033      0.3526  \n \n  GRU4Rec   \n \n|      0.8699      0.8652      0.4307      0.4419      0.4777      0.8448      0.8587      0.3269      0.3353      0.3794 SLi-Rec      0.8843      0.8816      0.3999      0.4143      0.4552      0.8622      0.8709      0.3175      0.3237      0.3705  \n \n  CLSR      0.9049      0.9052      0.4652      0.4817      0.5182      0.8751      0.8858      0.3436      0.3512      0.3981 FMLP-Rec}      0.8910      0.9158      0.5529      0.5696      0.5957      0.8782      0.9176      0.5547      0.5714      0.6011  \n \n  FEARec      0.9155      0.9179      0.5551      0.5763      0.6070      0.9063      0.9187      0.5581      0.5748      0.6055 LSIDN      |0.9218      0.9213      0.5752      0.5931      0.6211      |0.9082      0.9206      0.5741      0.5878      0.6144\nTaobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10\nLSIDN      0.9213      0.6211      0.9206      0.6144\n(1)      w/o      LD   \n \n|      0.8987      2.45%)      0.5796      (-6.68%)      0.9153      (-0.58%)      0.6022      (-1.99%)\n(2)      w/oSD   \n \n|      0.9155      (-0.63%)      0.5967      (-3.93%)      0.9189      (-0.19%)      0.6139      (-0.08%)\n(3)      w/o      RI   \n \n|      0.9185      (-0.30%)      0.6185      (-0.42%)      0.9201      (-0.05%)      0.6135      (-0.15%)\n(4)      w/o      CI   \n \n|      0.9125      (-0.96%)      0.5857      (-5.70%)      0.8697      (-5.53%)      0.4513      (-26.55%)\n(5)      w/o      LI   \n \n|      0.9086      (-1.38%)      0.6150      (-0.98%)      0.9072      (-1.46%)      0.5998      (-2.38%)\n(6)      w/o      SI   \n \n|      0.8619      (-6.45%)      0.4588      (-26.13%)   \n \n|      0.8317      (-9.66%)      0.3752      (-38.93%)\n4.4      Long-      and      Short-term      Interest      Analysis  \n \n  Taking      the      Taobao      dataset      as      an      example,      we      con-  \n \n  duct      further      experiments      to      thoroughly      analyze      whether  \n \n  LSIDN      captures      effective      and      meaningful      long-      and       short-term      interest      representations,      respectively,      by  \n \n  comparing      LSIDN      with      two      other      long-      and      short-term  \n \n  interest      models,      i.e.,      CLSR      and      SLi-Rec."
            },
            {
              "id": 438,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      given      each      of      the      three      models,      we      sepa-  \n \n  rately      construct      two      variants,      i.e.,      Long      (removing      the  \n \n  short-term      interest      encoder)      and      Short      (removing      the  \n \n  long-term      interest      encoder),      and      we      denote      the      origi-  \n \n  nal      model      as      Both. From      Figs."
            },
            {
              "id": 439,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "f(a)      and      [A{b),      we\n \n \n  can      see      that      LSIDN      outperforms      SLi-Rec      and      CLSR  \n \n  in      all      cases,      revealing      that      LSIDN      learns      more      effec-  \n \n  tive      long-      and      short-term      interests      than      the      other      two  \n \n  models."
            },
            {
              "id": 440,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      we      find      that      previous      work      [32]  \n \n  claims      that      expensive      behaviors      (i.e.,      purchases)      tend  \n \n  to      be      driven      more      by      stable      long-term      user      preferences,  \n \n  whereas      cheap      behaviors      (i.e.,      clicks)      are      more      likely      to  \n \n  imply      variable      short-term      user      intentions;      also,      we      find  \n \n  that      SLi-Rec,      CLSR,      and      LSIDN      all      have      an      adaptive  \n \n  weight      a,      whose      value      depends      on      the      sequence      con-  \n \n  text      and      reflects      the      importance      of      the      user’s      long-term  \n \n  interest."
            },
            {
              "id": 441,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Inspired      by      this,      we      use      each      of      the      three  \n \n  previously      trained      models      to      make      predictions      for      click  \n \n  and      purchase      items,      respectively. We      believe      that      if  \n \n  a      certain      one      of      the      three      models      captures      meaningful  \n \n  long-      and      short-term      interests,      then      the      Avg."
            },
            {
              "id": 442,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "a      of      the model      on      purchase      items      should      be      larger      than      its      Avg. a      on      click      items. From      Fig. Ac),      we      find      that      only  \n \n  LSIDN      meets      our      expectations,      suggesting      that      LSIDN  \n \n  has      learned      more      meaningful      long-      and      short-term      inter-  \n \n  ests      than      SLi-Rec      and      CLSR. And      from      Figs."
            },
            {
              "id": 443,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "[(d)      and       [4{e),      LSIDN      outperforms      the      other      two      models      in      both the      purchase      and      click      datasets,      further      demonstrating  \n \n  its      superiority      in      long-      and      short-term      user      modeling."
            },
            {
              "id": 444,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "4.5      Robustness      Analysis      To      evaluate      the      robust-  \n \n  ness      of      LSIDN      and      other      methods,      we      modify      the  \n \n  Taobao      datasets      as      follows:      contaminate      the      training  \n \n  and      validation      sets      by      adding   \n \na      proportion      of      adversarial  \n \n  instances      (i.e.,      10%,      20%,      and      30%      negative      user-item  \n \n  interactions),      while      keeping      the      test      set      unchanged."
            },
            {
              "id": 445,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      compare      the      robustness      of      LSIDN      and       several      baseline      models. As      shown      in      Fig."
            },
            {
              "id": 446,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "bla),      the      sim-\n \n \n  ple      holistic      interest      model,      i.e.,      GRU4Rec,      shows      poor  \n \n  noise      resistance,      while      FMLP-Rec      and      CLSR      perform  \n \n  better,      indicating      that      either      denoising      designs      or      joint  \n \n  modeling      of      different      time-scale      interests      can      improve  \n \n  model      robustness."
            },
            {
              "id": 447,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Importantly,      LSIDN      performs      best      in  \n \n  all      cases      due      to      its      robust      and      comprehensive      user      mod-  \n \n  eling. Secondly,      we      investigate      the      effect      of      different  \n \n  time-scale      denoising      strategies      employed      in      LSIDN. As  \n \n  shown      in      Fig."
            },
            {
              "id": 448,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "[b(b),      we      can      see      that      after      removing      the  \n \n  denoising      strategy      in      short-term      interest      modeling      (i.e.,  \n \n  w/o      SD),      performance      declines      faster      as      the      noise      rate  \n \n  Se,\nClick      ‘Purchase\ninterest      models. ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      ."
            },
            {
              "id": 449,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "—*-LSIDN       ] Drop      Rate(%)\neae\n2\n \n \n  o  \n \n  iB  \n \n  BN  \n \n  RS  \n \n  ies pas 0.1 0.2   \n \n3 (c)\nFigure      5:      Robustness      analysis      of      different      methods."
            },
            {
              "id": 450,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "increases,      proving      the      effectiveness      of      contrastive      learn-  \n \n  ing      in      denoising;      after      removing      the      denoising      strategy  \n \n  in      long-term      interest      modeling      (i-e.,      w/o      LD),      the      eval-  \n \n  uation      metric      significantly      decreases      due      to      the      intro-  \n \n  duced      inter-session      interference,      but      the      noise      resistance  \n \n  is      comparable      to      original      LSIDN      due      to      reserved      short-  \n \n  term      denoising      component."
            },
            {
              "id": 451,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Finally,      we      replace      our  \n \n  augmentation      with      traditional      augmentation      methods  \n \n  (i.e.,      crop,      mask,      and      reorder)      for      comparisons,      denoted  \n \n  as      LSIDN      w/      C,      LSIDN      w/      M,      and      LSIDN      w/      R,      re-  \n \n  spectively. As      shown      in      Fig."
            },
            {
              "id": 452,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Ble),      we      can      see      that      the  \n \n  tion,      too      large   \n \nA      will      conflict      with      the      main      task      and       too      small      \\\\\\\\      will      lead      to      ineffective      regularization. The  \n \n  results      shown      in      Fig."
            },
            {
              "id": 453,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "6b)      support      the      view      of      point,  \n \n  where      the      optimal      value      of   \n \n)      is      0.1;      (iii)      the      session      di-  \n \n  vision      threshold      w,      which      controls      the      division      criteria  \n \n  of      the      user      behavior      sequence,      small      w      leads      to      over-  \n \n  segmentation      while      large      w      leads      to      under-segmentation,  \n \n  both      of      which      make      segmented      sessions      sub-optimal  \n \n  for      representing      session-level      interests."
            },
            {
              "id": 454,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "As      shown      in  \n \n  Fig. [6(c),      360      minutes      is      the      best      for      w,      while      smaller  \n \n  or      larger      values      both      impair      performance. Note      that      we  \n \n  keep      all      other      hyperparameters      optimal      when      investi-  \n \n  gating      each      hyperparameter."
            },
            {
              "id": 455,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "original      LSIDN      outperforms      its      variants      in      terms      of      eval-  \n \n  uation      metrics      and      noise      resistance,      further      demonstrat-  \n \n  ing      the      superiority      of      our      augmentation      method."
            },
            {
              "id": 456,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "4.6      Hyper-parameter      Sensitivity      We      investigate  \n \n  the      effect      of      three      important      hyperparameters      on      model  \n \n  performance,      including      (i)      the      temperature      index      7,  \n \n  which      plays   \n \na      critical      role      in      mining      hard      negatives      [T7]. As      shown      in      Fig."
            },
            {
              "id": 457,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "6a),      when   \n \n7   \n \n=      0.2,      LSIDN      performs\n5\n \n   Conclusion  \n \n  In      this      paper,      we      propose   \n \na      long-      and      short-term      in-  \n \n  terest      denoising      network,      which      employs      different      en-  \n \n  coders      and      tailored      denoising      strategies      to      extract      differ-  \n \n  ent      time-scale      user      interests,      respectively,      thus      achieve  \n \n  more      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 458,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Specif-  \n \n  ically,      we      employ   \n \na      session-level      interest      extraction      and       evolution      strategy      to      avoid      introducing      inter-session      be-  \n \n  havioral      noise      into      long-term      interest      modeling;      we      also  \n \n  the      best,      whereas      smaller      or      larger      values      will      result  \n \n  in      poor      performance;      (ii)      the      contrastive      loss      weight      A,  \n \n  which      controls      the      strength      of      contrastive      regulariza- [15] [16]  \n \n  A      simple      framework      for      contrastive      learning      of      visual  \n \n  representations."
            },
            {
              "id": 459,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "In:      ICML. pp. 1597—1607(2020)  \n \n  Yu,      J.,      Huang,      Z.,      et      al. :      Self-supervised      learning      for  \n \n  recommender      systems:   \n \nA      survey. IEEE      Transactions  \n \n  on      Knowledge      and      Data      Engineering      (2023)  \n \n  He,      X.,      et      al. :      Neural      collaborative      filtering. In:      WWW. pp."
            },
            {
              "id": 460,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "173-182      (2017)  \n \n  Zhou,      G.,      Zhu,      X.,      Yan,      Y.,      Jin,      J.,      Li,      H.,      Gai,      K.,  \n \n  et      al. :      Deep      interest      network      for      click-through      rate  \n \n  prediction. In:      SIGKDD. pp. 1059-1068      (2018) Tang, J Wang, K.: Personalized top-n sequential  \n \n  recommendation      via      convolutional      sequence      embedding. In:      WSDM. pp."
            },
            {
              "id": 461,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "565-573      (2018)  \n \n  Hidasi,      B.,      Karatzoglou,      A.,      Baltrunas,      L.,      Tikk,      D.:  \n \n  Session-based      recommendations      with      recurrent      neural  \n \n  networks. arXiv      preprint      arXiv:1511.06939      (2015)  \n \n  Yu,      Y.,      Jin,      B.,      Song,      J.,      Li,      B.,      et      al. :      Improving  \n \n  Micro-video      Recommendation      by      Controlling      Position  \n \n  Bias. In:      ECML-PKDD. pp."
            },
            {
              "id": 462,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "508-523      (2022). Li      B,      Jin      B,      Song      J,      Yu      Y,      Zheng      Y,      Zhou      W. Improving  \n \n  Micro-video      Recommendation      via      Contrastive      Multiple  \n \n  Interests. In:      SIGIR. pp. 2377-2381      (2022)  \n \n  Zhou,      K.,      et      al. :      S?-Rec:      Self-supervised      learning      for  \n \n  sequential      recommendation      with      mutual      information  \n \n  maximization. In:      CIKM. pp."
            },
            {
              "id": 463,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "1893-1902      (2020)  \n \n  Xie,      X.,      Sun,      F.,      Gao,      J.,      Ding,      B.,      Cui,      B.,      et      al. :  \n \n  Contrastive      learning      for      sequential      recommendation. In:      ICDE. pp. 1259-1273. IEEE      (2022)  \n \n  Cheng,      M.,      et      al. :      Learning      transferable      user      repre-  \n \n  sentations      with      sequential      behaviors      via      contrastive      pre-  \n \n  training. In:      ICDM. pp. 51-60."
            },
            {
              "id": 464,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "IEEE      (2021)  \n \n  Vaswani,      A.,      Shazeer,      Gomez,      A.N.,      Kaiser,      L.,      Polo-  \n \n  sukhin,      I.,      et      al. :      Attention      is      all      you      need. Advances  \n \n  in      neural      information      processing      systems      30      (2017)  \n \n  Beltagy,      I.,      Peters,      M.E.,      Cohan,      A::      Long-  \n \n  former:      The      long-document      transformer."
            },
            {
              "id": 465,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "arXiv  \n \n  preprint      arXiv:2004.05150)      (2020)  \n \n  Dey,      R.,      Salem,      F. M.:      Gate-variants      of      gated      recurrent  \n \n  unit      (GRU)      neural      networks. In:      MWSCAS. pp. 1597-  \n \n  1600. IEEE      (2017)  \n \n  Tan,      et      al. :      Improved      recurrent      neural      networks      for  \n \n  session-based      recommendations."
            },
            {
              "id": 466,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "In:      The      1st      workshop  \n \n  on      deep      learning      for      recommender      systems. pp. 17—22  \n \n  (2016)  \n \n  Argyriou,      A.,      Gonzdlez-Fierro,      M.,      Zhang,      L.:      Mi-  \n \n  crosoft      recommenders:      Best      practices      for      production-  \n \n  ready      recommendation      systems. In:      WWW. pp."
            },
            {
              "id": 467,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "50-51  \n \n  (2020)  \n \n  Grbovic,      M.,      Cheng,      H.:      Real-time      personalization  \n \n  using      embeddings      for      search      ranking      at      Airbnb. In:  \n \n  SIGKDD. pp."
            },
            {
              "id": 468,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "311-320      (2018) [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [8] [10] [11] [12]  \n \n  [13]  \n \n  Fang,      H.,      Zhang,      D.,      Shu,      Y.,      Guo,      G.:      Deep      learning  \n \n  for      sequential      recommendation:      Algorithms,      influential  \n \n  factors,      and      evaluations."
            },
            {
              "id": 469,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "ACM      Transactions      on      Infor-  \n \n  mation      Systems      (TOIS)      39(1),      1-42      (2020)  \n \n  Ying,      H.,      Zhuang,      F.,      Liu,      Y.,      Xie,      X.,      Xiong,      H.,  \n \n  Wu,      J.,      et      al. :      Sequential      recommender      system      based  \n \n  on      hierarchical      attention      network."
            },
            {
              "id": 470,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI      (2018)  \n \n  Ly,      F.,      Jin,      T.,      Lin,      Q.,      Yang,      K.,      Ng,      W.,      et      al. :      SDM:\n |  |       ——auc|*”*      °°. —      GAUC      —*—      AUC       —=—      GAUC |       ——auc|*”*      °°."
            },
            {
              "id": 471,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "—      GAUC      —*—      AUC       —=—      GAUC       0.922      0.922      +--~~      ~~      ae      0.922       I      <=       \\\\\\\\      §550      oe      8      0.921      -      \"lo      o0Q       5      I       ‘*      x      vos      Ss      918      —_      918       0.924 | \n | --- | --- | --- | ---\n | 0.905       o       0.1      02      04      06      08      1      :      0       T 0.916      0.916       wane      40.916      }      —."
            },
            {
              "id": 472,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "| 0.914      0.914\n\n0.05      ,0.1      O15      0.2      30      90      360      720  \n \n  @      (min) ny\n(c)  \n \n  [3]\n(a)\n \n \n  Sequential      deep      matching      model      for      online      large-scale  \n \n  recommender      system. In:      CHKM. pp. 2635-2643      (2019)  \n \n  Yu,      Z.,      Lian,      J.,      Xie,      X.,      et      al."
            },
            {
              "id": 473,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": ":      Adaptive      user      modeling  \n \n  with      long      and      short-term      preferences      for      personalized  \n \n  recommendation. In:      IJCAI. pp. 4213-4219      (2019)      .Tan,      Q.,      Zhang,      J.,      Zhou,      J.,      Hu,      X.,      et      al. :      Dynamic  \n \n  memory      based      attention      network      for      sequential      recom-  \n \n  mendation. In:      AAAI. vol. 35,      pp."
            },
            {
              "id": 474,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "4384-4392(2021)  \n \n  Zheng,      Y.,      Gao,      C.,      Chang,      J.,      Niu,      Y.,      Song,      Y.,      Jin,  \n \n  D.,      Li,      Y.:      Disentangling      long      and      short-term      interests  \n \n  for      recommendation. In:      WWW. pp."
            },
            {
              "id": 475,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 76",
              "type": "chunk",
              "children": [],
              "content": "2256-2267      (2022)  \n \n  Du,      J.,      Ye,      Z.,      Guo,      B.,      Yu,      Z.,      Yao,      L.:      IDNP:      Interest  \n \n  Dynamics      Modeling      using      Generative      Neural      Processes  \n \n  for      Sequential      Recommendation. In:      WSDM. pp. 481-  \n \n  489      (2023)  \n \n  Jagerman,      R.,      et      al."
            },
            {
              "id": 476,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 77",
              "type": "chunk",
              "children": [],
              "content": ":      To      model      or      to      intervene:   \n \nA       comparison      of      counterfactual      and      online      learning      to  \n \n  rank      from      user      interactions. In:      SIGIR. pp. 15-24  \n \n  (2019)  \n \n  Hofmann,      Katja.,      et      al. :      On      caption      bias      in      interleaving  \n \n  experiments. In:      CIKM. pp."
            },
            {
              "id": 477,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 78",
              "type": "chunk",
              "children": [],
              "content": "115-124      (2012)  \n \n  Zheng,      Y.,      Gao,      C.,      Chen,      L.,      Jin,      D.,   \n \n&      Li,      Y.:      DGCN:  \n \n  Diversified      recommendation      with      graph      convolutional  \n \n  networks. In:      WWW. pp. 401-412      (2021)  \n \n  Luo,      A.,      Wang,      D.,      Xu,      J.,      Fang,      J.,      Sheng,      V.S.,      et      al. :  \n \n  Collaborative      self-attention      network      for      session-based  \n \n  recommendation."
            },
            {
              "id": 478,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 79",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI. pp. 2591-2597      (2020)  \n \n  Qin,      Y.,      Wang,      P.,      Li,      C.:      The      world      is      binary:      Con-  \n \n  trastive      learning      for      denoising      neat      basket      recommen-  \n \n  dation. In:      SIGIR. pp. 859-868      (2021)  \n \n  Lin,      Y.,      Wang,      C.,      Xin,      X.,      Yan,      Q.,      de      Rijke,      M.,  \n \n  Cheng,      X.,      Ren,      P.,      et      al."
            },
            {
              "id": 479,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 80",
              "type": "chunk",
              "children": [],
              "content": ":   \n \nA      self-correcting      sequential  \n \n  recommender. arXiv      preprint      arXiv:2303.02297      (2023)  \n \n  [14] [4] [5] [6] [7 [31]  \n \n  [32]  \n \n  Zhou,      K.,      Yu,      H.,      Zhao,      W.X.,      Wen,      J.R. :      Filter-  \n \n  enhanced      mlp      is      all      you      need      for      sequential      recommen-  \n \n  dation. In:      WWW. pp."
            },
            {
              "id": 480,
              "title": "V2)      U3      U5      V7      V9       V7?)      (v9      Future - Chunk 81",
              "type": "chunk",
              "children": [],
              "content": "2388-2399      (2022)  \n \n  Du,      X.,      Liu,      G.,      Liu,      Y.,      Sheng,      V.S.,      et      al. :      Frequency  \n \n  enhanced      hybrid      attention      network      for      sequential      rec-  \n \n  ommendation. In:      SIGIR. pp. 78-88      (2023)  \n \n  Chen,      T.,      Kornblith,      $.,      Norouzi,      M.,      Hinton,      G.:"
            }
          ],
          "content": ""
        },
        {
          "id": 481,
          "title": "(3.13)       Lmain(Uu,      v)      =",
          "type": "section",
          "children": [
            {
              "id": 482,
              "title": "(3.13)       Lmain(Uu,      v)      = - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(3.13)       Lmain(Uu,      v)      =\n \n  Lmain(Uu,      v)   \n \n=    \n. N   \n \nv       where   \n \n©      is      the      set      of      training      instances,      containing   \n \na       positive      item      vr      that      the      user      has      interacted      with,      and       N   \n \n—   \n \n1      negative      items      that      are      sampled      within   \n \na      batch."
            },
            {
              "id": 483,
              "title": "(3.13)       Lmain(Uu,      v)      = - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Finally,      we      use   \n \na      multi-task      strategy      to      optimize      the  \n \n  above      two      objectives:"
            }
          ],
          "content": ""
        },
        {
          "id": 484,
          "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2,",
          "type": "section",
          "children": [
            {
              "id": 485,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2,\nll2, 4\n \n   Experiments  \n \n  of      them      include      behaviors      such      as      click,      favorite,      add-  \n \n  to-cart,      and      purchase."
            },
            {
              "id": 486,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Details      of      the      datasets      are      listed  \n \n  in      Table      The      Taobao      dataset,      collected      from      the  \n \n  largest      online      shopping      platform      in      China,      includes  \n \n  user-item      interactions      from      25/11/2017      to      4/12/2017."
            },
            {
              "id": 487,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "We      use      interactions      before      1st      Dec      for      training      and       interactions      from      the      last   \n \n2      days      for      validation      and       testing,      respectively. The      Fliggy      dataset,      provided      by  \n \n  one      of      the      most      popular      online      travel      platforms      in  \n \n  China,      contains      user-item      interactions      from      3/6/2019  \n \n  to      3/6/2021."
            },
            {
              "id": 488,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "We      use      the      first      18      months      of      interactions  \n \n  for      training,      the      following   \n \n3      months      for      validation,      and       the      final   \n \n3      months      for      testing. We      leverage      the      same  \n \n  preprocessing      and      negative      sampling      methods      as      [6]. Baselines      and      Metrics."
            },
            {
              "id": 489,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      compare      LSIDN      with  \n \n  recommendation      models      of      various      research      lines:      (i)  \n \n  simple      holistic      interest      models      that      neither      distin-  \n \n  guish      between      different      time-scale      user      interests      nor      con-  \n \n  sider      denoising,      i.e.,      NCF      [18],      DIN      [19],      Caser      [20],      and       GRU4Rec      [21];      (ii)      long-      and      short-term      interest  \n \n  models      without      denoising      components,      i.e.,      SLi-Rec      [4]  \n \n  and      CLSR      [6];      (iii)      denoising      sequential      models      that  \n \n  do      not      distinguish      between      different      time-scale      user      in-  \n \n  terests,      i.e.,      FMLP-Rec      [14]      and      FEAR¢ec      [15]."
            },
            {
              "id": 490,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "We      eval-  \n \n  uate      these      models      with      two      accuracy      metrics,      i.e.,      AUC       and      GAUC,      and      two      ranking      metrics,      i.e.,      MRR      and       NDCGQK,      here   \n \nK   \n \n=      {5,10}. Implementation      Details."
            },
            {
              "id": 491,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      fair      comparison,      we  \n \n  implement      all      models      with      the      Microsoft      Recommenders  \n \n  framework      [31]      that      is      based      on      TensorFlow. We  \n \n  initialize      all      models      with   \n \na      normal      distribution      in      the  \n \n  range      [—0.01,0.01]      and      use      the      early      stopping      strategy  \n \n  of      [6]."
            },
            {
              "id": 492,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "We      set      the      embedding      size,      the      batch      size,      and       the      maximum      sequence      length      to      40,      500,      and      50      for  \n \n  all      models. Particularly      for      LSIDN,      we      set   \n \n6   \n \n=   \n \n5      and    \n \n1   \n \n=      10      for      both      datasets. We      use   \n \na      grid      search      to      find  \n \n  the      best      hyper-parameters."
            },
            {
              "id": 493,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Finally,      6,      A,      y,      and   \n \nr      are  \n \n  respectively      set      to      0.1,      0.1,      0.4,      and      30      for      Taobao      and       Fliggy;   \n \n7      is      0.2      for      Taobao      and      0.8      for      Fliggy,      w      is      360  \n \n  minutes      for      Taobao      and   \n \n5      days      for      Fliggy. 4.3."
            },
            {
              "id": 494,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Ablation      Study      To      demonstrate      how      each      key  \n \n  component      of      LSIDN      impacts      overall      performance,      we  \n \n  design      several      LSIDN      variants      by      removing      certain      com-  \n \n  ponents      for      comparisons,      including      (1)      w/o      LD:      re-  \n \n  moving      long-term      denoising      strategy      (i.e.,      directly      feed-  \n \n  ing      the      user      behavior      sequence      into      the      encoder      with-  \n \n  out      session      division),      (2)      w/o      SD:      removing      short-term  \n \n  denoising      components      (i.e.,      removing      the      contrastive  \n \n  learning),      (3)      w/o      RI:      without      the      recent      interest      evo-  \n \n  lution      layer   \n \n,      (4)      w/o      CI:      without      the      current      session  \n \n  interest      extraction      layer,      (5)      w/o      LI:      without      the      long-  \n \n  term      interest      encoder,      (6)      w/o      SI:      without      the      short-  \n \n  term      interest      encoder."
            },
            {
              "id": 495,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "From      Table      8}      we      find      that      removing      any      key      com-  \n \n  ponent      of      LSIDN      will      result      in      performance      degradation. Besides,      we      have      the      following      observations."
            },
            {
              "id": 496,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Firstly,  \n \n  the      short-term      interest      encoder      contributes      more      to      per-  \n \n  formance      than      the      long-term      interest      encoder,      mean-  \n \n  while,      for      the      two      components      of      the      short-term      inter-  \n \n  est      encoder,      i.e.,      current      session      interest      extraction      layer  \n \n  and      the      recent      interest      evolution      layer,      the      former      is  \n \n  more      important      than      the      latter."
            },
            {
              "id": 497,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "These      observations      are  \n \n  more      evident      in      Fliggy,      which      may      be      due      to      the      low-  \n \n  frequency      nature      of      the      travel      scenario,      making      user  \n \n  modeling      more      reliant      on      the      most      recent      behaviors. Secondly,      our      proposed      different      time-scale      denoising  \n \n  strategies      are      more      effective      in      Taobao."
            },
            {
              "id": 498,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "This      may      be  \n \n  because,      in      the      shopping      scenario,      the      goods      are      more  \n \n  abundant      and      diverse,      thus      user      behaviors      are      more      sus-  \n \n  ceptible      to      various      distractions      and      also      more      heteroge-  \n \n  neous      across      sessions,      which      exacerbates      the      noise      prob-  \n \n  lem      and      makes      our      denoising      strategies      more      useful."
            },
            {
              "id": 499,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "4.1      Experimental      Settings      We      elaborate      on      the  \n \n  details      of      experimental      setups      as      follows. Datasets. We      conduct      experiments      on      two      public      e-  \n \n  commerce      datasets,      i.e.,      Taobag\\\\\\'|      and      Fliggy||      Both\n*https://tianchi.aliyun.com/dataset/649  \n \n  thttps://tianchi.aliyun.com/dataset/113649  \n \n  Dataset      #Users      #Items      +#Interactions      Avg."
            },
            {
              "id": 500,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "length\nTaobao      —-36,915      64,138      1,471,155      39.85  \n \n  Fliggy      180,232      50,355      5,781,867      22.58 Table      1:      Statistics      of      Datasets 4.2      Performance      Comparison      We      list      the      perfor-  \n \n  mance      of      all      models      in      Table   \n \n|      and      obtain      the      following  \n \n  observation."
            },
            {
              "id": 501,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      the      long-      and      short-term      interest  \n \n  models,      i.e.,      SLi-Rec      and      CLSR,      outperform      the      simple  \n \n  holistic      interest      models      in      most      cases,      demonstrating      the  \n \n  superiority      of      jointly      modeling      different      time      scales      of  \n \n  user      interests."
            },
            {
              "id": 502,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      the      denoising      sequential      mod-  \n \n  els      outperform      the      above      non-denoising      models      in      most  \n \n  cases,      indicating      the      importance      of      denoising      compo-  \n \n  nents. Thirdly,      the      proposed      LSIDN      exceeds      all      base-  \n \n  lines      by   \n \na      large      margin      in      all      cases."
            },
            {
              "id": 503,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "This      is      attributed  \n \n  to      the      combination      of      different      time-scale      user      interests  \n \n  and      the      implementation      of      corresponding      time-scale      de-  \n \n  noising      strategies,      allowing      for      more      comprehensive      and       robust      user      modeling."
            },
            {
              "id": 504,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Taobao      Fliggy       Model      AUC      GAUC      MRR      NDCG@5      NDCG@10}      AUC      GAUC      MRR      NDCG@5      NDCG@10\n \n \n  NCF      0.7159      0.7196      0.1405      0.1231      0.1625      0.6622      0.6837      0.115      0.0951      0.1311  \n \n  DIN      0.7572      0.8552      0.3250      0.3355      0.3840      0.7695      0.8434      0.2898      0.2945      0.3444  \n \n  Caser      0.8538      0.8607      0.3944      0.4055      0.4440      0.8075      0.8516      0.2910      0.3033      0.3526  \n \n  GRU4Rec   \n \n|      0.8699      0.8652      0.4307      0.4419      0.4777      0.8448      0.8587      0.3269      0.3353      0.3794 SLi-Rec      0.8843      0.8816      0.3999      0.4143      0.4552      0.8622      0.8709      0.3175      0.3237      0.3705  \n \n  CLSR      0.9049      0.9052      0.4652      0.4817      0.5182      0.8751      0.8858      0.3436      0.3512      0.3981 FMLP-Rec}      0.8910      0.9158      0.5529      0.5696      0.5957      0.8782      0.9176      0.5547      0.5714      0.6011  \n \n  FEARec      0.9155      0.9179      0.5551      0.5763      0.6070      0.9063      0.9187      0.5581      0.5748      0.6055 LSIDN      |0.9218      0.9213      0.5752      0.5931      0.6211      |0.9082      0.9206      0.5741      0.5878      0.6144\nTaobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10\nLSIDN      0.9213      0.6211      0.9206      0.6144\n(1)      w/o      LD   \n \n|      0.8987      2.45%)      0.5796      (-6.68%)      0.9153      (-0.58%)      0.6022      (-1.99%)\n(2)      w/oSD   \n \n|      0.9155      (-0.63%)      0.5967      (-3.93%)      0.9189      (-0.19%)      0.6139      (-0.08%)\n(3)      w/o      RI   \n \n|      0.9185      (-0.30%)      0.6185      (-0.42%)      0.9201      (-0.05%)      0.6135      (-0.15%)\n(4)      w/o      CI   \n \n|      0.9125      (-0.96%)      0.5857      (-5.70%)      0.8697      (-5.53%)      0.4513      (-26.55%)\n(5)      w/o      LI   \n \n|      0.9086      (-1.38%)      0.6150      (-0.98%)      0.9072      (-1.46%)      0.5998      (-2.38%)\n(6)      w/o      SI   \n \n|      0.8619      (-6.45%)      0.4588      (-26.13%)   \n \n|      0.8317      (-9.66%)      0.3752      (-38.93%)\n4.4      Long-      and      Short-term      Interest      Analysis  \n \n  Taking      the      Taobao      dataset      as      an      example,      we      con-  \n \n  duct      further      experiments      to      thoroughly      analyze      whether  \n \n  LSIDN      captures      effective      and      meaningful      long-      and       short-term      interest      representations,      respectively,      by  \n \n  comparing      LSIDN      with      two      other      long-      and      short-term  \n \n  interest      models,      i.e.,      CLSR      and      SLi-Rec."
            },
            {
              "id": 505,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      given      each      of      the      three      models,      we      sepa-  \n \n  rately      construct      two      variants,      i.e.,      Long      (removing      the  \n \n  short-term      interest      encoder)      and      Short      (removing      the  \n \n  long-term      interest      encoder),      and      we      denote      the      origi-  \n \n  nal      model      as      Both. From      Figs."
            },
            {
              "id": 506,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "f(a)      and      [A{b),      we\n \n \n  can      see      that      LSIDN      outperforms      SLi-Rec      and      CLSR  \n \n  in      all      cases,      revealing      that      LSIDN      learns      more      effec-  \n \n  tive      long-      and      short-term      interests      than      the      other      two  \n \n  models."
            },
            {
              "id": 507,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      we      find      that      previous      work      [32]  \n \n  claims      that      expensive      behaviors      (i.e.,      purchases)      tend  \n \n  to      be      driven      more      by      stable      long-term      user      preferences,  \n \n  whereas      cheap      behaviors      (i.e.,      clicks)      are      more      likely      to  \n \n  imply      variable      short-term      user      intentions;      also,      we      find  \n \n  that      SLi-Rec,      CLSR,      and      LSIDN      all      have      an      adaptive  \n \n  weight      a,      whose      value      depends      on      the      sequence      con-  \n \n  text      and      reflects      the      importance      of      the      user’s      long-term  \n \n  interest."
            },
            {
              "id": 508,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "Inspired      by      this,      we      use      each      of      the      three  \n \n  previously      trained      models      to      make      predictions      for      click  \n \n  and      purchase      items,      respectively. We      believe      that      if  \n \n  a      certain      one      of      the      three      models      captures      meaningful  \n \n  long-      and      short-term      interests,      then      the      Avg."
            },
            {
              "id": 509,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "a      of      the model      on      purchase      items      should      be      larger      than      its      Avg. a      on      click      items. From      Fig. Ac),      we      find      that      only  \n \n  LSIDN      meets      our      expectations,      suggesting      that      LSIDN  \n \n  has      learned      more      meaningful      long-      and      short-term      inter-  \n \n  ests      than      SLi-Rec      and      CLSR. And      from      Figs."
            },
            {
              "id": 510,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "[(d)      and       [4{e),      LSIDN      outperforms      the      other      two      models      in      both the      purchase      and      click      datasets,      further      demonstrating  \n \n  its      superiority      in      long-      and      short-term      user      modeling."
            },
            {
              "id": 511,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "4.5      Robustness      Analysis      To      evaluate      the      robust-  \n \n  ness      of      LSIDN      and      other      methods,      we      modify      the  \n \n  Taobao      datasets      as      follows:      contaminate      the      training  \n \n  and      validation      sets      by      adding   \n \na      proportion      of      adversarial  \n \n  instances      (i.e.,      10%,      20%,      and      30%      negative      user-item  \n \n  interactions),      while      keeping      the      test      set      unchanged."
            },
            {
              "id": 512,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      compare      the      robustness      of      LSIDN      and       several      baseline      models. As      shown      in      Fig."
            },
            {
              "id": 513,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "bla),      the      sim-\n \n \n  ple      holistic      interest      model,      i.e.,      GRU4Rec,      shows      poor  \n \n  noise      resistance,      while      FMLP-Rec      and      CLSR      perform  \n \n  better,      indicating      that      either      denoising      designs      or      joint  \n \n  modeling      of      different      time-scale      interests      can      improve  \n \n  model      robustness."
            },
            {
              "id": 514,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Importantly,      LSIDN      performs      best      in  \n \n  all      cases      due      to      its      robust      and      comprehensive      user      mod-  \n \n  eling. Secondly,      we      investigate      the      effect      of      different  \n \n  time-scale      denoising      strategies      employed      in      LSIDN. As  \n \n  shown      in      Fig."
            },
            {
              "id": 515,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "[b(b),      we      can      see      that      after      removing      the  \n \n  denoising      strategy      in      short-term      interest      modeling      (i.e.,  \n \n  w/o      SD),      performance      declines      faster      as      the      noise      rate  \n \n  Se,\nClick      ‘Purchase\ninterest      models. ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      ."
            },
            {
              "id": 516,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "—*-LSIDN       ] Drop      Rate(%)\neae\n2\n \n \n  o  \n \n  iB  \n \n  BN  \n \n  RS  \n \n  ies pas 0.1 0.2   \n \n3 (c)\nFigure      5:      Robustness      analysis      of      different      methods."
            },
            {
              "id": 517,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "increases,      proving      the      effectiveness      of      contrastive      learn-  \n \n  ing      in      denoising;      after      removing      the      denoising      strategy  \n \n  in      long-term      interest      modeling      (i-e.,      w/o      LD),      the      eval-  \n \n  uation      metric      significantly      decreases      due      to      the      intro-  \n \n  duced      inter-session      interference,      but      the      noise      resistance  \n \n  is      comparable      to      original      LSIDN      due      to      reserved      short-  \n \n  term      denoising      component."
            },
            {
              "id": 518,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Finally,      we      replace      our  \n \n  augmentation      with      traditional      augmentation      methods  \n \n  (i.e.,      crop,      mask,      and      reorder)      for      comparisons,      denoted  \n \n  as      LSIDN      w/      C,      LSIDN      w/      M,      and      LSIDN      w/      R,      re-  \n \n  spectively. As      shown      in      Fig."
            },
            {
              "id": 519,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Ble),      we      can      see      that      the  \n \n  tion,      too      large   \n \nA      will      conflict      with      the      main      task      and       too      small      \\\\\\\\      will      lead      to      ineffective      regularization. The  \n \n  results      shown      in      Fig."
            },
            {
              "id": 520,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "6b)      support      the      view      of      point,  \n \n  where      the      optimal      value      of   \n \n)      is      0.1;      (iii)      the      session      di-  \n \n  vision      threshold      w,      which      controls      the      division      criteria  \n \n  of      the      user      behavior      sequence,      small      w      leads      to      over-  \n \n  segmentation      while      large      w      leads      to      under-segmentation,  \n \n  both      of      which      make      segmented      sessions      sub-optimal  \n \n  for      representing      session-level      interests."
            },
            {
              "id": 521,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "As      shown      in  \n \n  Fig. [6(c),      360      minutes      is      the      best      for      w,      while      smaller  \n \n  or      larger      values      both      impair      performance. Note      that      we  \n \n  keep      all      other      hyperparameters      optimal      when      investi-  \n \n  gating      each      hyperparameter."
            },
            {
              "id": 522,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "original      LSIDN      outperforms      its      variants      in      terms      of      eval-  \n \n  uation      metrics      and      noise      resistance,      further      demonstrat-  \n \n  ing      the      superiority      of      our      augmentation      method."
            },
            {
              "id": 523,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "4.6      Hyper-parameter      Sensitivity      We      investigate  \n \n  the      effect      of      three      important      hyperparameters      on      model  \n \n  performance,      including      (i)      the      temperature      index      7,  \n \n  which      plays   \n \na      critical      role      in      mining      hard      negatives      [T7]. As      shown      in      Fig."
            },
            {
              "id": 524,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "6a),      when   \n \n7   \n \n=      0.2,      LSIDN      performs\n5\n \n   Conclusion  \n \n  In      this      paper,      we      propose   \n \na      long-      and      short-term      in-  \n \n  terest      denoising      network,      which      employs      different      en-  \n \n  coders      and      tailored      denoising      strategies      to      extract      differ-  \n \n  ent      time-scale      user      interests,      respectively,      thus      achieve  \n \n  more      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 525,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Specif-  \n \n  ically,      we      employ   \n \na      session-level      interest      extraction      and       evolution      strategy      to      avoid      introducing      inter-session      be-  \n \n  havioral      noise      into      long-term      interest      modeling;      we      also  \n \n  the      best,      whereas      smaller      or      larger      values      will      result  \n \n  in      poor      performance;      (ii)      the      contrastive      loss      weight      A,  \n \n  which      controls      the      strength      of      contrastive      regulariza- [15] [16]  \n \n  A      simple      framework      for      contrastive      learning      of      visual  \n \n  representations."
            },
            {
              "id": 526,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "In:      ICML. pp. 1597—1607(2020)  \n \n  Yu,      J.,      Huang,      Z.,      et      al. :      Self-supervised      learning      for  \n \n  recommender      systems:   \n \nA      survey. IEEE      Transactions  \n \n  on      Knowledge      and      Data      Engineering      (2023)  \n \n  He,      X.,      et      al. :      Neural      collaborative      filtering. In:      WWW. pp."
            },
            {
              "id": 527,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "173-182      (2017)  \n \n  Zhou,      G.,      Zhu,      X.,      Yan,      Y.,      Jin,      J.,      Li,      H.,      Gai,      K.,  \n \n  et      al. :      Deep      interest      network      for      click-through      rate  \n \n  prediction. In:      SIGKDD. pp. 1059-1068      (2018) Tang, J Wang, K.: Personalized top-n sequential  \n \n  recommendation      via      convolutional      sequence      embedding. In:      WSDM. pp."
            },
            {
              "id": 528,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "565-573      (2018)  \n \n  Hidasi,      B.,      Karatzoglou,      A.,      Baltrunas,      L.,      Tikk,      D.:  \n \n  Session-based      recommendations      with      recurrent      neural  \n \n  networks. arXiv      preprint      arXiv:1511.06939      (2015)  \n \n  Yu,      Y.,      Jin,      B.,      Song,      J.,      Li,      B.,      et      al. :      Improving  \n \n  Micro-video      Recommendation      by      Controlling      Position  \n \n  Bias. In:      ECML-PKDD. pp."
            },
            {
              "id": 529,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "508-523      (2022). Li      B,      Jin      B,      Song      J,      Yu      Y,      Zheng      Y,      Zhou      W. Improving  \n \n  Micro-video      Recommendation      via      Contrastive      Multiple  \n \n  Interests. In:      SIGIR. pp. 2377-2381      (2022)  \n \n  Zhou,      K.,      et      al. :      S?-Rec:      Self-supervised      learning      for  \n \n  sequential      recommendation      with      mutual      information  \n \n  maximization. In:      CIKM. pp."
            },
            {
              "id": 530,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "1893-1902      (2020)  \n \n  Xie,      X.,      Sun,      F.,      Gao,      J.,      Ding,      B.,      Cui,      B.,      et      al. :  \n \n  Contrastive      learning      for      sequential      recommendation. In:      ICDE. pp. 1259-1273. IEEE      (2022)  \n \n  Cheng,      M.,      et      al. :      Learning      transferable      user      repre-  \n \n  sentations      with      sequential      behaviors      via      contrastive      pre-  \n \n  training. In:      ICDM. pp. 51-60."
            },
            {
              "id": 531,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "IEEE      (2021)  \n \n  Vaswani,      A.,      Shazeer,      Gomez,      A.N.,      Kaiser,      L.,      Polo-  \n \n  sukhin,      I.,      et      al. :      Attention      is      all      you      need. Advances  \n \n  in      neural      information      processing      systems      30      (2017)  \n \n  Beltagy,      I.,      Peters,      M.E.,      Cohan,      A::      Long-  \n \n  former:      The      long-document      transformer."
            },
            {
              "id": 532,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "arXiv  \n \n  preprint      arXiv:2004.05150)      (2020)  \n \n  Dey,      R.,      Salem,      F. M.:      Gate-variants      of      gated      recurrent  \n \n  unit      (GRU)      neural      networks. In:      MWSCAS. pp. 1597-  \n \n  1600. IEEE      (2017)  \n \n  Tan,      et      al. :      Improved      recurrent      neural      networks      for  \n \n  session-based      recommendations."
            },
            {
              "id": 533,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "In:      The      1st      workshop  \n \n  on      deep      learning      for      recommender      systems. pp. 17—22  \n \n  (2016)  \n \n  Argyriou,      A.,      Gonzdlez-Fierro,      M.,      Zhang,      L.:      Mi-  \n \n  crosoft      recommenders:      Best      practices      for      production-  \n \n  ready      recommendation      systems. In:      WWW. pp."
            },
            {
              "id": 534,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "50-51  \n \n  (2020)  \n \n  Grbovic,      M.,      Cheng,      H.:      Real-time      personalization  \n \n  using      embeddings      for      search      ranking      at      Airbnb. In:  \n \n  SIGKDD. pp."
            },
            {
              "id": 535,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "311-320      (2018) [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [8] [10] [11] [12]  \n \n  [13]  \n \n  Fang,      H.,      Zhang,      D.,      Shu,      Y.,      Guo,      G.:      Deep      learning  \n \n  for      sequential      recommendation:      Algorithms,      influential  \n \n  factors,      and      evaluations."
            },
            {
              "id": 536,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "ACM      Transactions      on      Infor-  \n \n  mation      Systems      (TOIS)      39(1),      1-42      (2020)  \n \n  Ying,      H.,      Zhuang,      F.,      Liu,      Y.,      Xie,      X.,      Xiong,      H.,  \n \n  Wu,      J.,      et      al. :      Sequential      recommender      system      based  \n \n  on      hierarchical      attention      network."
            },
            {
              "id": 537,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI      (2018)  \n \n  Ly,      F.,      Jin,      T.,      Lin,      Q.,      Yang,      K.,      Ng,      W.,      et      al. :      SDM:\n |  |       ——auc|*”*      °°. —      GAUC      —*—      AUC       —=—      GAUC |       ——auc|*”*      °°."
            },
            {
              "id": 538,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "—      GAUC      —*—      AUC       —=—      GAUC       0.922      0.922      +--~~      ~~      ae      0.922       I      <=       \\\\\\\\      §550      oe      8      0.921      -      \"lo      o0Q       5      I       ‘*      x      vos      Ss      918      —_      918       0.924 | \n | --- | --- | --- | ---\n | 0.905       o       0.1      02      04      06      08      1      :      0       T 0.916      0.916       wane      40.916      }      —."
            },
            {
              "id": 539,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "| 0.914      0.914\n\n0.05      ,0.1      O15      0.2      30      90      360      720  \n \n  @      (min) ny\n(c)  \n \n  [3]\n(a)\n \n \n  Sequential      deep      matching      model      for      online      large-scale  \n \n  recommender      system. In:      CHKM. pp. 2635-2643      (2019)  \n \n  Yu,      Z.,      Lian,      J.,      Xie,      X.,      et      al."
            },
            {
              "id": 540,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": ":      Adaptive      user      modeling  \n \n  with      long      and      short-term      preferences      for      personalized  \n \n  recommendation. In:      IJCAI. pp. 4213-4219      (2019)      .Tan,      Q.,      Zhang,      J.,      Zhou,      J.,      Hu,      X.,      et      al. :      Dynamic  \n \n  memory      based      attention      network      for      sequential      recom-  \n \n  mendation. In:      AAAI. vol. 35,      pp."
            },
            {
              "id": 541,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "4384-4392(2021)  \n \n  Zheng,      Y.,      Gao,      C.,      Chang,      J.,      Niu,      Y.,      Song,      Y.,      Jin,  \n \n  D.,      Li,      Y.:      Disentangling      long      and      short-term      interests  \n \n  for      recommendation. In:      WWW. pp."
            },
            {
              "id": 542,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "2256-2267      (2022)  \n \n  Du,      J.,      Ye,      Z.,      Guo,      B.,      Yu,      Z.,      Yao,      L.:      IDNP:      Interest  \n \n  Dynamics      Modeling      using      Generative      Neural      Processes  \n \n  for      Sequential      Recommendation. In:      WSDM. pp. 481-  \n \n  489      (2023)  \n \n  Jagerman,      R.,      et      al."
            },
            {
              "id": 543,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": ":      To      model      or      to      intervene:   \n \nA       comparison      of      counterfactual      and      online      learning      to  \n \n  rank      from      user      interactions. In:      SIGIR. pp. 15-24  \n \n  (2019)  \n \n  Hofmann,      Katja.,      et      al. :      On      caption      bias      in      interleaving  \n \n  experiments. In:      CIKM. pp."
            },
            {
              "id": 544,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "115-124      (2012)  \n \n  Zheng,      Y.,      Gao,      C.,      Chen,      L.,      Jin,      D.,   \n \n&      Li,      Y.:      DGCN:  \n \n  Diversified      recommendation      with      graph      convolutional  \n \n  networks. In:      WWW. pp. 401-412      (2021)  \n \n  Luo,      A.,      Wang,      D.,      Xu,      J.,      Fang,      J.,      Sheng,      V.S.,      et      al. :  \n \n  Collaborative      self-attention      network      for      session-based  \n \n  recommendation."
            },
            {
              "id": 545,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI. pp. 2591-2597      (2020)  \n \n  Qin,      Y.,      Wang,      P.,      Li,      C.:      The      world      is      binary:      Con-  \n \n  trastive      learning      for      denoising      neat      basket      recommen-  \n \n  dation. In:      SIGIR. pp. 859-868      (2021)  \n \n  Lin,      Y.,      Wang,      C.,      Xin,      X.,      Yan,      Q.,      de      Rijke,      M.,  \n \n  Cheng,      X.,      Ren,      P.,      et      al."
            },
            {
              "id": 546,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": ":   \n \nA      self-correcting      sequential  \n \n  recommender. arXiv      preprint      arXiv:2303.02297      (2023)  \n \n  [14] [4] [5] [6] [7 [31]  \n \n  [32]  \n \n  Zhou,      K.,      Yu,      H.,      Zhao,      W.X.,      Wen,      J.R. :      Filter-  \n \n  enhanced      mlp      is      all      you      need      for      sequential      recommen-  \n \n  dation. In:      WWW. pp."
            },
            {
              "id": 547,
              "title": "(3.14)      L=Lmain      +      Lss1      +      B\\\\\\\\|Oll2, - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "2388-2399      (2022)  \n \n  Du,      X.,      Liu,      G.,      Liu,      Y.,      Sheng,      V.S.,      et      al. :      Frequency  \n \n  enhanced      hybrid      attention      network      for      sequential      rec-  \n \n  ommendation. In:      SIGIR. pp. 78-88      (2023)  \n \n  Chen,      T.,      Kornblith,      $.,      Norouzi,      M.,      Hinton,      G.:"
            }
          ],
          "content": ""
        },
        {
          "id": 548,
          "title": "Taobao      Fliggy       Model      AUC      GAUC      MRR      NDCG@5      NDCG@10}      AUC      GAUC      MRR      NDCG@5      NDCG@10",
          "type": "section",
          "children": [
            {
              "id": 549,
              "title": "Taobao      Fliggy       Model      AUC      GAUC      MRR      NDCG@5      NDCG@10}      AUC      GAUC      MRR      NDCG@5      NDCG@10 - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Taobao      Fliggy       Model      AUC      GAUC      MRR      NDCG@5      NDCG@10}      AUC      GAUC      MRR      NDCG@5      NDCG@10\n \n \n  NCF      0.7159      0.7196      0.1405      0.1231      0.1625      0.6622      0.6837      0.115      0.0951      0.1311  \n \n  DIN      0.7572      0.8552      0.3250      0.3355      0.3840      0.7695      0.8434      0.2898      0.2945      0.3444  \n \n  Caser      0.8538      0.8607      0.3944      0.4055      0.4440      0.8075      0.8516      0.2910      0.3033      0.3526  \n \n  GRU4Rec   \n \n|      0.8699      0.8652      0.4307      0.4419      0.4777      0.8448      0.8587      0.3269      0.3353      0.3794 SLi-Rec      0.8843      0.8816      0.3999      0.4143      0.4552      0.8622      0.8709      0.3175      0.3237      0.3705  \n \n  CLSR      0.9049      0.9052      0.4652      0.4817      0.5182      0.8751      0.8858      0.3436      0.3512      0.3981 FMLP-Rec}      0.8910      0.9158      0.5529      0.5696      0.5957      0.8782      0.9176      0.5547      0.5714      0.6011  \n \n  FEARec      0.9155      0.9179      0.5551      0.5763      0.6070      0.9063      0.9187      0.5581      0.5748      0.6055 LSIDN      |0.9218      0.9213      0.5752      0.5931      0.6211      |0.9082      0.9206      0.5741      0.5878      0.6144"
            }
          ],
          "content": ""
        },
        {
          "id": 550,
          "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10",
          "type": "section",
          "children": [
            {
              "id": 551,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10\nLSIDN      0.9213      0.6211      0.9206      0.6144\n(1)      w/o      LD   \n \n|      0.8987      2.45%)      0.5796      (-6.68%)      0.9153      (-0.58%)      0.6022      (-1.99%)\n(2)      w/oSD   \n \n|      0.9155      (-0.63%)      0.5967      (-3.93%)      0.9189      (-0.19%)      0.6139      (-0.08%)\n(3)      w/o      RI   \n \n|      0.9185      (-0.30%)      0.6185      (-0.42%)      0.9201      (-0.05%)      0.6135      (-0.15%)\n(4)      w/o      CI   \n \n|      0.9125      (-0.96%)      0.5857      (-5.70%)      0.8697      (-5.53%)      0.4513      (-26.55%)\n(5)      w/o      LI   \n \n|      0.9086      (-1.38%)      0.6150      (-0.98%)      0.9072      (-1.46%)      0.5998      (-2.38%)\n(6)      w/o      SI   \n \n|      0.8619      (-6.45%)      0.4588      (-26.13%)   \n \n|      0.8317      (-9.66%)      0.3752      (-38.93%)\n4.4      Long-      and      Short-term      Interest      Analysis  \n \n  Taking      the      Taobao      dataset      as      an      example,      we      con-  \n \n  duct      further      experiments      to      thoroughly      analyze      whether  \n \n  LSIDN      captures      effective      and      meaningful      long-      and       short-term      interest      representations,      respectively,      by  \n \n  comparing      LSIDN      with      two      other      long-      and      short-term  \n \n  interest      models,      i.e.,      CLSR      and      SLi-Rec."
            },
            {
              "id": 552,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      given      each      of      the      three      models,      we      sepa-  \n \n  rately      construct      two      variants,      i.e.,      Long      (removing      the  \n \n  short-term      interest      encoder)      and      Short      (removing      the  \n \n  long-term      interest      encoder),      and      we      denote      the      origi-  \n \n  nal      model      as      Both. From      Figs."
            },
            {
              "id": 553,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "f(a)      and      [A{b),      we\n \n \n  can      see      that      LSIDN      outperforms      SLi-Rec      and      CLSR  \n \n  in      all      cases,      revealing      that      LSIDN      learns      more      effec-  \n \n  tive      long-      and      short-term      interests      than      the      other      two  \n \n  models."
            },
            {
              "id": 554,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Secondly,      we      find      that      previous      work      [32]  \n \n  claims      that      expensive      behaviors      (i.e.,      purchases)      tend  \n \n  to      be      driven      more      by      stable      long-term      user      preferences,  \n \n  whereas      cheap      behaviors      (i.e.,      clicks)      are      more      likely      to  \n \n  imply      variable      short-term      user      intentions;      also,      we      find  \n \n  that      SLi-Rec,      CLSR,      and      LSIDN      all      have      an      adaptive  \n \n  weight      a,      whose      value      depends      on      the      sequence      con-  \n \n  text      and      reflects      the      importance      of      the      user’s      long-term  \n \n  interest."
            },
            {
              "id": 555,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Inspired      by      this,      we      use      each      of      the      three  \n \n  previously      trained      models      to      make      predictions      for      click  \n \n  and      purchase      items,      respectively. We      believe      that      if  \n \n  a      certain      one      of      the      three      models      captures      meaningful  \n \n  long-      and      short-term      interests,      then      the      Avg."
            },
            {
              "id": 556,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "a      of      the model      on      purchase      items      should      be      larger      than      its      Avg. a      on      click      items. From      Fig. Ac),      we      find      that      only  \n \n  LSIDN      meets      our      expectations,      suggesting      that      LSIDN  \n \n  has      learned      more      meaningful      long-      and      short-term      inter-  \n \n  ests      than      SLi-Rec      and      CLSR. And      from      Figs."
            },
            {
              "id": 557,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "[(d)      and       [4{e),      LSIDN      outperforms      the      other      two      models      in      both the      purchase      and      click      datasets,      further      demonstrating  \n \n  its      superiority      in      long-      and      short-term      user      modeling."
            },
            {
              "id": 558,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "4.5      Robustness      Analysis      To      evaluate      the      robust-  \n \n  ness      of      LSIDN      and      other      methods,      we      modify      the  \n \n  Taobao      datasets      as      follows:      contaminate      the      training  \n \n  and      validation      sets      by      adding   \n \na      proportion      of      adversarial  \n \n  instances      (i.e.,      10%,      20%,      and      30%      negative      user-item  \n \n  interactions),      while      keeping      the      test      set      unchanged."
            },
            {
              "id": 559,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      compare      the      robustness      of      LSIDN      and       several      baseline      models. As      shown      in      Fig."
            },
            {
              "id": 560,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "bla),      the      sim-\n \n \n  ple      holistic      interest      model,      i.e.,      GRU4Rec,      shows      poor  \n \n  noise      resistance,      while      FMLP-Rec      and      CLSR      perform  \n \n  better,      indicating      that      either      denoising      designs      or      joint  \n \n  modeling      of      different      time-scale      interests      can      improve  \n \n  model      robustness."
            },
            {
              "id": 561,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Importantly,      LSIDN      performs      best      in  \n \n  all      cases      due      to      its      robust      and      comprehensive      user      mod-  \n \n  eling. Secondly,      we      investigate      the      effect      of      different  \n \n  time-scale      denoising      strategies      employed      in      LSIDN. As  \n \n  shown      in      Fig."
            },
            {
              "id": 562,
              "title": "Taobao      Fliggy       Method      GAUC      NDCG@10      GAUC      NDCG@10 - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "[b(b),      we      can      see      that      after      removing      the  \n \n  denoising      strategy      in      short-term      interest      modeling      (i.e.,  \n \n  w/o      SD),      performance      declines      faster      as      the      noise      rate  \n \n  Se,"
            }
          ],
          "content": ""
        },
        {
          "id": 563,
          "title": "Click      ‘Purchase",
          "type": "section",
          "children": [
            {
              "id": 564,
              "title": "Click      ‘Purchase - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Click      ‘Purchase\ninterest      models."
            }
          ],
          "content": ""
        },
        {
          "id": 565,
          "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%)",
          "type": "section",
          "children": [
            {
              "id": 566,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      . —*-LSIDN       ] Drop      Rate(%)\neae\n2\n \n \n  o  \n \n  iB  \n \n  BN  \n \n  RS  \n \n  ies pas 0.1 0.2   \n \n3 (c)\nFigure      5:      Robustness      analysis      of      different      methods."
            },
            {
              "id": 567,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "increases,      proving      the      effectiveness      of      contrastive      learn-  \n \n  ing      in      denoising;      after      removing      the      denoising      strategy  \n \n  in      long-term      interest      modeling      (i-e.,      w/o      LD),      the      eval-  \n \n  uation      metric      significantly      decreases      due      to      the      intro-  \n \n  duced      inter-session      interference,      but      the      noise      resistance  \n \n  is      comparable      to      original      LSIDN      due      to      reserved      short-  \n \n  term      denoising      component."
            },
            {
              "id": 568,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Finally,      we      replace      our  \n \n  augmentation      with      traditional      augmentation      methods  \n \n  (i.e.,      crop,      mask,      and      reorder)      for      comparisons,      denoted  \n \n  as      LSIDN      w/      C,      LSIDN      w/      M,      and      LSIDN      w/      R,      re-  \n \n  spectively. As      shown      in      Fig."
            },
            {
              "id": 569,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Ble),      we      can      see      that      the  \n \n  tion,      too      large   \n \nA      will      conflict      with      the      main      task      and       too      small      \\\\\\\\      will      lead      to      ineffective      regularization. The  \n \n  results      shown      in      Fig."
            },
            {
              "id": 570,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "6b)      support      the      view      of      point,  \n \n  where      the      optimal      value      of   \n \n)      is      0.1;      (iii)      the      session      di-  \n \n  vision      threshold      w,      which      controls      the      division      criteria  \n \n  of      the      user      behavior      sequence,      small      w      leads      to      over-  \n \n  segmentation      while      large      w      leads      to      under-segmentation,  \n \n  both      of      which      make      segmented      sessions      sub-optimal  \n \n  for      representing      session-level      interests."
            },
            {
              "id": 571,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "As      shown      in  \n \n  Fig. [6(c),      360      minutes      is      the      best      for      w,      while      smaller  \n \n  or      larger      values      both      impair      performance. Note      that      we  \n \n  keep      all      other      hyperparameters      optimal      when      investi-  \n \n  gating      each      hyperparameter."
            },
            {
              "id": 572,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "original      LSIDN      outperforms      its      variants      in      terms      of      eval-  \n \n  uation      metrics      and      noise      resistance,      further      demonstrat-  \n \n  ing      the      superiority      of      our      augmentation      method."
            },
            {
              "id": 573,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "4.6      Hyper-parameter      Sensitivity      We      investigate  \n \n  the      effect      of      three      important      hyperparameters      on      model  \n \n  performance,      including      (i)      the      temperature      index      7,  \n \n  which      plays   \n \na      critical      role      in      mining      hard      negatives      [T7]. As      shown      in      Fig."
            },
            {
              "id": 574,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "6a),      when   \n \n7   \n \n=      0.2,      LSIDN      performs\n5\n \n   Conclusion  \n \n  In      this      paper,      we      propose   \n \na      long-      and      short-term      in-  \n \n  terest      denoising      network,      which      employs      different      en-  \n \n  coders      and      tailored      denoising      strategies      to      extract      differ-  \n \n  ent      time-scale      user      interests,      respectively,      thus      achieve  \n \n  more      comprehensive      and      robust      user      modeling."
            },
            {
              "id": 575,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Specif-  \n \n  ically,      we      employ   \n \na      session-level      interest      extraction      and       evolution      strategy      to      avoid      introducing      inter-session      be-  \n \n  havioral      noise      into      long-term      interest      modeling;      we      also  \n \n  the      best,      whereas      smaller      or      larger      values      will      result  \n \n  in      poor      performance;      (ii)      the      contrastive      loss      weight      A,  \n \n  which      controls      the      strength      of      contrastive      regulariza- [15] [16]  \n \n  A      simple      framework      for      contrastive      learning      of      visual  \n \n  representations."
            },
            {
              "id": 576,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "In:      ICML. pp. 1597—1607(2020)  \n \n  Yu,      J.,      Huang,      Z.,      et      al. :      Self-supervised      learning      for  \n \n  recommender      systems:   \n \nA      survey. IEEE      Transactions  \n \n  on      Knowledge      and      Data      Engineering      (2023)  \n \n  He,      X.,      et      al. :      Neural      collaborative      filtering. In:      WWW. pp."
            },
            {
              "id": 577,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "173-182      (2017)  \n \n  Zhou,      G.,      Zhu,      X.,      Yan,      Y.,      Jin,      J.,      Li,      H.,      Gai,      K.,  \n \n  et      al. :      Deep      interest      network      for      click-through      rate  \n \n  prediction. In:      SIGKDD. pp. 1059-1068      (2018) Tang, J Wang, K.: Personalized top-n sequential  \n \n  recommendation      via      convolutional      sequence      embedding. In:      WSDM. pp."
            },
            {
              "id": 578,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "565-573      (2018)  \n \n  Hidasi,      B.,      Karatzoglou,      A.,      Baltrunas,      L.,      Tikk,      D.:  \n \n  Session-based      recommendations      with      recurrent      neural  \n \n  networks. arXiv      preprint      arXiv:1511.06939      (2015)  \n \n  Yu,      Y.,      Jin,      B.,      Song,      J.,      Li,      B.,      et      al. :      Improving  \n \n  Micro-video      Recommendation      by      Controlling      Position  \n \n  Bias. In:      ECML-PKDD. pp."
            },
            {
              "id": 579,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "508-523      (2022). Li      B,      Jin      B,      Song      J,      Yu      Y,      Zheng      Y,      Zhou      W. Improving  \n \n  Micro-video      Recommendation      via      Contrastive      Multiple  \n \n  Interests. In:      SIGIR. pp. 2377-2381      (2022)  \n \n  Zhou,      K.,      et      al. :      S?-Rec:      Self-supervised      learning      for  \n \n  sequential      recommendation      with      mutual      information  \n \n  maximization. In:      CIKM. pp."
            },
            {
              "id": 580,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "1893-1902      (2020)  \n \n  Xie,      X.,      Sun,      F.,      Gao,      J.,      Ding,      B.,      Cui,      B.,      et      al. :  \n \n  Contrastive      learning      for      sequential      recommendation. In:      ICDE. pp. 1259-1273. IEEE      (2022)  \n \n  Cheng,      M.,      et      al. :      Learning      transferable      user      repre-  \n \n  sentations      with      sequential      behaviors      via      contrastive      pre-  \n \n  training. In:      ICDM. pp. 51-60."
            },
            {
              "id": 581,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "IEEE      (2021)  \n \n  Vaswani,      A.,      Shazeer,      Gomez,      A.N.,      Kaiser,      L.,      Polo-  \n \n  sukhin,      I.,      et      al. :      Attention      is      all      you      need. Advances  \n \n  in      neural      information      processing      systems      30      (2017)  \n \n  Beltagy,      I.,      Peters,      M.E.,      Cohan,      A::      Long-  \n \n  former:      The      long-document      transformer."
            },
            {
              "id": 582,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "arXiv  \n \n  preprint      arXiv:2004.05150)      (2020)  \n \n  Dey,      R.,      Salem,      F. M.:      Gate-variants      of      gated      recurrent  \n \n  unit      (GRU)      neural      networks. In:      MWSCAS. pp. 1597-  \n \n  1600. IEEE      (2017)  \n \n  Tan,      et      al. :      Improved      recurrent      neural      networks      for  \n \n  session-based      recommendations."
            },
            {
              "id": 583,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In:      The      1st      workshop  \n \n  on      deep      learning      for      recommender      systems. pp. 17—22  \n \n  (2016)  \n \n  Argyriou,      A.,      Gonzdlez-Fierro,      M.,      Zhang,      L.:      Mi-  \n \n  crosoft      recommenders:      Best      practices      for      production-  \n \n  ready      recommendation      systems. In:      WWW. pp."
            },
            {
              "id": 584,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "50-51  \n \n  (2020)  \n \n  Grbovic,      M.,      Cheng,      H.:      Real-time      personalization  \n \n  using      embeddings      for      search      ranking      at      Airbnb. In:  \n \n  SIGKDD. pp."
            },
            {
              "id": 585,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "311-320      (2018) [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [8] [10] [11] [12]  \n \n  [13]  \n \n  Fang,      H.,      Zhang,      D.,      Shu,      Y.,      Guo,      G.:      Deep      learning  \n \n  for      sequential      recommendation:      Algorithms,      influential  \n \n  factors,      and      evaluations."
            },
            {
              "id": 586,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "ACM      Transactions      on      Infor-  \n \n  mation      Systems      (TOIS)      39(1),      1-42      (2020)  \n \n  Ying,      H.,      Zhuang,      F.,      Liu,      Y.,      Xie,      X.,      Xiong,      H.,  \n \n  Wu,      J.,      et      al. :      Sequential      recommender      system      based  \n \n  on      hierarchical      attention      network."
            },
            {
              "id": 587,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI      (2018)  \n \n  Ly,      F.,      Jin,      T.,      Lin,      Q.,      Yang,      K.,      Ng,      W.,      et      al. :      SDM:\n |  |       ——auc|*”*      °°. —      GAUC      —*—      AUC       —=—      GAUC |       ——auc|*”*      °°."
            },
            {
              "id": 588,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "—      GAUC      —*—      AUC       —=—      GAUC       0.922      0.922      +--~~      ~~      ae      0.922       I      <=       \\\\\\\\      §550      oe      8      0.921      -      \"lo      o0Q       5      I       ‘*      x      vos      Ss      918      —_      918       0.924 | \n | --- | --- | --- | ---\n | 0.905       o       0.1      02      04      06      08      1      :      0       T 0.916      0.916       wane      40.916      }      —."
            },
            {
              "id": 589,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "| 0.914      0.914\n\n0.05      ,0.1      O15      0.2      30      90      360      720  \n \n  @      (min) ny\n(c)  \n \n  [3]\n(a)\n \n \n  Sequential      deep      matching      model      for      online      large-scale  \n \n  recommender      system. In:      CHKM. pp. 2635-2643      (2019)  \n \n  Yu,      Z.,      Lian,      J.,      Xie,      X.,      et      al."
            },
            {
              "id": 590,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": ":      Adaptive      user      modeling  \n \n  with      long      and      short-term      preferences      for      personalized  \n \n  recommendation. In:      IJCAI. pp. 4213-4219      (2019)      .Tan,      Q.,      Zhang,      J.,      Zhou,      J.,      Hu,      X.,      et      al. :      Dynamic  \n \n  memory      based      attention      network      for      sequential      recom-  \n \n  mendation. In:      AAAI. vol. 35,      pp."
            },
            {
              "id": 591,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "4384-4392(2021)  \n \n  Zheng,      Y.,      Gao,      C.,      Chang,      J.,      Niu,      Y.,      Song,      Y.,      Jin,  \n \n  D.,      Li,      Y.:      Disentangling      long      and      short-term      interests  \n \n  for      recommendation. In:      WWW. pp."
            },
            {
              "id": 592,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "2256-2267      (2022)  \n \n  Du,      J.,      Ye,      Z.,      Guo,      B.,      Yu,      Z.,      Yao,      L.:      IDNP:      Interest  \n \n  Dynamics      Modeling      using      Generative      Neural      Processes  \n \n  for      Sequential      Recommendation. In:      WSDM. pp. 481-  \n \n  489      (2023)  \n \n  Jagerman,      R.,      et      al."
            },
            {
              "id": 593,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": ":      To      model      or      to      intervene:   \n \nA       comparison      of      counterfactual      and      online      learning      to  \n \n  rank      from      user      interactions. In:      SIGIR. pp. 15-24  \n \n  (2019)  \n \n  Hofmann,      Katja.,      et      al. :      On      caption      bias      in      interleaving  \n \n  experiments. In:      CIKM. pp."
            },
            {
              "id": 594,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "115-124      (2012)  \n \n  Zheng,      Y.,      Gao,      C.,      Chen,      L.,      Jin,      D.,   \n \n&      Li,      Y.:      DGCN:  \n \n  Diversified      recommendation      with      graph      convolutional  \n \n  networks. In:      WWW. pp. 401-412      (2021)  \n \n  Luo,      A.,      Wang,      D.,      Xu,      J.,      Fang,      J.,      Sheng,      V.S.,      et      al. :  \n \n  Collaborative      self-attention      network      for      session-based  \n \n  recommendation."
            },
            {
              "id": 595,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "In:      IJCAI. pp. 2591-2597      (2020)  \n \n  Qin,      Y.,      Wang,      P.,      Li,      C.:      The      world      is      binary:      Con-  \n \n  trastive      learning      for      denoising      neat      basket      recommen-  \n \n  dation. In:      SIGIR. pp. 859-868      (2021)  \n \n  Lin,      Y.,      Wang,      C.,      Xin,      X.,      Yan,      Q.,      de      Rijke,      M.,  \n \n  Cheng,      X.,      Ren,      P.,      et      al."
            },
            {
              "id": 596,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": ":   \n \nA      self-correcting      sequential  \n \n  recommender. arXiv      preprint      arXiv:2303.02297      (2023)  \n \n  [14] [4] [5] [6] [7 [31]  \n \n  [32]  \n \n  Zhou,      K.,      Yu,      H.,      Zhao,      W.X.,      Wen,      J.R. :      Filter-  \n \n  enhanced      mlp      is      all      you      need      for      sequential      recommen-  \n \n  dation. In:      WWW. pp."
            },
            {
              "id": 597,
              "title": "ESE=      —s—      LSIDN      w/M       —4—      LSIDN      w/R       83      ——      LSIDN      w/C      .       —*-LSIDN       ] Drop      Rate(%) - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "2388-2399      (2022)  \n \n  Du,      X.,      Liu,      G.,      Liu,      Y.,      Sheng,      V.S.,      et      al. :      Frequency  \n \n  enhanced      hybrid      attention      network      for      sequential      rec-  \n \n  ommendation. In:      SIGIR. pp. 78-88      (2023)  \n \n  Chen,      T.,      Kornblith,      $.,      Norouzi,      M.,      Hinton,      G.:"
            }
          ],
          "content": ""
        }
      ],
      "content": ""
    },
    {
      "id": 598,
      "title": "Book 3",
      "type": "book",
      "children": [
        {
          "id": 599,
          "title": "Tp      =      Micy      +      Moco",
          "type": "section",
          "children": [
            {
              "id": 600,
              "title": "Tp      =      Micy      +      Moco - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Tp      =      Micy      +      Moco\n \n \n  Applying      this      recursively,      we      can      find   \n \na      vector      representing  \n \n  each      node      of      the      tree;      and      because      generically      M;      M2   \n \n4       M2M,,      distinct      nodes      will      be      associated      with   \n \na      distinct  \n \n  vectors."
            },
            {
              "id": 601,
              "title": "Tp      =      Micy      +      Moco - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "While      we      have      not      found      this      mechanism      explic-  \n \n  itly      mentioned      in      the      literature,      it      can      be      viewed      as   \n \na      trivial  \n \n  linear      version      of   \n \na      Tree-RNN,   \n \na      network      that      creates   \n \na      vec-  \n \n  tor      representation      of   \n \na      tree      by      operating      recursively      on      its  \n \n  nodes      (Socher      et      al.,      2013;      2014;      Bowman      et      al.,      2015)."
            },
            {
              "id": 602,
              "title": "Tp      =      Micy      +      Moco - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Tree-RNNs      enjoyed   \n \na      surge      of      interest      in      the      years      before  \n \n  transformers      were      introduced:      using      Tree-RNNs      to      pro-  \n \n  cess      parse      trees      seemed      to      improve      performance      in      mul-  \n \n  tiple      systems."
            },
            {
              "id": 603,
              "title": "Tp      =      Micy      +      Moco - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Interestingly,      for      small      fixed-depth      trees  \n \n  there’s   \n \na      natural      way      for      transformers      to      implement      some-  \n \n  thing      like   \n \na      Tree-RNN,      since      attention      heads      can      focus      on—  \n \n  and      thus      can      read      information      from—syntactically      depen-  \n \n  dent      tokens      (Phang      et      al.,      2019;      Ravishankar      et      al.,      2021)."
            },
            {
              "id": 604,
              "title": "Tp      =      Micy      +      Moco - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "It      might      be      worthwhile      to      look      for      evidence      of      this      type      of  \n \n  representation      in      real-world      networks. 3.3. Feature      multiplicity      in      additive      models\n \n \n  If      neural      networks      use      one      of      these      matrix-based      mecha-  \n \n  nisms,      how      might      that      affect      the      search      for      features?"
            },
            {
              "id": 605,
              "title": "Tp      =      Micy      +      Moco - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "In      an  \n \n  idealized      case,      there’s      actually   \n \na      clear      answer:      it      will      create  \n \n  a      series      of      duplicate      features,      which      we      call      echo      features."
            },
            {
              "id": 606,
              "title": "Tp      =      Micy      +      Moco - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "To      see      this,      consider   \n \na      set      of      random      unit      feature      vectors {v1,,Um}, and a model in which a representation vec-  \n \n  tor   \n \nx      is      arandom      sparse      linear      combination      of      these      vectors. To      be      concrete,      take   \n \nx   \n \n=   \n \na      a;v;      where      the      a;      are      each  \n \n  independent      Bernoulli      random      variables      with      p   \n \n=      1/m."
            },
            {
              "id": 607,
              "title": "Tp      =      Micy      +      Moco - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      large      sample      of      vectors      from      this      distribution,   \n \na       3One      recent      piece      of      empirical      work      is      potentially      related:  \n \n  (Engels      et      al.,      2024)      describe      “feature      manifolds,”      placed      in      super-  \n \n  position      using      linear      transformations      that      satisfy   \n \na      certain      mutual  \n \n  orthogonality      condition."
            },
            {
              "id": 608,
              "title": "Tp      =      Micy      +      Moco - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "This      suggests      that      neural      networks      are  \n \n  capable      of      learning      something      like      additive      binding      mechanisms. capable      dictionary      learning      algorithm,      such      as   \n \na      sparse      au-  \n \n  toencoder,      will      recover      the      underlying      feature      vectors      {v;      }."
            },
            {
              "id": 609,
              "title": "Tp      =      Micy      +      Moco - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Now      consider   \n \na      simple      version      of      the      additive      model      de-  \n \n  scribed      above. Suppose      we      apply      dictionary      learning      tech-  \n \n  niques      to      representations      of      the      form   \n \nz   \n \n=   \n \n2   \n \n+      Ay,      where x\n \n   and   \n \ny      are      independently      drawn      from      the      same      sparse      ran-  \n \n  dom      distribution."
            },
            {
              "id": 610,
              "title": "Tp      =      Micy      +      Moco - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "If   \n \nA      is      random,      the      vectors      {Av;}      will  \n \n  probably      be      nearly      orthogonal      to      the      {v;}. That      means  \n \n  we      can      view   \n \nz   \n \n=   \n \nx   \n \n+      Ay      as   \n \na      sparse      sum      of      2m      random  \n \n  vectors,      where      coefficients      are      independent      Bernoulli      with  \n \n  p   \n \n=      1/m."
            },
            {
              "id": 611,
              "title": "Tp      =      Micy      +      Moco - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Therefore,      applying   \n \na      dictionary      learning      algo-  \n \n  rithm      to   \n \na      large      sample      of   \n \nz      is      likely      to      identify      2m      feature  \n \n  vectors      .,      AUm      }\n \n \n  The      issue,      of      course,      is      that      each      pair      of      vectors      (v;,      Av;)  \n \n  actually      corresponds      to      the      same      underlying      feature—the  \n \n  only      difference      being      its      position      in      the      ordered      pair      (x,      y)."
            },
            {
              "id": 612,
              "title": "Tp      =      Micy      +      Moco - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "We      refer      to      multiple      distinct      vectors      for      the      same      concept  \n \n  as      “echo”      vectors      since      they      echo      each      other’s      representa-  \n \n  tion. Obviously,      the      problem      is      not      just      restricted      to      pairs:\n \n \n \na      representation      of   \n \na      list      of      three      vectors      would      yield      triple  \n \n  multiplicity."
            },
            {
              "id": 613,
              "title": "Tp      =      Micy      +      Moco - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "The      tree      representation      described      above      could  \n \n  yield      even      more. {v1,,Um,Av1,--\n \n \n  It’s      an      open      question      whether      this      idealized      setting      reflects  \n \n  the      behavior      or      real-world      networks. However,      the      general  \n \n  structure      of      transformer      attention      suggests      that      something  \n \n  like      this      phenomenon      could      easily      occur."
            },
            {
              "id": 614,
              "title": "Tp      =      Micy      +      Moco - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In      fact,      one      re-  \n \n  cent      report      describes      how      an      SAE      appears      to      uncover   \n \na       large      set      of      “induction      features”      corresponding      to      predicted  \n \n  next      tokens      (Kissane      et      al.,      2024). A      closely      related      issue      is  \n \n  also      documented      in   \n \na      real-world      setting      in      (Makelov      et      al.,  \n \n  2023)."
            },
            {
              "id": 615,
              "title": "Tp      =      Micy      +      Moco - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "If      this      type      of      feature      multiplicity      does      turn      out      to      be   \n \na       common      phenomenon,      it      could      make      interpretability      work  \n \n  more      difficult. At      the      very      least,      it      would      greatly      expand  \n \n  the      catalog      of      seemingly      independent      features      found      by      an  \n \n  SAE."
            },
            {
              "id": 616,
              "title": "Tp      =      Micy      +      Moco - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Understanding      the      structure      of      this      catalog      would      re-  \n \n  quire      knowledge      of      the      underlying      matrices      that      lead      to  \n \n  echo      vectors. Conversely,      knowing      these      matrices      would  \n \n  greatly      help      us      organize      and      analyze      SAE-derived      features."
            }
          ],
          "content": ""
        },
        {
          "id": 617,
          "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES",
          "type": "section",
          "children": [
            {
              "id": 618,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "3.3.1. FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES\n \n \n  Feature      multiplicity      might      cause      anomalies      when      using  \n \n  features      to      steer   \n \na      network’s      behavior      during      inference."
            },
            {
              "id": 619,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Indeed,   \n \na      number      of      recent      reports      have      described      sys-  \n \n  tems      where      the      optimal      vectors      for      predicting      behavior  \n \n  and      steering      it      turn      out      to      be      different      (Zou      et      al.,      2023;  \n \n  Marks   \n \n&      Tegmark,      2023;      Li      et      al.,      2024;      Chen      et      al.,      2024). We      call      this      predict/control      discrepancy."
            },
            {
              "id": 620,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "On      its      face,      this  \n \n  discrepancy      is      not      necessarily      shocking—a      linear      probe      can  \n \n  easily      pick      up      on      spurious      or      redundant      correlations,      such  \n \n  as      non-causal      aspects      of      the      input      data."
            },
            {
              "id": 621,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "In      (Bricken      et      al.,  \n \n  2023),      for      example,      the      authors      perform      experiments      to  \n \n  check      that      features      have      expected      causal      effects      on      the      net-  \n \n  works      output. On      the      other      hand,      it      is      conceivable      that      fea-  \n \n  ture      multiplicity      may      make      predict/control      discrepancies  \n \n  especially      likely‘."
            },
            {
              "id": 622,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Here’s   \n \na      hypothetical      example      that      serves      as   \n \na      plausibility  \n \n  argument      for      this      idea. Consider   \n \na      transformer      layer      that  \n \n  does      nothing      but      augment      the      residual      stream      for   \n \na      given  \n \n  token      with      information      about      the      previous      token. Imagine  \n \n  it      does      so      with      additive      matrix      binding."
            },
            {
              "id": 623,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "In      particular,      if      ¢;  \n \n  and      ¢;_;      are      sequential      tokens      at      layer      N   \n \n—      1,      then      after  \n \n  layer      N      the      residual      stream      at      token      7,      which      we      denote      by  \n \n  ti,      becomes th   \n \n=      t;   \n \n+      Ati-1  \n \n  where   \n \nA      is      an      orthogonal      matrix      far      from      the      identity."
            },
            {
              "id": 624,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Now       imagine      that      representations      in      the      residual      stream      for      layer  \n \n  N   \n \n—   \n \n1      involve   \n \na      feature      vector      v;,,,      for      toxic      content."
            },
            {
              "id": 625,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "It      fol-  \n \n  lows      that,      for      different      tokens,      the      residual      stream      in      layer  \n \n  N      could      have      multiple      distinct      vectors      related      to      toxicity:\n \n \n  Vtox»      AVtox,      OF      Vitor   \n \n+      Avior."
            },
            {
              "id": 626,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "A      linear      probe      P;,,      trained  \n \n  to      recognize      toxic      content,      based      on      multiple      tokens      in      the  \n \n  residual      stream      at      layer      N,      might      look      something      like\nProx      (x)      =      (x,      Vtoa      +      Avtox)\n \n \n  On      the      other      hand,      if      we      trained      on      just      one      token      (perhaps  \n \n  the      last      token      in   \n \na      prompt,   \n \na      non-toxic      function      word,      in  \n \n  order      to      predict      subsequent      behavior)      we      could      easily      pro-  \n \n  duce   \n \na      probe      such      as:\nQtox      (x)      =      (a,      Avtox)\n \n \n  Both      of      these      probes      might      perform      well,      but      this      already  \n \n  illustrates   \n \na      problem:      different      tokens      might      easily      produce  \n \n  different      probes      for      unimportant      contextual      reasons."
            },
            {
              "id": 627,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Now,      suppose      we      wish      to      intervene      during      network  \n \n  inference—for      instance,      we      want      to      change      the      residual  \n \n  stream      to      cause      the      network      to      produce      less      toxic      text."
            },
            {
              "id": 628,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Sim-  \n \n  ply      inspecting      the      second      probe,      we      might      hope      to      inter-  \n \n  vene      to      “remove      toxicity”      by      intervening      during      inference  \n \n  (Li      et      al.,      2024)      to      change      each      token   \n \n¢      to      have      the      new       value t=      t—      Avtox  \n \n  It’s      entirely      possible,      however,      that      the      values      of      inner      prod-  \n \n  ucts      (2,      Vtor)      and      (x,      Avior)      will      play      different      roles      in  \n \n  computing      the      toxicity      of      the      next      word."
            },
            {
              "id": 629,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "It’s      certainly      con-  \n \n  ceivable      that      the      toxicity      of      the      current      word      plays   \n \na      greater  \n \n  role      than      information      about      the      previous      word."
            },
            {
              "id": 630,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Quite      likely,  \n \n  the      most      effective      intervention      will      look      more      like      the      fol-  \n \n  lowing      equation,      where      cy      F      Co:\nt=t—C1Ut0«   \n \n—      C2AV      {0x 4See      also      (Marks,      2024)      for   \n \na      related      discussion;      we      return      to  \n \n  ideas      from      that      essay      in   \n \na      subsequent      section."
            },
            {
              "id": 631,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "In      other      words,      the      right      vector      for      controlling      the      network  \n \n  might      differ      from      the      most      effective      probe      vector      for      pre-  \n \n  dicting      its      behavior. This      phenomenon      would      make      it      harder      to      exploit      features  \n \n  derived      from      dictionary      learning."
            },
            {
              "id": 632,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "For      example,      if      there      are  \n \n  many      multiple      features      related      to      toxicity,      one      couldn’t      au-  \n \n  tomatically      extract   \n \na      steering      vector      from      the      dictionary,  \n \n  but      would      need      to      do      experiments      to      find      the      right      linear  \n \n  combination      of      feature      vectors."
            },
            {
              "id": 633,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Of      course,      the      analysis      out-  \n \n  lined      here      is      still      speculative. On      the      other      hand,      we      believe  \n \n  this      is   \n \na      plausible      picture,      especially      given      transformer      ar-  \n \n  chitecture. A      cynic      might      even      say      attention      layers      are      ma-  \n \n  chines      for      producing      spurious      correlations. 4."
            },
            {
              "id": 634,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Multi-token      mechanisms\n \n \n  So      far,      we’ve      discussed      binding      mechanisms      that      operate  \n \n  wthin   \n \na      single      vector      space."
            },
            {
              "id": 635,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "However,      since      the      earliest  \n \n  days      of      the      field,      there      has      been      speculation      that      that      some  \n \n  notion      of      sequence—that      is,      representations      across      multi-  \n \n  ple      input      observations—is      necessary      for      representing      com-  \n \n  plex      relationships      (Rosenblatt,      1961)."
            },
            {
              "id": 636,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "In      this      section,      with  \n \n  the      transformer      architecture      in      mind,      we      discuss   \n \na      class      of  \n \n  mechanisms      that      relate      specifically      to      sequence      models."
            },
            {
              "id": 637,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Mathematically,      we      consider   \n \na      sequence      of      “token      vectors” ty, to,,tp € R”  \n \n  where      each      ¢;      contains      feature      information      and,      potentially,  \n \n  information      about      its      relation      to      other      tokens."
            },
            {
              "id": 638,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "For      instance,  \n \n  each      t;      might      represent      the      residual      stream      for      the      7-th      el-  \n \n  ement      of   \n \na      sequence      at   \n \na      particular      layer      in   \n \na      transformer. To      extract      the      relational      data,      it      might      not      be      enough      to      look  \n \n  at   \n \na      single      token      ¢;      but      at      pairs      of      tokens      (¢;,t;)."
            },
            {
              "id": 639,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "This      per-  \n \n  spective      opens      up   \n \na      different      set      of      possibilities. It’s      also   \n \na       very      plausible      type      of      representation. For      example,      when  \n \n  working      with      word      embeddings,   \n \na      variety      of      relationships  \n \n  between      words      can      famously      be      read      by      taking      vector      dif-  \n \n  ferences      (Mikolov      et      al.,      2013a)."
            },
            {
              "id": 640,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "A      generalization      of      using      vector      differences      is      “linear      rela-  \n \n  tional      embedding”      (Paccanaro   \n \n&      Hinton,      2001). The      idea  \n \n  here      is      that   \n \na      relation      between      token      vectors      ¢;      and      t;      is  \n \n  present      when\n \n \n  for   \n \na      matrix   \n \nA      and      vector   \n \nb      which      depend      only      on      the  \n \n  relation."
            },
            {
              "id": 641,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "Recent      work      suggests      that      something      like      this  \n \n  representation      may      be      found      in      the      way      that      language-  \n \n  model      transformers      represent      relationships      between      enti-  \n \n  ties      (Hernandez      et      al.,      2023). 4.1."
            },
            {
              "id": 642,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "Syntactic      relations      and      tree      embeddings\n \n \n  One      striking      finding      related      to      the      BERT      network  \n \n  (Devlin      et      al.,      2018)      is      that      parse      trees      are      represented      ge-  \n \n  ometrically      by      relative      positions      of      token      vectors."
            },
            {
              "id": 643,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "In      partic-  \n \n  ular,      the      “syntactic      distance”      between      two      words—as      mea-  \n \n  sured      in   \n \na      dependency      grammar      parse      tree—can      be      recov-  \n \n  ered      from      their      corresponding      token      vectors      in   \n \na      middle  \n \n  layer      of      BERT      (Hewitt   \n \n&      Manning,      2019;      Manning      et      al.,  \n \n  2020)."
            },
            {
              "id": 644,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "To      be      precise,      if      two      words      w;,      w;      in      the      same      sen-  \n \n  tence      are      represented      by      embedding      vectors      ¢;      and      ¢;,      and       if      d;(w;,      w;)      is      the      tree      distance      in      the      syntactic      parse      tree  \n \n  between      w;      and      we,      then ||W0t;   \n \n—      Mtj||?"
            },
            {
              "id": 645,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "©      de(wi,      w;)  \n \n  where      M      is   \n \na      constant      linear      transformation,      depending  \n \n  only      on      the      network."
            },
            {
              "id": 646,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "The      fact      that      tree      distance      corresponds  \n \n  to      the      square      of      the      Euclidean      distance      may      seem      surprising  \n \n  but,      as      described      in      (Reif      et      al.,      2019),      it’s      actually      natural  \n \n  in      the      context      of      mapping   \n \na      tree      metric      to   \n \na      Euclidean      met-  \n \n  ric."
            },
            {
              "id": 647,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "As      described      in      (Chi      et      al.,      2020),      one      possible      expla-  \n \n  nation      of      this      representation      is      that      the      differences      between  \n \n  token      embeddings      represent      syntactic      dependencies:      that  \n \n  is,      if      t;      and      ¢;      have   \n \na      specific      syntactic      relation      (such      as  \n \n  an      adjective      modifying   \n \na      noun)      then      the      vector      difference  \n \n  Mt,   \n \n—      Mt;      encodes      that      relation."
            },
            {
              "id": 648,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "This      area      seems      like   \n \na      promising      direction      for      follow-up  \n \n  work. For      one      thing,      tree      structures      might      naturally      occur  \n \n  in      many      other      situations. More      generally,      the      idea      that      dif-  \n \n  ferences      between      tokens      encode      specific,      contextual      rela-  \n \n  tionships      seems      powerful."
            },
            {
              "id": 649,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "A      natural      question      is      whether  \n \n  applying      dictionary      learning      to      residual      stream      differences,  \n \n  rather      than      the      residual      stream      itself,      might      yield   \n \na      set      of  \n \n  interpretable      “relation      features.”\n4.2."
            },
            {
              "id": 650,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Reference      mechanisms:      pointers      and      identifiers\n \n \n  Software      engineers      have      invented      many      ways      to      tie      differ-  \n \n  ent      data      structures      together. Is      it      possible      that      neural      net-  \n \n  works      use      the      same      techniques? Some      recent      investigations  \n \n  hint      that      they      might."
            },
            {
              "id": 651,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "One      fundamental      component      of      many      software      data      struc-  \n \n  tures      is   \n \na      pointer:   \n \na      reference      to   \n \na      location      in      memory. The  \n \n  analog      of   \n \na      pointer,      for   \n \na      transformer      network,      might      be  \n \n  a      positional      embedding      that      defines   \n \na      reference      to   \n \na      spe-  \n \n  cific      token      in   \n \na      sequence."
            },
            {
              "id": 652,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "One      might      imagine      using      matrix  \n \n  binding      to      augment   \n \na      token      with      this      positional      information  \n \n  rather      than      semantic      data. For      instance,      if      p;      represents      the  \n \n  positional      embedding      for      position      j,      and      A,."
            },
            {
              "id": 653,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "is   \n \na      binding  \n \n  matrix,      one      might      represent   \n \na      relationship      between      tokens  \n \n  t;      and      ¢;      as:\n \n \n  r(ti,      t;)      =t;+      A,Dpj  \n \n  In      fact,      the      study      described      in      (Prakash      et      al.,      2024)      un-  \n \n  covers   \n \na      circuit      that      seems      to      use      something      like      this      kind  \n \n  of      “pointer”      mechanism      to      relate      an      entity      to      information  \n \n  about      its      state      elsewhere      in   \n \na      sequence."
            },
            {
              "id": 654,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "The      authors      de-  \n \n  scribe      specific      attention      heads      that      seem      to      move      and      read relevant      positional      encodings      in      order      to      connect      tokens      in  \n \n  this      way."
            },
            {
              "id": 655,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "A      second      fundamental      way      to      connect      data      comes      from  \n \n  the      world      of      databases:      using   \n \na      shared      identifier,      or      ID,  \n \n  to      link      two      pieces      of      information. Some      transformers  \n \n  may      actually      use   \n \na      geometric      form      of      this      mechanism  \n \n  (Feng   \n \n&      Steinhardt,      2023;      Feng      et      al.,      2024)."
            },
            {
              "id": 656,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "The      idea      is  \n \n  that      there      may      be   \n \na      special      subspace      of      the      residual      stream  \n \n  in      which      vector      similarity      encodes      binding      information. To  \n \n  be      precise,      they      find   \n \na      certain      low-rank      matrix      Ajg,      with  \n \n  the      property      that      for   \n \na      token      vector      ¢,      the      value      Ajgt      acts  \n \n  like      an      ID."
            },
            {
              "id": 657,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "That      is,      two      token      representations      t;      and      tz      are  \n \n  considered      to      be      bound      to      each      other      if\nAit;   \n \ny      Aiat;\n \n \n  One      interesting      question      is      how      and      whether      this      idea  \n \n  relates      to      the      syntax      tree      representations      described      in  \n \n  (Manning      et      al.,      2020)."
            },
            {
              "id": 658,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "For      example,      after      applying      the  \n \n  proper      structural      probe,      one      could      imagine      projecting      or-  \n \n  thogonally      to      an      adjective-modifies-noun      direction. This  \n \n  could      produce      something      like      an      ID      vector      linking      adjec-  \n \n  tives      with      the      nouns      they      modify."
            },
            {
              "id": 659,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "A      geometric      ID      mechanism      may      pose      challenges      for   \n \na      pure  \n \n  feature-vector-based      analysis. In      particular,      there’s      no      rea-  \n \n  son      to      assume      that      ID      information      clusters      in      any      useful  \n \n  way."
            },
            {
              "id": 660,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "The      only      structure      that      (Feng   \n \n&      Steinhardt,      2023)  \n \n  note      in      the      subspace      S      is      metric:      nearby      vectors      are      more  \n \n  likely      to      match      as      markers."
            },
            {
              "id": 661,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Thus      for      any      given      sequence,  \n \n  ID      vectors      conceivably      could      be      effectively      random—the  \n \n  only      constraint      being      that      distinct      ID      vectors      should      be      far  \n \n  from      each      other. Thus      dictionary      learning      or      classic      linear  \n \n  probing      may      not      encounter   \n \na      useful      signal. 5."
            },
            {
              "id": 662,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Vector      symbolic      architecture\n \n \n  Finally,      we      discuss   \n \na      set      of      historical      ideas      for      vector      bind-  \n \n  ing,      collectively      known      as      “vector      symbolic      architecture,”  \n \n  or      VSA      (Smolensky,      1990;      Plate,      1994;      1997;      Kanerva,  \n \n  2009;      Jones   \n \n&      Mewhort,      2007;      Schlegel      et      al.,      2022)."
            },
            {
              "id": 663,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "A       comprehensive      survey      and      analysis      of      the      zoo      of      techniques  \n \n  in      this      area      is      far      beyond      the      scope      of      this      paper. Our      goal  \n \n  is      simply      to      provide   \n \na      gentle      introduction      to      techniques      that  \n \n  can      potentially      seem      arcane,      unmotivated,      and      intimidating."
            },
            {
              "id": 664,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "To      do      so,      we      focus      on      two      foundational      constructions,      one  \n \n  in      R”      and      one      in      {0,      1}”,      which      underlie      much      of      the      work  \n \n  in      this      field."
            },
            {
              "id": 665,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Both      mechanisms      have      the      potential      to      lead      to  \n \n  feature      “dark      matter.”\nThat      is,      they      might      represent      infor-  \n \n  mation      in   \n \na      way      that      is      out      of      reach      of      dictionary      learning  \n \n  or      probing      methods. 5.1."
            },
            {
              "id": 666,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "Tensor      constructions\n \n \n  As      described      in      (Schlegel      et      al.,      2022),   \n \na      technique      intro-  \n \n  duced      in      (Smolensky,      1990)      forms      the      basis      of   \n \na      large      set  \n \n  of      different      VSA      mechanisms."
            },
            {
              "id": 667,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "It      is      often      referred      to      as   \n \na       “tensor”      method,      but      we’ll      describe      it      with      the      more      down-  \n \n  to-earth      notation      of      outer      products. As      before,      suppose      we      wish      to      compose,      or      bind,      two      vec-  \n \n  tors   \n \nx      and      y."
            },
            {
              "id": 668,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "One      way      is      to      use      an      outer      product      to      define   \n \na       representation:\nr=      xy This      representation      distinguishes      order,      since      generally  \n \n  xy’   \n \n#      yx’). It      respects      vector      addition,      since      it      is      linear in      each      of   \n \nx      and   \n \ny      respectively."
            },
            {
              "id": 669,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      one      can      recover x\n \n   and      y,      at      least      up      to      scalar      multiples,      with      easy      vector  \n \n  algebra."
            },
            {
              "id": 670,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "For      example,      if      you      know      y,      you      can      recover   \n \na       scalar      multiple      of   \n \nx      via      the      product\nry      =xy\\\\\\'y   \n \n=      |lyll?x\n \n \n  The      alert      reader      will      notice,      however,      that      this      outer      prod-  \n \n  uct      representation      is   \n \na      cheat:      it      lives      in      R”*”      rather      than  \n \n  IR”."
            },
            {
              "id": 671,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "One      may      view      much      of      the      VSA      literature      as   \n \na      bag      of  \n \n  tricks      to      get      around      this      inconvenient      fact. The      most      com-  \n \n  mon      trick      is      to      create      an      n-dimensional      projection      of      the  \n \n  outer      product,      which      can      still      be      used      for      approximate      re-  \n \n  construction."
            },
            {
              "id": 672,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "One      method,      for      instance,      is      projecting      the  \n \n  outer      product      matrix      via      circular      convolution      (Plate,      1997). 5.2. Binary      vectors\n \n \n \nA      second      category      of      VSA      techniques      relies      on      binary-  \n \n  valued      vectors      (Kanerva      et      al.,      1997;      Kanerva,      2009). We  \n \n  describe      one      simple      proposal      of      this      type."
            },
            {
              "id": 673,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "To      bind      two      bi-  \n \n  nary      vectors   \n \nx      and      y,      we      fix   \n \na      permutation      P      that      rearranges  \n \n  the      entries      of   \n \na      vector,      and      then      compute r=a2®      Ply)  \n \n  Here   \n \n©      denotes      modulo-2      addition. Like      the      outer      prod-  \n \n  uct,      this      distinguishes      between      the      ordered      pairs      (x,      y)      and       (y,x)."
            },
            {
              "id": 674,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "It      respects      the      binary      OR      function,      which      can      be  \n \n  used      to      take      unions      of      two      sets      of      features."
            },
            {
              "id": 675,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "It      also      allows  \n \n  for      easy      reconstruction      of      one      vector      in      the      pair      if      you      know  \n \n  the      other:\nz=r®      Ply) y=P\\\\\\'(r@2)  \n \n  >We      need      the      permutation      P      because      mod-2      addition      is      com-  \n \n  mutative,      and      otherwise      we      couldn’t      distinguish      the      pairs      (a,      y)  \n \n  and      (y,      x)."
            },
            {
              "id": 676,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "The      situation      is      similar      to      an      additive      matrix      binding  \n \n  formula   \n \nx   \n \n+      Ay. Permuting      one      argument      also      allows      us      to      bind  \n \n  a      vector      to      itself      without      leading      to   \n \na      zero      representation."
            },
            {
              "id": 677,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "This      is   \n \na      conceptually      elegant      method,      although      it      requires  \n \n  extremely      large      vectors      for      effective      storage      and      decoding. 5.3. Is      VSA   \n \na      plausible      mechanism      for      real      neural      nets?"
            },
            {
              "id": 678,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Unlike      additive      binding      models,      the      techniques      proposed  \n \n  for      tensor-based      VSA      don’t      obviously      map      to      deep      learn-  \n \n  ing      architectures. Investigations      of      whether      real-world      net-  \n \n  works      use      VSA      have      yielded      mixed      conclusions."
            },
            {
              "id": 679,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "For      ex-  \n \n  ample,   \n \na      study      of      whether      CLIP      might      use      these      mech-  \n \n  anisms      produced      largely      negative      results      (Lewis      et      al.,  \n \n  2022),      while      there      are      some      indications      RNNs      may      repro-  \n \n  duce      tensor-related      structures      (McCoy      et      al.,      2018)."
            },
            {
              "id": 680,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "Techniques      based      on      binary      vectors      might      seem      even      fur-  \n \n  ther      from      modern      language      model      architectures."
            },
            {
              "id": 681,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "Surpris-  \n \n  ingly,      some      recent      work      suggests      that      for      sparse      vectors  \n \n  in      superposition,      not      only      can      neural      nets      compute      XORs  \n \n  of      such      features      in      theory      (Dmitry      Vaintrob,      2024),      they  \n \n  seem      to      do      so      in      practice      (Marks,      2024)."
            },
            {
              "id": 682,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "Traditional      bi-  \n \n  nary      VSA      is      based      on      dense      vectors,      of      course,      but      this  \n \n  seems      like      an      interesting      avenue      for      exploration. One      might  \n \n  imagine      combining      ideas      from      the      tensor      and      binary      VSA  \n \n  schemes—perhaps      based      on      outer      products      specifically      of  \n \n  zero-one      vectors,      either      over   \n \nR      or      Zo."
            },
            {
              "id": 683,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "5.4. Implications      for      the      search      for      features\n \n \n  As      with      matrix      addition      binding,      we      speculate      that      VSA  \n \n  mechanisms      may      lead      to      feature      multiplicity. For      exam-  \n \n  ple,      outer      product      binding      could      plausibly      produce   \n \na      com-  \n \n  binatorial      proliferation      of      potential      features®."
            },
            {
              "id": 684,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "To      see      the  \n \n  issue,      consider   \n \na      setting      where      we      have      m      feature      vectors, {v1,,Um}, and we want to compose representation vec-  \n \n  tors   \n \nx      and      y:\n \n \n  m       c=   \n \n)      AQUyz  \n \n  i=1  \n \n  m       y=   \n \n>      div;\n \n \n  i=l  \n \n  where      the      sums      are      assumed      to      be      sparse,      and      {a;}      and       {b;}      independently      chosen."
            },
            {
              "id": 685,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "Suppose      we      have   \n \na      composi-  \n \n  tion      method      of      the      form r(x,y)   \n \n=      m(xy\") where   \n \n7   \n \n:      R\"*”   \n \n—      R”      is   \n \na      projection      operator. By      linear-  \n \n  ity,      we      have r(z,y)   \n \n=      S>      ajbjm      (Viv;   \n \n) 4g We      have      now      moved      from      using      m      feature      vectors      {v;}      to  \n \n  a      situation      with      m?"
            },
            {
              "id": 686,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "potential      feature      vectors      {r(viv}      )}. °The      essay      (Marks,      2024)      has   \n \na      discussion      of      parallel      concerns  \n \n  in      the      case      of      binary      codes. This      is   \n \na      problem."
            },
            {
              "id": 687,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "To      begin      with,      even      if      we      could      use      dic-  \n \n  tionary      learning      to      find      all      these      features,      there      may      be   \n \na       truly      huge      number      of      them. Even      if      not      all      combinations  \n \n  are      likely      to      occur,      the      potential      number      of      new      combina-  \n \n  tons      is      vast."
            },
            {
              "id": 688,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      person      interpreting   \n \na      network,      having  \n \n  fine-grained      versions      of      the      same      feature      is      confusing. For  \n \n  example,      one      might      see      many      different      vectors      reflecting  \n \n  the      same      concept      in      different      overall      contexts."
            },
            {
              "id": 689,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "Something  \n \n  like      this      actually      appears      repeatedly      in   \n \na      language      model  \n \n  analyzed      in      (Bricken      et      al.,      2023)."
            },
            {
              "id": 690,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "For      example,      they      don’t  \n \n  find   \n \na      single      pure      “English      preposition”      feature,      but      they      do  \n \n  identify   \n \na      feature      corresponding      to      “prepositions      in      scien-  \n \n  tific/statistical      contexts”’      and   \n \na      separate      feature      that      fires      on  \n \n  “prepositions      in      contexts      discussing      poetry/poets”®."
            },
            {
              "id": 691,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": "This  \n \n  is      just      one      of      many      examples      from      the      feature      catalog      of  \n \n  (Bricken      et      al.,      2023)."
            },
            {
              "id": 692,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "As      the      authors      of      that      study      discuss,  \n \n  this      seems      to      be      part      of   \n \na      much      larger      story      related      to   \n \na       non-isotropic      distribution      of      features—perhaps      an      analysis  \n \n  of      compositional      mechanisms      could      shed      light      on      this      phe- nomenon."
            },
            {
              "id": 693,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 76",
              "type": "chunk",
              "children": [],
              "content": "A      second      problem      with      the      proliferation      of      fine-grained      fea-  \n \n  tures      is      that      we      might      need      far      more      data      to      discover      each  \n \n  one."
            },
            {
              "id": 694,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 77",
              "type": "chunk",
              "children": [],
              "content": "For      example,      features      for      “inspiring”      and      ”architec-  \n \n  ture”      might      be      just      common      enough      to      find,      but      the      combi-  \n \n  nation      of      “inspiring      architecture”      might,      sadly,      be      too      rare  \n \n  to      appear      in      the      output      of   \n \na      dictionary      learning      algorithm."
            },
            {
              "id": 695,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 78",
              "type": "chunk",
              "children": [],
              "content": "This      may      lead      to      “dark      matter”—feature      representation      that  \n \n  are      out      of      reach      unless      one      tests      with      vast      amounts      of      data. From      an      optimistic      viewpoint,      this      phenomenon      can      also  \n \n  be      seen      as   \n \na      cause      for      hope."
            },
            {
              "id": 696,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 79",
              "type": "chunk",
              "children": [],
              "content": "As      discussed      earlier,      many      fea-  \n \n  tures      in      the      catalog      of      (Bricken      et      al.,      2023)      seem      to      have  \n \n  combinatorial      interpretations."
            },
            {
              "id": 697,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 80",
              "type": "chunk",
              "children": [],
              "content": "If      we      had   \n \na      principled      way  \n \n  of      “factoring”      these      features,      extracting      an      outer-product  \n \n  structure      automatically,      that      could      be   \n \na      huge      help      in      iden-  \n \n  tifying      primitive      features. It      could      also      help      simplify      and       organize      feature      catalogs. 6."
            },
            {
              "id": 698,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 81",
              "type": "chunk",
              "children": [],
              "content": "Conclusion      and      future      work\n \n \n  We’ve      described   \n \na      series      of      proposals—some      historical,  \n \n  some      very      recent—for      how      neural      nets      might      represent      re-  \n \n  lationships      between      features."
            },
            {
              "id": 699,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 82",
              "type": "chunk",
              "children": [],
              "content": "Along      the      way,      we’ve      given  \n \n  conceptual      arguments      that      these      mechanisms      might      present  \n \n  problems      when      finding      and      using      linear      feature      representa-  \n \n  tions. One      challenge      is      that      of      “dark      matter’:      feature      rep-  \n \n  resentations      that      are      difficult      to      find      using      standard      meth-  \n \n  ods."
            },
            {
              "id": 700,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 83",
              "type": "chunk",
              "children": [],
              "content": "Another      potential      problem      is      feature      multiplicity,      or  \n \n  the      presence      of      multiple      “echo      vectors”      that      correspond      to  \n \n  the      same      feature."
            },
            {
              "id": 701,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 84",
              "type": "chunk",
              "children": [],
              "content": "An      issue      of      special      concern,      related      to  \n \n  multiplicity,      is      whether      feature      vectors      discovered      by      prob-\nFeature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation\n \n \n  ing      or      dictionary-learning      methods      will      be      as      useful      for      in-  \n \n  terventions      as      they      are      for      predicting      the      state      of      the      net-  \n \n  work."
            },
            {
              "id": 702,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 85",
              "type": "chunk",
              "children": [],
              "content": "The      arguments      here      are      conjectural      and      often      involve      ideal-  \n \n  ized      settings. A      great      deal      of      work      would      be      necessary      to  \n \n  resolve      the      questions      we’      ve      raised—calling      for      that      work      is  \n \n  the      point      of      this      note."
            },
            {
              "id": 703,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 86",
              "type": "chunk",
              "children": [],
              "content": "Here      are      some      directions      that      might  \n \n  shed      light      on      the      key      issues:\n \n \n \n¢      Toy      models      that      learn      composition. One      way      to  \n \n  gather      data      would      be      to      experiment      with      minimal  \n \n  models. It      would      be      useful      to      find      toy      models      of  \n \n  learned      composition."
            },
            {
              "id": 704,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 87",
              "type": "chunk",
              "children": [],
              "content": "If      we      give      an      autoencoder   \n \na      task  \n \n  that      requires      learning      relational      composition,      what  \n \n  mechanisms      are      found      via      gradient      descent?"
            },
            {
              "id": 705,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 88",
              "type": "chunk",
              "children": [],
              "content": "Some  \n \n  work      in      this      area      dates      back      decades      (Pollack,      1988;\n \n \n  Blank      et      al.,      2014)      and      it      would      be      interesting      to      ana-  \n \n  lyze      these      same      systems      with      modern      methods,      and      to  \n \n  extend      this      line      of      research      further."
            },
            {
              "id": 706,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 89",
              "type": "chunk",
              "children": [],
              "content": "¢      Apply      feature      extraction      methods      to      synthetic      com-  \n \n  position      mechanisms. We      provided   \n \na      conceptual      out-  \n \n  line      of      how      feature      discovery      techniques      might      run  \n \n  into      trouble      on      compositional      representations."
            },
            {
              "id": 707,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 90",
              "type": "chunk",
              "children": [],
              "content": "A      nat-  \n \n  ural      next      step      would      be      to      test      these      arguments      empir-  \n \n  ically,      by      creating      synthetic      versions      of      VSA,      matrix  \n \n  binding,      and      other      mechanisms,      and      applying      dictio-  \n \n  nary      learning      to      the      results. ¢      Apply      dictionary      learning      to      token      differences."
            },
            {
              "id": 708,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 91",
              "type": "chunk",
              "children": [],
              "content": "Syntactic      relations      appear      to      be      encoded      in      differences  \n \n  between      token      vectors. Are      other      relations      encoded  \n \n  this      way      as      well? It      could      be      worth      applying      dictio-  \n \n  nary      learning      techniques      to      token      differences      to      find  \n \n  additional      “relational      features.”\n \n \n \n¢      Investigate      marker      mechanisms."
            },
            {
              "id": 709,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 92",
              "type": "chunk",
              "children": [],
              "content": "The      “ID      vector”  \n \n  mechanism      suggested      by      (Feng   \n \n&      Steinhardt,      2023)      is  \n \n  extremely      interesting. It      also      presents   \n \na      clear      problem  \n \n  for      feature-based      interpretability      methods. It      would  \n \n  be      helpful      to      understand      just      how      widely      the      mecha-  \n \n  nism      might      apply."
            },
            {
              "id": 710,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 93",
              "type": "chunk",
              "children": [],
              "content": "How      does      it      relate      to      the      syntax  \n \n  representations      of      (Manning      et      al.,      2020)? Experimen-  \n \n  tation      with      small      synthetic      models      might      advance      our  \n \n  understanding      of      the      basic      process. It      would      also      be  \n \n  helpful      to      find      lightweight      ways      to      identify      ID      vector  \n \n  subspaces."
            },
            {
              "id": 711,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 94",
              "type": "chunk",
              "children": [],
              "content": "¢      Look      for      feature      multiplicity. If      feature      multiplic-  \n \n  ity      is   \n \na      real      problem,      it      may      not      be      hard      to      iden-  \n \n  tify. One      sign      would      be      the      discovery      of      redundant      or  \n \n  contextually      dependent      feature      vectors."
            },
            {
              "id": 712,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 95",
              "type": "chunk",
              "children": [],
              "content": "The      features  \n \n  found      in      (Bricken      et      al.,      2023;      Templeton      et      al.,      2024;  \n \n  Kissane      et      al.,      2024)      sometimes      exhibit      this      type      of  \n \n  behavior,      for      instance."
            },
            {
              "id": 713,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 96",
              "type": "chunk",
              "children": [],
              "content": "If      one      could      pair      up   \n \na      suffi-  \n \n  ciently      large      number      of      redundant      features      via   \n \na      sin-  \n \n  gle      linear      transformation,      that      would      provide      strong  \n \n  evidence      for      the      multiplicity      hypothesis,      and      also      help  \n \n  organize      feature      catalogs. ¢      Understand      predict/control      discrepancy."
            },
            {
              "id": 714,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 97",
              "type": "chunk",
              "children": [],
              "content": "Feature  \n \n  multiplicity      might      cause   \n \na      problem      that      we      have  \n \n  termed      “predict/control      discrepancy.”\nThat      is,      an      ef-  \n \n  fective      vector      for      predicting   \n \na      particular      network      be-  \n \n  havior      might      be      different      from      the      best      “steering      vec-  \n \n  tor”      for      inducing      that      same      behavior."
            },
            {
              "id": 715,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 98",
              "type": "chunk",
              "children": [],
              "content": "Given      the      ob-  \n \n  vious      practical      implications,      and      that      there      are      multi-  \n \n  ple      examples      of      this      phenomenon      in      the      literature,      it  \n \n  seems      important      to      investigate      further. ¢      Measure      real      models      for      relational      composition."
            },
            {
              "id": 716,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 99",
              "type": "chunk",
              "children": [],
              "content": "One      alternative      to      explicitly      identifying      relational      rep-  \n \n  resentations      is      to      look      for      behavioral      evidence      that  \n \n  they      exist. That      can      at      least      alert      us      to      “dark      matter”  \n \n  that      isn’t      observed      by      feature      identification      methods."
            },
            {
              "id": 717,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 100",
              "type": "chunk",
              "children": [],
              "content": "A      review      of      this      type      of      work      is      beyond      the      scope  \n \n  of      this      paper,      but      several      studies      suggest      promising  \n \n  directions      (Andreas,      2019;      Lovering   \n \n&      Pavlick,      2022;  \n \n  Akyiirek   \n \n&      Andreas,      2023). ¢      Investigate      VSA-based      binding      in      real      networks."
            },
            {
              "id": 718,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 101",
              "type": "chunk",
              "children": [],
              "content": "The      findings      in      (Dmitry      Vaintrob,      2024;      Marks,      2024)  \n \n  suggest      some      natural      mechanisms      by      which      binary  \n \n  VSA      codes      might      be      implemented      in      realistic      net-  \n \n  works."
            },
            {
              "id": 719,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 102",
              "type": "chunk",
              "children": [],
              "content": "It      may      be      worth      systematically      working      out      the  \n \n  simplest      implementations      of      these      mechanisms,      and       investigating      whether      real      networks      make      use      of      them."
            },
            {
              "id": 720,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 103",
              "type": "chunk",
              "children": [],
              "content": "To      sum      up,      there      are      major      practical      and      theoretical  \n \n  questions      around      how      the      linear      representation      hypothesis  \n \n  might      interact      with      mechanisms      for      relational      composition. We      strongly      advocate      for      continued      research      in      this      area."
            },
            {
              "id": 721,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 104",
              "type": "chunk",
              "children": [],
              "content": "Identifying      mechanisms      for      relational      composition      would  \n \n  be   \n \na      step      forward      for      useful      interpretability      work. Even      if  \n \n  it      turns      out      that      neural      nets      show      no      evidence      of      relational  \n \n  composition,      that      would      be      an      important      theoretical      result. ents\n7. Acknowledgments\nents\nReferences\n \n \n  Akyiirek,      E. and      Andreas,      J."
            },
            {
              "id": 722,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 105",
              "type": "chunk",
              "children": [],
              "content": "Lexsym:      Compositionality  \n \n  as      lexical      symmetry. In      Proceedings      of      the      61st      Annual  \n \n  Meeting      of      the      Association      for      Computational      Linguis-  \n \n  tics      (Volume      1:      Long      Papers),      pp. 639-657,      2023. Andreas,      J. Measuring      compositionality      in      representation  \n \n  learning. arXiv      preprint      arXiv:      1902.07181,      2019."
            },
            {
              "id": 723,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 106",
              "type": "chunk",
              "children": [],
              "content": "Arora,      S.,      Li,      Y.,      Liang,      Y.,      Ma,      T.,      and      Risteski,      A. A       latent      variable      model      approach      to      pmi-based      word      em-  \n \n  beddings. Transactions      of      the      Association      for      Computa-  \n \n  tional      Linguistics,      4:385-399,      2016. Blank,      D. S.,      Meeden,      L. A.,      and      Marshall,      J. B."
            },
            {
              "id": 724,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 107",
              "type": "chunk",
              "children": [],
              "content": "Exploring  \n \n  the      symbolic/subsymbolic      continuum:   \n \nA      case      study      of  \n \n  raam. In      The      Symbolic      and      Connectionist      Paradigms,  \n \n  pp. 113-148. Psychology      Press,      2014. Bowman,      S.,      Potts,      C.,      and      Manning,      C. D. Recursive      neu-  \n \n  ral      networks      can      learn      logical      semantics."
            },
            {
              "id": 725,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 108",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings  \n \n  of      the      3rd      workshop      on      continuous      vector      space      models  \n \n  and      their      compositionality,      pp. 12-21,      2015. Bricken,      T.,      Templeton,      A.,      Batson,      J.,      Chen,      B.,      Jermyn,  \n \n  A.,      Conerly,      T.,      Turner,      N.,      Anil,      C.,      Denison,      C.,      Askell,  \n \n  A.,      et      al."
            },
            {
              "id": 726,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 109",
              "type": "chunk",
              "children": [],
              "content": "Towards      monosemanticity:      Decomposing      lan-  \n \n  guage      models      with      dictionary      learning. Transformer      Cir-  \n \n  cuits      Thread,      pp. 2,      2023. Chen,      Y.,      Wu,      A.,      DePodesta,      T.,      Yeh,      C.,      Li,      K.,      Marin,  \n \n  N.C.,      Patel,      O.,      Riecke,      J.,      Raval,      S.,      Seow,      O.,      et      al."
            },
            {
              "id": 727,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 110",
              "type": "chunk",
              "children": [],
              "content": "De-  \n \n  signing   \n \na      dashboard      for      transparency      and      control      of      con-  \n \n  versational      ai. arXiv      preprint      arXiv:2406.07882,      2024. Chi,      E. A.,      Hewitt,      J.,      and      Manning,      C. D. Finding      uni-  \n \n  versal      grammatical      relations      in      multilingual      bert. arXiv  \n \n  preprint      arXiv:2005.04511,      2020."
            },
            {
              "id": 728,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 111",
              "type": "chunk",
              "children": [],
              "content": "Cunningham,      H.,      Ewart,      A.,      Riggs,      L.,      Huben,      R.,      and       Sharkey,      L. Sparse      autoencoders      find      highly      inter-  \n \n  pretable      features      in      language      models. arXiv      preprint  \n \n  arXiv:2309.08600,      2023. Devlin,      J.,      Chang,      M.-W.,      Lee,      K.,      and      Toutanova,      K."
            },
            {
              "id": 729,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 112",
              "type": "chunk",
              "children": [],
              "content": "Bert:  \n \n  Pre-training      of      deep      bidirectional      transformers      for      lan-  \n \n  guage      understanding. arXiv      preprint      arXiv:      1810.04805,  \n \n  2018. Dmitry      Vaintrob,      Jake      Mendel,      K. Toward  \n \n  a      mathematical      framework      for      computation  \n \n  in      superposition. LessWrong,      2024."
            },
            {
              "id": 730,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 113",
              "type": "chunk",
              "children": [],
              "content": "URL\n \n \n  Elhage,      N.,      Nanda,      N.,      Olsson,      C.,      Henighan,      T.,      Joseph,  \n \n  N.,      Mann,      B.,      Askell,      A.,      Bai,      Y.,      Chen,      A.,      Conerly,      T.,  \n \n  et      al. A      mathematical      framework      for      transformer      circuits. 2024. Accessed:      2024-07-13. Transformer      Circuits      Thread,      1:1,      2021."
            },
            {
              "id": 731,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 114",
              "type": "chunk",
              "children": [],
              "content": "Elhage,      N.,      Hume,      T.,      Olsson,      C.,      Schiefer,      N.,      Henighan,  \n \n  T.,      Kravec,      S.,      Hatfield-Dodds,      Z.,      Lasenby,      R.,      Drain,  \n \n  D.,      Chen,      C.,      et      al. Toy      models      of      superposition. arXiv  \n \n  preprint      arXiv:2209. 10652,      2022. Engels,      J.,      Liao,      IL,      Michaud,      E. J.,      Gurnee,      W.,      and       Tegmark,      M."
            },
            {
              "id": 732,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 115",
              "type": "chunk",
              "children": [],
              "content": "Not      all      language      model      features      are      linear. arXiv      preprint      arXiv:2405. 14860,      2024. Feldman,      J. The      neural      binding      problem      (s). Cognitive  \n \n  neurodynamics,      7:1-11,      2013. Feng,      J. and      Steinhardt,      J. How      do      language      models      bind  \n \n  entities      in      context? arXiv      preprint      arXiv:2310.17191,  \n \n  2023."
            },
            {
              "id": 733,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 116",
              "type": "chunk",
              "children": [],
              "content": "Feng,      J.,      Russell,      S.,      and      Steinhardt,      J. Monitoring      la-  \n \n  tent      world      states      in      language      models      with      propositional  \n \n  probes. arXiv      preprint      arXiv:2406.19501,      2024. Fodor,      J. A. and      Pylyshyn,      Z. W. Connectionism      and      cogni-  \n \n  tive      architecture:   \n \nA      critical      analysis. Cognition,      28(1-2):\n \n \n  3-71,      1988. Gallant,      S. I. and      Okaywe,      T. W."
            },
            {
              "id": 734,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 117",
              "type": "chunk",
              "children": [],
              "content": "Representing      objects,      rela-  \n \n  tions,      and      sequences. Neural      computation,      25(8):2038—  \n \n  2078,      2013. Hernandez,      E.,      Sharma,      A. S.,      Haklay,      T.,      Meng,      K.,      Wat-  \n \n  tenberg,      M.,      Andreas,      J.,      Belinkov,      Y.,      and      Bau,      D. Lin-  \n \n  earity      of      relation      decoding      in      transformer      language      mod-  \n \n  els."
            },
            {
              "id": 735,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 118",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:2308.09124,      2023. Hewitt,      J. and      Manning,      C. D. A      structural      probe      for      find-  \n \n  ing      syntax      in      word      representations."
            },
            {
              "id": 736,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 119",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the  \n \n  2019      Conference      of      the      North      American      Chapter      of      the  \n \n  Association      for      Computational      Linguistics:      Human      Lan-  \n \n  guage      Technologies,      Volume   \n \n1      (Long      and      Short      Papers),  \n \n  pp. 4129-4138,      2019. Jones,      M. N. and      Mewhort,      D. J."
            },
            {
              "id": 737,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 120",
              "type": "chunk",
              "children": [],
              "content": "Representing      word      mean-  \n \n  ing      and      order      information      in   \n \na      composite      holographic  \n \n  lexicon. Psychological      review,      114(1):1,      2007. Kanerva,      P. Hyperdimensional      computing:      An      introduc-  \n \n  tion      to      computing      in      distributed      representation      with      high-  \n \n  dimensional      random      vectors. Cognitive      computation,      |:  \n \n  139-159,      2009. Kanerva,      P."
            },
            {
              "id": 738,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 121",
              "type": "chunk",
              "children": [],
              "content": "et      al. Fully      distributed      representation. PAT,      1\nKissane,      C.,      Robertzk,      Conmy,      A.,      and      Nanda,      N. Sparse      autoencoders      work      on      attention      layer      outputs. Relational      Composition\nLewis,      M.,      Nayak,      N. V.,      Yu,      P.,      Yu,      Q.,      Merullo,      J.,      Bach,      Mitchell,      J. and      Lapata,      M. Composition      in      distributional H.,      and      Pavlick,      E."
            },
            {
              "id": 739,
              "title": "3.3.1.      FEATURE      MULTIPLICITY      AND       PREDICT/CONTROL      DISCREPANCIES - Chunk 122",
              "type": "chunk",
              "children": [],
              "content": "Does      clip      bind      concepts? probing      models      of      semantics. Cognitive      science,      34(8):1388-  \n \n  compositionality      in      large      image      models. arXiv      preprint      1429,      2010. arXiv:2212.10537,      2022."
            }
          ],
          "content": ""
        },
        {
          "id": 740,
          "title": "Prox      (x)      =      (x,      Vtoa      +      Avtox)",
          "type": "section",
          "children": [
            {
              "id": 741,
              "title": "Prox      (x)      =      (x,      Vtoa      +      Avtox) - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Prox      (x)      =      (x,      Vtoa      +      Avtox)\n \n \n  On      the      other      hand,      if      we      trained      on      just      one      token      (perhaps  \n \n  the      last      token      in   \n \na      prompt,   \n \na      non-toxic      function      word,      in  \n \n  order      to      predict      subsequent      behavior)      we      could      easily      pro-  \n \n  duce   \n \na      probe      such      as:"
            }
          ],
          "content": ""
        },
        {
          "id": 742,
          "title": "Qtox      (x)      =      (a,      Avtox)",
          "type": "section",
          "children": [
            {
              "id": 743,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Qtox      (x)      =      (a,      Avtox)\n \n \n  Both      of      these      probes      might      perform      well,      but      this      already  \n \n  illustrates   \n \na      problem:      different      tokens      might      easily      produce  \n \n  different      probes      for      unimportant      contextual      reasons."
            },
            {
              "id": 744,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Now,      suppose      we      wish      to      intervene      during      network  \n \n  inference—for      instance,      we      want      to      change      the      residual  \n \n  stream      to      cause      the      network      to      produce      less      toxic      text."
            },
            {
              "id": 745,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Sim-  \n \n  ply      inspecting      the      second      probe,      we      might      hope      to      inter-  \n \n  vene      to      “remove      toxicity”      by      intervening      during      inference  \n \n  (Li      et      al.,      2024)      to      change      each      token   \n \n¢      to      have      the      new       value t=      t—      Avtox  \n \n  It’s      entirely      possible,      however,      that      the      values      of      inner      prod-  \n \n  ucts      (2,      Vtor)      and      (x,      Avior)      will      play      different      roles      in  \n \n  computing      the      toxicity      of      the      next      word."
            },
            {
              "id": 746,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "It’s      certainly      con-  \n \n  ceivable      that      the      toxicity      of      the      current      word      plays   \n \na      greater  \n \n  role      than      information      about      the      previous      word."
            },
            {
              "id": 747,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Quite      likely,  \n \n  the      most      effective      intervention      will      look      more      like      the      fol-  \n \n  lowing      equation,      where      cy      F      Co:\nt=t—C1Ut0«   \n \n—      C2AV      {0x 4See      also      (Marks,      2024)      for   \n \na      related      discussion;      we      return      to  \n \n  ideas      from      that      essay      in   \n \na      subsequent      section."
            },
            {
              "id": 748,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "In      other      words,      the      right      vector      for      controlling      the      network  \n \n  might      differ      from      the      most      effective      probe      vector      for      pre-  \n \n  dicting      its      behavior. This      phenomenon      would      make      it      harder      to      exploit      features  \n \n  derived      from      dictionary      learning."
            },
            {
              "id": 749,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "For      example,      if      there      are  \n \n  many      multiple      features      related      to      toxicity,      one      couldn’t      au-  \n \n  tomatically      extract   \n \na      steering      vector      from      the      dictionary,  \n \n  but      would      need      to      do      experiments      to      find      the      right      linear  \n \n  combination      of      feature      vectors."
            },
            {
              "id": 750,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Of      course,      the      analysis      out-  \n \n  lined      here      is      still      speculative. On      the      other      hand,      we      believe  \n \n  this      is   \n \na      plausible      picture,      especially      given      transformer      ar-  \n \n  chitecture. A      cynic      might      even      say      attention      layers      are      ma-  \n \n  chines      for      producing      spurious      correlations. 4."
            },
            {
              "id": 751,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Multi-token      mechanisms\n \n \n  So      far,      we’ve      discussed      binding      mechanisms      that      operate  \n \n  wthin   \n \na      single      vector      space."
            },
            {
              "id": 752,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "However,      since      the      earliest  \n \n  days      of      the      field,      there      has      been      speculation      that      that      some  \n \n  notion      of      sequence—that      is,      representations      across      multi-  \n \n  ple      input      observations—is      necessary      for      representing      com-  \n \n  plex      relationships      (Rosenblatt,      1961)."
            },
            {
              "id": 753,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "In      this      section,      with  \n \n  the      transformer      architecture      in      mind,      we      discuss   \n \na      class      of  \n \n  mechanisms      that      relate      specifically      to      sequence      models."
            },
            {
              "id": 754,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Mathematically,      we      consider   \n \na      sequence      of      “token      vectors” ty, to,,tp € R”  \n \n  where      each      ¢;      contains      feature      information      and,      potentially,  \n \n  information      about      its      relation      to      other      tokens."
            },
            {
              "id": 755,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "For      instance,  \n \n  each      t;      might      represent      the      residual      stream      for      the      7-th      el-  \n \n  ement      of   \n \na      sequence      at   \n \na      particular      layer      in   \n \na      transformer. To      extract      the      relational      data,      it      might      not      be      enough      to      look  \n \n  at   \n \na      single      token      ¢;      but      at      pairs      of      tokens      (¢;,t;)."
            },
            {
              "id": 756,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "This      per-  \n \n  spective      opens      up   \n \na      different      set      of      possibilities. It’s      also   \n \na       very      plausible      type      of      representation. For      example,      when  \n \n  working      with      word      embeddings,   \n \na      variety      of      relationships  \n \n  between      words      can      famously      be      read      by      taking      vector      dif-  \n \n  ferences      (Mikolov      et      al.,      2013a)."
            },
            {
              "id": 757,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "A      generalization      of      using      vector      differences      is      “linear      rela-  \n \n  tional      embedding”      (Paccanaro   \n \n&      Hinton,      2001). The      idea  \n \n  here      is      that   \n \na      relation      between      token      vectors      ¢;      and      t;      is  \n \n  present      when\n \n \n  for   \n \na      matrix   \n \nA      and      vector   \n \nb      which      depend      only      on      the  \n \n  relation."
            },
            {
              "id": 758,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Recent      work      suggests      that      something      like      this  \n \n  representation      may      be      found      in      the      way      that      language-  \n \n  model      transformers      represent      relationships      between      enti-  \n \n  ties      (Hernandez      et      al.,      2023). 4.1."
            },
            {
              "id": 759,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Syntactic      relations      and      tree      embeddings\n \n \n  One      striking      finding      related      to      the      BERT      network  \n \n  (Devlin      et      al.,      2018)      is      that      parse      trees      are      represented      ge-  \n \n  ometrically      by      relative      positions      of      token      vectors."
            },
            {
              "id": 760,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In      partic-  \n \n  ular,      the      “syntactic      distance”      between      two      words—as      mea-  \n \n  sured      in   \n \na      dependency      grammar      parse      tree—can      be      recov-  \n \n  ered      from      their      corresponding      token      vectors      in   \n \na      middle  \n \n  layer      of      BERT      (Hewitt   \n \n&      Manning,      2019;      Manning      et      al.,  \n \n  2020)."
            },
            {
              "id": 761,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "To      be      precise,      if      two      words      w;,      w;      in      the      same      sen-  \n \n  tence      are      represented      by      embedding      vectors      ¢;      and      ¢;,      and       if      d;(w;,      w;)      is      the      tree      distance      in      the      syntactic      parse      tree  \n \n  between      w;      and      we,      then ||W0t;   \n \n—      Mtj||?"
            },
            {
              "id": 762,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "©      de(wi,      w;)  \n \n  where      M      is   \n \na      constant      linear      transformation,      depending  \n \n  only      on      the      network."
            },
            {
              "id": 763,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "The      fact      that      tree      distance      corresponds  \n \n  to      the      square      of      the      Euclidean      distance      may      seem      surprising  \n \n  but,      as      described      in      (Reif      et      al.,      2019),      it’s      actually      natural  \n \n  in      the      context      of      mapping   \n \na      tree      metric      to   \n \na      Euclidean      met-  \n \n  ric."
            },
            {
              "id": 764,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "As      described      in      (Chi      et      al.,      2020),      one      possible      expla-  \n \n  nation      of      this      representation      is      that      the      differences      between  \n \n  token      embeddings      represent      syntactic      dependencies:      that  \n \n  is,      if      t;      and      ¢;      have   \n \na      specific      syntactic      relation      (such      as  \n \n  an      adjective      modifying   \n \na      noun)      then      the      vector      difference  \n \n  Mt,   \n \n—      Mt;      encodes      that      relation."
            },
            {
              "id": 765,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "This      area      seems      like   \n \na      promising      direction      for      follow-up  \n \n  work. For      one      thing,      tree      structures      might      naturally      occur  \n \n  in      many      other      situations. More      generally,      the      idea      that      dif-  \n \n  ferences      between      tokens      encode      specific,      contextual      rela-  \n \n  tionships      seems      powerful."
            },
            {
              "id": 766,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "A      natural      question      is      whether  \n \n  applying      dictionary      learning      to      residual      stream      differences,  \n \n  rather      than      the      residual      stream      itself,      might      yield   \n \na      set      of  \n \n  interpretable      “relation      features.”\n4.2."
            },
            {
              "id": 767,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "Reference      mechanisms:      pointers      and      identifiers\n \n \n  Software      engineers      have      invented      many      ways      to      tie      differ-  \n \n  ent      data      structures      together. Is      it      possible      that      neural      net-  \n \n  works      use      the      same      techniques? Some      recent      investigations  \n \n  hint      that      they      might."
            },
            {
              "id": 768,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "One      fundamental      component      of      many      software      data      struc-  \n \n  tures      is   \n \na      pointer:   \n \na      reference      to   \n \na      location      in      memory. The  \n \n  analog      of   \n \na      pointer,      for   \n \na      transformer      network,      might      be  \n \n  a      positional      embedding      that      defines   \n \na      reference      to   \n \na      spe-  \n \n  cific      token      in   \n \na      sequence."
            },
            {
              "id": 769,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "One      might      imagine      using      matrix  \n \n  binding      to      augment   \n \na      token      with      this      positional      information  \n \n  rather      than      semantic      data. For      instance,      if      p;      represents      the  \n \n  positional      embedding      for      position      j,      and      A,."
            },
            {
              "id": 770,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "is   \n \na      binding  \n \n  matrix,      one      might      represent   \n \na      relationship      between      tokens  \n \n  t;      and      ¢;      as:\n \n \n  r(ti,      t;)      =t;+      A,Dpj  \n \n  In      fact,      the      study      described      in      (Prakash      et      al.,      2024)      un-  \n \n  covers   \n \na      circuit      that      seems      to      use      something      like      this      kind  \n \n  of      “pointer”      mechanism      to      relate      an      entity      to      information  \n \n  about      its      state      elsewhere      in   \n \na      sequence."
            },
            {
              "id": 771,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "The      authors      de-  \n \n  scribe      specific      attention      heads      that      seem      to      move      and      read relevant      positional      encodings      in      order      to      connect      tokens      in  \n \n  this      way."
            },
            {
              "id": 772,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "A      second      fundamental      way      to      connect      data      comes      from  \n \n  the      world      of      databases:      using   \n \na      shared      identifier,      or      ID,  \n \n  to      link      two      pieces      of      information. Some      transformers  \n \n  may      actually      use   \n \na      geometric      form      of      this      mechanism  \n \n  (Feng   \n \n&      Steinhardt,      2023;      Feng      et      al.,      2024)."
            },
            {
              "id": 773,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "The      idea      is  \n \n  that      there      may      be   \n \na      special      subspace      of      the      residual      stream  \n \n  in      which      vector      similarity      encodes      binding      information. To  \n \n  be      precise,      they      find   \n \na      certain      low-rank      matrix      Ajg,      with  \n \n  the      property      that      for   \n \na      token      vector      ¢,      the      value      Ajgt      acts  \n \n  like      an      ID."
            },
            {
              "id": 774,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "That      is,      two      token      representations      t;      and      tz      are  \n \n  considered      to      be      bound      to      each      other      if\nAit;   \n \ny      Aiat;\n \n \n  One      interesting      question      is      how      and      whether      this      idea  \n \n  relates      to      the      syntax      tree      representations      described      in  \n \n  (Manning      et      al.,      2020)."
            },
            {
              "id": 775,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "For      example,      after      applying      the  \n \n  proper      structural      probe,      one      could      imagine      projecting      or-  \n \n  thogonally      to      an      adjective-modifies-noun      direction. This  \n \n  could      produce      something      like      an      ID      vector      linking      adjec-  \n \n  tives      with      the      nouns      they      modify."
            },
            {
              "id": 776,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "A      geometric      ID      mechanism      may      pose      challenges      for   \n \na      pure  \n \n  feature-vector-based      analysis. In      particular,      there’s      no      rea-  \n \n  son      to      assume      that      ID      information      clusters      in      any      useful  \n \n  way."
            },
            {
              "id": 777,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "The      only      structure      that      (Feng   \n \n&      Steinhardt,      2023)  \n \n  note      in      the      subspace      S      is      metric:      nearby      vectors      are      more  \n \n  likely      to      match      as      markers."
            },
            {
              "id": 778,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Thus      for      any      given      sequence,  \n \n  ID      vectors      conceivably      could      be      effectively      random—the  \n \n  only      constraint      being      that      distinct      ID      vectors      should      be      far  \n \n  from      each      other. Thus      dictionary      learning      or      classic      linear  \n \n  probing      may      not      encounter   \n \na      useful      signal. 5."
            },
            {
              "id": 779,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "Vector      symbolic      architecture\n \n \n  Finally,      we      discuss   \n \na      set      of      historical      ideas      for      vector      bind-  \n \n  ing,      collectively      known      as      “vector      symbolic      architecture,”  \n \n  or      VSA      (Smolensky,      1990;      Plate,      1994;      1997;      Kanerva,  \n \n  2009;      Jones   \n \n&      Mewhort,      2007;      Schlegel      et      al.,      2022)."
            },
            {
              "id": 780,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "A       comprehensive      survey      and      analysis      of      the      zoo      of      techniques  \n \n  in      this      area      is      far      beyond      the      scope      of      this      paper. Our      goal  \n \n  is      simply      to      provide   \n \na      gentle      introduction      to      techniques      that  \n \n  can      potentially      seem      arcane,      unmotivated,      and      intimidating."
            },
            {
              "id": 781,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "To      do      so,      we      focus      on      two      foundational      constructions,      one  \n \n  in      R”      and      one      in      {0,      1}”,      which      underlie      much      of      the      work  \n \n  in      this      field."
            },
            {
              "id": 782,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Both      mechanisms      have      the      potential      to      lead      to  \n \n  feature      “dark      matter.”\nThat      is,      they      might      represent      infor-  \n \n  mation      in   \n \na      way      that      is      out      of      reach      of      dictionary      learning  \n \n  or      probing      methods. 5.1."
            },
            {
              "id": 783,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Tensor      constructions\n \n \n  As      described      in      (Schlegel      et      al.,      2022),   \n \na      technique      intro-  \n \n  duced      in      (Smolensky,      1990)      forms      the      basis      of   \n \na      large      set  \n \n  of      different      VSA      mechanisms."
            },
            {
              "id": 784,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "It      is      often      referred      to      as   \n \na       “tensor”      method,      but      we’ll      describe      it      with      the      more      down-  \n \n  to-earth      notation      of      outer      products. As      before,      suppose      we      wish      to      compose,      or      bind,      two      vec-  \n \n  tors   \n \nx      and      y."
            },
            {
              "id": 785,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "One      way      is      to      use      an      outer      product      to      define   \n \na       representation:\nr=      xy This      representation      distinguishes      order,      since      generally  \n \n  xy’   \n \n#      yx’). It      respects      vector      addition,      since      it      is      linear in      each      of   \n \nx      and   \n \ny      respectively."
            },
            {
              "id": 786,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      one      can      recover x\n \n   and      y,      at      least      up      to      scalar      multiples,      with      easy      vector  \n \n  algebra."
            },
            {
              "id": 787,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "For      example,      if      you      know      y,      you      can      recover   \n \na       scalar      multiple      of   \n \nx      via      the      product\nry      =xy\\\\\\'y   \n \n=      |lyll?x\n \n \n  The      alert      reader      will      notice,      however,      that      this      outer      prod-  \n \n  uct      representation      is   \n \na      cheat:      it      lives      in      R”*”      rather      than  \n \n  IR”."
            },
            {
              "id": 788,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "One      may      view      much      of      the      VSA      literature      as   \n \na      bag      of  \n \n  tricks      to      get      around      this      inconvenient      fact. The      most      com-  \n \n  mon      trick      is      to      create      an      n-dimensional      projection      of      the  \n \n  outer      product,      which      can      still      be      used      for      approximate      re-  \n \n  construction."
            },
            {
              "id": 789,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "One      method,      for      instance,      is      projecting      the  \n \n  outer      product      matrix      via      circular      convolution      (Plate,      1997). 5.2. Binary      vectors\n \n \n \nA      second      category      of      VSA      techniques      relies      on      binary-  \n \n  valued      vectors      (Kanerva      et      al.,      1997;      Kanerva,      2009). We  \n \n  describe      one      simple      proposal      of      this      type."
            },
            {
              "id": 790,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "To      bind      two      bi-  \n \n  nary      vectors   \n \nx      and      y,      we      fix   \n \na      permutation      P      that      rearranges  \n \n  the      entries      of   \n \na      vector,      and      then      compute r=a2®      Ply)  \n \n  Here   \n \n©      denotes      modulo-2      addition. Like      the      outer      prod-  \n \n  uct,      this      distinguishes      between      the      ordered      pairs      (x,      y)      and       (y,x)."
            },
            {
              "id": 791,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "It      respects      the      binary      OR      function,      which      can      be  \n \n  used      to      take      unions      of      two      sets      of      features."
            },
            {
              "id": 792,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "It      also      allows  \n \n  for      easy      reconstruction      of      one      vector      in      the      pair      if      you      know  \n \n  the      other:\nz=r®      Ply) y=P\\\\\\'(r@2)  \n \n  >We      need      the      permutation      P      because      mod-2      addition      is      com-  \n \n  mutative,      and      otherwise      we      couldn’t      distinguish      the      pairs      (a,      y)  \n \n  and      (y,      x)."
            },
            {
              "id": 793,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "The      situation      is      similar      to      an      additive      matrix      binding  \n \n  formula   \n \nx   \n \n+      Ay. Permuting      one      argument      also      allows      us      to      bind  \n \n  a      vector      to      itself      without      leading      to   \n \na      zero      representation."
            },
            {
              "id": 794,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "This      is   \n \na      conceptually      elegant      method,      although      it      requires  \n \n  extremely      large      vectors      for      effective      storage      and      decoding. 5.3. Is      VSA   \n \na      plausible      mechanism      for      real      neural      nets?"
            },
            {
              "id": 795,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Unlike      additive      binding      models,      the      techniques      proposed  \n \n  for      tensor-based      VSA      don’t      obviously      map      to      deep      learn-  \n \n  ing      architectures. Investigations      of      whether      real-world      net-  \n \n  works      use      VSA      have      yielded      mixed      conclusions."
            },
            {
              "id": 796,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "For      ex-  \n \n  ample,   \n \na      study      of      whether      CLIP      might      use      these      mech-  \n \n  anisms      produced      largely      negative      results      (Lewis      et      al.,  \n \n  2022),      while      there      are      some      indications      RNNs      may      repro-  \n \n  duce      tensor-related      structures      (McCoy      et      al.,      2018)."
            },
            {
              "id": 797,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "Techniques      based      on      binary      vectors      might      seem      even      fur-  \n \n  ther      from      modern      language      model      architectures."
            },
            {
              "id": 798,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Surpris-  \n \n  ingly,      some      recent      work      suggests      that      for      sparse      vectors  \n \n  in      superposition,      not      only      can      neural      nets      compute      XORs  \n \n  of      such      features      in      theory      (Dmitry      Vaintrob,      2024),      they  \n \n  seem      to      do      so      in      practice      (Marks,      2024)."
            },
            {
              "id": 799,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "Traditional      bi-  \n \n  nary      VSA      is      based      on      dense      vectors,      of      course,      but      this  \n \n  seems      like      an      interesting      avenue      for      exploration. One      might  \n \n  imagine      combining      ideas      from      the      tensor      and      binary      VSA  \n \n  schemes—perhaps      based      on      outer      products      specifically      of  \n \n  zero-one      vectors,      either      over   \n \nR      or      Zo."
            },
            {
              "id": 800,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "5.4. Implications      for      the      search      for      features\n \n \n  As      with      matrix      addition      binding,      we      speculate      that      VSA  \n \n  mechanisms      may      lead      to      feature      multiplicity. For      exam-  \n \n  ple,      outer      product      binding      could      plausibly      produce   \n \na      com-  \n \n  binatorial      proliferation      of      potential      features®."
            },
            {
              "id": 801,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "To      see      the  \n \n  issue,      consider   \n \na      setting      where      we      have      m      feature      vectors, {v1,,Um}, and we want to compose representation vec-  \n \n  tors   \n \nx      and      y:\n \n \n  m       c=   \n \n)      AQUyz  \n \n  i=1  \n \n  m       y=   \n \n>      div;\n \n \n  i=l  \n \n  where      the      sums      are      assumed      to      be      sparse,      and      {a;}      and       {b;}      independently      chosen."
            },
            {
              "id": 802,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "Suppose      we      have   \n \na      composi-  \n \n  tion      method      of      the      form r(x,y)   \n \n=      m(xy\") where   \n \n7   \n \n:      R\"*”   \n \n—      R”      is   \n \na      projection      operator. By      linear-  \n \n  ity,      we      have r(z,y)   \n \n=      S>      ajbjm      (Viv;   \n \n) 4g We      have      now      moved      from      using      m      feature      vectors      {v;}      to  \n \n  a      situation      with      m?"
            },
            {
              "id": 803,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "potential      feature      vectors      {r(viv}      )}. °The      essay      (Marks,      2024)      has   \n \na      discussion      of      parallel      concerns  \n \n  in      the      case      of      binary      codes. This      is   \n \na      problem."
            },
            {
              "id": 804,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "To      begin      with,      even      if      we      could      use      dic-  \n \n  tionary      learning      to      find      all      these      features,      there      may      be   \n \na       truly      huge      number      of      them. Even      if      not      all      combinations  \n \n  are      likely      to      occur,      the      potential      number      of      new      combina-  \n \n  tons      is      vast."
            },
            {
              "id": 805,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      person      interpreting   \n \na      network,      having  \n \n  fine-grained      versions      of      the      same      feature      is      confusing. For  \n \n  example,      one      might      see      many      different      vectors      reflecting  \n \n  the      same      concept      in      different      overall      contexts."
            },
            {
              "id": 806,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "Something  \n \n  like      this      actually      appears      repeatedly      in   \n \na      language      model  \n \n  analyzed      in      (Bricken      et      al.,      2023)."
            },
            {
              "id": 807,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "For      example,      they      don’t  \n \n  find   \n \na      single      pure      “English      preposition”      feature,      but      they      do  \n \n  identify   \n \na      feature      corresponding      to      “prepositions      in      scien-  \n \n  tific/statistical      contexts”’      and   \n \na      separate      feature      that      fires      on  \n \n  “prepositions      in      contexts      discussing      poetry/poets”®."
            },
            {
              "id": 808,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "This  \n \n  is      just      one      of      many      examples      from      the      feature      catalog      of  \n \n  (Bricken      et      al.,      2023)."
            },
            {
              "id": 809,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "As      the      authors      of      that      study      discuss,  \n \n  this      seems      to      be      part      of   \n \na      much      larger      story      related      to   \n \na       non-isotropic      distribution      of      features—perhaps      an      analysis  \n \n  of      compositional      mechanisms      could      shed      light      on      this      phe- nomenon."
            },
            {
              "id": 810,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "A      second      problem      with      the      proliferation      of      fine-grained      fea-  \n \n  tures      is      that      we      might      need      far      more      data      to      discover      each  \n \n  one."
            },
            {
              "id": 811,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "For      example,      features      for      “inspiring”      and      ”architec-  \n \n  ture”      might      be      just      common      enough      to      find,      but      the      combi-  \n \n  nation      of      “inspiring      architecture”      might,      sadly,      be      too      rare  \n \n  to      appear      in      the      output      of   \n \na      dictionary      learning      algorithm."
            },
            {
              "id": 812,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "This      may      lead      to      “dark      matter”—feature      representation      that  \n \n  are      out      of      reach      unless      one      tests      with      vast      amounts      of      data. From      an      optimistic      viewpoint,      this      phenomenon      can      also  \n \n  be      seen      as   \n \na      cause      for      hope."
            },
            {
              "id": 813,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "As      discussed      earlier,      many      fea-  \n \n  tures      in      the      catalog      of      (Bricken      et      al.,      2023)      seem      to      have  \n \n  combinatorial      interpretations."
            },
            {
              "id": 814,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "If      we      had   \n \na      principled      way  \n \n  of      “factoring”      these      features,      extracting      an      outer-product  \n \n  structure      automatically,      that      could      be   \n \na      huge      help      in      iden-  \n \n  tifying      primitive      features. It      could      also      help      simplify      and       organize      feature      catalogs. 6."
            },
            {
              "id": 815,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "Conclusion      and      future      work\n \n \n  We’ve      described   \n \na      series      of      proposals—some      historical,  \n \n  some      very      recent—for      how      neural      nets      might      represent      re-  \n \n  lationships      between      features."
            },
            {
              "id": 816,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": "Along      the      way,      we’ve      given  \n \n  conceptual      arguments      that      these      mechanisms      might      present  \n \n  problems      when      finding      and      using      linear      feature      representa-  \n \n  tions. One      challenge      is      that      of      “dark      matter’:      feature      rep-  \n \n  resentations      that      are      difficult      to      find      using      standard      meth-  \n \n  ods."
            },
            {
              "id": 817,
              "title": "Qtox      (x)      =      (a,      Avtox) - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "Another      potential      problem      is      feature      multiplicity,      or  \n \n  the      presence      of      multiple      “echo      vectors”      that      correspond      to  \n \n  the      same      feature. An      issue      of      special      concern,      related      to  \n \n  multiplicity,      is      whether      feature      vectors      discovered      by      prob-"
            }
          ],
          "content": ""
        },
        {
          "id": 818,
          "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation",
          "type": "section",
          "children": [
            {
              "id": 819,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation\n \n \n  ing      or      dictionary-learning      methods      will      be      as      useful      for      in-  \n \n  terventions      as      they      are      for      predicting      the      state      of      the      net-  \n \n  work."
            },
            {
              "id": 820,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "The      arguments      here      are      conjectural      and      often      involve      ideal-  \n \n  ized      settings. A      great      deal      of      work      would      be      necessary      to  \n \n  resolve      the      questions      we’      ve      raised—calling      for      that      work      is  \n \n  the      point      of      this      note."
            },
            {
              "id": 821,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Here      are      some      directions      that      might  \n \n  shed      light      on      the      key      issues:\n \n \n \n¢      Toy      models      that      learn      composition. One      way      to  \n \n  gather      data      would      be      to      experiment      with      minimal  \n \n  models. It      would      be      useful      to      find      toy      models      of  \n \n  learned      composition."
            },
            {
              "id": 822,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "If      we      give      an      autoencoder   \n \na      task  \n \n  that      requires      learning      relational      composition,      what  \n \n  mechanisms      are      found      via      gradient      descent?"
            },
            {
              "id": 823,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Some  \n \n  work      in      this      area      dates      back      decades      (Pollack,      1988;\n \n \n  Blank      et      al.,      2014)      and      it      would      be      interesting      to      ana-  \n \n  lyze      these      same      systems      with      modern      methods,      and      to  \n \n  extend      this      line      of      research      further."
            },
            {
              "id": 824,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "¢      Apply      feature      extraction      methods      to      synthetic      com-  \n \n  position      mechanisms. We      provided   \n \na      conceptual      out-  \n \n  line      of      how      feature      discovery      techniques      might      run  \n \n  into      trouble      on      compositional      representations."
            },
            {
              "id": 825,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "A      nat-  \n \n  ural      next      step      would      be      to      test      these      arguments      empir-  \n \n  ically,      by      creating      synthetic      versions      of      VSA,      matrix  \n \n  binding,      and      other      mechanisms,      and      applying      dictio-  \n \n  nary      learning      to      the      results. ¢      Apply      dictionary      learning      to      token      differences."
            },
            {
              "id": 826,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Syntactic      relations      appear      to      be      encoded      in      differences  \n \n  between      token      vectors. Are      other      relations      encoded  \n \n  this      way      as      well? It      could      be      worth      applying      dictio-  \n \n  nary      learning      techniques      to      token      differences      to      find  \n \n  additional      “relational      features.”\n \n \n \n¢      Investigate      marker      mechanisms."
            },
            {
              "id": 827,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "The      “ID      vector”  \n \n  mechanism      suggested      by      (Feng   \n \n&      Steinhardt,      2023)      is  \n \n  extremely      interesting. It      also      presents   \n \na      clear      problem  \n \n  for      feature-based      interpretability      methods. It      would  \n \n  be      helpful      to      understand      just      how      widely      the      mecha-  \n \n  nism      might      apply."
            },
            {
              "id": 828,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "How      does      it      relate      to      the      syntax  \n \n  representations      of      (Manning      et      al.,      2020)? Experimen-  \n \n  tation      with      small      synthetic      models      might      advance      our  \n \n  understanding      of      the      basic      process. It      would      also      be  \n \n  helpful      to      find      lightweight      ways      to      identify      ID      vector  \n \n  subspaces."
            },
            {
              "id": 829,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "¢      Look      for      feature      multiplicity. If      feature      multiplic-  \n \n  ity      is   \n \na      real      problem,      it      may      not      be      hard      to      iden-  \n \n  tify. One      sign      would      be      the      discovery      of      redundant      or  \n \n  contextually      dependent      feature      vectors."
            },
            {
              "id": 830,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "The      features  \n \n  found      in      (Bricken      et      al.,      2023;      Templeton      et      al.,      2024;  \n \n  Kissane      et      al.,      2024)      sometimes      exhibit      this      type      of  \n \n  behavior,      for      instance."
            },
            {
              "id": 831,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "If      one      could      pair      up   \n \na      suffi-  \n \n  ciently      large      number      of      redundant      features      via   \n \na      sin-  \n \n  gle      linear      transformation,      that      would      provide      strong  \n \n  evidence      for      the      multiplicity      hypothesis,      and      also      help  \n \n  organize      feature      catalogs. ¢      Understand      predict/control      discrepancy."
            },
            {
              "id": 832,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Feature  \n \n  multiplicity      might      cause   \n \na      problem      that      we      have  \n \n  termed      “predict/control      discrepancy.”\nThat      is,      an      ef-  \n \n  fective      vector      for      predicting   \n \na      particular      network      be-  \n \n  havior      might      be      different      from      the      best      “steering      vec-  \n \n  tor”      for      inducing      that      same      behavior."
            },
            {
              "id": 833,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Given      the      ob-  \n \n  vious      practical      implications,      and      that      there      are      multi-  \n \n  ple      examples      of      this      phenomenon      in      the      literature,      it  \n \n  seems      important      to      investigate      further. ¢      Measure      real      models      for      relational      composition."
            },
            {
              "id": 834,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "One      alternative      to      explicitly      identifying      relational      rep-  \n \n  resentations      is      to      look      for      behavioral      evidence      that  \n \n  they      exist. That      can      at      least      alert      us      to      “dark      matter”  \n \n  that      isn’t      observed      by      feature      identification      methods."
            },
            {
              "id": 835,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "A      review      of      this      type      of      work      is      beyond      the      scope  \n \n  of      this      paper,      but      several      studies      suggest      promising  \n \n  directions      (Andreas,      2019;      Lovering   \n \n&      Pavlick,      2022;  \n \n  Akyiirek   \n \n&      Andreas,      2023). ¢      Investigate      VSA-based      binding      in      real      networks."
            },
            {
              "id": 836,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "The      findings      in      (Dmitry      Vaintrob,      2024;      Marks,      2024)  \n \n  suggest      some      natural      mechanisms      by      which      binary  \n \n  VSA      codes      might      be      implemented      in      realistic      net-  \n \n  works."
            },
            {
              "id": 837,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "It      may      be      worth      systematically      working      out      the  \n \n  simplest      implementations      of      these      mechanisms,      and       investigating      whether      real      networks      make      use      of      them."
            },
            {
              "id": 838,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "To      sum      up,      there      are      major      practical      and      theoretical  \n \n  questions      around      how      the      linear      representation      hypothesis  \n \n  might      interact      with      mechanisms      for      relational      composition. We      strongly      advocate      for      continued      research      in      this      area."
            },
            {
              "id": 839,
              "title": "Feature      A/1/3533      in      the      study’s      notation       Feature      A/1/3977      in      the      study’s      notation - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Identifying      mechanisms      for      relational      composition      would  \n \n  be   \n \na      step      forward      for      useful      interpretability      work. Even      if  \n \n  it      turns      out      that      neural      nets      show      no      evidence      of      relational  \n \n  composition,      that      would      be      an      important      theoretical      result. ents"
            }
          ],
          "content": ""
        },
        {
          "id": 840,
          "title": "7.      Acknowledgments",
          "type": "section",
          "children": [
            {
              "id": 841,
              "title": "7.      Acknowledgments - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "7. Acknowledgments\nents\nReferences\n \n \n  Akyiirek,      E. and      Andreas,      J. Lexsym:      Compositionality  \n \n  as      lexical      symmetry. In      Proceedings      of      the      61st      Annual  \n \n  Meeting      of      the      Association      for      Computational      Linguis-  \n \n  tics      (Volume      1:      Long      Papers),      pp. 639-657,      2023. Andreas,      J. Measuring      compositionality      in      representation  \n \n  learning."
            },
            {
              "id": 842,
              "title": "7.      Acknowledgments - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:      1902.07181,      2019. Arora,      S.,      Li,      Y.,      Liang,      Y.,      Ma,      T.,      and      Risteski,      A. A       latent      variable      model      approach      to      pmi-based      word      em-  \n \n  beddings. Transactions      of      the      Association      for      Computa-  \n \n  tional      Linguistics,      4:385-399,      2016. Blank,      D. S.,      Meeden,      L. A.,      and      Marshall,      J. B."
            },
            {
              "id": 843,
              "title": "7.      Acknowledgments - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Exploring  \n \n  the      symbolic/subsymbolic      continuum:   \n \nA      case      study      of  \n \n  raam. In      The      Symbolic      and      Connectionist      Paradigms,  \n \n  pp. 113-148. Psychology      Press,      2014. Bowman,      S.,      Potts,      C.,      and      Manning,      C. D. Recursive      neu-  \n \n  ral      networks      can      learn      logical      semantics."
            },
            {
              "id": 844,
              "title": "7.      Acknowledgments - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings  \n \n  of      the      3rd      workshop      on      continuous      vector      space      models  \n \n  and      their      compositionality,      pp. 12-21,      2015. Bricken,      T.,      Templeton,      A.,      Batson,      J.,      Chen,      B.,      Jermyn,  \n \n  A.,      Conerly,      T.,      Turner,      N.,      Anil,      C.,      Denison,      C.,      Askell,  \n \n  A.,      et      al."
            },
            {
              "id": 845,
              "title": "7.      Acknowledgments - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Towards      monosemanticity:      Decomposing      lan-  \n \n  guage      models      with      dictionary      learning. Transformer      Cir-  \n \n  cuits      Thread,      pp. 2,      2023. Chen,      Y.,      Wu,      A.,      DePodesta,      T.,      Yeh,      C.,      Li,      K.,      Marin,  \n \n  N.C.,      Patel,      O.,      Riecke,      J.,      Raval,      S.,      Seow,      O.,      et      al."
            },
            {
              "id": 846,
              "title": "7.      Acknowledgments - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "De-  \n \n  signing   \n \na      dashboard      for      transparency      and      control      of      con-  \n \n  versational      ai. arXiv      preprint      arXiv:2406.07882,      2024. Chi,      E. A.,      Hewitt,      J.,      and      Manning,      C. D. Finding      uni-  \n \n  versal      grammatical      relations      in      multilingual      bert. arXiv  \n \n  preprint      arXiv:2005.04511,      2020."
            },
            {
              "id": 847,
              "title": "7.      Acknowledgments - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Cunningham,      H.,      Ewart,      A.,      Riggs,      L.,      Huben,      R.,      and       Sharkey,      L. Sparse      autoencoders      find      highly      inter-  \n \n  pretable      features      in      language      models. arXiv      preprint  \n \n  arXiv:2309.08600,      2023. Devlin,      J.,      Chang,      M.-W.,      Lee,      K.,      and      Toutanova,      K."
            },
            {
              "id": 848,
              "title": "7.      Acknowledgments - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Bert:  \n \n  Pre-training      of      deep      bidirectional      transformers      for      lan-  \n \n  guage      understanding. arXiv      preprint      arXiv:      1810.04805,  \n \n  2018. Dmitry      Vaintrob,      Jake      Mendel,      K. Toward  \n \n  a      mathematical      framework      for      computation  \n \n  in      superposition. LessWrong,      2024."
            },
            {
              "id": 849,
              "title": "7.      Acknowledgments - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "URL\n \n \n  Elhage,      N.,      Nanda,      N.,      Olsson,      C.,      Henighan,      T.,      Joseph,  \n \n  N.,      Mann,      B.,      Askell,      A.,      Bai,      Y.,      Chen,      A.,      Conerly,      T.,  \n \n  et      al. A      mathematical      framework      for      transformer      circuits. 2024. Accessed:      2024-07-13. Transformer      Circuits      Thread,      1:1,      2021."
            },
            {
              "id": 850,
              "title": "7.      Acknowledgments - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Elhage,      N.,      Hume,      T.,      Olsson,      C.,      Schiefer,      N.,      Henighan,  \n \n  T.,      Kravec,      S.,      Hatfield-Dodds,      Z.,      Lasenby,      R.,      Drain,  \n \n  D.,      Chen,      C.,      et      al. Toy      models      of      superposition. arXiv  \n \n  preprint      arXiv:2209. 10652,      2022. Engels,      J.,      Liao,      IL,      Michaud,      E. J.,      Gurnee,      W.,      and       Tegmark,      M."
            },
            {
              "id": 851,
              "title": "7.      Acknowledgments - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Not      all      language      model      features      are      linear. arXiv      preprint      arXiv:2405. 14860,      2024. Feldman,      J. The      neural      binding      problem      (s). Cognitive  \n \n  neurodynamics,      7:1-11,      2013. Feng,      J. and      Steinhardt,      J. How      do      language      models      bind  \n \n  entities      in      context? arXiv      preprint      arXiv:2310.17191,  \n \n  2023."
            },
            {
              "id": 852,
              "title": "7.      Acknowledgments - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Feng,      J.,      Russell,      S.,      and      Steinhardt,      J. Monitoring      la-  \n \n  tent      world      states      in      language      models      with      propositional  \n \n  probes. arXiv      preprint      arXiv:2406.19501,      2024. Fodor,      J. A. and      Pylyshyn,      Z. W. Connectionism      and      cogni-  \n \n  tive      architecture:   \n \nA      critical      analysis. Cognition,      28(1-2):\n \n \n  3-71,      1988. Gallant,      S. I. and      Okaywe,      T. W."
            },
            {
              "id": 853,
              "title": "7.      Acknowledgments - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Representing      objects,      rela-  \n \n  tions,      and      sequences. Neural      computation,      25(8):2038—  \n \n  2078,      2013. Hernandez,      E.,      Sharma,      A. S.,      Haklay,      T.,      Meng,      K.,      Wat-  \n \n  tenberg,      M.,      Andreas,      J.,      Belinkov,      Y.,      and      Bau,      D. Lin-  \n \n  earity      of      relation      decoding      in      transformer      language      mod-  \n \n  els."
            },
            {
              "id": 854,
              "title": "7.      Acknowledgments - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:2308.09124,      2023. Hewitt,      J. and      Manning,      C. D. A      structural      probe      for      find-  \n \n  ing      syntax      in      word      representations."
            },
            {
              "id": 855,
              "title": "7.      Acknowledgments - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the  \n \n  2019      Conference      of      the      North      American      Chapter      of      the  \n \n  Association      for      Computational      Linguistics:      Human      Lan-  \n \n  guage      Technologies,      Volume   \n \n1      (Long      and      Short      Papers),  \n \n  pp. 4129-4138,      2019. Jones,      M. N. and      Mewhort,      D. J."
            },
            {
              "id": 856,
              "title": "7.      Acknowledgments - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Representing      word      mean-  \n \n  ing      and      order      information      in   \n \na      composite      holographic  \n \n  lexicon. Psychological      review,      114(1):1,      2007. Kanerva,      P. Hyperdimensional      computing:      An      introduc-  \n \n  tion      to      computing      in      distributed      representation      with      high-  \n \n  dimensional      random      vectors. Cognitive      computation,      |:  \n \n  139-159,      2009. Kanerva,      P."
            },
            {
              "id": 857,
              "title": "7.      Acknowledgments - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "et      al. Fully      distributed      representation. PAT,      1\nKissane,      C.,      Robertzk,      Conmy,      A.,      and      Nanda,      N. Sparse      autoencoders      work      on      attention      layer      outputs. Relational      Composition\nLewis,      M.,      Nayak,      N. V.,      Yu,      P.,      Yu,      Q.,      Merullo,      J.,      Bach,      Mitchell,      J. and      Lapata,      M. Composition      in      distributional H.,      and      Pavlick,      E."
            },
            {
              "id": 858,
              "title": "7.      Acknowledgments - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Does      clip      bind      concepts? probing      models      of      semantics. Cognitive      science,      34(8):1388-  \n \n  compositionality      in      large      image      models. arXiv      preprint      1429,      2010. arXiv:2212.10537,      2022."
            }
          ],
          "content": ""
        },
        {
          "id": 859,
          "title": "References",
          "type": "section",
          "children": [
            {
              "id": 860,
              "title": "References - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "References\n \n \n  Akyiirek,      E. and      Andreas,      J. Lexsym:      Compositionality  \n \n  as      lexical      symmetry. In      Proceedings      of      the      61st      Annual  \n \n  Meeting      of      the      Association      for      Computational      Linguis-  \n \n  tics      (Volume      1:      Long      Papers),      pp. 639-657,      2023. Andreas,      J. Measuring      compositionality      in      representation  \n \n  learning."
            },
            {
              "id": 861,
              "title": "References - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:      1902.07181,      2019. Arora,      S.,      Li,      Y.,      Liang,      Y.,      Ma,      T.,      and      Risteski,      A. A       latent      variable      model      approach      to      pmi-based      word      em-  \n \n  beddings. Transactions      of      the      Association      for      Computa-  \n \n  tional      Linguistics,      4:385-399,      2016. Blank,      D. S.,      Meeden,      L. A.,      and      Marshall,      J. B."
            },
            {
              "id": 862,
              "title": "References - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Exploring  \n \n  the      symbolic/subsymbolic      continuum:   \n \nA      case      study      of  \n \n  raam. In      The      Symbolic      and      Connectionist      Paradigms,  \n \n  pp. 113-148. Psychology      Press,      2014. Bowman,      S.,      Potts,      C.,      and      Manning,      C. D. Recursive      neu-  \n \n  ral      networks      can      learn      logical      semantics."
            },
            {
              "id": 863,
              "title": "References - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings  \n \n  of      the      3rd      workshop      on      continuous      vector      space      models  \n \n  and      their      compositionality,      pp. 12-21,      2015. Bricken,      T.,      Templeton,      A.,      Batson,      J.,      Chen,      B.,      Jermyn,  \n \n  A.,      Conerly,      T.,      Turner,      N.,      Anil,      C.,      Denison,      C.,      Askell,  \n \n  A.,      et      al."
            },
            {
              "id": 864,
              "title": "References - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Towards      monosemanticity:      Decomposing      lan-  \n \n  guage      models      with      dictionary      learning. Transformer      Cir-  \n \n  cuits      Thread,      pp. 2,      2023. Chen,      Y.,      Wu,      A.,      DePodesta,      T.,      Yeh,      C.,      Li,      K.,      Marin,  \n \n  N.C.,      Patel,      O.,      Riecke,      J.,      Raval,      S.,      Seow,      O.,      et      al."
            },
            {
              "id": 865,
              "title": "References - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "De-  \n \n  signing   \n \na      dashboard      for      transparency      and      control      of      con-  \n \n  versational      ai. arXiv      preprint      arXiv:2406.07882,      2024. Chi,      E. A.,      Hewitt,      J.,      and      Manning,      C. D. Finding      uni-  \n \n  versal      grammatical      relations      in      multilingual      bert. arXiv  \n \n  preprint      arXiv:2005.04511,      2020."
            },
            {
              "id": 866,
              "title": "References - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Cunningham,      H.,      Ewart,      A.,      Riggs,      L.,      Huben,      R.,      and       Sharkey,      L. Sparse      autoencoders      find      highly      inter-  \n \n  pretable      features      in      language      models. arXiv      preprint  \n \n  arXiv:2309.08600,      2023. Devlin,      J.,      Chang,      M.-W.,      Lee,      K.,      and      Toutanova,      K."
            },
            {
              "id": 867,
              "title": "References - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Bert:  \n \n  Pre-training      of      deep      bidirectional      transformers      for      lan-  \n \n  guage      understanding. arXiv      preprint      arXiv:      1810.04805,  \n \n  2018. Dmitry      Vaintrob,      Jake      Mendel,      K. Toward  \n \n  a      mathematical      framework      for      computation  \n \n  in      superposition. LessWrong,      2024."
            },
            {
              "id": 868,
              "title": "References - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "URL\n \n \n  Elhage,      N.,      Nanda,      N.,      Olsson,      C.,      Henighan,      T.,      Joseph,  \n \n  N.,      Mann,      B.,      Askell,      A.,      Bai,      Y.,      Chen,      A.,      Conerly,      T.,  \n \n  et      al. A      mathematical      framework      for      transformer      circuits. 2024. Accessed:      2024-07-13. Transformer      Circuits      Thread,      1:1,      2021."
            },
            {
              "id": 869,
              "title": "References - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Elhage,      N.,      Hume,      T.,      Olsson,      C.,      Schiefer,      N.,      Henighan,  \n \n  T.,      Kravec,      S.,      Hatfield-Dodds,      Z.,      Lasenby,      R.,      Drain,  \n \n  D.,      Chen,      C.,      et      al. Toy      models      of      superposition. arXiv  \n \n  preprint      arXiv:2209. 10652,      2022. Engels,      J.,      Liao,      IL,      Michaud,      E. J.,      Gurnee,      W.,      and       Tegmark,      M."
            },
            {
              "id": 870,
              "title": "References - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Not      all      language      model      features      are      linear. arXiv      preprint      arXiv:2405. 14860,      2024. Feldman,      J. The      neural      binding      problem      (s). Cognitive  \n \n  neurodynamics,      7:1-11,      2013. Feng,      J. and      Steinhardt,      J. How      do      language      models      bind  \n \n  entities      in      context? arXiv      preprint      arXiv:2310.17191,  \n \n  2023."
            },
            {
              "id": 871,
              "title": "References - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Feng,      J.,      Russell,      S.,      and      Steinhardt,      J. Monitoring      la-  \n \n  tent      world      states      in      language      models      with      propositional  \n \n  probes. arXiv      preprint      arXiv:2406.19501,      2024. Fodor,      J. A. and      Pylyshyn,      Z. W. Connectionism      and      cogni-  \n \n  tive      architecture:   \n \nA      critical      analysis. Cognition,      28(1-2):\n \n \n  3-71,      1988. Gallant,      S. I. and      Okaywe,      T. W."
            },
            {
              "id": 872,
              "title": "References - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Representing      objects,      rela-  \n \n  tions,      and      sequences. Neural      computation,      25(8):2038—  \n \n  2078,      2013. Hernandez,      E.,      Sharma,      A. S.,      Haklay,      T.,      Meng,      K.,      Wat-  \n \n  tenberg,      M.,      Andreas,      J.,      Belinkov,      Y.,      and      Bau,      D. Lin-  \n \n  earity      of      relation      decoding      in      transformer      language      mod-  \n \n  els."
            },
            {
              "id": 873,
              "title": "References - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint      arXiv:2308.09124,      2023. Hewitt,      J. and      Manning,      C. D. A      structural      probe      for      find-  \n \n  ing      syntax      in      word      representations."
            },
            {
              "id": 874,
              "title": "References - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the  \n \n  2019      Conference      of      the      North      American      Chapter      of      the  \n \n  Association      for      Computational      Linguistics:      Human      Lan-  \n \n  guage      Technologies,      Volume   \n \n1      (Long      and      Short      Papers),  \n \n  pp. 4129-4138,      2019. Jones,      M. N. and      Mewhort,      D. J."
            },
            {
              "id": 875,
              "title": "References - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Representing      word      mean-  \n \n  ing      and      order      information      in   \n \na      composite      holographic  \n \n  lexicon. Psychological      review,      114(1):1,      2007. Kanerva,      P. Hyperdimensional      computing:      An      introduc-  \n \n  tion      to      computing      in      distributed      representation      with      high-  \n \n  dimensional      random      vectors. Cognitive      computation,      |:  \n \n  139-159,      2009. Kanerva,      P."
            },
            {
              "id": 876,
              "title": "References - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "et      al. Fully      distributed      representation. PAT,      1\nKissane,      C.,      Robertzk,      Conmy,      A.,      and      Nanda,      N. Sparse      autoencoders      work      on      attention      layer      outputs. Relational      Composition\nLewis,      M.,      Nayak,      N. V.,      Yu,      P.,      Yu,      Q.,      Merullo,      J.,      Bach,      Mitchell,      J. and      Lapata,      M. Composition      in      distributional H.,      and      Pavlick,      E."
            },
            {
              "id": 877,
              "title": "References - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Does      clip      bind      concepts? probing      models      of      semantics. Cognitive      science,      34(8):1388-  \n \n  compositionality      in      large      image      models. arXiv      preprint      1429,      2010. arXiv:2212.10537,      2022."
            }
          ],
          "content": ""
        },
        {
          "id": 878,
          "title": "Relational      Composition",
          "type": "section",
          "children": [
            {
              "id": 879,
              "title": "Relational      Composition - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Relational      Composition\nLewis,      M.,      Nayak,      N. V.,      Yu,      P.,      Yu,      Q.,      Merullo,      J.,      Bach,      Mitchell,      J. and      Lapata,      M. Composition      in      distributional H.,      and      Pavlick,      E. Does      clip      bind      concepts? probing      models      of      semantics. Cognitive      science,      34(8):1388-  \n \n  compositionality      in      large      image      models. arXiv      preprint      1429,      2010."
            },
            {
              "id": 880,
              "title": "Relational      Composition - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "arXiv:2212.10537,      2022."
            }
          ],
          "content": ""
        },
        {
          "id": 881,
          "title": "S.      H",
          "type": "section",
          "children": [
            {
              "id": 882,
              "title": "S.      H - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "S. H\nprobing      models      of      semantics. Cognitive      science,      34(8):1388-  \n \n  compositionality      in      large      image      models. arXiv      preprint      1429,      2010. arXiv:2212.10537,      2022. Li,      K.,      Patel,      O.,      Viégas,      F.,      Pfister,      H.,      and      Wattenberg,      M. and      superposition. Transformer      Circuits,      2024."
            },
            {
              "id": 883,
              "title": "S.      H - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "URL  \n \n  Inference-time      intervention:      Eliciting      truthful      answers      https://transformer-circuits.pub/2023/superpositi  \n \n  from   \n \na      language      model. Advances      in      Neural      Information  \n \n  Processing      Systems,      36,      2024. Olah,      C.,      Cammarata,      N.,      Schubert,      L.,      Goh,      G.,      Petrov,   \n \n. . . . . M.,      and      Carter,      S. Zoom      in:      An      introduction      to      circuits."
            },
            {
              "id": 884,
              "title": "S.      H - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Lovering,      C. and      Pavlick,      E. Unit      testing      for      concepts      in      Distill,      5(3):e00024—001,      2020. neural      networks. Transactions      of      the      Association      for  \n \n  Computational      Linguistics,      10:1193—-1208,      2022. Paccanaro,      A. and      Hinton,      G. E. Learning      distributed      repre- Makelov. A Lange. G Geiger. A and Nanda. N. Is this sentations of concepts using linear relational embedding."
            },
            {
              "id": 885,
              "title": "S.      H - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "no      so      ene  \n \n. htt,   \n \n|      IEEE      Transactions      on      Knowledge      and      Data      Engineer-  \n \n  the      subspace      you      are      looking      for? an      interpretability      il-  \n \n  lusion      for      subspace      activation      patching. In      The      Twelfth      ing,      13(2):232—244,      2001. International      Conference      on      Learning      Representations,      Phang,      J.,      Bordia,      S.,      Bowman,      S."
            },
            {
              "id": 886,
              "title": "S.      H - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "R.,      et      al. Do      atten-  \n \n  2023. tion      heads      in      bert      track      syntactic      dependencies? In Manning,      C. D.,      Clark,      K.,      Hewitt,      J.,      Khandelwal,      U.,      and      NY      Academy      of      Sciences      NLP,      Dialog,      and      Speech      Work-  \n \n  Levy,      O. Emergent      linguistic      structure      in      artificial      neu-      shop,      2019."
            },
            {
              "id": 887,
              "title": "S.      H - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "ral      networks      trained      by      self-supervision. Proceedings      oo,  \n \n  of      the      National      Academy      of      Sciences,      117(48):30046-      Plate,      T. A      common      framework      for      distributed      representa-  \n \n  30054. 2020. tion      schemes      for      compositional      structure. Connectionist  \n \n  ,      systems      for      knowledge      representation      and      deduction,      pp. Marks,      S."
            },
            {
              "id": 888,
              "title": "S.      H - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "|      _What’s      up      with      lIlms      representing      xors      15-34,      1997. of      arbitrary      features? LessWrong,      2024. URL  \n \n  https://www. lesswrong.com/posts/hjIXCn      9G      PIKe      Sb      He      Mistnibuted      representations      and      nested      eaPE+      ng—xors-of- sitional      structure. Citeseer,      1994. Marks,      S. and      Tegmark,      M."
            },
            {
              "id": 889,
              "title": "S.      H - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "The      geometry      of      truth:  \n \n  Emergent      linear      structure      in      large      language      model      rep-      _—      Pollack,      J. Implications      of      recursive      distributed      represen-  \n \n  resentations      of      true/false      datasets. arXiv      preprint      tations. Advances      in      neural      information      processing      sys-  \n \n  arXiv:2310.06824,      2023. tems,      1,      1988. McCoy,      R."
            },
            {
              "id": 890,
              "title": "S.      H - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "qT,      Linzen,      T.,      Dunbar,      E.,      and      Smolensky,      Prakash,      N.,      Shaham,      T. R.,      Haklay,      T.,      Belinkov,      Y., P. _Rans      implicitly      implement      tensor      product      represen-      and      Bau,      D. Fine-tuning      enhances      existing      mecha-  \n \n  tations. arXiv      preprint      arXiv:      1812.08718,      2018. nisms:   \n \nA      case      study      on      entity      tracking."
            },
            {
              "id": 891,
              "title": "S.      H - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "arXiv      preprint\nMetullo,      J.,      Eickhoff,      C.,      and      Pavlick,      E. Talking      heads;   \n \n9      @/*!v:2402.14811,      2024. |       Understanding      inter-layer      communication      in      transformer       language      models. arXiv      preprint      arXiv:2406.09519,       2024."
            },
            {
              "id": 892,
              "title": "S.      H - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "|       Rajamanoharan,      S.,      Conmy,      A.,      Smith,      L.,      Lieberum,      T.,       Varma,      V.,      Kramar,      J.,      Shah,      R.,      and      Nanda,      N. Improv-       ing      dictionary      learning      with      gated      sparse      autoencoders. | Mikolov,      T.,      Sutskever,      I,      Chen,      K.,      Corrado,      G. S.,      arXiv      preprint      arXiv:2404. 16014,      2024. |       and      Dean,      J."
            },
            {
              "id": 893,
              "title": "S.      H - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Distributed      representations      of      words      and       phrases      and      their      compositionality. Advances      in      neural       information      processing      systems,      26,      2013a. |       Ravishankar,      V.,      Kulmizev,      A.,      Abdou,      M.,      Sggaard,      A.,       and      Nivre,      J. Attention      can      reflect      syntactic      structure      (if       you      let      it). arXiv      preprint      arXiv:2101.10927,      2021."
            },
            {
              "id": 894,
              "title": "S.      H - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Mikolov,      T.,      Yih,      W.-t.,      and      Zweig,      G. Linguistic      regular-  \n \n  ities      in      continuous      space      word      representations. In      Pro-      Reif,      E.,      Yuan,      A.,      Wattenberg,      M.,      Viegas,      F. B.,      Coenen,  \n \n  ceedings      of      the      2013      conference      of      the      north      american      A.,      Pearce,      A.,      and      Kim,      B."
            },
            {
              "id": 895,
              "title": "S.      H - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Visualizing      and      measuring  \n \n  chapter      of      the      association      for      computational      linguistics:      the      geometry      of      bert. Advances      in      Neural      Information  \n \n  Human      language      technologies,      pp. 746-751,      2013b. Processing      Systems,      32,      2019. Mitchell,      J. and      Lapata,      M. Vector-based      models      of      seman-      _—      Rosenblatt,      F. Principles      of      neurodynamics."
            },
            {
              "id": 896,
              "title": "S.      H - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "perceptrons  \n \n  tic      composition. In      proceedings      of      ACL-08:      HLT,      pp. and      the      theory      of      brain      mechanisms. Technical      report,  \n \n  236-244,      2008. Cornell      Aeronautical      Lab      Inc      Buffalo      NY,      1961. Schlegel,      K.,      Neubert,      P.,      and      Protzel,      P. A      comparison  \n \n  of      vector      symbolic      architectures."
            },
            {
              "id": 897,
              "title": "S.      H - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Artificial      Intelligence  \n \n  Review,      55(6):4523-4555,      2022. Smolensky,      P. Tensor      product      variable      binding      and      the      rep-  \n \n  resentation      of      symbolic      structures      in      connectionist      sys-  \n \n  tems. Artificial      intelligence,      46(1-2):159-216,      1990. ures\nA. Appendix:      Features\nures\nSocher, R., Bauer, J Manning, C. D., and Ng, A. Y. Pars-  \n \n  ing      with      compositional      vector      grammars."
            },
            {
              "id": 898,
              "title": "S.      H - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "In      Proceed-  \n \n  ings      of      the      51st      Annual      Meeting      of      the      Association      for  \n \n  Computational      Linguistics      (Volume      1:      Long      Papers),      pp. 455-465,      2013. Socher,      R.,      Karpathy,      A.,      Le,      Q. V.,      Manning,      C. D.,      and       Ng,      A. Y. Grounded      compositional      semantics      for      find-  \n \n  ing      and      describing      images      with      sentences."
            },
            {
              "id": 899,
              "title": "S.      H - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Transactions  \n \n  of      the      Association      for      Computational      Linguistics,      2:207—  \n \n  218,      2014. The      general      intuition      we’ve      found      most      helpful,      however,  \n \n  is      simply      that   \n \na      feature      represents   \n \na      unit      of      data      that      is      use-  \n \n  ful      for      future      computations."
            },
            {
              "id": 900,
              "title": "S.      H - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "We      also      believe      it’s      helpful  \n \n  to      divide      these      representations      into      three      broad      categories. Some      features      relate      to      the      input—that      is,      they      represent   \n \na       useful      property      of      the      data      seen      by      the      network."
            },
            {
              "id": 901,
              "title": "S.      H - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "(“Red      area  \n \n  on      green      background”      or      “‘apple.”)      Other      features,      like      data  \n \n  structures      in   \n \na      traditional      algorithm,      are      related      to      interme-  \n \n  diate      processing."
            },
            {
              "id": 902,
              "title": "S.      H - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "(“Food      and      hunger’’.)      Finally,   \n \na      third      set  \n \n  of      features      will      relate      to      the      result      of      the      network’s      compu-  \n \n  tations:      they      will      represent      properties      of      the      output,      rather  \n \n  than      input      (“Reach      arm”      or      “open      mouth’)."
            },
            {
              "id": 903,
              "title": "S.      H - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Templeton,      A.,      Conerly,      T.,      Marcus,      J.,      Lindsey,      J.,  \n \n  Bricken,      T.,      Chen,      B.,      Pearce,      A.,      Citro,      C.,      Ameisen,  \n \n  E.,      Jones,      A.,      Cunningham,      H.,      Turner,      N. L.,      Mc-  \n \n  Dougall,      C.,      MacDiarmid,      M.,      Freeman,      C."
            },
            {
              "id": 904,
              "title": "S.      H - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "D.,      Sumers, R.,      Rees,      E.,      Batson,      J.,      Jermyn,      A.,      Carter,      S.,  \n \n  Olah,      C.,      and      Henighan,      T. Scaling      monoseman-  \n \n  ticity:      Extracting      interpretable      features      from      claude  \n \n  3      sonnet. Transformer      Circuits      Thread,      2024."
            },
            {
              "id": 905,
              "title": "S.      H - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "URL The      analogy      is      obviously      with      biological      nervous      systems,  \n \n  which      can      be      broken      into      areas      for      sensory,      motor,      and      in-"
            }
          ],
          "content": ""
        },
        {
          "id": 906,
          "title": "A.      Appendix:      Features",
          "type": "section",
          "children": [
            {
              "id": 907,
              "title": "A.      Appendix:      Features - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A. Appendix:      Features\nures\nSocher, R., Bauer, J Manning, C. D., and Ng, A. Y. Pars-  \n \n  ing      with      compositional      vector      grammars. In      Proceed-  \n \n  ings      of      the      51st      Annual      Meeting      of      the      Association      for  \n \n  Computational      Linguistics      (Volume      1:      Long      Papers),      pp. 455-465,      2013. Socher,      R.,      Karpathy,      A.,      Le,      Q. V.,      Manning,      C."
            },
            {
              "id": 908,
              "title": "A.      Appendix:      Features - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "D.,      and       Ng,      A. Y. Grounded      compositional      semantics      for      find-  \n \n  ing      and      describing      images      with      sentences. Transactions  \n \n  of      the      Association      for      Computational      Linguistics,      2:207—  \n \n  218,      2014."
            },
            {
              "id": 909,
              "title": "A.      Appendix:      Features - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "The      general      intuition      we’ve      found      most      helpful,      however,  \n \n  is      simply      that   \n \na      feature      represents   \n \na      unit      of      data      that      is      use-  \n \n  ful      for      future      computations. We      also      believe      it’s      helpful  \n \n  to      divide      these      representations      into      three      broad      categories."
            },
            {
              "id": 910,
              "title": "A.      Appendix:      Features - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Some      features      relate      to      the      input—that      is,      they      represent   \n \na       useful      property      of      the      data      seen      by      the      network. (“Red      area  \n \n  on      green      background”      or      “‘apple.”)      Other      features,      like      data  \n \n  structures      in   \n \na      traditional      algorithm,      are      related      to      interme-  \n \n  diate      processing."
            },
            {
              "id": 911,
              "title": "A.      Appendix:      Features - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "(“Food      and      hunger’’.)      Finally,   \n \na      third      set  \n \n  of      features      will      relate      to      the      result      of      the      network’s      compu-  \n \n  tations:      they      will      represent      properties      of      the      output,      rather  \n \n  than      input      (“Reach      arm”      or      “open      mouth’)."
            },
            {
              "id": 912,
              "title": "A.      Appendix:      Features - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Templeton,      A.,      Conerly,      T.,      Marcus,      J.,      Lindsey,      J.,  \n \n  Bricken,      T.,      Chen,      B.,      Pearce,      A.,      Citro,      C.,      Ameisen,  \n \n  E.,      Jones,      A.,      Cunningham,      H.,      Turner,      N. L.,      Mc-  \n \n  Dougall,      C.,      MacDiarmid,      M.,      Freeman,      C."
            },
            {
              "id": 913,
              "title": "A.      Appendix:      Features - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "D.,      Sumers, R.,      Rees,      E.,      Batson,      J.,      Jermyn,      A.,      Carter,      S.,  \n \n  Olah,      C.,      and      Henighan,      T. Scaling      monoseman-  \n \n  ticity:      Extracting      interpretable      features      from      claude  \n \n  3      sonnet. Transformer      Circuits      Thread,      2024."
            },
            {
              "id": 914,
              "title": "A.      Appendix:      Features - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "URL The      analogy      is      obviously      with      biological      nervous      systems,  \n \n  which      can      be      broken      into      areas      for      sensory,      motor,      and      in-"
            }
          ],
          "content": ""
        },
        {
          "id": 915,
          "title": "T.      R",
          "type": "section",
          "children": [
            {
              "id": 916,
              "title": "T.      R - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "T. R\n \n  Olah,      C.,      and      Henighan,      T. Scaling      monoseman-  \n \n  ticity:      Extracting      interpretable      features      from      claude  \n \n  3      sonnet. Transformer      Circuits      Thread,      2024. URL The      analogy      is      obviously      with      biological      nervous      systems,  \n \n  which      can      be      broken      into      areas      for      sensory,      motor,      and      in-\nThorpe,      S. Local      vs."
            },
            {
              "id": 917,
              "title": "T.      R - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "distributed      coding. Intellectica,      8(2):  \n \n  3-40,      1989. Zanzotto,      F.,      Korkontzelos,      I.,      Fallucchi,      F,      Manandhar,      S.,  \n \n  et      al. Estimating      linear      models      for      compositional      dis-  \n \n  tributional      semantics."
            },
            {
              "id": 918,
              "title": "T.      R - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the      23rd      inter-  \n \n  national      conference      on      computational      linguistics      (COL-  \n \n  ING)(GGS      Conference      Rating   \n \n2      A),      2010. Zou,      A.,      Phan,      L.,      Chen,      S.,      Campbell,      J.,      Guo,      P.,      Ren,      R.,  \n \n  Pan,      A.,      Yin,      X.,      Mazeika,      M.,      Dombrowski,      A.-K.,      et      al."
            },
            {
              "id": 919,
              "title": "T.      R - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Representation      engineering:   \n \nA      top-down      approach      to      ai  \n \n  transparency. arXiv      preprint      arXiv:2310.01405,      2023."
            }
          ],
          "content": ""
        }
      ],
      "content": ""
    },
    {
      "id": 920,
      "title": "Book 4",
      "type": "book",
      "children": [
        {
          "id": 921,
          "title": "Abstract",
          "type": "section",
          "children": [
            {
              "id": 922,
              "title": "Abstract - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Abstract\n \n \n  Identifying      causal      relations      is      crucial      for   \n \na      variety  \n \n  of      downstream      tasks. In      additional      to      observa-  \n \n  tional      data,      background      knowledge      (BK),      which  \n \n  could      be      attained      from      human      expertise      or      ex-  \n \n  periments,      is      usually      introduced      for      uncovering  \n \n  causal      relations."
            },
            {
              "id": 923,
              "title": "Abstract - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "This      raises      an      open      problem      that  \n \n  in      the      presence      of      latent      variables,      what      causal  \n \n  relations      are      identifiable      from      observational      data  \n \n  and      BK. In      this      paper,      we      propose      two      novel      rules  \n \n  for      incorporating      BK,      which      offer   \n \na      new      perspec-  \n \n  tive      to      the      open      problem."
            },
            {
              "id": 924,
              "title": "Abstract - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "In      addition,      we      show  \n \n  that      these      rules      are      applicable      in      some      typical  \n \n  causality      tasks,      such      as      determining      the      set      of      pos-  \n \n  sible      causal      effects      with      observational      data."
            },
            {
              "id": 925,
              "title": "Abstract - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Our  \n \n  rule-based      approach      enhances      the      state-of-the-art  \n \n  method      by      circumventing   \n \na      process      of      enumerat-  \n \n  ing      block      sets      that      would      otherwise      take      exponen-  \n \n  tial      complexity. 1."
            },
            {
              "id": 926,
              "title": "Abstract - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Introduction\ntion  \n \n  In      recent      years,      the      adoption      of      causal      thinking      (Pearl}      2009)  \n \n  has      opened      up      new      venues      for      many      machine      learning      topics,  \n \n  such      as      semi-supervised      learning      (Schélkopf      et      al.)      /2012;  \n \n  von      Kiigelgen      et      al. 2020),      reinforcement      learning      (Huang  \n \n  et      al.}      2022;      [Ruan      et      al."
            },
            {
              "id": 927,
              "title": "Abstract - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "2023),      transfer      learning      (Gong      et      al.}  \n \n  2016;      Zhang      et      al.)      2020;      |Cai      et      al.,      2021),      and      so      on. One  \n \n  essence      of      causal      thinking      lies      in      the      causal      relations      among  \n \n  the      variables,      generally      characterized      by   \n \na      causal      graph."
            },
            {
              "id": 928,
              "title": "Abstract - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "As  \n \n  a      causal      graph      is      usually      not      pre-known,      uncovering      the  \n \n  causal      relations      is      vital      for      addressing      downstream      tasks."
            },
            {
              "id": 929,
              "title": "Abstract - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      the      existing      theoretical      results  \n \n  have      shown      that      only   \n \na      Markov      equivalence      class      (MEC)      of  \n \n  causal      graphs      is      identifiable,      which      contains      some      uncertain  \n \n  causal      relations      (Spirtes      et      al.|      2000;      |Ali      et      al,      (2005;      Zhang}  \n \n  2008)."
            },
            {
              "id": 930,
              "title": "Abstract - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "To      further      reveal      these      relations,      additional      structural  \n \n  knowledge      is      usually      incorporated,      which      could      be      attained  \n \n  from      experiments      or      human      expertise      (Meek      |1995). In  \n \n  \\\\\\'National      Key      Laboratory      for      Novel      Software      Technology,  \n \n  Nanjing      University,      Nanjing,      210023,      China."
            },
            {
              "id": 931,
              "title": "Abstract - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Correspondence      to:  \n \n  Zhi-Hua      Zhou      <zhouzh@lamda.nju.edu.cn>. Preprint. |  |  |       the      literature,      we      usually      call      this      kind      of      knowledge      by       background      knowledge,      or      BK      for      short."
            },
            {
              "id": 932,
              "title": "Abstract - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "| --- | --- | ---\n |       arXiv:2407.15259v1      [cs.Al]      21      Jul      2024 | In      the      presence      of      both      observational      data      and      BK,   \n \na      core  \n \n  problem      is      causal      identification,      i.e.,      understanding      what  \n \n  causal      relations      are      identifiable      from      these      knowledge."
            },
            {
              "id": 933,
              "title": "Abstract - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "This  \n \n  problem      is      vital      because      it      concerns      the      extent      to      which  \n \n  causal      relations      can      be      inferred      from      available      information."
            },
            {
              "id": 934,
              "title": "Abstract - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "On      one      hand,      it      pursues      to      identify      as      many      causal      relations  \n \n  as      possible      from      existing      knowledge,      which      can      provide      sup-  \n \n  ports      for      fully      utilizing      BK      in      practical      tasks      (He   \n \n&      Geng}  \n \n  2008;      [Hauser   \n \n&      BithImann|      |2014)."
            },
            {
              "id": 935,
              "title": "Abstract - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "On      the      other      hand,      even  \n \n  without      BK,      it      is      still      valuable      to      some      tasks      with      only      ob-  \n \n  servational      data,      such      as      causal      effect      estimation      (Maathuis  \n \n  et      al.)      2009;      [Fang   \n \n&      He,      |2020;      |Wang      et      al.)\n(2023a)      and       equivalent      causal      graph      enumeration      (Wiendébst      et      al.)      |2023;  \n \n  Wang      et      al.)\n2024)."
            },
            {
              "id": 936,
              "title": "Abstract - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In      these      tasks,      some      additional      struc-  \n \n  tures      that      can      be      viewed      as      hypothetical      BK      are      possibly  \n \n  introduced,      thus      solving      causal      identification      can      facilitate  \n \n  uncovering      the      most      informative      causal      graph      given      these  \n \n  additional      structures."
            },
            {
              "id": 937,
              "title": "Abstract - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Significant      efforts      have      been      made      towards      causal      identifi-  \n \n  cation      in      scenarios      without      latent      variables      (Verma   \n \n&      Pearl},  \n \n  1990;      |1992)). And|Meek\\\\\\'      (1995)      closed      the      problem      by      pre-  \n \n  senting      four      sound      and      complete      rules      to      uncover      causal      rela-  \n \n  tions."
            },
            {
              "id": 938,
              "title": "Abstract - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "However,      in      real      world      tasks,      latent      confounders      that  \n \n  influence      some      observable      variables      generally      exist. In      these  \n \n  instances,      ancestral      graph      is      usually      used      to      characterize  \n \n  the      causal      relations      among      observable      variables      (Richardson  \n \n  et      al.,      2002)."
            },
            {
              "id": 939,
              "title": "Abstract - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "To      identify      causal      relations      with      observational  \n \n  data      in      such      contexts,      ten      sound      and      complete      rules      have  \n \n  been      proposed      (Ali      et      al.,      2005;      |Zhang,      2008). And      there      are  \n \n  also      several      studies      about      causal      identification      with      some  \n \n  kind      of      specific      BK      (Andrews      et      al."
            },
            {
              "id": 940,
              "title": "Abstract - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "2020;      Jaber      et      al.)      2020;  \n \n  Wang      et      al. (2023b)). Nevertheless,      the      thorough      result      for  \n \n  causal      identification      with      any      kinds      of      BK      in      the      presence  \n \n  of      latent      confounders      remains      elusive. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK      in      the      presence      of      latent      confounders."
            },
            {
              "id": 941,
              "title": "Abstract - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Different      from  \n \n  existing      rules      which      identify      causal      relations      based      on      few  \n \n  edges      or      paths,      the      identified      causal      relations      by      our      pro-  \n \n  posed      rules      may      rely      on   \n \na      subgraph."
            },
            {
              "id": 942,
              "title": "Abstract - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Our      findings      suggest  \n \n  that      in      the      presence      of      latent      variables,      causal      identification  \n \n  requires      more      complicated      orientation      rules      when      BK      is |       In      the      presence      of      both      observational      data      and      BK,      a      core       problem      is      causal      identification,      i.e.,      understanding      what       causal      relations      are      identifiable      from      these      knowledge."
            },
            {
              "id": 943,
              "title": "Abstract - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "This       problem      is      vital      because      it      concerns      the      extent      to      which       causal      relations      can      be      inferred      from      available      information."
            },
            {
              "id": 944,
              "title": "Abstract - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "On      one      hand,      it      pursues      to      identify      as      many      causal      relations       as      possible      from      existing      knowledge,      which      can      provide      sup-       ports      for      fully      utilizing      BK      in      practical      tasks      (He      &      Geng}       2008;      [Hauser      &      BithImann|      |2014)."
            },
            {
              "id": 945,
              "title": "Abstract - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "On      the      other      hand,      even       without      BK,      it      is      still      valuable      to      some      tasks      with      only      ob-       servational      data,      such      as      causal      effect      estimation      (Maathuis       et      al.)      2009;      [Fang      &      He,      |2020;      |Wang      et      al.)      (2023a)      and       equivalent      causal      graph      enumeration      (Wiendébst      et      al.)      |2023;       Wang      et      al.)      2024)."
            },
            {
              "id": 946,
              "title": "Abstract - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "In      these      tasks,      some      additional      struc-       tures      that      can      be      viewed      as      hypothetical      BK      are      possibly       introduced,      thus      solving      causal      identification      can      facilitate       uncovering      the      most      informative      causal      graph      given      these       additional      structures."
            },
            {
              "id": 947,
              "title": "Abstract - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Significant      efforts      have      been      made      towards      causal      identifi-       cation      in      scenarios      without      latent      variables      (Verma      &      Pearl},       1990;      |1992)). And|Meek\\\\\\'      (1995)      closed      the      problem      by      pre-       senting      four      sound      and      complete      rules      to      uncover      causal      rela-       tions."
            },
            {
              "id": 948,
              "title": "Abstract - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "However,      in      real      world      tasks,      latent      confounders      that       influence      some      observable      variables      generally      exist. In      these       instances,      ancestral      graph      is      usually      used      to      characterize       the      causal      relations      among      observable      variables      (Richardson       et      al.,      2002)."
            },
            {
              "id": 949,
              "title": "Abstract - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "To      identify      causal      relations      with      observational       data      in      such      contexts,      ten      sound      and      complete      rules      have       been      proposed      (Ali      et      al.,      2005;      |Zhang,      2008). And      there      are       also      several      studies      about      causal      identification      with      some       kind      of      specific      BK      (Andrews      et      al."
            },
            {
              "id": 950,
              "title": "Abstract - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "2020;      Jaber      et      al.)      2020;       Wang      et      al. (2023b)). Nevertheless,      the      thorough      result      for       causal      identification      with      any      kinds      of      BK      in      the      presence       of      latent      confounders      remains      elusive. In      this      paper,      we      propose      two      novel      rules      for      incorporating       BK      in      the      presence      of      latent      confounders."
            },
            {
              "id": 951,
              "title": "Abstract - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Different      from       existing      rules      which      identify      causal      relations      based      on      few       edges      or      paths,      the      identified      causal      relations      by      our      pro-       posed      rules      may      rely      on      a      subgraph."
            },
            {
              "id": 952,
              "title": "Abstract - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Our      findings      suggest       that      in      the      presence      of      latent      variables,      causal      identification       requires      more      complicated      orientation      rules      when      BK      is\n |       incorporated,      thereby      highlighting      the      intrinsic      hardness      of       causal      identification      with      BK."
            },
            {
              "id": 953,
              "title": "Abstract - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "Interestingly,      we      find      that       the      proposed      rules      are      essentially      the      generalizations      of      two       existing      rules      in      the      literature. We      believe      that      the      proposed       rules      can      inspire      the      establishment      of      sound      and      complete       rules      to      incorporate      BK      in      the      future."
            },
            {
              "id": 954,
              "title": "Abstract - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "|       Further,      even      without      BK,      the      proposed      rules      are      also      appli-       cable      in      some      typical      causality      tasks      with      only      observational       data. We      show      that      our      proposed      rules      can      take      benefit      to      set       determination      task      by      improving      the      state-of-the-art      method       PAGcauses      (Wang      et      al,      /2023a)."
            },
            {
              "id": 955,
              "title": "Abstract - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "As      previously      discussed,       with      observational      data,      we      can      only      identify      a      MEC,      within       which      the      causal      effect      of      a      variable      X      on      variable      Y      is       possibly      unidentifiable."
            },
            {
              "id": 956,
              "title": "Abstract - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "To      mitigate      this      unidentifiable      case,       a      common      solution      is      to      determine      the      set      of      possible      causal       effects      instead,      which      consists      of      the      causal      effect      values      in       all      the      causal      graphs      within      the      MEC,      which      is      called      set       determination      for      brevity."
            },
            {
              "id": 957,
              "title": "Abstract - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "In      the      absence      of      latent      variables,       many      efficient      methods      have      been      proposed      for      set      determi-       nation      (Maathuis      et      al.)      (2009;      |Perkovic      et      al.)      2017a;      |Fang      &       He,      |2020;      |Witte      et      al.)      |2020)."
            },
            {
              "id": 958,
              "title": "Abstract - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "For      the      scenarios      with      latent       confounders,      |Malinsky      &      Spirtes|      (2016)      proposed      the      first       relevant      method      by      locally      enumerating      MAGs. Then,      /Wang       et      al.|((2023b)      presented      an      enumeration-free      method      PAG-       causes,      which      reduces      the      complexity      super-exponentially       compared      to      the      enumeration-based      method."
            },
            {
              "id": 959,
              "title": "Abstract - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "In      this      paper,       we      introduce      the      proposed      rules      to      enhance      PAGcauses      by       avoiding      a      process      of      enumerating      block      sets,      which      reduces       an      exponential      complexity      relative      to      the      number      of      vertices. |       In      summary,      this      paper      makes      two      significant      contributions."
            },
            {
              "id": 960,
              "title": "Abstract - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      present      two      novel      rules      for      incorporating      BK       in      the      presence      of      latent      confounders. Secondly,      we      apply       the      rules      in      set      determination      task,      effectively      eliminating       an      exponential      computational      burden      of      the      state-of-the-art       method. All      the      proofs      are      shown      in      appendix. | 2."
            },
            {
              "id": 961,
              "title": "Abstract - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Preliminary\n |       Denote      a      graph      by      G. Let      V(G)      denote      the      set      of      vertices       (variables)      and      E(G)      denote      the      set      of      edges      in      G. We      use       bold      letter      (e.g.,      A)      to      denote      a      set      of      vertices      and      normal       letter      (e.g.,      A)      to      denote      a      vertex."
            },
            {
              "id": 962,
              "title": "Abstract - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Given      a      set      of      vertices       Vv’      C      V(G),      G[V\"      is      the      subgraph      of      G      induced      by      V’       which      consists      of      vertices      V’      and      all      the      edges      between      V’. G[—V\"]      denotes      G[V(G)\\\\\\\\V’]. G      is      a      complete      graph      if       for      any      two      vertices      in      G,      there      is      an      edge      connecting      them. | 2."
            },
            {
              "id": 963,
              "title": "Abstract - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Preliminary\n | 2. Preliminary\n |       Ina      graph      G,      if      there      is      Vix      Vj      <*V;,      where      V;      is      not      adja-       cent      to      V;,      they      form      an      unshielded      collider."
            },
            {
              "id": 964,
              "title": "Abstract - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "Consider      a      path       p      =      (Vi,      Vo,---      ,      Ve),      p      is      a      possible      directed      path      if      for       the      edge      between      V;      and      V;41,      V1      <7      <      k      —1,      there      is      no       arrowhead      at      V;      and      no      tail      at      V;4.1;      pis      uncovered      if      V;_,      is       not      adjacent      to      Vji1,      V2      <i      <      k—1."
            },
            {
              "id": 965,
              "title": "Abstract - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "InG,      denote      the      set      of       parents/ancestors/descendants/possible      descendants      of      V;      by       Pa(V;,      G)      /Anc(V;,      G)/De(V;,      G)/PossDe(V;,G). Given       a      vertex      V;      and      a      set      of      vertices      V’      in      G,      V;      €      Anc(V’,G)       if      there      exists      a      vertex      V;      €      V’      such      that      V;      €      Anc(V;,      G)."
            },
            {
              "id": 966,
              "title": "Abstract - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "|       Covariate      adjustment      is      a      classical      method      to      estimate      the | In      the      literature,      there      are      orientation      rules      R,   \n \n—      711      to  \n \n  identify   \n \na      PAG      or      incorporate      local      background      knowledge  \n \n  into   \n \na      PAG."
            },
            {
              "id": 967,
              "title": "Abstract - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "These      rules      are      shown      in      Appendix      [A-2}  \n \n  Covariate      adjustment      is   \n \na      classical      method      to      estimate      the  \n \n  causal      effect      given   \n \na      causal      graph,      by      finding      an      adjustment  \n \n  set   \n \nZ      such      that      P(Y      |do(X))   \n \n=      )0,      P(Z)P(Y      |X,      Z)      dZ."
            },
            {
              "id": 968,
              "title": "Abstract - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "More      related      results      are      shown      in      Appendix |       For      a      mixed      graph      G,      if      there      is      a      directed      path      from      V;      to       V;      and      an      edge      V;      —      V;/V;      ©      Vj,      they      form      a      directed       cycle/almost      directed      cycle."
            },
            {
              "id": 969,
              "title": "Abstract - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "A      mixed      graph      G      is      ancestral       if      there      are      no      directed      cycles      and      no      almost      directed      cycles. The      maximal      property      is      given      in      Appendix      |A."
            },
            {
              "id": 970,
              "title": "Abstract - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "1]      In      the      pres-       ence      of      latent      variables,      maximal      ancestral      graph      (MAG)      is       usually      used      to      characterize      the      causal      relations      among      ob-       servable      variables."
            },
            {
              "id": 971,
              "title": "Abstract - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is      a      projection      graph       on      the      observable      variables      of      an      underlying      DAG      that      con-       tains      both      observable      and      latent      variables. We      say      a      DAG       D      is      represented      by      a      MAG      M      if      M      is      a      projection      graph       of      an      underlying      D."
            },
            {
              "id": 972,
              "title": "Abstract - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Note      many      DAGs      can      be      represented       by      one      MAG,      which      is      detailed      in      Appendix      [A.1]      A      partial       ancestral      graph      (PAG)      represents      a      Markov      equivalence       class      (MEC)      of      MAGs. Denote      MAG      and      PAG      by      M      and       P,      respectively."
            },
            {
              "id": 973,
              "title": "Abstract - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Suppose      we      obtain      a      PMG      H      from      P      by       transforming      some      circles. We      say      a      MAG      M      is      consistent       with      H      if      M      has      the      same      non-circle      marks      at      H      and      M       belongs      to      the      MEC      represented      by      P."
            },
            {
              "id": 974,
              "title": "Abstract - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Note      when      we      say      an       edge      +0,      the      *      here      is      not      a      tail,      for      otherwise      the      circle      can       only      be      an      arrowhead      due      to      no      selection      bias. Gx      denotes       the      subgraph      of      G      by      deleting      all      the      edges      out      of      X."
            },
            {
              "id": 975,
              "title": "Abstract - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "In      the      literature,      there      are      orientation      rules      R,      —      711      to       identify      a      PAG      or      incorporate      local      background      knowledge       into      a      PAG."
            },
            {
              "id": 976,
              "title": "Abstract - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "These      rules      are      shown      in      Appendix      [A-2}       More      related      results      are      shown      in      Appendix\n |  | In      this      section,      we      present      two      novel      rules      to      incorporate  \n \n  BK      into   \n \na      partial      mixed      graph      (PMG)      H."
            },
            {
              "id": 977,
              "title": "Abstract - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "As      there      have  \n \n  established      sound      and      complete      rules      to      obtain   \n \na      PAG      with  \n \n  observational      data      in      the      literature      (Zhang,      |2008),      we      do      not  \n \n  Lio      Ait       {A      2 |       3."
            },
            {
              "id": 978,
              "title": "Abstract - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "Proposed      Rules       In      this      section,      we      present      two      novel      rules      to      incorporate       BK      into      a      partial      mixed      graph      (PMG)      H. As      there      have       established      sound      and      complete      rules      to      obtain      a      PAG      with       observational      data      in      the      literature      (Zhang,      |2008),      we      do      not       {A      2"
            }
          ],
          "content": ""
        },
        {
          "id": 979,
          "title": "1.      Introduction",
          "type": "section",
          "children": [
            {
              "id": 980,
              "title": "1.      Introduction - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "1. Introduction\ntion  \n \n  In      recent      years,      the      adoption      of      causal      thinking      (Pearl}      2009)  \n \n  has      opened      up      new      venues      for      many      machine      learning      topics,  \n \n  such      as      semi-supervised      learning      (Schélkopf      et      al.)      /2012;  \n \n  von      Kiigelgen      et      al. 2020),      reinforcement      learning      (Huang  \n \n  et      al.}      2022;      [Ruan      et      al."
            },
            {
              "id": 981,
              "title": "1.      Introduction - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "2023),      transfer      learning      (Gong      et      al.}  \n \n  2016;      Zhang      et      al.)      2020;      |Cai      et      al.,      2021),      and      so      on. One  \n \n  essence      of      causal      thinking      lies      in      the      causal      relations      among  \n \n  the      variables,      generally      characterized      by   \n \na      causal      graph."
            },
            {
              "id": 982,
              "title": "1.      Introduction - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "As  \n \n  a      causal      graph      is      usually      not      pre-known,      uncovering      the  \n \n  causal      relations      is      vital      for      addressing      downstream      tasks."
            },
            {
              "id": 983,
              "title": "1.      Introduction - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      the      existing      theoretical      results  \n \n  have      shown      that      only   \n \na      Markov      equivalence      class      (MEC)      of  \n \n  causal      graphs      is      identifiable,      which      contains      some      uncertain  \n \n  causal      relations      (Spirtes      et      al.|      2000;      |Ali      et      al,      (2005;      Zhang}  \n \n  2008)."
            },
            {
              "id": 984,
              "title": "1.      Introduction - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "To      further      reveal      these      relations,      additional      structural  \n \n  knowledge      is      usually      incorporated,      which      could      be      attained  \n \n  from      experiments      or      human      expertise      (Meek      |1995). In  \n \n  \\\\\\'National      Key      Laboratory      for      Novel      Software      Technology,  \n \n  Nanjing      University,      Nanjing,      210023,      China."
            },
            {
              "id": 985,
              "title": "1.      Introduction - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Correspondence      to:  \n \n  Zhi-Hua      Zhou      <zhouzh@lamda.nju.edu.cn>. Preprint. |  |  |       the      literature,      we      usually      call      this      kind      of      knowledge      by       background      knowledge,      or      BK      for      short."
            },
            {
              "id": 986,
              "title": "1.      Introduction - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "| --- | --- | ---\n |       arXiv:2407.15259v1      [cs.Al]      21      Jul      2024 | In      the      presence      of      both      observational      data      and      BK,   \n \na      core  \n \n  problem      is      causal      identification,      i.e.,      understanding      what  \n \n  causal      relations      are      identifiable      from      these      knowledge."
            },
            {
              "id": 987,
              "title": "1.      Introduction - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "This  \n \n  problem      is      vital      because      it      concerns      the      extent      to      which  \n \n  causal      relations      can      be      inferred      from      available      information."
            },
            {
              "id": 988,
              "title": "1.      Introduction - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "On      one      hand,      it      pursues      to      identify      as      many      causal      relations  \n \n  as      possible      from      existing      knowledge,      which      can      provide      sup-  \n \n  ports      for      fully      utilizing      BK      in      practical      tasks      (He   \n \n&      Geng}  \n \n  2008;      [Hauser   \n \n&      BithImann|      |2014)."
            },
            {
              "id": 989,
              "title": "1.      Introduction - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "On      the      other      hand,      even  \n \n  without      BK,      it      is      still      valuable      to      some      tasks      with      only      ob-  \n \n  servational      data,      such      as      causal      effect      estimation      (Maathuis  \n \n  et      al.)      2009;      [Fang   \n \n&      He,      |2020;      |Wang      et      al.)\n(2023a)      and       equivalent      causal      graph      enumeration      (Wiendébst      et      al.)      |2023;  \n \n  Wang      et      al.)\n2024)."
            },
            {
              "id": 990,
              "title": "1.      Introduction - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "In      these      tasks,      some      additional      struc-  \n \n  tures      that      can      be      viewed      as      hypothetical      BK      are      possibly  \n \n  introduced,      thus      solving      causal      identification      can      facilitate  \n \n  uncovering      the      most      informative      causal      graph      given      these  \n \n  additional      structures."
            },
            {
              "id": 991,
              "title": "1.      Introduction - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Significant      efforts      have      been      made      towards      causal      identifi-  \n \n  cation      in      scenarios      without      latent      variables      (Verma   \n \n&      Pearl},  \n \n  1990;      |1992)). And|Meek\\\\\\'      (1995)      closed      the      problem      by      pre-  \n \n  senting      four      sound      and      complete      rules      to      uncover      causal      rela-  \n \n  tions."
            },
            {
              "id": 992,
              "title": "1.      Introduction - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "However,      in      real      world      tasks,      latent      confounders      that  \n \n  influence      some      observable      variables      generally      exist. In      these  \n \n  instances,      ancestral      graph      is      usually      used      to      characterize  \n \n  the      causal      relations      among      observable      variables      (Richardson  \n \n  et      al.,      2002)."
            },
            {
              "id": 993,
              "title": "1.      Introduction - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "To      identify      causal      relations      with      observational  \n \n  data      in      such      contexts,      ten      sound      and      complete      rules      have  \n \n  been      proposed      (Ali      et      al.,      2005;      |Zhang,      2008). And      there      are  \n \n  also      several      studies      about      causal      identification      with      some  \n \n  kind      of      specific      BK      (Andrews      et      al."
            },
            {
              "id": 994,
              "title": "1.      Introduction - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "2020;      Jaber      et      al.)      2020;  \n \n  Wang      et      al. (2023b)). Nevertheless,      the      thorough      result      for  \n \n  causal      identification      with      any      kinds      of      BK      in      the      presence  \n \n  of      latent      confounders      remains      elusive. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK      in      the      presence      of      latent      confounders."
            },
            {
              "id": 995,
              "title": "1.      Introduction - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Different      from  \n \n  existing      rules      which      identify      causal      relations      based      on      few  \n \n  edges      or      paths,      the      identified      causal      relations      by      our      pro-  \n \n  posed      rules      may      rely      on   \n \na      subgraph."
            },
            {
              "id": 996,
              "title": "1.      Introduction - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Our      findings      suggest  \n \n  that      in      the      presence      of      latent      variables,      causal      identification  \n \n  requires      more      complicated      orientation      rules      when      BK      is |       In      the      presence      of      both      observational      data      and      BK,      a      core       problem      is      causal      identification,      i.e.,      understanding      what       causal      relations      are      identifiable      from      these      knowledge."
            },
            {
              "id": 997,
              "title": "1.      Introduction - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "This       problem      is      vital      because      it      concerns      the      extent      to      which       causal      relations      can      be      inferred      from      available      information."
            },
            {
              "id": 998,
              "title": "1.      Introduction - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "On      one      hand,      it      pursues      to      identify      as      many      causal      relations       as      possible      from      existing      knowledge,      which      can      provide      sup-       ports      for      fully      utilizing      BK      in      practical      tasks      (He      &      Geng}       2008;      [Hauser      &      BithImann|      |2014)."
            },
            {
              "id": 999,
              "title": "1.      Introduction - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "On      the      other      hand,      even       without      BK,      it      is      still      valuable      to      some      tasks      with      only      ob-       servational      data,      such      as      causal      effect      estimation      (Maathuis       et      al.)      2009;      [Fang      &      He,      |2020;      |Wang      et      al.)      (2023a)      and       equivalent      causal      graph      enumeration      (Wiendébst      et      al.)      |2023;       Wang      et      al.)      2024)."
            },
            {
              "id": 1000,
              "title": "1.      Introduction - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "In      these      tasks,      some      additional      struc-       tures      that      can      be      viewed      as      hypothetical      BK      are      possibly       introduced,      thus      solving      causal      identification      can      facilitate       uncovering      the      most      informative      causal      graph      given      these       additional      structures."
            },
            {
              "id": 1001,
              "title": "1.      Introduction - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Significant      efforts      have      been      made      towards      causal      identifi-       cation      in      scenarios      without      latent      variables      (Verma      &      Pearl},       1990;      |1992)). And|Meek\\\\\\'      (1995)      closed      the      problem      by      pre-       senting      four      sound      and      complete      rules      to      uncover      causal      rela-       tions."
            },
            {
              "id": 1002,
              "title": "1.      Introduction - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "However,      in      real      world      tasks,      latent      confounders      that       influence      some      observable      variables      generally      exist. In      these       instances,      ancestral      graph      is      usually      used      to      characterize       the      causal      relations      among      observable      variables      (Richardson       et      al.,      2002)."
            },
            {
              "id": 1003,
              "title": "1.      Introduction - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "To      identify      causal      relations      with      observational       data      in      such      contexts,      ten      sound      and      complete      rules      have       been      proposed      (Ali      et      al.,      2005;      |Zhang,      2008). And      there      are       also      several      studies      about      causal      identification      with      some       kind      of      specific      BK      (Andrews      et      al."
            },
            {
              "id": 1004,
              "title": "1.      Introduction - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "2020;      Jaber      et      al.)      2020;       Wang      et      al. (2023b)). Nevertheless,      the      thorough      result      for       causal      identification      with      any      kinds      of      BK      in      the      presence       of      latent      confounders      remains      elusive. In      this      paper,      we      propose      two      novel      rules      for      incorporating       BK      in      the      presence      of      latent      confounders."
            },
            {
              "id": 1005,
              "title": "1.      Introduction - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Different      from       existing      rules      which      identify      causal      relations      based      on      few       edges      or      paths,      the      identified      causal      relations      by      our      pro-       posed      rules      may      rely      on      a      subgraph."
            },
            {
              "id": 1006,
              "title": "1.      Introduction - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Our      findings      suggest       that      in      the      presence      of      latent      variables,      causal      identification       requires      more      complicated      orientation      rules      when      BK      is\n |       incorporated,      thereby      highlighting      the      intrinsic      hardness      of       causal      identification      with      BK."
            },
            {
              "id": 1007,
              "title": "1.      Introduction - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Interestingly,      we      find      that       the      proposed      rules      are      essentially      the      generalizations      of      two       existing      rules      in      the      literature. We      believe      that      the      proposed       rules      can      inspire      the      establishment      of      sound      and      complete       rules      to      incorporate      BK      in      the      future."
            },
            {
              "id": 1008,
              "title": "1.      Introduction - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "|       Further,      even      without      BK,      the      proposed      rules      are      also      appli-       cable      in      some      typical      causality      tasks      with      only      observational       data. We      show      that      our      proposed      rules      can      take      benefit      to      set       determination      task      by      improving      the      state-of-the-art      method       PAGcauses      (Wang      et      al,      /2023a)."
            },
            {
              "id": 1009,
              "title": "1.      Introduction - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "As      previously      discussed,       with      observational      data,      we      can      only      identify      a      MEC,      within       which      the      causal      effect      of      a      variable      X      on      variable      Y      is       possibly      unidentifiable."
            },
            {
              "id": 1010,
              "title": "1.      Introduction - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "To      mitigate      this      unidentifiable      case,       a      common      solution      is      to      determine      the      set      of      possible      causal       effects      instead,      which      consists      of      the      causal      effect      values      in       all      the      causal      graphs      within      the      MEC,      which      is      called      set       determination      for      brevity."
            },
            {
              "id": 1011,
              "title": "1.      Introduction - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "In      the      absence      of      latent      variables,       many      efficient      methods      have      been      proposed      for      set      determi-       nation      (Maathuis      et      al.)      (2009;      |Perkovic      et      al.)      2017a;      |Fang      &       He,      |2020;      |Witte      et      al.)      |2020)."
            },
            {
              "id": 1012,
              "title": "1.      Introduction - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "For      the      scenarios      with      latent       confounders,      |Malinsky      &      Spirtes|      (2016)      proposed      the      first       relevant      method      by      locally      enumerating      MAGs. Then,      /Wang       et      al.|((2023b)      presented      an      enumeration-free      method      PAG-       causes,      which      reduces      the      complexity      super-exponentially       compared      to      the      enumeration-based      method."
            },
            {
              "id": 1013,
              "title": "1.      Introduction - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "In      this      paper,       we      introduce      the      proposed      rules      to      enhance      PAGcauses      by       avoiding      a      process      of      enumerating      block      sets,      which      reduces       an      exponential      complexity      relative      to      the      number      of      vertices. |       In      summary,      this      paper      makes      two      significant      contributions."
            },
            {
              "id": 1014,
              "title": "1.      Introduction - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Firstly,      we      present      two      novel      rules      for      incorporating      BK       in      the      presence      of      latent      confounders. Secondly,      we      apply       the      rules      in      set      determination      task,      effectively      eliminating       an      exponential      computational      burden      of      the      state-of-the-art       method. All      the      proofs      are      shown      in      appendix. | 2."
            },
            {
              "id": 1015,
              "title": "1.      Introduction - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Preliminary\n |       Denote      a      graph      by      G. Let      V(G)      denote      the      set      of      vertices       (variables)      and      E(G)      denote      the      set      of      edges      in      G. We      use       bold      letter      (e.g.,      A)      to      denote      a      set      of      vertices      and      normal       letter      (e.g.,      A)      to      denote      a      vertex."
            },
            {
              "id": 1016,
              "title": "1.      Introduction - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "Given      a      set      of      vertices       Vv’      C      V(G),      G[V\"      is      the      subgraph      of      G      induced      by      V’       which      consists      of      vertices      V’      and      all      the      edges      between      V’. G[—V\"]      denotes      G[V(G)\\\\\\\\V’]. G      is      a      complete      graph      if       for      any      two      vertices      in      G,      there      is      an      edge      connecting      them. | 2."
            },
            {
              "id": 1017,
              "title": "1.      Introduction - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Preliminary\n | 2. Preliminary\n |       Ina      graph      G,      if      there      is      Vix      Vj      <*V;,      where      V;      is      not      adja-       cent      to      V;,      they      form      an      unshielded      collider."
            },
            {
              "id": 1018,
              "title": "1.      Introduction - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "Consider      a      path       p      =      (Vi,      Vo,---      ,      Ve),      p      is      a      possible      directed      path      if      for       the      edge      between      V;      and      V;41,      V1      <7      <      k      —1,      there      is      no       arrowhead      at      V;      and      no      tail      at      V;4.1;      pis      uncovered      if      V;_,      is       not      adjacent      to      Vji1,      V2      <i      <      k—1."
            },
            {
              "id": 1019,
              "title": "1.      Introduction - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "InG,      denote      the      set      of       parents/ancestors/descendants/possible      descendants      of      V;      by       Pa(V;,      G)      /Anc(V;,      G)/De(V;,      G)/PossDe(V;,G). Given       a      vertex      V;      and      a      set      of      vertices      V’      in      G,      V;      €      Anc(V’,G)       if      there      exists      a      vertex      V;      €      V’      such      that      V;      €      Anc(V;,      G)."
            },
            {
              "id": 1020,
              "title": "1.      Introduction - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "|       Covariate      adjustment      is      a      classical      method      to      estimate      the | In      the      literature,      there      are      orientation      rules      R,   \n \n—      711      to  \n \n  identify   \n \na      PAG      or      incorporate      local      background      knowledge  \n \n  into   \n \na      PAG."
            },
            {
              "id": 1021,
              "title": "1.      Introduction - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "These      rules      are      shown      in      Appendix      [A-2}  \n \n  Covariate      adjustment      is   \n \na      classical      method      to      estimate      the  \n \n  causal      effect      given   \n \na      causal      graph,      by      finding      an      adjustment  \n \n  set   \n \nZ      such      that      P(Y      |do(X))   \n \n=      )0,      P(Z)P(Y      |X,      Z)      dZ."
            },
            {
              "id": 1022,
              "title": "1.      Introduction - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "More      related      results      are      shown      in      Appendix |       For      a      mixed      graph      G,      if      there      is      a      directed      path      from      V;      to       V;      and      an      edge      V;      —      V;/V;      ©      Vj,      they      form      a      directed       cycle/almost      directed      cycle."
            },
            {
              "id": 1023,
              "title": "1.      Introduction - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "A      mixed      graph      G      is      ancestral       if      there      are      no      directed      cycles      and      no      almost      directed      cycles. The      maximal      property      is      given      in      Appendix      |A."
            },
            {
              "id": 1024,
              "title": "1.      Introduction - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "1]      In      the      pres-       ence      of      latent      variables,      maximal      ancestral      graph      (MAG)      is       usually      used      to      characterize      the      causal      relations      among      ob-       servable      variables."
            },
            {
              "id": 1025,
              "title": "1.      Introduction - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is      a      projection      graph       on      the      observable      variables      of      an      underlying      DAG      that      con-       tains      both      observable      and      latent      variables. We      say      a      DAG       D      is      represented      by      a      MAG      M      if      M      is      a      projection      graph       of      an      underlying      D."
            },
            {
              "id": 1026,
              "title": "1.      Introduction - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Note      many      DAGs      can      be      represented       by      one      MAG,      which      is      detailed      in      Appendix      [A.1]      A      partial       ancestral      graph      (PAG)      represents      a      Markov      equivalence       class      (MEC)      of      MAGs. Denote      MAG      and      PAG      by      M      and       P,      respectively."
            },
            {
              "id": 1027,
              "title": "1.      Introduction - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Suppose      we      obtain      a      PMG      H      from      P      by       transforming      some      circles. We      say      a      MAG      M      is      consistent       with      H      if      M      has      the      same      non-circle      marks      at      H      and      M       belongs      to      the      MEC      represented      by      P."
            },
            {
              "id": 1028,
              "title": "1.      Introduction - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "Note      when      we      say      an       edge      +0,      the      *      here      is      not      a      tail,      for      otherwise      the      circle      can       only      be      an      arrowhead      due      to      no      selection      bias. Gx      denotes       the      subgraph      of      G      by      deleting      all      the      edges      out      of      X."
            },
            {
              "id": 1029,
              "title": "1.      Introduction - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "In      the      literature,      there      are      orientation      rules      R,      —      711      to       identify      a      PAG      or      incorporate      local      background      knowledge       into      a      PAG."
            },
            {
              "id": 1030,
              "title": "1.      Introduction - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "These      rules      are      shown      in      Appendix      [A-2}       More      related      results      are      shown      in      Appendix\n |  | In      this      section,      we      present      two      novel      rules      to      incorporate  \n \n  BK      into   \n \na      partial      mixed      graph      (PMG)      H."
            },
            {
              "id": 1031,
              "title": "1.      Introduction - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "As      there      have  \n \n  established      sound      and      complete      rules      to      obtain   \n \na      PAG      with  \n \n  observational      data      in      the      literature      (Zhang,      |2008),      we      do      not  \n \n  Lio      Ait       {A      2 |       3."
            },
            {
              "id": 1032,
              "title": "1.      Introduction - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Proposed      Rules       In      this      section,      we      present      two      novel      rules      to      incorporate       BK      into      a      partial      mixed      graph      (PMG)      H. As      there      have       established      sound      and      complete      rules      to      obtain      a      PAG      with       observational      data      in      the      literature      (Zhang,      |2008),      we      do      not       {A      2"
            }
          ],
          "content": ""
        },
        {
          "id": 1033,
          "title": "WA.",
          "type": "section",
          "children": [
            {
              "id": 1034,
              "title": "WA. - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "WA. ys      ays      &\n©\n \n   @\n \n \n  consider      the      stage      of      identifying   \n \na      PAG      in      this      paper. Hence,  \n \n  we      restrict      that      H      is   \n \na      PAG      or   \n \na      PMG      transformed      from   \n \na       PAG. Also,      we      assume      that      the      introduced      BK      is      correct,  \n \n  i.e.,      there      exist      MAGs      consistent      with      the      PMG      and      BK."
            },
            {
              "id": 1035,
              "title": "WA. - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "At      first,      we      introduce      an      important      concept,      unbridged      path  \n \n  relative      to      V\\\\\\'      ina      PMG      H,      in      Def. [I]      where      V’      is   \n \na      set      of  \n \n  vertices      in      H."
            },
            {
              "id": 1036,
              "title": "WA. - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Intuitively,      an      unbridged      path      p      relative      to      V’  \n \n  is   \n \na      path      with      an      intriguing      property:      if      every      vertex      in      p      is  \n \n  not      an      ancestor      of      V’      in      H,      then      every      vertex      in      p      must      be  \n \n  an      ancestor      of      V’      in      any      MAG      consistent      with      H."
            },
            {
              "id": 1037,
              "title": "WA. - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Definition   \n \n1      (Unbridged      path      relative      to      V’). Suppose      H   \n \na       PMG."
            },
            {
              "id": 1038,
              "title": "WA. - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "If      there      is      an      uncovered      circle      path      p   \n \n:      Vo      o-c      Vj      o-o  \n \n  ---o-0V,,n   \n \n>      Lin      H[—V’]      such      that      Fy,\\\\\\\\Fy,   \n \n4   \n \n0      and       Fy,,\\\\\\\\Fv,,_,      #9,      where      Fy,   \n \n=      {V   \n \n€      V’   \n \n|      V0      V;      or      Veo  \n \n  V;      in      H},      then      p      is      an      unbridged      path      relative      to      V’. Remark      1."
            },
            {
              "id": 1039,
              "title": "WA. - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "One      may      wonder      why      the      abovementioned  \n \n  property      holds      for      unbridged      path      p      if      every      vertex      in      p      is  \n \n  not      an      ancestor      of      V’      in      H."
            },
            {
              "id": 1040,
              "title": "WA. - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "The      reason      is,      in      any      MAG      M       consistent      with      H,      there      cannot      be      additional      unshielded  \n \n  colliders      relative      to      H,      which      introduce      additional      condi-  \n \n  tional      independence      such      that      the      graphs      do      not      belong      to  \n \n  the      MEC."
            },
            {
              "id": 1041,
              "title": "WA. - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Suppose      C)   \n \n€      Fy,\\\\\\\\Fy,      and      C2   \n \n€      Fy,      \\\\\\\\Fv,_,  \n \n  according      to      Def. [i]      Since      (1)      Ci   \n \n¢      Fy,      and      (2)      V;      is      not  \n \n  an      ancestor      of      C,   \n \n€      V’      in      H,      we      can      conclude      that      C      is  \n \n  not      adjacent      to      V,. Similarly,      C2      is      not      adjacent      to      V,,_1."
            },
            {
              "id": 1042,
              "title": "WA. - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Hence,      to      avoid      generating      unshielded      colliders,      the      corre-  \n \n  sponding      path      in      M      of      p      as      well      as      C;      and      C2      can      only      be  \n \n  Cy      **Vo      -23V,   \n \n3      Co,C,      H      Vo   \n \n&      »-o      Vi,      Co,  \n \n  or      Cy      —&      Yo      Hee)      Vie      +e      Vy   \n \n>      Co."
            },
            {
              "id": 1043,
              "title": "WA. - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "In      any  \n \n  case,      any      vertex      in      p      is      an      ancestor      of      either      C;      or      C9. See      Fig. for      an      example. D      o—o      EF      is      an      unbridged  \n \n  path      relative      to      V’   \n \n=      {C,,C      2}      due      to      C,   \n \n©      Fp\\\\\\\\Fr  \n \n  and      C2   \n \n€      Fr\\\\\\\\Fp."
            },
            {
              "id": 1044,
              "title": "WA. - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "If      we      transform      all      the      circles      in  \n \n  C,      «oD      o—o      Eo-      Cp»      without      generating      unshielded  \n \n  colliders,      D      and   \n \n£      must      be      ancestors      of      either      Cy      or      Co."
            },
            {
              "id": 1045,
              "title": "WA. - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      present      the      orientation      rule      R42      inspired      by      the  \n \n  property      above,      and      then      the      orientation      rule      713      as   \n \na      sup-  \n \n  plement      of      the      case      of      R12      when      some      vertex      in      the      un-  \n \n  bridged      path      has      been      an      ancestor      of      V’      in      H      f       Rig      Suppose      an      edge      Ace      BinaPMG      H."
            },
            {
              "id": 1046,
              "title": "WA. - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "LetS,   \n \n=      {V   \n \n€       V(H)|Vx>      Ain      H}   \n \nU      {A}."
            },
            {
              "id": 1047,
              "title": "WA. - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "If      there      is      an      unbridged  \n \n  path      (iqy,---   \n \n,      Ky)      relative      to      S4      in      H[—S,4]      and       for      every      vertex      K;   \n \n€      {Ky,---   \n \n,      Kim},      there      exists  \n \n  an      uncovered      possible      directed      path      (A,      B,---   \n \n,      K;)  \n \n  (B   \n \n#      K;),      then      orient   \n \nA      o-*«      Bas   \n \nA      o*B."
            },
            {
              "id": 1048,
              "title": "WA. - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "R13      Suppose      an      edge   \n \nA      o-«      Bina      PMG      H. Let      Sy   \n \n=       {V   \n \n€      V(H)|V*x—      Ain      H}   \n \nU      {A}. If      there      is      an  \n \n  uncovered      possible      directed      path      (A,      B,---   \n \n,      A)      in  \n \n  H,      where   \n \nK   \n \n€      Anc(Sy,      H),      then      orient   \n \nA      o-*   \n \nB       as   \n \nA      oxB."
            },
            {
              "id": 1049,
              "title": "WA. - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "We      present      two      examples      for      R12      and      R}3      in      Fig. [I]      Con-  \n \n  sider      PAG      in      Fig. [I(a)]and      BK      C,*>   \n \nA      <*      C4      in      Fig."
            },
            {
              "id": 1050,
              "title": "WA. - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "[I(b)}  \n \n  See      Rio,      Sa   \n \n=      {C,      Co,      A},      and      there      exist      uncovered      pos-  \n \n  sible      directed      paths      py   \n \n=      (A,      B,D)      and      pz   \n \n=      (A,      B,      E)  \n \n  from   \n \nA      to      D      and      E,      respectively. D      c-o      E      is      unbridged      rela-  \n \n  tive      to      S4."
            },
            {
              "id": 1051,
              "title": "WA. - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Hence,      the      edge      between   \n \nA      and   \n \nB      is      transformed  \n \n  to   \n \nA      +oB      by      Rj2. This      transformation      is      intuitive      after  \n \n  knowing      the      property      of      unbridged      path. In      Fig."
            },
            {
              "id": 1052,
              "title": "WA. - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "[[(b)}      no      ver-  \n \n  tex      in      the      unbridged      path      is      an      ancestor      of      S4,      thus      D      and      E       are      ancestors      of      S   \n \n4      in      any      MAG      consistent      with      H. With-  \n \n  out      loss      of      generality,      suppose      D      is      ancestor      of      C’,."
            },
            {
              "id": 1053,
              "title": "WA. - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  the      uncovered      possible      directed      path      p,,      if      there      is   \n \nA   \n \n>      B,  \n \n  p;      can      only      be   \n \na      directed      path      from   \n \nA      to      D,      and      thus      there  \n \n  is      an      almost      directed      cycle   \n \nA   \n \n>   \n \nB      +>      D>      C,   \n \n4      A,  \n \n  which      violates      the      ancestral      property. For      R43,      see   \n \na      PAG      in  \n \n  Fig."
            },
            {
              "id": 1054,
              "title": "WA. - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "[I(©)}      If      BK      is      Cp      ++   \n \nA      and      D   \n \n>      C2      as      Fig. there  \n \n  is      S4   \n \n=      {A,      C2}      and      an      uncovered      possible      directed      path  \n \n  (A,      B,      D)      where      D   \n \n€      Anc(S,4,      H). Hence      we      transform  \n \n  Ao-o   \n \nB      to   \n \nA      +oB      for      the      same      reason      as      above. We      present      Thm."
            },
            {
              "id": 1055,
              "title": "WA. - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "[I]      to      imply      the      soundness      of      R42      and      R43\nto      incorporate      BK      in      the      presence      of      latent      confounders. Note      previous      rules      (Zhang}      |2008;      [Andrews      et      al.,      2020;\n\\\\\\'Recently,      R13      was      independently      identified      by      {Venkateswaran  \n \n  &      Perkovic      (2024),      along      with      some      other      fundamental      results."
            },
            {
              "id": 1056,
              "title": "WA. - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Algorithm      1:      Implementation      of      Rj:      and      R13  \n \n  Input:      PMG  \n \n  Output:      Updated      H       while      there      is      an      edge   \n \nA      o-«   \n \nB      in      H      do  \n \n  Obtain      S4   \n \n=      {V   \n \n€      V(A)|Vx>      Ain      H}   \n \nU      {A};  \n \n  Obtain   \n \na      set      of      vertices      D      defined      as   \n \nV   \n \n€      D      if      and       only      if   \n \nV   \n \n€      V(H)\\\\\\\\S,4      and      there      is      an      uncovered  \n \n  path      p      from   \n \nA      to   \n \nV      where   \n \nB      is      the      vertex      adjacent  \n \n  to   \n \nA      in      p;  \n \n  if      there      exists   \n \nV   \n \n€      D      such      that   \n \nV   \n \n€      Anc(S,a,      H)  \n \n  then  \n \n  Transform      Ao      Bto      A¢*B  \n \n  else  \n \n  Obtain      graph      H’      based      on      H      by      transforming  \n \n  Vox      V’      toV      <*V\\\\\\'’,      VV      ED,VV’   \n \n€      Sy;  \n \n  Update      the      circle      component      in      H’[D]      as  \n \n  follows      until      no      updates:      for      V;,      V;   \n \n€      D,  \n \n  transform      V;      o-0      V;      into      V;   \n \n—      V;      if      either      of  \n \n  the      two      conditions      holds      (1)      Fy,\\\\\\\\Fy,   \n \n4      0;      or (2)      there      is   \n \na      vertex      V;   \n \n€      D      such      that      there      is  \n \n  V;,   \n \n—      Vj      and      V;,      is      not      adjacent      to      V;,      where  \n \n  Fy      ={V\\\\\\'      €S,4|V’      +o   \n \nV      or      V\\\\\\'*x>   \n \nV      in      A};  \n \n  if      there      are      new      unshielded      colliders      in      H\\\\\\'      then  \n \n  Transform   \n \nA      o-*   \n \nB      to   \n \nA      ¢+*B      in      H;\n \n \n  Wang      et      al."
            },
            {
              "id": 1057,
              "title": "WA. - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "!/2023b)      cannot      trigger      these      two      transformations. Recently,      [Venkateswaran   \n \n&      Perkovic}      (2024)      independently  \n \n  discover      Ry3,      along      with      some      fundamental      results,      while  \n \n  R42      is      not      involved. Theorem      1. 72      and      R43      are      sound      to      incorporate      BK. One      remaining      issue      is      the      implementation      of      #42      and      R43."
            },
            {
              "id": 1058,
              "title": "WA. - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "We      provide      Alg. [I|to      implement      R42      and      Ry   \n \n3      with      theoret-  \n \n  ical      guarantee      in      Prop. [I]      Essentially,      the      edges      transformed  \n \n  on      Line   \n \n5      of      Alg. [Ijare      triggered      by      R13,      the      edges      trans-  \n \n  formed      on      Line   \n \n9      are      triggered      by      #12."
            },
            {
              "id": 1059,
              "title": "WA. - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Line   \n \n8      involves  \n \n  detecting      the      presence      of      unbridged      paths,      during      which  \n \n  new      unshielded      colliders      are      generated      if      such      paths      are  \n \n  found. See      the      proof      of      Prop. [I]      for      the      details. Suppose      the  \n \n  number      of      edges      in      H      is      m,      the      complexity      of      implementing  \n \n  Alg."
            },
            {
              "id": 1060,
              "title": "WA. - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "[l]is      O(m*),      detailed      in      Appendix      |C} Proposition      1. Given   \n \na      PMG      H,      Alg. [I|can      transform      all  \n \n  and      only      the      edges      that      can      be      transformed      by      R42      or      R13."
            },
            {
              "id": 1061,
              "title": "WA. - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Note      R42      is      quite      different      from      the      previous      rules      Ry   \n \n—       Ri,      which      are      shown      in      Appendix      [A-2|      These      existing  \n \n  rules      transform      an      edge      based      on      just      few      edges      or      few  \n \n  paths."
            },
            {
              "id": 1062,
              "title": "WA. - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "R12      is      more      complicated,      since      12      considers      not  \n \n  only      the      unbridged      path,      but      also      the      large      number      of      paths  \n \n  °The      main      focus      of      our      paper      is      not      on      implementation."
            },
            {
              "id": 1063,
              "title": "WA. - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "It      is  \n \n  possible      that      there      can      be   \n \na      more      efficient      method      to      implement  \n \n  Rig      and      R13,      which      we      leave      for      future      work. from   \n \nA      in      R42      to      every      vertex      in      the      unbridged      path,      which  \n \n  form   \n \na      sub-graph."
            },
            {
              "id": 1064,
              "title": "WA. - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "The      establishment      of      this      rule      implies      the  \n \n  intrinsic      hardness      of      causal      identification      from      observational  \n \n  data      and      BK      in      the      presence      of      latent      variables. 3\n \n \n  Interestingly,      we      find      that      essentially,      Ri2      and      R43      are  \n \n  two      generalizations      of      R3      and      Rz."
            },
            {
              "id": 1065,
              "title": "WA. - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "See      Ry      and      R3      in  \n \n  Appendix      [A-2|      Suppose   \n \na      PMG      H."
            },
            {
              "id": 1066,
              "title": "WA. - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Consider      there      is      E       Cx      A:      Re      says      if      there      is      an      edge      AcE,      then      we      orient      it  \n \n  as   \n \nA      +*E;      while      R13      says      if      there      is      an      uncovered      possible  \n \n  directed      path      from   \n \nA      to      F      beginning      with   \n \nA      o-*      B,      then      we  \n \n  orient      Ao*«      Bas   \n \nA      +*B."
            },
            {
              "id": 1067,
              "title": "WA. - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "R13      generalizes      an      edge      Ao*      EF  \n \n  in      Rz      to      an      uncovered      possible      directed      path      from   \n \nA      to      E       beginning      with   \n \nA      o-*      B. R42      is      also   \n \na      generalization      of      R3."
            },
            {
              "id": 1068,
              "title": "WA. - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Consider      there      is      an      unshielded      triple      Cx   \n \nA      «*D      ina  \n \n  PMG      H:      Rs3      says      if      there      is      Co      Box      D      and      an      edge      Aox      B,  \n \n  then      we      orient   \n \nA      o-«   \n \nB      to   \n \nA      <«B."
            },
            {
              "id": 1069,
              "title": "WA. - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Here      the      reason      for      the  \n \n  transformation      is,      although   \n \nB      is      not      an      ancestor      of      {C’,      D}  \n \n  in      H,   \n \nB      must      be      an      ancestor      of      either      C      or      D      in      any      MAG  \n \n  consistent      with      H. That      is,      the      vertex   \n \nB      here      has      the      same  \n \n  property      as      the      unbridged      path      we      discuss      above."
            },
            {
              "id": 1070,
              "title": "WA. - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "Consider  \n \n  Cx—   \n \nA      and      D«x—   \n \nA      in      Rz,      if      there      is   \n \nA   \n \n—      B,      either  \n \n  A,      B,C      or      A,      B,      D      will      form   \n \na      directed      or      almost      directed  \n \n  cycle,      which      violates      the      ancestral      property."
            },
            {
              "id": 1071,
              "title": "WA. - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "While      7212      says  \n \n  if      there      is      an      unbridged      path      p      relative      to      {A,      C,      D}      and   \n \nB       is      the      vertex      adjacent      to   \n \nA      in      the      uncovered      path      from   \n \nA      to  \n \n  every      vertex      in      p,      then      we      orient   \n \nA      o-*   \n \nB      to   \n \nA      ¢*«B."
            },
            {
              "id": 1072,
              "title": "WA. - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "R43  \n \n  generalizes      the      one      vertex   \n \nB      in      R3      to   \n \na      subgraph      induced  \n \n  by   \n \nB      and      all      the      vertices   \n \nV      such      that      there      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to   \n \nV      beginning      with   \n \nA      o-«      B. 4."
            },
            {
              "id": 1073,
              "title": "WA. - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Application      on      Set      Determination\ntion  \n \n  In      this      section,      we      demonstrate      the      applicability      of      the      rules  \n \n  proposed      in      Sec. B]to      causality      tasks      that      rely      solely      on      ob-  \n \n  servational      data."
            },
            {
              "id": 1074,
              "title": "WA. - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Specifically,      we      focus      on      set      determination  \n \n  task      in      the      presence      of      latent      confounders,      i.e.,      determin-  \n \n  ing      the      set      of      possible      causal      effects      of      vertex   \n \nX      on      vertex  \n \n  Y      with      observational      data."
            },
            {
              "id": 1075,
              "title": "WA. - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "We      will      present   \n \na      rule-based  \n \n  method      by      introducing      the      proposed      rules      into      the      state-of-  \n \n  the-art      method      PAGcauses      (Wang      et      al.,      {2023a),      which      takes  \n \n  a      substantial      improvement      on      efficiency."
            },
            {
              "id": 1076,
              "title": "WA. - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "In      set      determination      task,      we      have   \n \na      PAG      P      identified      with  \n \n  observational      data      (Spirtes      et      al.,      2000). Suppose      we      are      in-  \n \n  terested      in      the      causal      effect      of   \n \nX      on   \n \nY      henceforth."
            },
            {
              "id": 1077,
              "title": "WA. - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "As      many  \n \n  causal      graphs      are      consistent      with      P      and      possibly      associated  \n \n  with      different      causal      effects,      the      target      of      set      determination  \n \n  is      to      determine      the      set      of      possible      causal      effects,      consisting  \n \n  of      all      the      causal      effects      in      the      DAGs      represented      by      the  \n \n  MAGs      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1078,
              "title": "WA. - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Following      previous  \n \n  studies      (Maathuis      et      al. (2009;      |Malinsky   \n \n&      Spirtes)      |2016;  \n \n  Fang   \n \n&      He}      |2020;      |Wang      et      al.)\n[2023a),      we      only      consider  \n \n  the      possible      causal      effects      that      are      estimated      by      covariate  \n \n  adjustment,      and      only      focus      on      finding      all      the      adjustment\nE      Cy       ZS      (GE\n\\\\\\\\= \\\\\\\\E=,."
            },
            {
              "id": 1079,
              "title": "WA. - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "E       WA      \\\\\\\\   \n \n—      om, (c)      Mz      (d)      M’ M’\n(a)      P (b)      Mi\n \nP (b)      Mi\n \n \n  sets      for      estimating      the      possible      causal      effects."
            },
            {
              "id": 1080,
              "title": "WA. - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Note      there  \n \n  possibly      exist      some      DAGs      with      causal      effects      unidentifiable  \n \n  by      adjustment,      all      the      relevant      methods      cannot      output      these  \n \n  effects      as      it      is      beyond      the      ability      of      covariate      adjustment. We      start      by      revisiting      PAGcauses      in      Sec."
            },
            {
              "id": 1081,
              "title": "WA. - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "4.1]      Note      PAG-  \n \n  causes      is   \n \na      complicated      method,      which      is      hard      to      introduce  \n \n  in      limited      space. Hence,      we      just      show      the      core      idea      of      PAG-  \n \n  causes      and      the      parts      where      7212      can      take      an      improvement."
            },
            {
              "id": 1082,
              "title": "WA. - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "The      details      are      given      in      Appendix      |B}      Then,      we      propose      the  \n \n  theoretical      supports      for      set      determination      based      on      712      in  \n \n  Sec. 4-2)      and      present      the      rule-based      algorithm      in      Sec. 4.3}\n4.1. Revisiting      Latest      Results\nults  \n \n  PAGcauses      is   \n \na      two-step      method. See      PAG      P      in      Fig. for      an      example."
            },
            {
              "id": 1083,
              "title": "WA. - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      some      circles      at      X,      the      first      step  \n \n  is      to      transform      all      the      circles      at      X. This      step      is      similar      to      the  \n \n  classical      method      IDA      which      applies      for      set      determination  \n \n  without      latent      variables      (Maathuis      et      al.)      [2009)."
            },
            {
              "id": 1084,
              "title": "WA. - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "For      each  \n \n  possible      transformations      of      (the      circles      at)      X,      PAGcauses  \n \n  introduces   \n \na      graphical      characterization      to      evaluate      the      va-  \n \n  lidity      of      each      transformation      of      X,      that      is,      whether      there  \n \n  is   \n \na      MAG      consistent      with      the      local      transformation      in      the  \n \n  MEC      represented      by      P."
            },
            {
              "id": 1085,
              "title": "WA. - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "For      each      valid      transformation,      they  \n \n  obtain      an      updated      PMG      M      called      maximal      local      MAG      with  \n \n  the      proposed      sound      and      complete      orientation      rules. Mj      and       Mb      in      Fig. [2(b)|2(c)|      are      two      examples      of      maximal      local  \n \n  MAGs,      obtained      from      different      local      transformation      of      X."
            },
            {
              "id": 1086,
              "title": "WA. - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "In      the      presence      of      latent      variables,      obtaining      the      maximal  \n \n  local      MAG      M      by      incorporating      valid      local      transformation      of X\n \n   is      not      sufficient      for      determining      the      causal      effect      of   \n \nX      on  \n \n  Y      in      all      the      MAGs      consistent      with      M,      which      is      quite      differ-  \n \n  ent      from      the      case      absence      of      latent      confounders      (Maathuis  \n \n  et      al.|/2009)."
            },
            {
              "id": 1087,
              "title": "WA. - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      have      to      further      consider      the      uncer-  \n \n  tain      structures      in      M. However,      enumerating      all      the      MAGs  \n \n  and      then      finding      adjustment      sets      take   \n \na      super-exponential  \n \n  complexity,      which      is      evidently      infeasible."
            },
            {
              "id": 1088,
              "title": "WA. - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the  \n \n  second      step      of      PAGcauses,      for      each      M,      |Wang      et      al.|      (2023a)  \n \n  established      the      graphical      characterization      in      Prop. [2]      to      di-  \n \n  rectly      evaluate      whether      each      given      set      of      vertices      W      can      be  \n \n  an      adjustment      set      in      some      MAG      consistent      with      M."
            },
            {
              "id": 1089,
              "title": "WA. - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "With  \n \n  this      result,      instead      of      enumerating      the      super-exponential  \n \n  number      of      MAGs,      PAGcauses      only      needs      to      enumerate  \n \n  exponential      number      of      vertices      set      W      whose      space      is      super-  \n \n  exponentially      less      than      that      of      MAGs,      and      evaluates      whether  \n \n  each      W      is      an      adjustment      set      in      some      MAG      by      Prop."
            },
            {
              "id": 1090,
              "title": "WA. - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "[2}      Be-  \n \n  fore      presenting      Prop. [2      we      first      show      two      definitions. The  \n \n  definition      of      bridged      in      Prop. QJis      presented      in      Appendix\n \n \n  Definition      2."
            },
            {
              "id": 1091,
              "title": "WA. - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      W      in   \n \na      maximal      local  \n \n  MAG      M,      define   \n \na      set      of      vertices      W      as   \n \nV   \n \n€      W      if      and      only  \n \n  if   \n \nV   \n \n€      PossAn(Y,      M)\\\\\\\\W      and      there      exists   \n \na      collider      path  \n \n  beginning      with      an      arrowhead      from   \n \nX      to   \n \nV      where      each      non-  \n \n  endpoint      vertex      belongs      to      W."
            },
            {
              "id": 1092,
              "title": "WA. - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Denote      Anc(Y      UW,      M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      S,nin      and      PossAn(Y      UW,M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      Sax. S      is   \n \na      block      set      if      Smin   \n \nC SC      Sina. Definition      3."
            },
            {
              "id": 1093,
              "title": "WA. - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      maximal      local      MAG      M,      W      is   \n \na      potential  \n \n  adjustment      set      if\n(1)      VV   \n \n€      W,      there      is   \n \na      collider      path      XY   \n \n+      ---      <*V      such  \n \n  that      each      non-endpoint      belongs      to      W,      and      there      is   \n \na       possible      directed      path      from   \n \nV      to   \n \nY      that      does      not      go  \n \n  through      the      vertices      in      W;\n(2)      WN      PossDe(X,      M)   \n \n=      0;\n(3)      Wn      Anc(Y      UW,M)      =      0\n \n=      0."
            },
            {
              "id": 1094,
              "title": "WA. - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Proposition      2."
            },
            {
              "id": 1095,
              "title": "WA. - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      for      any  \n \n  potential      adjustment      set      W,      there      exists   \n \na      MAG      M      consis-  \n \n  tent      with      M      such      that      W      is      an      adjustment      set      in      M      if      there  \n \n  exists   \n \na      block      set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where  \n \n  Sy      ={V\\\\\\'      €S|V      ox      V’      in      M};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M."
            },
            {
              "id": 1096,
              "title": "WA. - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "Prop. 2]      provides   \n \na      sufficient      condition      for      the      existence      of  \n \n  MAGs      consistent      with      M      such      that   \n \na      given      set      W      is      an  \n \n  adjustment      set. When      using      this      condition      in      PAGcauses,  \n \n  it      includes      (1)      enumerate      every      block      set      S;      and      (2)      given  \n \n  each      S,      evaluate      the      three      conditions."
            },
            {
              "id": 1097,
              "title": "WA. - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  2  \n \n  3  \n \n  4 (2)      is      O(d?),      where      d      denotes      the      number      of      vertices. The\n \n \n  intuition      of      the      sufficient      condition      is,      they      try      to      construct  \n \n  a      MAG      M      such      that      the      adjustment      set      is      W."
            },
            {
              "id": 1098,
              "title": "WA. - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "To      ensure  \n \n  it,      they      have      to      restrict      that      some      vertices      (characterized      by  \n \n  set      W)      are      not      ancestors      of      W   \n \nU      {Y}      in      M. Hence,      it      is necessary      to      introduce      some      additional      arrowheads      to      block  \n \n  all      the      possible      directed      paths      from      W      to      WU{Y      }."
            },
            {
              "id": 1099,
              "title": "WA. - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "For      this  \n \n  purpose,      intuitively,      the      block      set      S      in      Def. [2|is      introduced  \n \n  to      characterize      the      position      to      introduce      arrowheads      to      block  \n \n  the      possibly      directed      paths      (See      Alg. 5]in      Appendix      [B]      for  \n \n  MAG      construction      algorithm)."
            },
            {
              "id": 1100,
              "title": "WA. - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "There      are      exponential      num-  \n \n  ber      (with      respect      to      d)      of      ways      to      introduce      arrowheads  \n \n  to      achieve      it,      hence      there      are      exponential      number      of      block  \n \n  sets      in      Def. Thus,      given      W,      evaluating      the      existence  \n \n  of      MAGs      in      Prop. |2}needs      to      enumerate      every      block      set      S."
            },
            {
              "id": 1101,
              "title": "WA. - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      the      process      of      enumerating      S      and      evaluating  \n \n  the      three      conditions      is      to      determine      the      existence      of   \n \na      kind  \n \n  of      way      to      introduce      arrowheads      such      that   \n \na      MAG      can      be  \n \n  constructed      with      W      being      the      adjustment      set. 4.2. Utilizing      Proposed      Rules\nules  \n \n  As      discussed      in      Sec."
            },
            {
              "id": 1102,
              "title": "WA. - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "4      I]      given   \n \na      potential      adjustment      set  \n \n  ‘W,      an      exponential      complexity      of      enumerating      all      the      block  \n \n  sets      is      involved      in      using      Prop."
            },
            {
              "id": 1103,
              "title": "WA. - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "[2]      because      there      are      expo-  \n \n  nential      number      of      possible      ways      to      block      all      the      possible  \n \n  directed      paths      from      W      to      W   \n \nU      {Y}      such      that      no      vertex  \n \n  in      W      is      an      ancestor      of      W   \n \nU      {Y}      in      the      constructed      MAG."
            },
            {
              "id": 1104,
              "title": "WA. - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "In      the      following,      we      show      that      enumerating      block      sets      can  \n \n  be      avoided      by      introducing      712,      thus      can      circumvent      the  \n \n  possibly      exponential      computational      burden      here. Note      the      final      target      is      to      find   \n \na      way      to      introduce      arrowheads  \n \n  to      prevent      W      being      ancestors      of      W   \n \nU      {Y}."
            },
            {
              "id": 1105,
              "title": "WA. - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "At      first      we  \n \n  determine   \n \na      set      of      vertices      So      in      Def. 4}  \n \n  Definition      4."
            },
            {
              "id": 1106,
              "title": "WA. - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      and   \n \na      po-  \n \n  tential      adjustment      set      W,      we      define      So      as      V’   \n \n€      So      if      and       only      if      there      exists   \n \na      vertex   \n \nV   \n \n€      W      and      there      exists   \n \na      mini-  \n \n  mal      possible      directed      path      p      from   \n \nV      to      Anc(W   \n \nU      {Y      },      M)  \n \n  such      that      V’      is      the      vertex      adjacent      to   \n \nV      in      p      and      each      non-  \n \n  endpoint      in      p      does      not      belong      to      W."
            },
            {
              "id": 1107,
              "title": "WA. - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      if      we      want      to      obtain   \n \na      MAG      M      consistent  \n \n  with      M      such      that      W      are      not      ancestors      of      W   \n \nU      {Y}      in  \n \n  M,      all      the      edges   \n \nV      o*      S,V   \n \n€      W,S   \n \n©      So      in      M      must      be  \n \n  transformed      to   \n \nV      <«,S,      for      otherwise      there      will      be   \n \na      directed  \n \n  path      from   \n \nV      to      WU      {Y}."
            },
            {
              "id": 1108,
              "title": "WA. - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "Initialize      S   \n \n=      So,      characterizing  \n \n  the      positions      to      introduce      arrowheads,      similar      to      the      block  \n \n  1\nAlgorithm      2:      Updating      S\n \n \n  Input:      Maximal      local      MAG      M,      X,      Y,      W       Output:      S       S      is      initialized      as      So      in      Def. 4      and      W      is      determined      as Def."
            },
            {
              "id": 1109,
              "title": "WA. - Chunk 76",
              "type": "chunk",
              "children": [],
              "content": "T\n \n   =\n \n   PossDe(W,      M[—S])\\\\\\\\W;\n \n \n  while   \n \n/      do  \n \n  if      M[Sy]      is      not   \n \na      complete      graph      for      some   \n \nV   \n \n€      W,  \n \n  where      Sy   \n \n=      {V’   \n \n€      S|V      ox      V/or   \n \nV      <«V\\\\\\'      in      M};  \n \n  or      PossDe(W,      M[—S])      M      Pa(S,      M)   \n \n#      0)      then  \n \n  return      “No”;  \n \n  Update      M      by      transforming   \n \nV      o-*      S      to   \n \nV      <«S\\\\\\'      for  \n \n  any   \n \nV   \n \n€      Wand      S      €§;\n \n \n  if      an      edge   \n \nA      +*B      can      be      transformed      by      R12      in      M       then  \n \n  |      S=SU      (Anc(B,M)T)  \n \n  else  \n \n  if      there      is      not      an      unbridged      path      relative      to      S      in  \n \n  M[PossDe(W,      M|[—S]})]      then  \n \n  |      return   \n \nS else  \n \n  |      return      “No”\n \n \n  set      in      Prop."
            },
            {
              "id": 1110,
              "title": "WA. - Chunk 77",
              "type": "chunk",
              "children": [],
              "content": "2|      The      transformed      edges      above      are      hypothesis  \n \n  BK,      and      can      possibly      trigger      7? to      further      update      the      graph. The      updates      triggered      by      12      help      us      enlarge      the      set      S. Following      the      idea      above,      we      present      Alg.|2}      Note      when      we  \n \n  propose      R42,      the      premise      is      that      BK      is      correct."
            },
            {
              "id": 1111,
              "title": "WA. - Chunk 78",
              "type": "chunk",
              "children": [],
              "content": "However,  \n \n  the      premise      does      not      necessarily      hold      here. Hence,      in      the  \n \n  process      of      triggering      12,      we      need      to      evaluate      whether      the  \n \n  hypothesis      BK      is      valid,      which      is      achieved      on      Line   \n \n4      and 12."
            },
            {
              "id": 1112,
              "title": "WA. - Chunk 79",
              "type": "chunk",
              "children": [],
              "content": "When      12      can      no      longer      be      triggered      (Line      8),      roughly  \n \n  speaking,      if      there      is      not      an      unbridged      path      relative      to      S,      S       is   \n \na      block      set      that      satisfies      the      three      conditions      of      Prop. [2\n \n \n  Then,      we      present      relevant      theoretical      guarantees      for      Alg. 2}  \n \n  Thm."
            },
            {
              "id": 1113,
              "title": "WA. - Chunk 80",
              "type": "chunk",
              "children": [],
              "content": "implies      that      given   \n \na      maximal      local      MAG      M      and   \n \na       potential      adjustment      set      W,      if      we      can      obtain   \n \na      set      by      Alg. then      there      isa      MAG      M      consistent      with      M      such      that      W      is      an  \n \n  adjustment      set      in      M. According      to      Thm. [2      whether      Alg."
            },
            {
              "id": 1114,
              "title": "WA. - Chunk 81",
              "type": "chunk",
              "children": [],
              "content": "[2]  \n \n  outputs   \n \na      set      of      vertices      or      “No”      is      an      indicator      of      whether  \n \n  the      input      W      is      an      adjustment      set      in      some      MAG      or      not. Hence,      by      executing      Alg.|2|      for      each      potential      adjustment  \n \n  set      W,      we      can      find   \n \na      set      of      adjustment      sets      in      the      MAGs  \n \n  consistent      with      M."
            },
            {
              "id": 1115,
              "title": "WA. - Chunk 82",
              "type": "chunk",
              "children": [],
              "content": "To      further      ensure      that      we      can      estimate  \n \n  all      the      causal      effects      identifiable      by      covariate      adjustment,  \n \n  we      provide      Thm."
            },
            {
              "id": 1116,
              "title": "WA. - Chunk 83",
              "type": "chunk",
              "children": [],
              "content": "3}      to      indicate      that      if      there      exists   \n \na      MAG      M       consistent      with      M      such      that      the      causal      effect      is      identifiable  \n \n  by      covariate      adjustment,      then      there      is      an      adjustment      set      in  \n \n  M      being   \n \na      potential      adjustment      set      such      that      Alg. 2]      can  \n \n  return   \n \na      set      of      vertices."
            },
            {
              "id": 1117,
              "title": "WA. - Chunk 84",
              "type": "chunk",
              "children": [],
              "content": "It      ensures      that      via      using      Alg. 2]      for  \n \n  each      potential      adjustment      set      W,      we      can      estimate      all      the possible      causal      effects      that      are      identifiable      by      adjustment. Theorem      2. Given   \n \na      maximal      local      MAG      M,      for      any      poten-  \n \n  tial      adjustment      set      W,      if      Alg."
            },
            {
              "id": 1118,
              "title": "WA. - Chunk 85",
              "type": "chunk",
              "children": [],
              "content": "2]      could      return   \n \na      set      of      vertices S,      then      there      exists   \n \na      MAG      M      consistent      with      MI      such      that  \n \n  W      is      an      adjustment      set      in      M. Theorem      3. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na       MAG   \n \n™      consistent      with      M      such      that      there      exists      an      adjust-  \n \n  ment      set      relative      to      (X,Y)."
            },
            {
              "id": 1119,
              "title": "WA. - Chunk 86",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)  \n \n  as      Def. [8]      Then      W      is   \n \na      potential      adjustment      set      in      M      and       Alg.2|can      return   \n \na      set      of      vertices      S      given      W      as      the      input."
            },
            {
              "id": 1120,
              "title": "WA. - Chunk 87",
              "type": "chunk",
              "children": [],
              "content": "Algorithm      3:      PAGrules Input:      PAG      P,      X,   \n \nY       Output:      AS(P)//      Adjustment      sets      in      MAGs      consistent with      P       AS(P)      =)      //      Record      all      the      valid      adjustment      sets;\n \n \n  Obtain   \n \na      maximal      local      MAG      M      based      on      P       and      C;  \n \n  Find      all      potential      adjustment      sets  \n \n  W),,      W2,---   \n \n,      that      contains  \n \n  DD-SEP(X,      Y,      M)      given      M;  \n \n  for      each      potential      adjustment      set      W;,      do  \n \n  Obtain      Sp      and      W      as      Def."
            },
            {
              "id": 1121,
              "title": "WA. - Chunk 88",
              "type": "chunk",
              "children": [],
              "content": "and      Def. if      the      conditions      in      Prop. Hare      satisfied      for      P      then  \n \n  |      return      AS(P)   \n \n<      {D-SEP(X,Y,Px)}  \n \n  //      Prop. [4 w ya   \n \na      wis for      each      setC      C      {V   \n \n|   \n \nV      +0   \n \nX      in      P}      do  \n \n  if      the      three      conditions      in      Prop. (dare      satisfied      then  \n \n  Remark      2."
            },
            {
              "id": 1122,
              "title": "WA. - Chunk 89",
              "type": "chunk",
              "children": [],
              "content": "There      are      at      most      d(d   \n \n—      1)/2      circles      that      could  \n \n  be      transformed      on      Line   \n \n6      of      Alg. |2|      where      d      denotes      the  \n \n  number      of      vertices. And      the      transformation      on      Line   \n \n6      is  \n \n  a      necessary      condition      for      entering      the      next      round      of      loop."
            },
            {
              "id": 1123,
              "title": "WA. - Chunk 90",
              "type": "chunk",
              "children": [],
              "content": "Hence,      the      number      of      loop      in      Alg.2Jis      at      most      O(d?). For  \n \n  the      other      parts      in      Alg|2}      the      complexity      is      at      most      O(d?). Hence      Alg. |2}can      be      implemented      in      polynomial      time. Remark      3."
            },
            {
              "id": 1124,
              "title": "WA. - Chunk 91",
              "type": "chunk",
              "children": [],
              "content": "One      may      wonder      given   \n \na      maximal      local      MAG  \n \n  M      and   \n \na      potential      adjustment      set      W,      whether      we      could  \n \n  determine      whether      W      can      be      an      adjustment      set      in      some  \n \n  MAG      consistent      with      M      by      judging      the      three      conditions  \n \n  in      Prop."
            },
            {
              "id": 1125,
              "title": "WA. - Chunk 92",
              "type": "chunk",
              "children": [],
              "content": "2]      with   \n \na      prescribed      S,      such      as      S   \n \n=      S,,;n      or      S   \n \n=       Snax      in      Def. 2      It      is      infeasible. Consider      My      in      Fig. 10  \n \n  11 12\nadjustment      set      D-SEP(X,      Y,      Mx)      in      any      MAG      M      (See  \n \n  Appendix      for      D-SEP(X,      Y,Mx)). In      the      following,  \n \n  we      present      Def."
            },
            {
              "id": 1126,
              "title": "WA. - Chunk 93",
              "type": "chunk",
              "children": [],
              "content": "5]      to      characterize      these      vertices,      and      show  \n \n  DD-SEP(X,      Y,      Mx)      C      D-SEP(X,      Y,      Mx)      in      Prop. if      Alg. PJ      can      return   \n \na      set      of      vertices      given W;      and      M      then  \n \n  |      AS(P)   \n \n—      AS(P)   \n \nU      {Wi};\n \n \n  and      W   \n \n=      9),      the      three      conditions      (in      Prop."
            },
            {
              "id": 1127,
              "title": "WA. - Chunk 94",
              "type": "chunk",
              "children": [],
              "content": "|2))      hold      when  \n \n  S   \n \n=      Snin   \n \n=      {EF},      but      do      not      hold      when      S   \n \n=      Spaz   \n \n=       {B,      D,      E}. While      consider      M! in      Fig. 2(@)and      W   \n \n=      0,      the  \n \n  three      conditions      do      not      hold      when      S   \n \n=      Syrin   \n \n=      {C1,      C2},  \n \n  but      hold      when      S   \n \n=      {C,      C2,      B}."
            },
            {
              "id": 1128,
              "title": "WA. - Chunk 95",
              "type": "chunk",
              "children": [],
              "content": "Hence,      it      is      not      direct      that  \n \n  which      block      set      can      satisfy      the      three      conditions. Intuitively,  \n \n  the      benefit      taken      by      utilizing      712      is      that      it      implies      which  \n \n  vertex      should      be      added      into      S,      instead      of      enumerating      all  \n \n  block      sets      as      Prop. 2|      For      example,      when      using      Alg."
            },
            {
              "id": 1129,
              "title": "WA. - Chunk 96",
              "type": "chunk",
              "children": [],
              "content": "2]      for  \n \n  Mb      in      Fig. 2(c)]      given      W   \n \n=      9,      there      is      Sy   \n \n=      {E}      and      no       unbridged      paths,      thus      S   \n \n=      {E£}      is      returned;      while      for      M’  \n \n  in      Fig."
            },
            {
              "id": 1130,
              "title": "WA. - Chunk 97",
              "type": "chunk",
              "children": [],
              "content": "2@)]      given      W   \n \n=      0),      there      is      Sp   \n \n=      {C,,      C2}      and      an  \n \n  unbridged      path      D      o-0      E,      thus      S   \n \n=      {C1,      C2,      B}      is      returned. 4.3. The      Algorithm      for      Set      Determination\ntion  \n \n  In      this      part,      we      present      the      improved      algorithm      for      set      deter-  \n \n  mination,      through      utilizing      the      proposed      rules."
            },
            {
              "id": 1131,
              "title": "WA. - Chunk 98",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG  \n \n  P,      we      can      obtain      several      maximal      local      MAGs      M      based  \n \n  on      different      local      transformations      of      X. Then      in      each      M,   \n \na       direct      method      is      to      find      each      subset      W      C      V(M)\\\\\\\\{X,Y},  \n \n  and      then      evaluate      whether      it      is   \n \na      potential      adjustment      set."
            },
            {
              "id": 1132,
              "title": "WA. - Chunk 99",
              "type": "chunk",
              "children": [],
              "content": "If  \n \n  it      is   \n \na      potential      adjustment      set,      we      further      evaluate      whether  \n \n  a      set      of      vertices      can      be      returned      by      Alg. 2]      By      this      direct  \n \n  method,      we      can      find      all      the      adjustment      sets      according      to  \n \n  Thm. 2land      Thm. Bl Definition   \n \n5      (DD-SEP(X,      Y,      Mx)). Let      M      be   \n \na      maximal local      MAG."
            },
            {
              "id": 1133,
              "title": "WA. - Chunk 100",
              "type": "chunk",
              "children": [],
              "content": "V   \n \n€      DD-SEP(X,      Y,      Mx)      if      and      only      if      there  \n \n  is   \n \na      collider      path   \n \nX   \n \n4      Vi   \n \n©      ar      Ve-1      <—*V      in Mx,      where      (1)   \n \nY   \n \n€      PossDe(X,      Ml);      (2)      Vi,---      ,Ve—-1   \n \n€ DD-SEP(X,      Y,      Mx);      (3)   \n \nV   \n \n€      Anc(Y,      M1)      or      the      subgraph M|Qy]      is      not   \n \na      complete      graph,      where      Qy   \n \n=      {V’   \n \n€       Anc(Y,      M)   \n \n|   \n \nV      o«      V’      in      M}."
            },
            {
              "id": 1134,
              "title": "WA. - Chunk 101",
              "type": "chunk",
              "children": [],
              "content": "Proposition      3. Given   \n \na      maximal      local      MAG      M,      if   \n \nV   \n \n€       DD-SEP(X,      Y,      Mx),      then   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)      in      any MAG      M      consistent      with      M      such      that      there      exists      an      adjust-  \n \n  ment      set      relative      to      (X,Y). Combining      the      parts      above,      we      provide      PAGrules      in      Alg."
            },
            {
              "id": 1135,
              "title": "WA. - Chunk 102",
              "type": "chunk",
              "children": [],
              "content": "8]  \n \n  for      set      determination,      based      on      the      framework      of      PAGcauses. Note      if   \n \nX   \n \n¢      PossAn(Y,      ?)      on      Line      2,   \n \nX      has      no      causal      ef-  \n \n  fect      on   \n \nY      in      all      the      MAGs      consistent      with      P,      thus      there      is      no       need      to      consider      the      set      of      possible      causal      effects."
            },
            {
              "id": 1136,
              "title": "WA. - Chunk 103",
              "type": "chunk",
              "children": [],
              "content": "Similarly,  \n \n  if      the      causal      effect      is      identifiable      by      covariate      adjustment      in  \n \n  P,      we      can      directly      return      the      causal      effect      by      Prop.)\nwhich  \n \n  is      detailed      in      Appendix      [A.3|      On      Line      5,      we      enumerate      all  \n \n  possible      local      transformations      of      X,      which      is      represented  \n \n  by   \n \na      set      of      vertices      C      that      implies      transforming      the      edge  \n \n  Xo   \n \nV      to   \n \nX      ¢xV      if   \n \nV   \n \n€      Candto   \n \nX   \n \n>      VifV      ¢C."
            },
            {
              "id": 1137,
              "title": "WA. - Chunk 104",
              "type": "chunk",
              "children": [],
              "content": "Evidently,      all      the      sets      C      can      represent      all      the      possible      local  \n \n  transformations      of      X."
            },
            {
              "id": 1138,
              "title": "WA. - Chunk 105",
              "type": "chunk",
              "children": [],
              "content": "On      Line      6-7,      we      obtain      all      the      valid  \n \n  local      transformations      of   \n \nX      and      obtain      the      maximal      local  \n \n  However,      the      method      above      is      still      somewhat      inefficient,      be-  \n \n  cause      the      enumeration      of      all      the      subsets      of      V(M)\\\\\\\\{X,      Y}  \n \n  is      not      always      necessary."
            },
            {
              "id": 1139,
              "title": "WA. - Chunk 106",
              "type": "chunk",
              "children": [],
              "content": "In      fact,      given   \n \na      maximal      local  \n \n  MAG,      some      vertices      can      be      determined      to      belong      to      the  \n \n  _  \n \n  MAGs      based      on      each      valid      local      transformation. According  \n \n  to      Prop. B|      we      only      need      to      consider      the      potential      adjust-  \n \n  ment      set      containing      DD-SEP(X,      Y,      M),      which      is      executed  \n \n  on      Line      8."
            },
            {
              "id": 1140,
              "title": "WA. - Chunk 107",
              "type": "chunk",
              "children": [],
              "content": "And      from      Line      9-12,      we      evaluate      whether      each  \n \n  potential      adjustment      set      is      an      adjustment      set      by      Alg. Finally,      Cor. [i]implies      that      PAGrules      can      return      the      set      of  \n \n  causal      effects      that      are      identifiable      by      covariate      adjustment  \n \n  in      the      DAGs      represented      by      the      MAGs      consistent      with      P."
            },
            {
              "id": 1141,
              "title": "WA. - Chunk 108",
              "type": "chunk",
              "children": [],
              "content": "Corollary      1."
            },
            {
              "id": 1142,
              "title": "WA. - Chunk 109",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      PAG      P,      denote      CE(P)      and      CE(P)      the  \n \n  set      of      causal      effects      in      the      DAGs      represented      by      the      MAGs  \n \n  consistent      with      P      that      can      be      estimated      by      covariate      adjust-  \n \n  ment      with      obseryable      variables      and      the      set      of      causal      effects  \n \n  set      AG  \n \n  output      by      Alg.|3}      It      holds      that      CE(P)   \n \n=      CE(P)."
            },
            {
              "id": 1143,
              "title": "WA. - Chunk 110",
              "type": "chunk",
              "children": [],
              "content": "5. Conclusion\nsion  \n \n  It      remains      an      open      problem      for   \n \na      long      time      that      what      causal  \n \n  relations      are      identifiable      from      observational      data      and      back-  \n \n  ground      knowledge      (BK)      in      the      presence      of      latent      variables. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK."
            },
            {
              "id": 1144,
              "title": "WA. - Chunk 111",
              "type": "chunk",
              "children": [],
              "content": "The      rules      are      quite      different      from      the      existing      rules      in  \n \n  the      form. We      believe      the      proposed      rules      can      take      some      new       insights      to      the      open      problem      and      could      possibly      inspire      the  \n \n  establishment      of      the      sound      and      complete      rules      in      the      future."
            },
            {
              "id": 1145,
              "title": "WA. - Chunk 112",
              "type": "chunk",
              "children": [],
              "content": "Further,      by      utilizing      the      proposed      rules,      we      present   \n \na      novel  \n \n  algorithm      to      determine      the      set      of      possible      causal      effects  \n \n  given   \n \na      PAG. The      rules      can      help      improve      the      efficiency      of  \n \n  the      state-of-the-art      method."
            },
            {
              "id": 1146,
              "title": "WA. - Chunk 113",
              "type": "chunk",
              "children": [],
              "content": "In      the      future,      it      is      worthy      to      continue      investigating      the      sound  \n \n  and      complete      rules      to      incorporate      BK,      based      on      the      rules  \n \n  that      have      been      established."
            },
            {
              "id": 1147,
              "title": "WA. - Chunk 114",
              "type": "chunk",
              "children": [],
              "content": "In      addition,      in      light      of      the      fact  \n \n  that      only   \n \na      Markov      equivalence      class      (MEC)      is      identifiable  \n \n  given      observational      data,      the      causal      effect      is      usually      uniden-  \n \n  tifiable      within   \n \na      MEC."
            },
            {
              "id": 1148,
              "title": "WA. - Chunk 115",
              "type": "chunk",
              "children": [],
              "content": "Hence,      exploring      and      exploiting      the  \n \n  additional      knowledge      that      is      available      in      practice      may      be  \n \n  helpful      to      causal      effect      estimation      tasks. References\n \n \n  Ali,      R. A.,      Richardson,      T.,      Spirtes,      P.,      and      Zhang,      J. Orien-  \n \n  tation      rules      for      constructing      markov      equivalence      classes  \n \n  of      maximal      ancestral      graphs."
            },
            {
              "id": 1149,
              "title": "WA. - Chunk 116",
              "type": "chunk",
              "children": [],
              "content": "Technical      report,      2005. Andrews,      B.,      Spirtes,      P.,      and      Cooper,      G. F. On      the      com-  \n \n  pleteness      of      causal      discovery      in      the      presence      of      latent  \n \n  confounding      with      tiered      background      knowledge. In      Pro-  \n \n  ceedings      of      the      23rd      International      Conference      on      Artifi-  \n \n  cial      Intelligence      and      Statistics,      pp. 4002-4011,      2020."
            },
            {
              "id": 1150,
              "title": "WA. - Chunk 117",
              "type": "chunk",
              "children": [],
              "content": "Cai,      R.,      Chen,      J.,      Li,      Z.,      Chen,      W.,      Zhang,      K.,      Ye,      J.,      Li,      Z.,  \n \n  Yang,      X.,      and      Zhang,      Z. Time      series      domain      adaptation  \n \n  via      sparse      associative      structure      alignment. In      Proceedings  \n \n  of      the      35th      AAAI      Conference      on      Artificial      Intelligence,      pp. 6859-6867,      2021. Fang,      Z. and      He,      Y."
            },
            {
              "id": 1151,
              "title": "WA. - Chunk 118",
              "type": "chunk",
              "children": [],
              "content": "IDA      with      background      knowledge. In  \n \n  Proceedings      of      the      Thirty-Sixth      Conference      on      Uncer-  \n \n  tainty      in      Artificial      Intelligence,      volume      124      of      Proceed-  \n \n  ings      of      Machine      Learning      Research,      pp. 270-279. AUAI  \n \n  Press,      2020. Gong,      M.,      Zhang,      K.,      Liu,      T.,      Tao,      D.,      Glymour,      C.,      and       Scholkopf,      B."
            },
            {
              "id": 1152,
              "title": "WA. - Chunk 119",
              "type": "chunk",
              "children": [],
              "content": "Domain      adaptation      with      conditional      trans-  \n \n  ferable      components. In      Balcan,      M. and      Weinberger,      K. Q. (eds.),      Proceedings      of      the      33nd      International      Conference  \n \n  on      Machine      Learning,      pp. 2839-2848,      2016. Hauser,      A. and      Bithlmann,      P. Two      optimal      strategies      for  \n \n  active      learning      of      causal      models      from      interventional      data."
            },
            {
              "id": 1153,
              "title": "WA. - Chunk 120",
              "type": "chunk",
              "children": [],
              "content": "International      Journal      of      Approximate      Reasoning,      55(4):\n \n \n  926-939,      2014. He,      Y. and      Geng,      Z. Active      learning      of      causal      networks      with  \n \n  intervention      experiments      and      optimal      designs. Journal      of  \n \n  Machine      Learning      Research,      9:2523-2547,      2008. Huang,      B.,      Feng,      F.,      Lu,      C.,      Magliacane,      S.,      and      Zhang, K."
            },
            {
              "id": 1154,
              "title": "WA. - Chunk 121",
              "type": "chunk",
              "children": [],
              "content": "Adarl:      What,      where,      and      how      to      adapt      in      transfer  \n \n  reinforcement      learning. In      Proceedings      of      the      10th      Inter-  \n \n  national      Conference      on      Learning      Representations,      2022. Jaber,      A.,      Kocaoglu,      M.,      Shanmugam,      K.,      and      Bareinboim, E."
            },
            {
              "id": 1155,
              "title": "WA. - Chunk 122",
              "type": "chunk",
              "children": [],
              "content": "Causal      discovery      from      soft      interventions      with      un-  \n \n  known      targets:      Characterization      and      learning. In      Ad-  \n \n  vances      in      Neural      Information      Processing      Systems,      2020. Maathuis,      M. H.,      Kalisch,      M.,      Biihlmann,      P,      et      al. Estimat-  \n \n  ing      high-dimensional      intervention      effects      from      observa-  \n \n  tional      data."
            },
            {
              "id": 1156,
              "title": "WA. - Chunk 123",
              "type": "chunk",
              "children": [],
              "content": "The      Annals      of      Statistics,      37(6A):3133-3164,  \n \n  2009. Maathuis,      M. H.,      Colombo,      D.,      et      al. A      generalized      back-  \n \n  door      criterion. The      Annals      of      Statistics,      43(3):1060—-1088,  \n \n  2015. Malinsky,      D. and      Spirtes,      P. Estimating      causal      effects      with  \n \n  ancestral      graph      markov      models."
            },
            {
              "id": 1157,
              "title": "WA. - Chunk 124",
              "type": "chunk",
              "children": [],
              "content": "In      Conference      on      Proba-  \n \n  bilistic      Graphical      Models,      pp. 299-309,      2016. Meek,      C. Causal      inference      and      causal      explanation      with  \n \n  background      knowledge. In      Proceedings      of      the      I1st      An-  \n \n  nual      Conference      on      Uncertainty      in      Artificial      Intelligence,  \n \n  pp. 403-410,      1995. Pearl,      J. Causality. Cambridge      University      Press,      2009."
            },
            {
              "id": 1158,
              "title": "WA. - Chunk 125",
              "type": "chunk",
              "children": [],
              "content": "Perkovic,      E.,      Kalisch,      M.,      and      Maathuis,      M. H. Interpret-  \n \n  ing      and      using      cpdags      with      background      knowledge. In  \n \n  Proceedings      of      the      33rd      Conference      on      Uncertainty      in  \n \n  Artificial      Intelligence,      2017a. Perkovic,      E.,      Textor,      J.,      Kalisch,      M.,      and      Maathuis,      M. H."
            },
            {
              "id": 1159,
              "title": "WA. - Chunk 126",
              "type": "chunk",
              "children": [],
              "content": "Complete      graphical      characterization      and      construction      of  \n \n  adjustment      sets      in      markov      equivalence      classes      of      ancestral  \n \n  graphs. Journal      of      Machine      Learning      Research,      18:220:1-  \n \n  220:62,      2017b. Richardson,      T.,      Spirtes,      P.,      et      al. Ancestral      graph      markov  \n \n  models. The      Annals      of      Statistics,      30(4):962—1030,      2002."
            },
            {
              "id": 1160,
              "title": "WA. - Chunk 127",
              "type": "chunk",
              "children": [],
              "content": "Ruan,      K.,      Zhang,      J.,      Di,      X.,      and      Bareinboim,      E. Causal      imi-  \n \n  tation      learning      via      inverse      reinforcement      learning. In      Pro-  \n \n  ceedings      of      the      11st      International      Conference      on      Learn-  \n \n  ing      Representations,      2023. Schélkopf,      B.,      Janzing,      D.,      Peters,      J.,      Sgouritsa,      E.,      Zhang,  \n \n  K.,      and      Mooij,      J. M."
            },
            {
              "id": 1161,
              "title": "WA. - Chunk 128",
              "type": "chunk",
              "children": [],
              "content": "On      causal      and      anticausal      learning. In      Proceedings      of      the      29th      International      Conference      on  \n \n  Machine      Learning,      pp. 459-466,      2012. Spirtes,      P.,      Glymour,      C. N.,      and      Scheines,      R. Causation,  \n \n  prediction,      and      search. MIT      Press,      2000. van      der      Zander,      B.,      Liskiewicz,      M.,      and      Textor,      J."
            },
            {
              "id": 1162,
              "title": "WA. - Chunk 129",
              "type": "chunk",
              "children": [],
              "content": "Construct-  \n \n  ing      separators      and      adjustment      sets      in      ancestral      graphs. In  \n \n  Proceedings      of      the      Thirtieth      Conference      on      Uncertainty  \n \n  in      Artificial      Intelligence,      pp. 907-916,      2014. Venkateswaran,      A. and      Perkovic,      E. Towards      complete  \n \n  causal      explanation      with      expert      knowledge. arXiv      preprint  \n \n  arXiv:      2407.07338,      2024. Verma,      T."
            },
            {
              "id": 1163,
              "title": "WA. - Chunk 130",
              "type": "chunk",
              "children": [],
              "content": "and      Pearl,      J. Equivalence      and      synthesis      of      causal  \n \n  models. In      Proceedings      of      the      Sixth      Annual      Conference  \n \n  on      Uncertainty      in      Artificial      Intelligence,      pp. 255-270,  \n \n  1990. Verma,      T. and      Pearl,      J. An      algorithm      for      deciding      if   \n \na      set  \n \n  of      observed      independencies      has   \n \na      causal      explanation."
            },
            {
              "id": 1164,
              "title": "WA. - Chunk 131",
              "type": "chunk",
              "children": [],
              "content": "In  \n \n  Proceedings      of      the      8th      Annual      Conference      on      Uncertainty  \n \n  in      Artificial      Intelligence,      pp. 323-330,      1992. von      Kiigelgen,      J.,      Mey,      A.,      Loog,      M.,      and      Schdélkopf,      B. Semi-supervised      learning,      causality,      and      the      conditional  \n \n  cluster      assumption."
            },
            {
              "id": 1165,
              "title": "WA. - Chunk 132",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the      36th      Confer-  \n \n  ence      on      Uncertainty      in      Artificial      Intelligence,      pp. 1-10,  \n \n  2020. Wang,      T.-Z.,      Qin,      T.,      and      Zhou,      Z.-H. Estimating      possi-  \n \n  ble      causal      effects      with      latent      variables      via      adjustment. In      Proceedings      of      the      40th      International      Conference      on  \n \n  Machine      Learning,      pp."
            },
            {
              "id": 1166,
              "title": "WA. - Chunk 133",
              "type": "chunk",
              "children": [],
              "content": "36308-36335,      2023a. Wang,      T.-Z.,      Qin,      T.,      and      Zhou,      Z.-H. Sound      and      complete  \n \n  causal      identification      with      latent      variables      given      local      back-  \n \n  ground      knowledge. Artificial      Intelligence,      322:103964,  \n \n  2023b. Wang,      T.-Z.,      Du,      W.-B.,      and      Zhou,      Z.-H. An      efficient      maxi-  \n \n  mal      ancestral      graph      listing      algorithm."
            },
            {
              "id": 1167,
              "title": "WA. - Chunk 134",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of  \n \n  the      41st      International      Conference      on      Machine      Learning,  \n \n  2024. Wiendbst,      M.,      Luttermann,      M.,      Bannach,      M.,      and       Liskiewicz,      M. Efficient      enumeration      of      markov      equiva-  \n \n  lent      dags. In      Proceedings      of      the      37th      AAAI      Conference  \n \n  on      Artificial      Intelligence,      pp. 12313-12320,      2023."
            },
            {
              "id": 1168,
              "title": "WA. - Chunk 135",
              "type": "chunk",
              "children": [],
              "content": "Witte,      J.,      Henckel,      L.,      Maathuis,      M. H.,      and      Didelez,      V. On      efficient      adjustment      in      causal      graphs. The      Journal      of  \n \n  Machine      Learning      Research,      21(1):9956—10000,      2020. Zhang,      J. On      the      completeness      of      orientation      rules      for  \n \n  causal      discovery      in      the      presence      of      latent      confounders  \n \n  and      selection      bias."
            },
            {
              "id": 1169,
              "title": "WA. - Chunk 136",
              "type": "chunk",
              "children": [],
              "content": "Artificial      Intelligence,      172(16-17):\n \n \n  1873-1896,      2008. Zhang,      K.,      Gong,      M.,      Stojanov,      P.,      Huang,      B.,      Liu,      Q.,      and       Glymour,      C. Domain      adaptation      as   \n \na      problem      of      inference  \n \n  on      graphical      models. In      Advances      in      Neural      Information  \n \n  Processing      Systems      33,      2020. A. Detailed      Preliminary\nA.1."
            },
            {
              "id": 1170,
              "title": "WA. - Chunk 137",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Graphs\n \n \n  In   \n \na      graph      G,      consider   \n \na      path      p   \n \n=      (Vi,      V2,---   \n \n,      Vx),      p      is   \n \na      directed      path      if      there      is      V;   \n \n>      Vizi,      V1      <i   \n \n<      k-—1;      pisa  \n \n  collider      path      if      there      is      V;_1*—      V;      <+*Vj41,      V2      <i   \n \n<   \n \nk   \n \n—      1;      p      is      minimal      if      any      two      non-consecutive      vertices      are      not  \n \n  adjacent."
            },
            {
              "id": 1171,
              "title": "WA. - Chunk 138",
              "type": "chunk",
              "children": [],
              "content": "A      vertex      Vj      is   \n \na      parent      of      V2      if      there      is      Vi   \n \n—      V2. V;      is      an      ancestor/descendant      of      V2      if      there      is   \n \na      directed      path  \n \n  from      V\\\\\\\\/V2      to      V2/V,. V,      is   \n \na      possible      ancestor/possible      descendant      of      V2      if      there      is   \n \na      possible      directed      path      from      V/V  \n \n  to      V2/V,."
            },
            {
              "id": 1172,
              "title": "WA. - Chunk 139",
              "type": "chunk",
              "children": [],
              "content": "Note      each      vertex      is      an      ancestor/descendant/possible      ancestor/possible      descendant      of      itself. An      edge      in      the      form  \n \n  of      o—o      is   \n \na      circle      edge. The      circle      component      of   \n \na      graph      G      is      the      subgraph      of      G   \n \n=      (V,E)      consisting      of      the      vertices V\n \n   and      all      the      circle      edges."
            },
            {
              "id": 1173,
              "title": "WA. - Chunk 140",
              "type": "chunk",
              "children": [],
              "content": "We      say      two      vertices      V;      and      V;      is   \n \na      connected      circle      component      in      G      if      there      is   \n \na      circle      path  \n \n  Vj;      0-0      ---      0-0      V;      from      V;      to      V;      in      G."
            },
            {
              "id": 1174,
              "title": "WA. - Chunk 141",
              "type": "chunk",
              "children": [],
              "content": "For      two      paths      p;   \n \n=      (Vi,      Vo,---   \n \n,      Va)      and      po   \n \n=      ($1,      S2,---   \n \n,      Sn),      we      use      pi   \n \n@      pe      to  \n \n  denote      the      concatenate      path      (Vi,---   \n \n,      Va,      S1,-+-   \n \n,      Sn)."
            },
            {
              "id": 1175,
              "title": "WA. - Chunk 142",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \na      path      V;   \n \n—      V2   \n \n>      ---   \n \n>      Vy      and      an      edge      Vg   \n \n—      V\\\\\\\\/Vq   \n \n+      V,,      then      there      is   \n \na      directed      cycle/almost      directed      cycle. For   \n \na      mixed      graph,      if      there      is      not   \n \na      directed      cycle      or      almost      directed      cycle,      then      it      is      ancestral."
            },
            {
              "id": 1176,
              "title": "WA. - Chunk 143",
              "type": "chunk",
              "children": [],
              "content": "For      an      ancestral      graph,      if      for  \n \n  any      two      non-adjacent      vertices,      there      is   \n \na      set      of      vertices      that      m-seperates      them,      then      the      graph      is      maximal. If   \n \na      mixed      graph      is  \n \n  both      ancestral      and      maximal,      it      is   \n \na      maximal      ancestral      graph      (MAG),      denoted      by      M."
            },
            {
              "id": 1177,
              "title": "WA. - Chunk 144",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is   \n \na      projection      graph      on      the      observable      variables      of      some      underlying      DAGs      containing      both      observable  \n \n  and      latent      variables."
            },
            {
              "id": 1178,
              "title": "WA. - Chunk 145",
              "type": "chunk",
              "children": [],
              "content": "|Spirtes      et      al.|      (2000);      [Zhang|      (2008)      presented      the      algorithm      to      obtain   \n \na      MAG      with      vertices   \n \nO      from   \n \na       DAG      with      vertices   \n \nO      UL      US,      where      O,      L,      S      denote      the      observable      vertices      set,      latent      vertices      set,      and      selection      vertices  \n \n  set."
            },
            {
              "id": 1179,
              "title": "WA. - Chunk 146",
              "type": "chunk",
              "children": [],
              "content": "Since      we      do      not      consider      selection      bias      in      this      paper,      we      do      not      consider      S      in      the      following. Next      we      show      inducing  \n \n  path      in      Def. 6,      followed      by      the      algorithm      to      obtain   \n \na      MAG      based      on   \n \na      DAG."
            },
            {
              "id": 1180,
              "title": "WA. - Chunk 147",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      algorithm,      as      the      number      of  \n \n  latent      vertices      can      be      arbitrary,      there      can      be      infinite      number      of      DAGs      which      could      lead      to      one      MAG      by      the      algorithm. Definition   \n \n6      (Inducing      path;      |Spirtes      et      al.|      (2000). Let      X,   \n \nY      be      two      vertices      in      an      maximal      ancestral      graph."
            },
            {
              "id": 1181,
              "title": "WA. - Chunk 148",
              "type": "chunk",
              "children": [],
              "content": "Denote      L,S  \n \n  two      disjoint      sets      of      vertices      that      X,   \n \nY      do      not      belong      to."
            },
            {
              "id": 1182,
              "title": "WA. - Chunk 149",
              "type": "chunk",
              "children": [],
              "content": "A      path      p      from   \n \nX      to   \n \nY      is      an      inducing      path      relative      to      (L,      S$)      if      every  \n \n  non-endpoint      vertex      on      p      is      either      in      L      or   \n \na      collider,      and      every      collider      on      p      is      an      ancestor      of      either      _X,      Y,      or   \n \na      member      of      S."
            },
            {
              "id": 1183,
              "title": "WA. - Chunk 150",
              "type": "chunk",
              "children": [],
              "content": "Input:   \n \na      DAG      D      over   \n \nV   \n \n=      OUL;  \n \n  Output:   \n \na      MAG      M      over      O."
            },
            {
              "id": 1184,
              "title": "WA. - Chunk 151",
              "type": "chunk",
              "children": [],
              "content": "(1)      for      each      pair      of      vertices      A,   \n \nB   \n \n€      O,   \n \nA      and   \n \nB      are      adjacent      in      M      if      and      only      if      there      is      an      inducing      path      relative      to      (L,      0)  \n \n  from   \n \nA      to   \n \nB      in      D;\n(2)      for      each      pair      of      adjacent      vertices      A,   \n \nB      in      M,      orient      the      edge      between   \n \nA      and   \n \nB      according      to      the      following      steps:\n(a)      orient      A>      Bin      M      if   \n \nA   \n \n€      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D);\n(b)      orient      A+      Bin      M      if   \n \nB   \n \n€      Anc(A,D)      and   \n \nA   \n \n¢      Anc(B,D);\n(c)      orient   \n \nA      Bin      M      if   \n \nA   \n \n¢      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D)."
            },
            {
              "id": 1185,
              "title": "WA. - Chunk 152",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      we      can      only      identify   \n \na      Markov      equivalence      class      (MEC)      of      MAGs,      which      is      represented      by   \n \na       partial      ancestral      graph      (PAG)      and      denoted      by      P."
            },
            {
              "id": 1186,
              "title": "WA. - Chunk 153",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      PAG,      there      is      an      arrowhead/tail      at      some      position      if      and      only      if      there      is  \n \n  an      arrowhead/tail      at      this      position      in      all      the      MAGs      in      the      MEC;      and      there      is   \n \na      circle      at      some      position      if      and      only      if      there      are  \n \n  both      arrowheads      and      tails      at      this      position      in      all      the      MAGs      in      the      MEC."
            },
            {
              "id": 1187,
              "title": "WA. - Chunk 154",
              "type": "chunk",
              "children": [],
              "content": "A.2. Preliminary      about      Orientation      Rules\n \n \n  Ali      et      al.|      (2005);      Zhang)      (2008)      proposed      ten      rules      7;   \n \n—      R40      to      identify   \n \na      PAG      with      observational      data."
            },
            {
              "id": 1188,
              "title": "WA. - Chunk 155",
              "type": "chunk",
              "children": [],
              "content": "Jaber      et      al.|      (2020)  \n \n  presented      the      solid      result      to      imply      that      when      there      is      additional      interventional      data      and      selection      bias      is      not      allowed      for,      the  \n \n  ten      rules      are      also      complete."
            },
            {
              "id": 1189,
              "title": "WA. - Chunk 156",
              "type": "chunk",
              "children": [],
              "content": "Another      study      (Andrews      et      al.|      /2020)      indicates      that      the      ten      rules      are      complete      if      we      incorporate  \n \n  tiered      background      knowledge,      which      means      that      the      BK      can      classify      the      variables      into      distinct      parts,      where      the      causal      order  \n \n  between      different      parts      is      explicit,      but      the      structural      information      within      each      part      cannot      be      directly      known      according      to      the  \n \n  BK."
            },
            {
              "id": 1190,
              "title": "WA. - Chunk 157",
              "type": "chunk",
              "children": [],
              "content": "Further,      when      we      have      obtained   \n \na      PAG      and      incorporate      local      background      knowledge      (local      BK),      i.e.,      the      full      structural  \n \n  knowledge      regarding      some      specific      variables,      Wang      et      al.|(2023b)      proposed   \n \na      rule      R4,      to      replace   \n \n4      and      an      additional      rule  \n \n  Ri."
            },
            {
              "id": 1191,
              "title": "WA. - Chunk 158",
              "type": "chunk",
              "children": [],
              "content": "|Wang      et      al.|      (2023b)      proved      that      the      rules      are      sound      and      complete      to      incorporate      local      BK      into   \n \na      PAG. We      show      these  \n \n  tules      in      the      following."
            },
            {
              "id": 1192,
              "title": "WA. - Chunk 159",
              "type": "chunk",
              "children": [],
              "content": "Since      R;   \n \n—      R7      are      triggered      only      if      the      selection      bias      is      involved      and      we      assume      the      absence      of  \n \n  selection      bias,      we      omit      these      three      rules. R1:      If      Ax>      Box      R,      and   \n \nA      and   \n \nR      are      not      adjacent,      then      orient      the      triple      as      Ax>      B—      R."
            },
            {
              "id": 1193,
              "title": "WA. - Chunk 160",
              "type": "chunk",
              "children": [],
              "content": "Reo:      If   \n \nA   \n \n>      Bx>      Ror      At>   \n \nB   \n \n>      R,      and   \n \nA      +~      R,      then      orient   \n \nA      «©      Ras      Ax>      R. Rs3:      If      Ax>      BorR,   \n \nA      x0      Do      R,   \n \nA      and   \n \nR      are      not      adjacent,      and      D      +o      B,      then      orient      D      *-o   \n \nB      as      Dx      B."
            },
            {
              "id": 1194,
              "title": "WA. - Chunk 161",
              "type": "chunk",
              "children": [],
              "content": "Ra: If (k,,A,B, R) is a discriminating path between K and R for B, and B o-* R; then if B € Sepset(K, R),  \n \n  orient   \n \nB      o-«      -R      as   \n \nB   \n \n+      R;      otherwise      orient      the      triple      (A,      B,      R)      as   \n \nA      Bo      R. Res:      If   \n \nA   \n \nB      —-      R,      and      Ao>      R,      orient      Ao>      Ras      A-      R."
            },
            {
              "id": 1195,
              "title": "WA. - Chunk 162",
              "type": "chunk",
              "children": [],
              "content": "Ro: If Ao R, and p = (A, B, D,, R) is an uncovered possible directed path from A to R such that R and B are  \n \n  not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R. Rio:      Suppose      Ao>      R,   \n \nB   \n \n+   \n \nR   \n \n«      D,      p;      is      an      uncovered      possible      directed      path      from   \n \nA      to      B,      and      pz      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to      D."
            },
            {
              "id": 1196,
              "title": "WA. - Chunk 163",
              "type": "chunk",
              "children": [],
              "content": "Let   \n \nU      be      the      vertex      adjacent      to   \n \nA      on      p;      (U      could      be      B),      and      W      be      the      vertex  \n \n  adjacent      to   \n \nA      on      pz      (W      could      be      D). If   \n \nU      and      W      are      distinct,      and      are      not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R."
            },
            {
              "id": 1197,
              "title": "WA. - Chunk 164",
              "type": "chunk",
              "children": [],
              "content": "Ri:      If      (K,---   \n \n,      A,      B,      R)      is   \n \na      discriminating      path      between   \n \nK      and   \n \nR      for      B,      and   \n \nB      o-*      R,      then      orient      Bo-*«      Ras   \n \nB   \n \n>      R. Ri:      If      A-©B,      then   \n \nA   \n \n>      B. A.3."
            },
            {
              "id": 1198,
              "title": "WA. - Chunk 165",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Causal      Effect      Estimation\nDefinition   \n \n7      (Adjustment      set;      Pearl]      (2009);      /van      der      Zander      et      al|      (2014)."
            },
            {
              "id": 1199,
              "title": "WA. - Chunk 166",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      DAG,      MAG,      or      PAG      G,,   \n \nZ      is      an      adjustment  \n \n  set      relative      to      (X,Y)      if      for      any      probability      density      f      compatible      with      G,      the      causal      effect      of   \n \nX      on   \n \nY (YX),      ifZ      =,  \n \n  P(Y|do(X))   \n \n=   \n \n|      poet      P(Y|Z,      X)P(Z)dZ,   \n \n_      otherwise."
            },
            {
              "id": 1200,
              "title": "WA. - Chunk 167",
              "type": "chunk",
              "children": [],
              "content": "©\n \n \n  Maathuis      et      al.|      (2015);      |Perkovic      et      al.|(2017b)      presented      the      necessary      and      sufficient      graphical      characterization      for      the      causal  \n \n  effect      identifiablility      via      covariate      adjustment      given   \n \na      DAG/CPDAG/MAG/PAG. We      show      them      in      Prop. 4]      See      Maathuis  \n \n  et      al.|      (2015)      for      the      notation      Gx."
            },
            {
              "id": 1201,
              "title": "WA. - Chunk 168",
              "type": "chunk",
              "children": [],
              "content": "At      first,      we      introduce      an      important      concept      D-SEP(X,      Y,      G)      in      Def.|8}      D-SEP(X,      Y,      G)  \n \n  is      essentially   \n \na      set      of      vertices. Definition   \n \n8      (D-SEP(X,      Y,      G);|Spirtes      et      al.|(2000)). Let   \n \nX      and   \n \nY      be      two      distinct      vertices      in   \n \na      mixed      graph      G."
            },
            {
              "id": 1202,
              "title": "WA. - Chunk 169",
              "type": "chunk",
              "children": [],
              "content": "We      say  \n \n  that   \n \nV   \n \n€      D-SEP(X,      Y,      G)      if   \n \nV   \n \n4      X,      and      there      is   \n \na      collider      path      between   \n \nX      and   \n \nV      in      G,      such      that      every      vertex      on      this      path  \n \n  (including      V)      is      an      ancestor      of   \n \nX      or   \n \nY      inG. Proposition   \n \n4      (Maathuis      et      al.|      (2015);      Perkovic      et      al.|(2017b))."
            },
            {
              "id": 1203,
              "title": "WA. - Chunk 170",
              "type": "chunk",
              "children": [],
              "content": "Let      G      be   \n \na      MAG      or      PAG,      and   \n \nX      and   \n \nY      be      two      distinct  \n \n  vertices      in      G. There      exists      an      adjustment      set      relative      to      (X,Y)      in      G      ifand      only      ifY   \n \n¢      Adj(X,      Gx)      and      D-SEP(X,      Y,Gx)N  \n \n  PossDe(X,      G)   \n \n=      9."
            },
            {
              "id": 1204,
              "title": "WA. - Chunk 171",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      if      an      adjustment      set      exists,      then      D-SEP(X,      Y,      Gx)      is      such   \n \na      set. Denote      D-SEP(X,      Y,      Gx)  \n \n  by      D,      then f(V      |do(X      =f      f(D)      f(V|D,   \n \nX      =a)      dD. (2) B. A      Detailed      Introduction      to      PAGcauses      (Wang      et      al."
            },
            {
              "id": 1205,
              "title": "WA. - Chunk 172",
              "type": "chunk",
              "children": [],
              "content": "2023a)\n \n \n  In      this      part,      we      introduce      the      method      PAGcaused      to      determine      the      set      of      possible      causal      effects      given   \n \na      PAG,      which      is  \n \n  proposed      by      |Wang      et      al. (2023a). We      first      show      some      theoretical      results      of      Wang      et      al. (2023a). Some      of      these      results      are  \n \n  needed      in      our      proof."
            },
            {
              "id": 1206,
              "title": "WA. - Chunk 173",
              "type": "chunk",
              "children": [],
              "content": "The      first      important      result      is      Prop. 5}      It      provides   \n \na      graphical      characterization      for      the      adjustment      set      comprised      of      observable  \n \n  variables      in      all      the      DAGs      represented      by   \n \na      given      MAG."
            },
            {
              "id": 1207,
              "title": "WA. - Chunk 174",
              "type": "chunk",
              "children": [],
              "content": "It      implies      that      there      exists   \n \na      DAG      where      the      causal      effect      of   \n \nX       on   \n \nY      is      identifiable      by      covariate      adjustment      and      the      adjustment      set      is      comprised      of      some      observable      variables      if      and      only  \n \n  if      D-SEP(X,      Y,      Mx)      De(X,      M)   \n \n=      0,      and      D-SEP(X,      Y,      Mx)      is      the      adjustment      set."
            },
            {
              "id": 1208,
              "title": "WA. - Chunk 175",
              "type": "chunk",
              "children": [],
              "content": "Hence,      given   \n \na      MAG      M,      we      can determine      whether      there      exists      some      DAG      where      the      causal      effect      is      identifiable      by      adjusting      for      observable      variables  \n \n  without      the      need      the      enumerate      the      DAGs. And      for      all      the      DAGs      above,      they      are      associated      with      the      same      causal      effect. Proposition      5."
            },
            {
              "id": 1209,
              "title": "WA. - Chunk 176",
              "type": "chunk",
              "children": [],
              "content": "Suppose   \n \na      MAG      M      where   \n \nX   \n \n©      Anc(Y,      M). There      exists   \n \na      DAG      D      represented      by      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      in      D      can      be      identified      by      adjusting      for   \n \na      set      comprised      of      V(M)      if      and      only      if      D-SEP(X,      Y,      Mx)   \n \n9 De(X,      M)   \n \n=      @."
            },
            {
              "id": 1210,
              "title": "WA. - Chunk 177",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      such   \n \na      set      exists,      D-SEP(X,      Y,      Mx)      is      an      adjustment      set."
            },
            {
              "id": 1211,
              "title": "WA. - Chunk 178",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the      following,      when we      say      an      adjustment      set      in      M,      it      means      the      adjustment      set      in      the      DAGs      represented      by      the      MAG      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      can      be      identified      by      adjusting      for      this      adjustment      set. According      to      Prop."
            },
            {
              "id": 1212,
              "title": "WA. - Chunk 179",
              "type": "chunk",
              "children": [],
              "content": "5,      when      addressing      the      set      determination      task      for      the      causal      effect      of   \n \nX      on      Y,      we      only      need      to      consider  \n \n  the      MAG      in      the      MEC      presented      by      ?,      without      the      need      to      consider      the      DAGs."
            },
            {
              "id": 1213,
              "title": "WA. - Chunk 180",
              "type": "chunk",
              "children": [],
              "content": "Considering      there      are      many      circles      ina      PAG  \n \n  P,      PAGcauses      considers      transforming      the      circles      of   \n \nX      at      first."
            },
            {
              "id": 1214,
              "title": "WA. - Chunk 181",
              "type": "chunk",
              "children": [],
              "content": "They      use   \n \na      set      of      vertices      C      to      represent   \n \na      local      transformation  \n \n  of      X,      i.e.,      transform   \n \nX      o*   \n \nV      to   \n \nX      <«V      if   \n \nV   \n \n€      C      and      transform   \n \nX      o*«   \n \nV      to   \n \nX      -*«V      if   \n \nV   \n \n€      {V   \n \n€      V(P)|X      o*   \n \nV      in      P}\\\\\\\\C."
            },
            {
              "id": 1215,
              "title": "WA. - Chunk 182",
              "type": "chunk",
              "children": [],
              "content": "An      important      problem      here      is      to      evaluate      the      validity      of      each      local      transformation,      i.e.,      whether      there      is   \n \na      MAG      consistent  \n \n  with      this      local      transformation      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1216,
              "title": "WA. - Chunk 183",
              "type": "chunk",
              "children": [],
              "content": "For      this      purpose,      they      presented   \n \na      graphical      characterization  \n \n  for      the      valid      local      transformation      of   \n \nX      implied      by      C      given      the      PAG      P,      which      is      shown      in      Prop. 6,      The      three      conditions      in  \n \n  Prop. (6|      can      be      evaluated      in      O(d?),      where      d      denotes      the      number      of      vertices. In      Prop."
            },
            {
              "id": 1217,
              "title": "WA. - Chunk 184",
              "type": "chunk",
              "children": [],
              "content": "(6      the      concept      of      bridged      is      involved, which      is      shown      in      Def. 9       Definition   \n \n9      (Bridged      relative      to      V’      in      H;      |Wang      et      al.||2023a). Let      H      be   \n \na      partial      mixed      graph. Denote      H’   \n \na      subgraph  \n \n  of      H      induced      by   \n \na      set      of      vertices      K."
            },
            {
              "id": 1218,
              "title": "WA. - Chunk 185",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      V’      in      H      that      is      disjoint      of      K,      two      vertices   \n \nA      and   \n \nB       in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V\\\\\\'      if      either   \n \nA   \n \n=   \n \nB      or      in      each      minimal      circle      path  \n \n  A(=      Vo)      o-0      Vj      o-0---      0-0      V,,      o-0      B(=      V,,41)      from   \n \nA      to   \n \nB      in      H’,      there      exists      one      vertex      V;,0   \n \n<      s   \n \n<      n+      1,      such      that  \n \n  Fy,   \n \n©      Fv,,,,0<i<s—land      Fy,,,      C      Fy,,s      <i      <n,      where      Fy,   \n \n=      {V   \n \n€      V’   \n \n|   \n \nV      +0      V;      or      Vx>      V;      in      H}."
            },
            {
              "id": 1219,
              "title": "WA. - Chunk 186",
              "type": "chunk",
              "children": [],
              "content": "Further,  \n \n  H\\\\\\'      is      bridged      relative      to      V’      in      H      if      any      two      vertices      in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V’. Proposition      6."
            },
            {
              "id": 1220,
              "title": "WA. - Chunk 187",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG      P,      for      any      set      of      vertices      C      C      {V   \n \n|   \n \nX      o-*   \n \nV      in      P},      there      exists   \n \na      MAG      M      consistent      with      P       with   \n \nX      +*V,      VV   \n \n€      Cand   \n \nX   \n \n>      V,VV   \n \n€      {V   \n \n|   \n \nX      o«V      in      P}\\\\\\\\C      ifand      only      if\n(1)      PossDe(X,      P{[—C])      N      Pa(C,      P)   \n \n=      0;\n(2)      the      subgraph      P|C]      of      P      induced      by      C      is   \n \na      complete      graph;\n(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P\n \n{   \n \nX      }]      is      bridged      relative      to      C   \n \nU      {X}      in      P."
            },
            {
              "id": 1221,
              "title": "WA. - Chunk 188",
              "type": "chunk",
              "children": [],
              "content": "After      incorporating   \n \na      valid      local      transformation      into      the      PAG      ?,      [Wang      et      al.|(2023a)      used      the      sound      and      complete      orientation  \n \n  rules      Ry   \n \n—      R3,R4,Rz   \n \n—      Rio,      R11      to      further      update      the      graph. And      the      obtained      graph      is      called      by      maximal      local      MAG,  \n \n  denoted      by      M."
            },
            {
              "id": 1222,
              "title": "WA. - Chunk 189",
              "type": "chunk",
              "children": [],
              "content": "By      incorporating      different      valid      local      transformations,      PAGcauses      can      obtain      different      maximal      local      MAGs. However,      determining   \n \na      maximal      local      MAG      M      is      not      sufficient      for      determining      the      only      adjustment      set      in      all      the      MAGs  \n \n  consistent      with      MI."
            },
            {
              "id": 1223,
              "title": "WA. - Chunk 190",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      established      the      graphical      characterization      for      the      adjustment      set      in      the      MAGs      consistent  \n \n  with      M      in      Prop. 2)and      Prop. {7}      Both      Prop. [2]and      Prop."
            },
            {
              "id": 1224,
              "title": "WA. - Chunk 191",
              "type": "chunk",
              "children": [],
              "content": "[/]ensure      that      PAGcauses      can      find      the      same      set      of      causal      effects      given  \n \n  M      as      methods      to      enumerate      all      the      MAGs      consistent      with      M. Proposition      7. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y)."
            },
            {
              "id": 1225,
              "title": "WA. - Chunk 192",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1226,
              "title": "WA. - Chunk 193",
              "type": "chunk",
              "children": [],
              "content": "Then      W      is   \n \na      potential      adjustment      set      in      M      and      there      exists   \n \na      block set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      V’      inM};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M\nM."
            },
            {
              "id": 1227,
              "title": "WA. - Chunk 194",
              "type": "chunk",
              "children": [],
              "content": "With      the      results      above,      they      proposed      their      method      PAGcauses      in      Alg. A}  \n \n  In      the      proof      of      Prop. |2}      if      the      three      conditions      are      satisfied,      they      present      an      algorithm      to      construct   \n \na      MAG      consistent      with      M       such      that      the      adjustment      set      is      W. We      show      the      algorithm      in      Alg."
            },
            {
              "id": 1228,
              "title": "WA. - Chunk 195",
              "type": "chunk",
              "children": [],
              "content": "[5}  \n \n  3\nAlgorithm      4:      PAGcauses Input:      PAG      P,      X,Y  \n \n  AS(P)      =0)      //      Record      all      the      valid      adjustment      sets;\n      if      X      ¢      PossAn(Y,      ?)      then      return      No      causal      effects;       if      the      conditions      in      Prop.\\\\\\\\4      Hare      satisfied      for      P      then       |      return      AS(P)      +      {D-SEP(X,      Y,      Px)}      //      Prop."
            },
            {
              "id": 1229,
              "title": "WA. - Chunk 196",
              "type": "chunk",
              "children": [],
              "content": "[4       4       5       6       7       8       9       10       11 for      each      setC      C{V      |      V      «0      X      in      P}      do       if      the      three      conditions      in      Prop. (dare      satisfied      then       Obtain      a      maximal      local      MAG      M      based      on      P      and      C;       Find      all      potential      adjustment      sets      W,,      W2,---      given      M      according      to      Def."
            },
            {
              "id": 1230,
              "title": "WA. - Chunk 197",
              "type": "chunk",
              "children": [],
              "content": "for      each      potential      adjustment      set      W;,      do       for      each      block      set      S      do       if      the      three      conditions      in      Prop."
            },
            {
              "id": 1231,
              "title": "WA. - Chunk 198",
              "type": "chunk",
              "children": [],
              "content": "2Jare      satisfied      given      S      then AS(P)      +      AS(P)      U      {Wi}: 12       13 break      //      Break      the      loop      of      S;       Output:      Set      of      causal      effects      via      adjustment      in      the      given      PAG      P      identified      with      AS(P)      by      (i)\nAlgorithm      5:      Orient   \n \na      maximal      local      MAG      of   \n \nX      as   \n \na      MAG  \n \n  input:      Maximal      local      MAG      M,      potential      adjustment      set      W      and      corresponding      W      according      to      Def."
            },
            {
              "id": 1232,
              "title": "WA. - Chunk 199",
              "type": "chunk",
              "children": [],
              "content": "2}      PI      block      set      S       1:      for      VK   \n \n€      PossDe(W,      M[—S])      and      VT   \n \n€      S      such      that   \n \nK      o~*   \n \nT      in      M,      orient      it      as   \n \nK      <+*T\\\\\\'      (the      mark      at   \n \nT      remains);  \n \n  2:      update      the      subgraph      M[PossDe(W,      M[—S])]      as      follows      until      no      feasible      updates:      for      any      two      vertices      V;      and      V;      such  \n \n  that      V;      0-0      V;,      orient      itas      V;   \n \n+      V;      if      (1)      Fy,      \\\\\\\\Fv;   \n \n#      or      (2)      Fy,   \n \n=      Fy,      as      well      as      there      is   \n \na      vertex  \n \n  V;,   \n \n€      PossDe(W,      M[—S})      not      adjacent      to      V;      such      that      V;,   \n \n>      V;      o-o      V;,      where      Fy,   \n \n=      {V   \n \n€      S|   \n \nV      +0      V;      in      M};  \n \n  3:      orient      the      circles      on      the      remaining      o—      edges      as      tails;  \n \n  4:      in      subgraph      M[PossDe(W,      M[—S])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders;  \n \n  5:      in      subgraph      M[—PossDe(W,      M[-S]])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders."
            },
            {
              "id": 1233,
              "title": "WA. - Chunk 200",
              "type": "chunk",
              "children": [],
              "content": "output:   \n \nA      MAG      M\n[I]  \n \n  Suppose      there      are      m      edges      and      d      vertices      in      H. There      are      m      edges      that      can      be      transformed. Hence      the      round      of      loop      is  \n \n  O(m). In      each      round,      suppose      we      want      to      detect      whether   \n \nA      o-*«   \n \nB      can      be      transformed      by      Ry2      or      R13."
            },
            {
              "id": 1234,
              "title": "WA. - Chunk 201",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  Line   \n \n2      and      Line   \n \n3      is      O(d). And      determining      the      set      Anc(S      4,      H)      takes   \n \na      O(md)      complexity. Executing      Line   \n \n7      and      Line   \n \n9       take   \n \na      O(m)      complexity. And      the      complexity      of      Line   \n \n8      is      O(m). Hence      the      complexity      of      Alg. [lis      O(m?3),. roof\nD.1. Proof      of      Proposition\nC."
            },
            {
              "id": 1235,
              "title": "WA. - Chunk 202",
              "type": "chunk",
              "children": [],
              "content": "Complexity      Analysis      of      Algorithm      [I]\n[I]\nD. Proof\nroof\n \n \n  Then      we      prove      that      if      Alg. [I]      transforms      an      edge   \n \nA      o-*«   \n \nB      to   \n \nA      +*B      on      Line      9,      then      R42      can      be      triggered. Since      the      rigorous  \n \n  proof      is      somewhat      tedious,      we      just      show   \n \na      proof      sketch      here. If      Alg."
            },
            {
              "id": 1236,
              "title": "WA. - Chunk 203",
              "type": "chunk",
              "children": [],
              "content": "[I]transforms      an      edge   \n \nA      o-   \n \nB      to   \n \nA      +*B      on      Line      9,  \n \n  then      there      is      an      unshielded      collider      formed      in      H’      on      Line      8. In      this      case,      according      to      the      proof      idea      of      Lemma   \n \n5      of      [Wang  \n \n  et      al.|(2023a)),      we      can      prove      that      H[D]      is      not      bridged      relative      to      S4."
            },
            {
              "id": 1237,
              "title": "WA. - Chunk 204",
              "type": "chunk",
              "children": [],
              "content": "Then,      we      will      prove      that      there      is      an      unbridged      path      in  \n \n  H[D|      relative      to      S      4. Suppose      there      is   \n \na      minimal      path      p   \n \n=      Vo      o-0---o-o      V,,41      in      H[D]      where      there      is      not   \n \na      vertex      V,      such      that      Fy,      C      Fy,      yO  \n \n  i<s—landfy,,,      C      Fy,,8      <i      <n."
            },
            {
              "id": 1238,
              "title": "WA. - Chunk 205",
              "type": "chunk",
              "children": [],
              "content": "As      Line   \n \n9      is      triggered,      no      vertex      in      D      belongs      to      Anc(S.,      H). Hence      if      there      is  \n \n  some      vertex   \n \nV   \n \n¢      Fy,,   \n \nV      is      not      adjacent      to      V;. Next,      we      consider      the      path      p. We      discuss      whether      Fy,      \\\\\\\\Fv,   \n \n=      0. If      empty,      we  \n \n  consider      whether      Fy,      \\\\\\\\Fy,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1239,
              "title": "WA. - Chunk 206",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process      above      until      we      find      the      first      index   \n \nj      such      that      Fy,\\\\\\\\Fv,,,   \n \n4      9."
            },
            {
              "id": 1240,
              "title": "WA. - Chunk 207",
              "type": "chunk",
              "children": [],
              "content": "Note      such   \n \n7      must      exist,      for      otherwise,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +:   \n \n©      Fy,,,,      in      which      case      there      is      s   \n \n=      n+1  \n \n  such      that      Fy,   \n \n©      Fy,,,,0      <7      <s—land      fy,,,   \n \n©      Fy,,8      <7   \n \n<      n,      contradiction. Then,      we      consider      the      sub-path  \n \n  V;      0-0      ---      0-0      V4."
            },
            {
              "id": 1241,
              "title": "WA. - Chunk 208",
              "type": "chunk",
              "children": [],
              "content": "Note      according      to      the      process      above,      there      is      Fy,      C      Fy,      C      Fy,   \n \n©      +++   \n \n©      Fy,      and      Fy,      \\\\\\\\FVja1      #. Then,      we      consider      whether      Fy,      ,,\\\\\\\\Fv,,   \n \n=      9. If      empty,      we      consider      whether      Fy,      \\\\\\\\Fy,,_,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1242,
              "title": "WA. - Chunk 209",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process  \n \n  above      until      we      find      the      first      index   \n \n&      such      that      Fy,      \\\\\\\\Fy,_,   \n \n4      @. Similar      to      the      proof      above,      such      index   \n \nk      must      exist. And       there      is      Fy,      D2      Fy,,,      2---   \n \n2      Fv,,,      and      Fy,_,   \n \n#      0. Next      we      discuss      the      relationship      between   \n \nj      and      k."
            },
            {
              "id": 1243,
              "title": "WA. - Chunk 210",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove  \n \n  the      impossibility      of   \n \nk   \n \n<      j. Suppose   \n \nk   \n \n<      7."
            },
            {
              "id": 1244,
              "title": "WA. - Chunk 211",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      result      above,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +++   \n \n©      Fy,      and       Fv,      »)      F      Views      Des      D      F      Vina      Hence,      there      is      Fy,      C      Fy,      C      Fy,      rae      Fy,   \n \n=      FV      nas      See   \n \n=      Fy,      DD      FVngt:      In  \n \n  this      case,      there      is      s   \n \n=   \n \n7      such      that      Fy,      C      Fy,,,,0      <i<s—Jland      Fy,,,      C      Fy,,8      <i      <n,      contradiction."
            },
            {
              "id": 1245,
              "title": "WA. - Chunk 212",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is  \n \n  k   \n \n>   \n \nj      +1. In      this      case,      there      is   \n \na      minimal      path      V;      0-0      Vj,      0-0      ---      o-o      Vj,      such      that      Fy,\\\\\\\\Fy,,,   \n \n#   \n \nO      and      Fy,\\\\\\\\Fy,_,      #0  \n \n  in      H[D]. It      is      an      unbridged      path      relative      to      S.4      in      H[D]."
            },
            {
              "id": 1246,
              "title": "WA. - Chunk 213",
              "type": "chunk",
              "children": [],
              "content": "And      since      there      are      an      uncovered      possible      directed      paths      from   \n \nA      to      any      vertice      in      D      and      at      the      same      time   \n \nB      is      the      vertex  \n \n  adjacent      to   \n \nA      in      the      paths,      7212      can      be      triggered      to      transform   \n \nA      o-«   \n \nB      to   \n \nA      +*B. The      proof      completes. O\nD.2. Proof      of      Theorem[I]\nProof."
            },
            {
              "id": 1247,
              "title": "WA. - Chunk 214",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      the      soundness      of      7213,      then      prove      the      soundness      of      R12. For      R13,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B. It      is      evident      that      the      uncovered      path      is   \n \nA   \n \n>   \n \nB   \n \n>      --. —      K."
            },
            {
              "id": 1248,
              "title": "WA. - Chunk 215",
              "type": "chunk",
              "children": [],
              "content": "According  \n \n  to      the      definition      of      S   \n \n,      and      the      conditions      in      713,      there      must      be   \n \na      vertex      C\\\\\\'   \n \n€      Sy      such      that      thereis      C+>      A—>---K      >---C,  \n \n  which      contradicts      with      the      ancestral      property,      contradiction. For      R12,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B."
            },
            {
              "id": 1249,
              "title": "WA. - Chunk 216",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      condition      of      R12,      it      is      evident      that      for      each      vertex  \n \n  K;,1      <4      <m,      there      is   \n \na      minimal      directed      path   \n \nA   \n \n>   \n \nB   \n \n>      ---   \n \n+      K;      in      M."
            },
            {
              "id": 1250,
              "title": "WA. - Chunk 217",
              "type": "chunk",
              "children": [],
              "content": "And      for      any   \n \nT   \n \n€      S,4      and      K;j,1      <<i<m  \n \n  such      that      there      is      an      edge      between   \n \nT      and      K;      in      the      PMG      H,      there      must      be      Tx—      K;      in      M,      for      otherwise      there      is  \n \n  A>      B-.-.—      K;   \n \n~      T*>      A,      contradicting      with      ancestral      property. According      to      Def."
            },
            {
              "id": 1251,
              "title": "WA. - Chunk 218",
              "type": "chunk",
              "children": [],
              "content": "[I]      there      is      an      unbridged      path  \n \n  p:      K,      0-0      Ky      0-0---o-0      K,,,      such      that      Fx,      \\\\\\\\Fr,      #0      and      Fr,,\\\\\\\\Fr,,_,      #0. Suppose      Cy   \n \n€      Fx,\\\\\\\\F      x,      and      C2   \n \n€      Fx,,\\\\\\\\Fx,,,_,-      If      Ci      is      adjacent      to      Ko,      as      Cy   \n \n¢      Fx,,      there      is      Ky   \n \n—      C,      in      H."
            },
            {
              "id": 1252,
              "title": "WA. - Chunk 219",
              "type": "chunk",
              "children": [],
              "content": "In      this  \n \n  case      there      must      be   \n \nA      +«*B      according      to      R43,      the      soundness      of      which      has      been      proven. Thus   \n \nA   \n \n—   \n \nB      and      that      C{      is      adjacent  \n \n  to      K2      are      impossible. In      the      following,      we      consider      the      case      that      C\\\\\\';      is      not      adjacent      to      K2      and      C2      is      not      adjacent      to      K,,_}."
            },
            {
              "id": 1253,
              "title": "WA. - Chunk 220",
              "type": "chunk",
              "children": [],
              "content": "We      have      shown      before      that      if      there      is      an      edge   \n \nA   \n \n>   \n \nB      in      M,      there      must      be      C)*>      Ky      and      C2*—>      K,,      in      M."
            },
            {
              "id": 1254,
              "title": "WA. - Chunk 221",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,  \n \n  no      matter      how      we      transform      the      circles      in      C,+—3      Ky      0-0      Ky      0-0      ---      0-0      K,,      <+Co,      there      will      be   \n \na      new      unshielded      collider  \n \n  in      M,      which      contradicts      with      the      fact      that      M      is      consistent      with      H. O\nD.3."
            },
            {
              "id": 1255,
              "title": "WA. - Chunk 222",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Theorem      [Z|\n \n \n  Proof      of      Theorem{2|      Note      the      graph      M      is      updated      in      every      round      of      Alg. 2]      To      distinguish      them,      we      use      M,      to      denote  \n \n  the      graph      obtained      after      Line   \n \n5      of      Alg. /2}in      the      7-th      round. Denote      M      the      original      maximal      local      MAG."
            },
            {
              "id": 1256,
              "title": "WA. - Chunk 223",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the  \n \n  whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      i,      Anc(Y,M;)   \n \n=      Anc(Y,M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nT      rounds      in      Alg."
            },
            {
              "id": 1257,
              "title": "WA. - Chunk 224",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge      A;      «+S;      is      transformed      by      Rj2      on      Line   \n \n6      of      Alg. [2](A;      just      denotes      any   \n \na      vertex),      and      thus  \n \n  Anc(5;,      M;)   \n \n9   \n \nT      is      incorporated      to      S      on      Line   \n \n7      of      Alg."
            },
            {
              "id": 1258,
              "title": "WA. - Chunk 225",
              "type": "chunk",
              "children": [],
              "content": "Since      the      algorithm      returns   \n \na      set      of      vertices      S      after      T’      rounds,      according      to      Line      4,      6,      and   \n \n9      of      Alg."
            },
            {
              "id": 1259,
              "title": "WA. - Chunk 226",
              "type": "chunk",
              "children": [],
              "content": "2}      we      conclude  \n \n  that      (1)      M7[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V\\\\\\'   \n \n©      S|V      o-*      VlorV      <#V’      in      Mr},      (2)  \n \n  PossDe(W,      Mr[—S])   \n \n7      Pa(S,      Mr)   \n \n=      @,      (3)      there      is      no      unbridged      path      relative      to      S      in      M7|PossDe(W,      Mr[—S])]."
            },
            {
              "id": 1260,
              "title": "WA. - Chunk 227",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  will      prove      that      the      three      conditions      in      Prop. 2Jare      satisfied      given      the      set      S,      thus      we      can      conclude      the      desired      result      by      Prop."
            },
            {
              "id": 1261,
              "title": "WA. - Chunk 228",
              "type": "chunk",
              "children": [],
              "content": "[2\n(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}\n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      Vor   \n \nV      ¢*V’      in      M}. In  \n \n  the      process      of      Alg."
            },
            {
              "id": 1262,
              "title": "WA. - Chunk 229",
              "type": "chunk",
              "children": [],
              "content": "2}      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads,      hence      M[Sy]   \n \n=      M,[Sy]      for      any   \n \nV   \n \n€      W. Hence      given      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W."
            },
            {
              "id": 1263,
              "title": "WA. - Chunk 230",
              "type": "chunk",
              "children": [],
              "content": "(2)      We      will      prove      that      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      0. Suppose   \n \nA   \n \n=      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)."
            },
            {
              "id": 1264,
              "title": "WA. - Chunk 231",
              "type": "chunk",
              "children": [],
              "content": "Without      loss  \n \n  of      generality,      suppose      there      is   \n \nV   \n \n€      W      and   \n \na      minimal      possible      directed      path      p   \n \n=      (V,      Ji,---   \n \n,      Jz,      A)      from   \n \nV      to   \n \nA      in      M      such  \n \n  that      each      non-endpoint      in      p      does      not      belong      to      W      (If      there      is      V’   \n \n€      W      in      the      path      p,      we      consider      V’      instead      of   \n \nV      and      the  \n \n  sub-path      from      V’      to   \n \nA      instead      of      p)."
            },
            {
              "id": 1265,
              "title": "WA. - Chunk 232",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the      process      of      Alg.|2|      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads  \n \n  on      the      edges      connecting      W      and      S. Hence,      since      p      is      not   \n \na      minimal      possible      directed      path      in      My,      and      each      non-endpoint  \n \n  does      not      belong      to      W,      there      must      be      J,   \n \n€      S."
            },
            {
              "id": 1266,
              "title": "WA. - Chunk 233",
              "type": "chunk",
              "children": [],
              "content": "However,      in      this      case      the      path      p      is      not      in      M[—S]      since      J,   \n \n€      S,      contradiction. Hence      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9. (3)      We      will      prove      that      there      is      no      unbridged      path      relative      to      S      in      M[PossDe(W,      M[-—S])}. Note      in      the      process      of      Alg."
            },
            {
              "id": 1267,
              "title": "WA. - Chunk 234",
              "type": "chunk",
              "children": [],
              "content": "2|      we\n \n \n  only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads      on      the      edges      connecting      W      and      S."
            },
            {
              "id": 1268,
              "title": "WA. - Chunk 235",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      there      is      an      unbridged  \n \n  path      relative      to      S      in      M,      this      path      still      exists      in      Mr      since      each      vertex      in      this      path      cannot      belong      to      S,      which      concludes      that  \n \n  M-[PossDe(W,      Mr[—S])]      is      not      bridged      relative      to      S      in      Mr,      contradiction."
            },
            {
              "id": 1269,
              "title": "WA. - Chunk 236",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is      no      unbridged      path      relative      to      S       in      M[PossDe(W,      M[—S})],      that      is,      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M      according      to      Def. (o}      0\nD.4. Proof      of      Theorem      B]\n \n \n  The      proof      relied      on      some      results      by      {Wang      et      al.|      (2023a))."
            },
            {
              "id": 1270,
              "title": "WA. - Chunk 237",
              "type": "chunk",
              "children": [],
              "content": "We      first      present      two      supporting      results      in      Lemma[I]and      Lemma]  \n \n  Lemma      [2]      implies      that      if      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in   \n \na      maximal      local      MAG      M,      then      we      can      find   \n \na       minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma   \n \n1      (Wang      et      al.|(2023a))."
            },
            {
              "id": 1271,
              "title": "WA. - Chunk 238",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      obtained      from   \n \na      PAG      P      and   \n \na      valid      local      transformation  \n \n  of   \n \nX      represented      by      C,      the      following      properties      are      satisfied:\n(Invariant)      The      arrowheads      and      tails      in      M      are      invariant      in      all      the      MAGs      consistent      with      P      and      the      local      transformation  \n \n  of   \n \nX      represented      by      C;\n(Chordal)      the      circle      component      in      M      is      chordal;\n \n \n  (Balanced)      for      any      three      vertices      A,      B,C      in      M,      if      Ax—   \n \nB      o-*      C,      then      there      is      an      edge      between   \n \nA      and      C      with      an  \n \n  arrowhead      at      C’,      namely,      Ax      C."
            },
            {
              "id": 1272,
              "title": "WA. - Chunk 239",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      the      edge      between   \n \nA      and   \n \nB      is   \n \nA   \n \n—      B,      then      the      edge      between   \n \nA      and       C      is      either   \n \nA      C      or      Ao      C      (i.e,      itis      not      A&C);\n(Complete)      for      each      circle      at      vertex   \n \nA      on      any      edge   \n \nA      o-*   \n \nB      in      M,      there      exist      MAGs      M,      and      Mg      consistent      with      M       with   \n \nA      +*B   \n \n€      E(M,)      and      A>      BE      E(Mg);\n(P6)      we      can      always      obtain   \n \na      MAG      consistent      with      P      and      the      local      transformation      of   \n \nX      represented      by      C,      by  \n \n  transforming      the      circle      component      into   \n \na      DAG      without      unshielded      colliders      and      transforming      Ao>      Bas   \n \nA   \n \n>      B."
            },
            {
              "id": 1273,
              "title": "WA. - Chunk 240",
              "type": "chunk",
              "children": [],
              "content": "Lemma   \n \n2      (Wang      et      al.|      (2023a)). Consider   \n \na      maximal      local      MAG      MA. If      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in      M,  \n \n  then      there      is   \n \na      minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma      3."
            },
            {
              "id": 1274,
              "title": "WA. - Chunk 241",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y). Let      W      be      D-SEP(X,Y,      Mx)."
            },
            {
              "id": 1275,
              "title": "WA. - Chunk 242",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (Jo(= V),      Ji,-:+      ,Js(=      T)      from   \n \nV   \n \n€      W      to   \n \na      vertex   \n \nT      in      M,      where      each      non-endpoint      in      p      does      not      belong      to      W      UW. If  \n \n  T   \n \n€      Anc(Y,      M),      then      p      can      only      be      as      Jyo>      Jy   \n \n>      +++   \n \n+      J,      in      M."
            },
            {
              "id": 1276,
              "title": "WA. - Chunk 243",
              "type": "chunk",
              "children": [],
              "content": "And      there      exists   \n \na      collider      path      X(=      Fo)   \n \n&      Fi   \n \n& »   \n \n>      Fi      <*V      in      M      with      edges      F;   \n \n>      J,,0<i<n-1. Proof. According      to      Def. there      exists   \n \na      collider      path   \n \nX      (=      Fo)   \n \n@      Fy      +++      Fy_y      +#V      in      M,      where      F),---   \n \n,      Fy-1   \n \n€ W."
            },
            {
              "id": 1277,
              "title": "WA. - Chunk 244",
              "type": "chunk",
              "children": [],
              "content": "There      cannot      be      an      edge      F;      <+*J;      in      M      for      any   \n \n0      <2   \n \n<   \n \nt   \n \n—      1,      for      otherwise      J,   \n \n©      WU      W. Since   \n \nV      is      not      an      ancestor      of   \n \nY      in      M      and      p      is   \n \na      minimal      possible      directed      path,      there      must      be      Fy_;   \n \n©   \n \nV      <+*J,      in      M."
            },
            {
              "id": 1278,
              "title": "WA. - Chunk 245",
              "type": "chunk",
              "children": [],
              "content": "Hence      F;_,      is      adjacent      to      J;,      for      otherwise      there      is   \n \na      new      unshielded      collider      in      M      relative      to      M."
            },
            {
              "id": 1279,
              "title": "WA. - Chunk 246",
              "type": "chunk",
              "children": [],
              "content": "Since      (1)      for      each  \n \n  F;,0      <i<t-—1,      there      cannot      be      F;      <+*.J,      in      M,      and      (2)      the      balanced      property      is      fulfilled      in      M,      we      can      conclude      that  \n \n  there      is      there      is      F;   \n \n>      J,      or      Fjo3      Jy,V1      <1      <n-—1      and   \n \nX   \n \n—      Jj,      otherwise      there      is      always   \n \na      discriminating      path      for Lemma      4."
            },
            {
              "id": 1280,
              "title": "WA. - Chunk 247",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment      set  \n \n  relative      to      (X,Y). Let      W      be      D-SEP(X,      Y,      Mx). For      any      S      incorporated      into      the      set      of      vertices      S      in      the      process      of      Alg."
            },
            {
              "id": 1281,
              "title": "WA. - Chunk 248",
              "type": "chunk",
              "children": [],
              "content": "2) (on      Line      7),      there      is      S   \n \n€      Anc(Y,      M). V\n \n   which      leads      to   \n \na      non-circle      mark      at   \n \nV      on      the      edge      between   \n \nV      and      J;      in      P. Due      to      Vx—      F,,_;   \n \n—      J;      in      M      and      the  \n \n  balanced      property      of      M,      there      is      Vo—      J;."
            },
            {
              "id": 1282,
              "title": "WA. - Chunk 249",
              "type": "chunk",
              "children": [],
              "content": "Since      the      path      p      is   \n \na      minimal      possible      directed      path,      the      path      can      only      be      as  \n \n  Vo      J,      7-3      Is. CI\n \n \n  Proof. Note      the      graph      M      is      updated      in      every      round      of      Alg.|2|      To      distinguish      them,      we      use      M1;      to      denote      the      graph      obtained  \n \n  after      Line   \n \n5      of      Alg."
            },
            {
              "id": 1283,
              "title": "WA. - Chunk 250",
              "type": "chunk",
              "children": [],
              "content": "/2|/in      the      i-th      round. Denote      M      the      original      maximal      local      MAG. Note      in      the      whole      process,      there      are      no       new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      S   \n \n€      W,      since      W   \n \n=      D-SEP(X,      Y,      Mx),      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)      and      S   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1284,
              "title": "WA. - Chunk 251",
              "type": "chunk",
              "children": [],
              "content": "For      S   \n \n€      So      defined  \n \n  in      Def. |4}      according      to      Lemma[3}      since      $\\\\\\'      is      the      vertex      adjacent      to   \n \na      vertex   \n \nV   \n \n€      W      ina      minimal      possible      directed      path  \n \n  from   \n \nV      to   \n \na      vertex      in      Anc(Y,      M),      there      is      S   \n \n€      Anc(Y,M)."
            },
            {
              "id": 1285,
              "title": "WA. - Chunk 252",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      are   \n \nT      rounds      in      Alg.|2)      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge   \n \nA      ++5S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2      and      thus      Anc(S;,      M,)      N   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg.|2|      For      brevity,      denote   \n \nT   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg."
            },
            {
              "id": 1286,
              "title": "WA. - Chunk 253",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      S;   \n \n€      Anc(Y,M). Since      R12      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (K1,---   \n \n,      Km)      relative      to      So  \n \n  and      there      exists      an      uncovered      possible      directed      path      (V,      S,,---   \n \n,      Kj)      for   \n \n1   \n \n<   \n \n7   \n \n<      min      M),      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1287,
              "title": "WA. - Chunk 254",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is      C_      *-o      Ky      0-0      ---      0-0      Ky,      o-*«      Din      M,  \n \n  where      C   \n \n€      Fx,\\\\\\\\Fr,,D   \n \n©      Fr,,\\\\\\\\Fr,_,»      Fk;   \n \n=      {V   \n \n€      VW’   \n \n|   \n \nV      +0      Kj      or      Vx      K;      in      My}."
            },
            {
              "id": 1288,
              "title": "WA. - Chunk 255",
              "type": "chunk",
              "children": [],
              "content": "Next      we      prove      there      is  \n \n  not      kK;   \n \n+      Cin      M,. Suppose      kK,   \n \n—      C      in      M,      for      contradiction. As      in      the      process      of      Alg. 2]      we      never      add   \n \na      tail,      there      is  \n \n  K,      €—>      CinM. In      this      case,      there      is   \n \na      directed      path      S;   \n \n>      ---   \n \n—      kK,   \n \n>      CinMandC   \n \n€      So      C      Anc(WU      {Y},M)."
            },
            {
              "id": 1289,
              "title": "WA. - Chunk 256",
              "type": "chunk",
              "children": [],
              "content": "Hence      S$,   \n \n€      Anc(W   \n \nU      {Y},M). Since   \n \nV   \n \n€      W      is      adjacent      to      91,      9;      should      belong      to      So,      contradiction. Hence      there  \n \n  cannot      be      an      edge      Ky   \n \n>      Cin      My."
            },
            {
              "id": 1290,
              "title": "WA. - Chunk 257",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      F’;,1   \n \n<   \n \n7   \n \n<      m,      it      is      easy      to      prove      that      F’;      is      an      ancestor      of      either      C      or      D,  \n \n  for      otherwise      there      will      be      an      unshielded      collider      in      the      path      (C,      Ky,---   \n \n,      Km,      D)      in      M."
            },
            {
              "id": 1291,
              "title": "WA. - Chunk 258",
              "type": "chunk",
              "children": [],
              "content": "And      since      C,      D   \n \n€      So,      and      C,      D       are      ancestors      of   \n \nY      in      M,      it      holds      C,      D   \n \n€      Anc(Y,M). And      since      there      is      Vo>      5;   \n \n—      ---   \n \n+      K,      in      M,      5;      is      an      ancestor      of  \n \n  Y      in      M. Thus      S;   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1292,
              "title": "WA. - Chunk 259",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      all      the      vertices      in      Anc(.S,,      My)      M   \n \nT      are      ancestors      of      Y. Next      we      prove      the      induction      result. Suppose      in      the      first   \n \ni      round,      each      vertex      in      So,      Anc(S;,M),---   \n \n,      Anc(.S;,      M1)      is      an  \n \n  ancestor      of   \n \nY      in      M. We      will      prove      S;,1   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1293,
              "title": "WA. - Chunk 260",
              "type": "chunk",
              "children": [],
              "content": "Since      R49      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (7,---   \n \n,      T\\\\\\')      relative      to      Sp      UU,      <,<;(Ane(Sq,      Mi)      N      T)      and      there  \n \n  exists      an      uncovered      possible      directed      path      (V,      $;41,---      ,7;)      forl   \n \n<      s   \n \n<      f      in      M,,1      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1294,
              "title": "WA. - Chunk 261",
              "type": "chunk",
              "children": [],
              "content": "Without      loss      of  \n \n  generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is   \n \nJ      *-o      T;      o-o      ---      0-0      Ty      o-*   \n \nK      in      M;41,      where  \n \n  J   \n \n€      Fr,\\\\\\\\Fr,,   \n \nK   \n \n€      Fr;      \\\\\\\\Frj_1:      Next      we      prove      there      is      not      T;   \n \n—   \n \nJ      in      M;,,."
            },
            {
              "id": 1295,
              "title": "WA. - Chunk 262",
              "type": "chunk",
              "children": [],
              "content": "Suppose      J;   \n \n—   \n \nJ      in      M      for      contradiction. Note      in      the      whole      process      of      Alg. 2}      we      never      add   \n \na      tail,      hence      there      is      T;      —>   \n \nJ      in      M. In      this      case,      there      is   \n \na      directed      path  \n \n  Sig1      3-1:   \n \n>      T,   \n \n>      JinMand   \n \nJ   \n \n€      So      UU      <g<;(Ane(Sq,      Mg)      OT)."
            },
            {
              "id": 1296,
              "title": "WA. - Chunk 263",
              "type": "chunk",
              "children": [],
              "content": "If   \n \nJ   \n \n€      So,      then      S341   \n \n€      Anc(WU{Y},M),      Sizi  \n \n  should      belong      to      So,      contradiction. If      5,4;   \n \n€      Anc(S,,M,)   \n \n7      T,1      <q      <3,      then      S;,1      should      have      been      incorporated      into  \n \n  S      in      the      g-round      of      Alg.|2}      contradiction. Hence      there      cannot      be      an      edge      T;   \n \n>   \n \nJ      in      M41."
            },
            {
              "id": 1297,
              "title": "WA. - Chunk 264",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      T,,1   \n \n<      s   \n \n<      f,      itis      an      ancestor      of      either   \n \nJ      or      K,      for      otherwise      there      will  \n \n  be      an      unshielded      collider      in      the      path      (J,T1,---      ,T,      A)      in      M."
            },
            {
              "id": 1298,
              "title": "WA. - Chunk 265",
              "type": "chunk",
              "children": [],
              "content": "And      since      J,   \n \n€      So      UUy<<;(Ane(Sq,M,)   \n \n9      T),      and       J,   \n \nK      are      ancestors      of   \n \nY      in      M,      it      holds      J,      kK   \n \n€      Anc(Y,M). And      since      there      is      Vo>      S;4;   \n \n>      ---   \n \n>      T,      in      M,      $;4,      is      an  \n \n  ancestor      of      Y. Thus      S;41;   \n \n€      Anc(Y,M)."
            },
            {
              "id": 1299,
              "title": "WA. - Chunk 266",
              "type": "chunk",
              "children": [],
              "content": "Hence      all      the      vertices      in      Anc(.$;41,      M41)      M   \n \nT      are      ancestors      of   \n \nY      in      M. By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M. O\nTheorem.B]      Prop. {/has      implied      that      W   \n \n=      D-SEP(X,      Y,      M.x)      is   \n \na      potential      adjustment      set."
            },
            {
              "id": 1300,
              "title": "WA. - Chunk 267",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      that   \n \na      set      of vertices      S$      will      be      returned      by      Alg. Note      the      graph      M      is      updated      in      every      round      of      Alg."
            },
            {
              "id": 1301,
              "title": "WA. - Chunk 268",
              "type": "chunk",
              "children": [],
              "content": "[2|      To      distinguish      them,      we      use      M|;      to      denote      the      graph      obtained      after  \n \n  Line   \n \n5      of      Alg.2|in      the      i-th      round,      use      S;      to      denote      the      set      of      vertices      obtained      after      Line   \n \n7      of      Alg. [2|in      the      i-th      round. Denote  \n \n  M      the      original      maximal      local      MAG. For      S   \n \n€      So      in      Def."
            },
            {
              "id": 1302,
              "title": "WA. - Chunk 269",
              "type": "chunk",
              "children": [],
              "content": "4}      there      must      be   \n \nV      <*S      in      M      if      there      is   \n \nV      o-*      S      in      M. Hence      the  \n \n  arrowheads      introduced      in      the      first      round      of      Alg. 2]      must      exist      in      /. And      due      to      the      soundness      of      Ri2      by      Thm. [I]      all      the  \n \n  arrowheads      introduced      in      Alg. RJexist      in      M."
            },
            {
              "id": 1303,
              "title": "WA. - Chunk 270",
              "type": "chunk",
              "children": [],
              "content": "In      the      whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nJ      rounds      in      Alg."
            },
            {
              "id": 1304,
              "title": "WA. - Chunk 271",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<J-—1,anedge   \n \nA      +S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2}      and      thus      Anc(S;,      M;)      M   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg. 2}      Hence      there      is      evidently      S;,;   \n \n=      S;   \n \nU      (Anc($;41,Mi41)      NT),      forO      <i<      J—1."
            },
            {
              "id": 1305,
              "title": "WA. - Chunk 272",
              "type": "chunk",
              "children": [],
              "content": "It      suffices      to      show      that      in      the      i-th      round   \n \n1   \n \n<   \n \ni   \n \n<      J,      there      is      (1)      PossDe(W,      M;;[—S,])      N      Pa(S;,      Mi)   \n \n=      0,      (2)      M;      [Sy]      is   \n \na       complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S;|V      o«      V’or   \n \nV      ¢*V’      in      Mj},      and      (3)      there      is      not      an      unbridged      path  \n \n  relative      to      S;      in      M;[PossDe(W,      M;[—S,])]."
            },
            {
              "id": 1306,
              "title": "WA. - Chunk 273",
              "type": "chunk",
              "children": [],
              "content": "As      when      these      three      conditions      are      satisfied      in      each      round,      Alg.|2|could      output a\n \n   set      of      vertices. Suppose      in      the   \n \n2      round,      the      algorithm      output      “No”. According      to      Alg.|2}      at      least      one      of      the      three      conditions  \n \n  is      violated."
            },
            {
              "id": 1307,
              "title": "WA. - Chunk 274",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      the      impossibility      of      the      violations      of      the      three      conditions      in      the      following."
            },
            {
              "id": 1308,
              "title": "WA. - Chunk 275",
              "type": "chunk",
              "children": [],
              "content": "If      PossDe(W,      M;[—S;])  \n \n  Pa(S;,M;)   \n \n4      T,      suppose      there      is   \n \na      minimal      possible      directed      path      p      from   \n \nV   \n \n€      W      to   \n \nT      in  \n \n  M;[—S,]      such      that      each      non-endpoint      does      not      belong      to      W,      and      there      is      an      edge   \n \nT   \n \n+      S      in      M;      for      S   \n \n€      S;. Hence  \n \n  T   \n \n€      Anc(S,M;)."
            },
            {
              "id": 1309,
              "title": "WA. - Chunk 276",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma}      p      is      Vo>—      --. +   \n \nT      in      M. In      this      case,      if      S   \n \n€      So,      according      to      Def. 4]      and       Lemmaj}}      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)."
            },
            {
              "id": 1310,
              "title": "WA. - Chunk 277",
              "type": "chunk",
              "children": [],
              "content": "Thus   \n \nT   \n \n€      Anc(W   \n \nU      {Y},      M),      which      implies      that      there      is   \n \na      minimal      possible  \n \n  directed      path      p\\\\\\'      from   \n \nV   \n \n€      W      to   \n \nT   \n \n€      Anc(W   \n \nU      {Y},M)      such      that      p’      is   \n \na      sub-path      of      p. However,      according      to      Def."
            },
            {
              "id": 1311,
              "title": "WA. - Chunk 278",
              "type": "chunk",
              "children": [],
              "content": "in      the      case      above,      the      vertex      adjacent      to   \n \nV      in      p’      should      belong      to      So,      contradicting      with      the      fact      that      the      path      p      is      in  \n \n  M,[—S,]. If      S;      is      incorporated      into      S      in      Alg."
            },
            {
              "id": 1312,
              "title": "WA. - Chunk 279",
              "type": "chunk",
              "children": [],
              "content": "Qin      the      7,7   \n \n<   \n \n7      round,      since      there      is   \n \nT   \n \n€      Anc(S,M),   \n \nT      should      belong      to  \n \n  S541,S;+42,:--      ,8;,      contradicting      with      the      fact      that      the      path      p      is      in      M;|—S,]. Hence      there      is      always   \n \na      contradiction      if      there  \n \n  is      PossDe(W,      M;;[—S;])      M      Pa(S;,M;)   \n \n4      0."
            },
            {
              "id": 1313,
              "title": "WA. - Chunk 280",
              "type": "chunk",
              "children": [],
              "content": "Since      W   \n \n=      D-SEP(X,      Y,      Mx),      for      any   \n \nV   \n \n€      W,   \n \nV      is      not      an      ancestor      of   \n \nY      in      M. If      M,[Sy]      is      not   \n \na      complete      graph for      some   \n \nV   \n \n€      W,      there      must      be      an      edge   \n \nV   \n \n>      Sin      M,      for      otherwise      there      will      be      new      unshielded      collider      at      V."
            },
            {
              "id": 1314,
              "title": "WA. - Chunk 281",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  Lemma}      S      is      an      ancestor      of      Y. Thus   \n \nV      is      an      ancestor      of      Y,      thus   \n \nV   \n \n€      WW,      contradicting      with      W   \n \n9      W   \n \n=      9. Finally,      we      prove      that      there      is      not      an      unbridged      path      relative      to      S;      in      M;[PossDe(W,M,[—S,])]."
            },
            {
              "id": 1315,
              "title": "WA. - Chunk 282",
              "type": "chunk",
              "children": [],
              "content": "Suppose  \n \n  M;{[PossDe(W,      M[—S,])]      is      not      bridged      relative      to      S;      in      M. Since      M;[PossDe(W,M,{—S;])]      is      not      bridged      relative  \n \n  to      S;      in      M;,      without      loss      of      generality,      suppose      an      unbridged      path      Ky,      o—o      ---      o—o      K,,,      relative      to      S;,      and      there      is  \n \n  AE      W."
            },
            {
              "id": 1316,
              "title": "WA. - Chunk 283",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma      4}      all      the      vertices      in      S;      are      ancestors      of   \n \nY      in      M. At      first,      we      prove      Ky,---   \n \n,      Ky      are  \n \n  ancestors      of   \n \nY      in      M."
            },
            {
              "id": 1317,
              "title": "WA. - Chunk 284",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      vertices      S),.S_   \n \n€      S;      such      that      S$;   \n \n€      Fx,      \\\\\\\\Fr,      and      Sy   \n \n€      Fr,,\\\\\\\\Fr      where  \n \n  Fy      ={V\\\\\\'      €S,|V      o*      V’      or   \n \nV      «V’      in      M;}      as      Def. [I] m—1? If      S   \n \n€      So,      according      to      Def."
            },
            {
              "id": 1318,
              "title": "WA. - Chunk 285",
              "type": "chunk",
              "children": [],
              "content": "|4}      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (V’,S,---      ,T)      from      V’   \n \n€      WtoT   \n \n€       Anc(W   \n \nU      {Y},M)      where      each      non-endpoint      does      not      belong      to      W      in      M;. According      to      Def. |2}      there      exists   \n \na      collider      path X\n \n   OF      O---&      Fy_   \n \n1      <V’      where      F\\\\\\\\,---   \n \n,      F;_1   \n \n€      W."
            },
            {
              "id": 1319,
              "title": "WA. - Chunk 286",
              "type": "chunk",
              "children": [],
              "content": "And      according      to      the      result      (2)      above,      M;|Sy-]      is   \n \na      complete  \n \n  graph. Hence      F;_,      is      adjacent      to      S. In      this      case      if      there      is      an      edge      F;_;      «+S      in      Mj,      there      is      F;_;      «+S      in      M,      thus      there  \n \n  is      S   \n \n€      WUW. And      due      to      S   \n \n¢      W,      there      is      S   \n \n€      W."
            },
            {
              "id": 1320,
              "title": "WA. - Chunk 287",
              "type": "chunk",
              "children": [],
              "content": "And      if      there      is      an      edge      F,_      o-*      S      or      F;_1   \n \n>      S\\\\\\'      in      Mj,      there      is\n \n \n  F,_,      o*      S      or      Fy_;   \n \n—      S      in      M,      there      must      be      Vo  \n \n  S      in      M."
            },
            {
              "id": 1321,
              "title": "WA. - Chunk 288",
              "type": "chunk",
              "children": [],
              "content": "Due      the      p      is   \n \na      minimal      possible      directed      path      in      Mj,      p      is      also   \n \na       minimal      possible      directed      path      in      M,      pis      V’o>      S   \n \n>      ---   \n \n>      Tin      M,      thus      S   \n \n€      Anc(W   \n \nU      {Y},      M)."
            },
            {
              "id": 1322,
              "title": "WA. - Chunk 289",
              "type": "chunk",
              "children": [],
              "content": "Hence,      no      matter      what  \n \n  the      edge      is      between      S      and      F;_1,      there      is      S   \n \n€      Anc(W   \n \nU      {Y},      M). In      this      case,      if      there      is      kK;   \n \n—      5S      in      M,      there      is      kK;   \n \n€      So  \n \n  due      to      S\\\\\\'   \n \n€      So,      contradicting      with      K;   \n \n€      PossDe(W,      M;[-S,])."
            },
            {
              "id": 1323,
              "title": "WA. - Chunk 290",
              "type": "chunk",
              "children": [],
              "content": "If      S      is      incorporated      into      S      in      the      j,   \n \n7   \n \n<   \n \ni      round      on      Line   \n \n7      of  \n \n  Alg. [2|   \n \nK      is      also      incorporated      into      S      in      this      round      due      to   \n \nK   \n \n€      Anc(S,M),      contradicting      with      K;   \n \n€      PossDe(W,      M;[—S;]). Hence      for      any      K;,1      <j   \n \n<      mand      5S   \n \n€      §,      in      the      process      of      Alg."
            },
            {
              "id": 1324,
              "title": "WA. - Chunk 291",
              "type": "chunk",
              "children": [],
              "content": "(2)      there      cannot      be      an      edge      S   \n \n+      K;. Hence,      consider      the      uncovered      path      py   \n \n=      ($1,      Ky,      Ko,--+   \n \n,      Km,      S2)      in      M;      where      the      sub-path      from      K,      to      K,,,      is   \n \na      circle  \n \n  path."
            },
            {
              "id": 1325,
              "title": "WA. - Chunk 292",
              "type": "chunk",
              "children": [],
              "content": "Note      the      non-circle      marks      in      M;      also      exist      in      M      due      to      the      soundness      of   \n \nR   \n \n2      according      to      Thm. {i}      Since      M      cannot have      new      unshielded      colliders      relative      to      M;,      there      is      each      vertex      in      K,,      K2,---   \n \n,      Km      is      an      ancestor      of      either      S;      or      So      in M."
            },
            {
              "id": 1326,
              "title": "WA. - Chunk 293",
              "type": "chunk",
              "children": [],
              "content": "Since      S;      and      S2      are      ancestors      of   \n \nY      according      to      Lemma      any      vertex      in      K,,---   \n \n,      Kj,      are      ancestors      of   \n \nY      in      M. Note      in      the      process      of      Alg."
            },
            {
              "id": 1327,
              "title": "WA. - Chunk 294",
              "type": "chunk",
              "children": [],
              "content": "2)      we      only      add      arrowheads      at      W,      which      are      not      ancestors      of   \n \nY      in      M,      hence      we      will  \n \n  never      introduce      any      arrowheads      at      K;,V1   \n \n<   \n \nj   \n \n<      min      Alg."
            },
            {
              "id": 1328,
              "title": "WA. - Chunk 295",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence      in      M;,      the      uncovered      path      p,      is      in      the      form      of S,      #0      Ky      0-0:      ++      0-0      Ky,      o-*      So,      that      is,      there      cannot      be      S$;   \n \n>      Ky,      or      Ky,      <*S>      in      M;."
            },
            {
              "id": 1329,
              "title": "WA. - Chunk 296",
              "type": "chunk",
              "children": [],
              "content": "Next,      for      any      K;,1   \n \n<   \n \n7   \n \n<      _m,      consider      the      minimal      possible      directed      path      p   \n \n=      (A,      Bj,  \n \n  K      A)      from   \n \nA      to      K;. Note      we  \n \n  use      notation   \n \nB      to      denote      the      vertex      adjacent      to   \n \nA      in      the      minimal      possible      directed      path      from   \n \nA      to      K;,1      <7      <m."
            },
            {
              "id": 1330,
              "title": "WA. - Chunk 297",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      we      suppose      each      non-endpoint      in      p      does      not      belong      to      W,      since      if      there      is      another      vertex      A’   \n \n€      W      in      p,  \n \n  we      can      consider      A’      instead      of      A,      it      is      evidently      that      K1,---   \n \n,      Ky,      are      possible      descendants      of      A’      as      well      since      there      is   \n \na       minimal      possible      directed      path      from      A’      to      A;      and      there      are      circle      paths      from      KX;      to      each      vertex      in      Ky,---   \n \n,      Km."
            },
            {
              "id": 1331,
              "title": "WA. - Chunk 298",
              "type": "chunk",
              "children": [],
              "content": "Note      it      is      possible      that      there      are      many      minimal      possible      directed      paths      from   \n \nA      to      K;."
            },
            {
              "id": 1332,
              "title": "WA. - Chunk 299",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      prove      that      for      any  \n \n  B;,B;,1<i<   \n \nJ      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;,      and      B;      is      adjacent      to      each  \n \n  vertex      in      S      in      M. Suppose      B;      is      not      adjacent      to      B;      or      S   \n \n€      S      in      M."
            },
            {
              "id": 1333,
              "title": "WA. - Chunk 300",
              "type": "chunk",
              "children": [],
              "content": "Since      S      is      an      ancestor      of   \n \nY      in      any      MAG      M      consistent  \n \n  with      M      such      that      W   \n \n=      D-SEP(X,Y,      Mx),      and   \n \nA   \n \n€      W,      there      is   \n \nA      +*S      in      M. Since      there      is      not   \n \nA      +*B;      or   \n \nA      *B;      in  \n \n  M,      there      is      either   \n \nA   \n \n+      B;      or   \n \nA   \n \n>      B;      in      M."
            },
            {
              "id": 1334,
              "title": "WA. - Chunk 301",
              "type": "chunk",
              "children": [],
              "content": "And      since      B;      and      B;      are      located      at      minimal      possible      directed      paths      from   \n \nA       to      K;      and      K;,      respectively,      there      must      be   \n \nA   \n \n€      Anc(.A;,      M)      or   \n \nA   \n \n€      Anc(;,      M)."
            },
            {
              "id": 1335,
              "title": "WA. - Chunk 302",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      that      K;,.K;      are  \n \n  ancestors      of   \n \nY      in      M,   \n \nA      is      an      ancestors      of   \n \nY      in      M,      in      which      case      there      is   \n \nA   \n \n©      WNW,      contradicting      with      WM      W      =Oin  \n \n  Def."
            },
            {
              "id": 1336,
              "title": "WA. - Chunk 303",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence,      for      any      B;,B;,1      <7   \n \n<   \n \n7      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;, and      B;      is      adjacent      to      each      vertex      in      S      in      M. Next,      we      prove      that      for      any   \n \n1   \n \n<   \n \nj   \n \n<      m,      there      is      not      B;   \n \n=      K,."
            },
            {
              "id": 1337,
              "title": "WA. - Chunk 304",
              "type": "chunk",
              "children": [],
              "content": "That      is,      the      minimal      possible      directed      path      from   \n \nA      to  \n \n  kK;      cannot      be   \n \nA      o—*      Kk;      in      M;. Suppose      there      is   \n \nA      o-*      A’;      in      M;. According      to      the      result      above,      for      any      S   \n \n€      S,      K;      is  \n \n  adjacent      to      S."
            },
            {
              "id": 1338,
              "title": "WA. - Chunk 305",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,      there      must      be      m   \n \n>      3,      for      otherwise      if      the      unbridged      path      is      just      Ky      o-o      K2,      suppose   \n \nj   \n \n=      1,  \n \n  then      there      must      be      Fx,      D      Fxx,,      contradicting      with      the      definition      of      unbridged      path      in      Def."
            },
            {
              "id": 1339,
              "title": "WA. - Chunk 306",
              "type": "chunk",
              "children": [],
              "content": "[I]      We      consider      the      circle  \n \n  path      kK;      o-      Kj4,0~©---co-0      K,,      inM      (If   \n \n7      =>      m   \n \n—      1,      then      we      consider      the      circle      path      Ky      o-0      ---      K;      instead. And      it  \n \n  is      impossible      that      m   \n \n=   \n \n3      and   \n \nj   \n \n=      2,      for      otherwise      the      path      cannot      be      unbridged). There      is      Sy   \n \n€      Fx,,\\\\\\\\Fx,,_,."
            },
            {
              "id": 1340,
              "title": "WA. - Chunk 307",
              "type": "chunk",
              "children": [],
              "content": "Since  \n \n  there      cannot      be      an      edge      K,,-1   \n \n—      52      in      M;      and      M,      which      we      have      proven      before,      and      S2   \n \n€      Fx,,      \\\\\\\\Fx,,_,,      52      cannot      be  \n \n  adjacent      to      K,,-1."
            },
            {
              "id": 1341,
              "title": "WA. - Chunk 308",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      can      conclude      that      K,,,_2      is      not      adjacent      to      S2,      for      otherwise      in      the      substructure      comprised      of  \n \n  Km—2,      Km—1,      Km,      S2,      there      must      be      K,,   \n \n>      Sg   \n \n+      K,,—2      oriented      by      Rg      in      P,      which      leads      to      K,,-2   \n \n>      Sin      M      and      M,,  \n \n  contradiction."
            },
            {
              "id": 1342,
              "title": "WA. - Chunk 309",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      conclude      that      no      vertices      in      K;,      Kj41,---   \n \n,      Km      is      adjacent      to      S. However,      we      have      proven  \n \n  that      K;      is      adjacent      to      S,      contradiction. Hence,      for      any      B;,1      <j      <_m,      Bj   \n \n4      K;."
            },
            {
              "id": 1343,
              "title": "WA. - Chunk 310",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      will      prove      that      for      any      B;,1   \n \n<   \n \nj   \n \n<      m,      B;      is      also      in      the      minimal      possible      directed      path      from   \n \nA      to      Kj,  \n \n  where   \n \n1   \n \n<   \n \ni   \n \n<      mandi   \n \n¥      j. Without      loss      of      generality,      suppose   \n \n7   \n \n>      7."
            },
            {
              "id": 1344,
              "title": "WA. - Chunk 311",
              "type": "chunk",
              "children": [],
              "content": "Consider      the      minimal      possible      directed      path  \n \n  (A,      By41,-+-   \n \n,      541)      from   \n \nA      to      Kj+41      in      M. We      will      prove      that      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible  \n \n  directed      path      from   \n \nA      to      Kj+1. If      Bj,      and      B;      denote      the      same      vertex,      the      result      evidently      holds."
            },
            {
              "id": 1345,
              "title": "WA. - Chunk 312",
              "type": "chunk",
              "children": [],
              "content": "We      just      consider      the      case  \n \n  Bj41   \n \n4      B;. We      have      proven      that      B;      is      adjacent      to      B;+1      before. Note      each      vertex      in      Ky,---   \n \n,      Ky,      is      an      ancestor      of   \n \nY      in      M. According      to      Lemma      3}      there      must      be      p)   \n \n=      Ao      B;   \n \n>       -++      —>      Kj      and      po   \n \n=      Ao      By,   \n \n—      ---   \n \n—      Kj41."
            },
            {
              "id": 1346,
              "title": "WA. - Chunk 313",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      Kj;   \n \n#      Bj,      above,   \n \nA      cannot      be      adjacent      to  \n \n  Kj+41,      for      otherwise      p      is      not   \n \na      minimal      possible      directed      path."
            },
            {
              "id": 1347,
              "title": "WA. - Chunk 314",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      adjacent      to      Kj;      in      M,      it      is      evident      that      there      is   \n \na       minimal      possible      directed      path      (A,      B;,      Kj+1),      thus      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path  \n \n  from   \n \nA      to      K;41."
            },
            {
              "id": 1348,
              "title": "WA. - Chunk 315",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      not      adjacent      to      K;+1,      due      to      the      possible      directed      path      B;   \n \n>      ---   \n \n>      K,;      o-0      Kj,      in      Mj,      the  \n \n  corresponding      path      in      M      is      also   \n \na      possible      directed      path,      there      must      be   \n \na      minimal      possible      directed      path      p’      from      B;      to      Kj41  \n \n  in      M      according      to      Lemma|2}      and      thus      the      corresponding      path      of      p’      in      M;      must      be      also   \n \na      minimal      possible      directed      path      since  \n \n  in      Alg."
            },
            {
              "id": 1349,
              "title": "WA. - Chunk 316",
              "type": "chunk",
              "children": [],
              "content": "2|      we      only      transform      some      edge   \n \nV      o-*      S      to   \n \nV      <*S\\\\\\'      for   \n \nV   \n \n€      W      and      S   \n \n€      S;,      while      each      vertex      in      p’      does      not      belong  \n \n  to      S      since      it      is      in      M;[—S,]."
            },
            {
              "id": 1350,
              "title": "WA. - Chunk 317",
              "type": "chunk",
              "children": [],
              "content": "And   \n \nA      is      not      adjacent      to      any      non-endpoint      in      p’      since      Ao      B;   \n \n>      ---   \n \n>      K;      is   \n \na      minimal  \n \n  possible      directed      path      and   \n \nA      is      not      adjacent      to      K;41."
            },
            {
              "id": 1351,
              "title": "WA. - Chunk 318",
              "type": "chunk",
              "children": [],
              "content": "Hence,      we      have   \n \na      new      minimal      possible      directed      path      Ao>      B;      Op’,  \n \n  where      B,      is      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      A’;+1."
            },
            {
              "id": 1352,
              "title": "WA. - Chunk 319",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      prove      that      B;      is  \n \n  also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      Kj42."
            },
            {
              "id": 1353,
              "title": "WA. - Chunk 320",
              "type": "chunk",
              "children": [],
              "content": "Repeat      the      process,      we      can      prove      that      B;  \n \n  is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      K;,      for      any   \n \n1      <i   \n \n<      mandi      F      7."
            },
            {
              "id": 1354,
              "title": "WA. - Chunk 321",
              "type": "chunk",
              "children": [],
              "content": "Till      now,      we      have      proven      that      there      exists   \n \na      minimal      possible      directed      path      from   \n \nA      to      each      vertex      in      Ky,---   \n \n,      Ky,      such      that  \n \n  B;      is      the      common      vertex      adjacent      to   \n \nA      in      all      paths. And      it      is      evidently      that      the      minimal      possible      directed      path      is      an      uncovered  \n \n  path."
            },
            {
              "id": 1355,
              "title": "WA. - Chunk 322",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      B;   \n \n¢      S;,      the      edge   \n \nA      o-«      B;      should      be      transformed      by      R42      in      M;      on      Line   \n \n6      of      Alg. [2|      thus      the      algorithm      will enter the next loop, contradiction. Hence there is not an unbridged path relative to S; in M;[PossDe(W, M;[—S,])] O\nD.5. Proof      of      Proposition\nProof. We      prove      it      by      mathematical      induction."
            },
            {
              "id": 1356,
              "title": "WA. - Chunk 323",
              "type": "chunk",
              "children": [],
              "content": "For      each   \n \nV   \n \n€      DD-SEP(X,      Y,      MLx      ),      we      consider      the      minimal      collider      path  \n \n  satisfying      the      three      conditions      of      Definition   \n \n|      in      M. If      the      length      is      1,      there      is   \n \nX      <-*V      in      My      since      there      cannot      be   \n \nX      -«V  \n \n  in      Mx      according      to      the      definition      of      Mx."
            },
            {
              "id": 1357,
              "title": "WA. - Chunk 324",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \nV   \n \n¢      Anc(Y,      M),      it      trivially      concludes      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)  \n \n  according      to      the      definition. If      M[Qy]      is      not   \n \na      complete      graph,      evidently      there      are      at      least      two      vertices      in      Oy. Suppose  \n \n  S1,S2   \n \n€      Oy      are      not      adjacent."
            },
            {
              "id": 1358,
              "title": "WA. - Chunk 325",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      there      is      either   \n \nV   \n \n>      5S;      or   \n \nV   \n \n—      S      in      M,      otherwise      there      is   \n \na      new      unshielded  \n \n  collider      in      M      relative      to      M      and      P,      which      contradicts      with      that      M      is      consistent      with      MI."
            },
            {
              "id": 1359,
              "title": "WA. - Chunk 326",
              "type": "chunk",
              "children": [],
              "content": "Thus      there      is      also   \n \nV   \n \n€      Anc(Y,      M)  \n \n  such      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Hence      if      the      length      is      1,      there      is   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Suppose      the      result      holds  \n \n  when      the      length      of      the      minimal      collider      path      mentioned      above      is      k."
            },
            {
              "id": 1360,
              "title": "WA. - Chunk 327",
              "type": "chunk",
              "children": [],
              "content": "For      the      vertex   \n \nV      with   \n \na      minimal      collider      path      satisfying  \n \n  the      three      conditions      of      Definition      [5]      whose      length      is   \n \nk   \n \n+      1,      suppose      the      path      is      comprised      of      X,V;,V2,-+-      ,Ve41. We  \n \n  have      Vi,      V2,---   \n \n,      Ve   \n \n€      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1361,
              "title": "WA. - Chunk 328",
              "type": "chunk",
              "children": [],
              "content": "For      Vi.41,      similar      to      the      proof      above,      no      matter      whether      V.+1   \n \n€      Anc(Y,      M) or      M[Qy,.,,]      is      not   \n \na      complete      graph,      there      is      always      Vii   \n \n€      Anc(Y,M),      thus      V4;   \n \n€      D-SEP(X,Y,      M4)      due      to      the collider      path      where      each      non-endpoint      belongs      to      D-SEP(X,      Y,      Mx). O\nD.6."
            },
            {
              "id": 1362,
              "title": "WA. - Chunk 329",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Corollary      {I|\nProof. The      proof      follows      Thm. 4      of|Wang      et      al! (2023a)      based      on      Thm. 2]      and      Thm. 3}      Thm. 2)and      Thm. 3)can      ensure      that  \n \n  by      using      Alg."
            },
            {
              "id": 1363,
              "title": "WA. - Chunk 330",
              "type": "chunk",
              "children": [],
              "content": "2]      for      each      potential      adjustment      set,      we      can      find      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the  \n \n  MAGs      consistent      with      M."
            },
            {
              "id": 1364,
              "title": "WA. - Chunk 331",
              "type": "chunk",
              "children": [],
              "content": "And      since      in      PAGrules,      all      possible      local      transformation      are      considered      on      Line      5,      PAGrules      can  \n \n  return      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the      MAGs      consistent      with      P. C"
            }
          ],
          "content": ""
        },
        {
          "id": 1365,
          "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43",
          "type": "section",
          "children": [
            {
              "id": 1366,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "We      present      Thm. [I]      to      imply      the      soundness      of      R42      and      R43\nto      incorporate      BK      in      the      presence      of      latent      confounders."
            },
            {
              "id": 1367,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Note      previous      rules      (Zhang}      |2008;      [Andrews      et      al.,      2020;\n\\\\\\'Recently,      R13      was      independently      identified      by      {Venkateswaran  \n \n  &      Perkovic      (2024),      along      with      some      other      fundamental      results."
            },
            {
              "id": 1368,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Algorithm      1:      Implementation      of      Rj:      and      R13  \n \n  Input:      PMG  \n \n  Output:      Updated      H       while      there      is      an      edge   \n \nA      o-«   \n \nB      in      H      do  \n \n  Obtain      S4   \n \n=      {V   \n \n€      V(A)|Vx>      Ain      H}   \n \nU      {A};  \n \n  Obtain   \n \na      set      of      vertices      D      defined      as   \n \nV   \n \n€      D      if      and       only      if   \n \nV   \n \n€      V(H)\\\\\\\\S,4      and      there      is      an      uncovered  \n \n  path      p      from   \n \nA      to   \n \nV      where   \n \nB      is      the      vertex      adjacent  \n \n  to   \n \nA      in      p;  \n \n  if      there      exists   \n \nV   \n \n€      D      such      that   \n \nV   \n \n€      Anc(S,a,      H)  \n \n  then  \n \n  Transform      Ao      Bto      A¢*B  \n \n  else  \n \n  Obtain      graph      H’      based      on      H      by      transforming  \n \n  Vox      V’      toV      <*V\\\\\\'’,      VV      ED,VV’   \n \n€      Sy;  \n \n  Update      the      circle      component      in      H’[D]      as  \n \n  follows      until      no      updates:      for      V;,      V;   \n \n€      D,  \n \n  transform      V;      o-0      V;      into      V;   \n \n—      V;      if      either      of  \n \n  the      two      conditions      holds      (1)      Fy,\\\\\\\\Fy,   \n \n4      0;      or (2)      there      is   \n \na      vertex      V;   \n \n€      D      such      that      there      is  \n \n  V;,   \n \n—      Vj      and      V;,      is      not      adjacent      to      V;,      where  \n \n  Fy      ={V\\\\\\'      €S,4|V’      +o   \n \nV      or      V\\\\\\'*x>   \n \nV      in      A};  \n \n  if      there      are      new      unshielded      colliders      in      H\\\\\\'      then  \n \n  Transform   \n \nA      o-*   \n \nB      to   \n \nA      ¢+*B      in      H;\n \n \n  Wang      et      al."
            },
            {
              "id": 1369,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "!/2023b)      cannot      trigger      these      two      transformations. Recently,      [Venkateswaran   \n \n&      Perkovic}      (2024)      independently  \n \n  discover      Ry3,      along      with      some      fundamental      results,      while  \n \n  R42      is      not      involved. Theorem      1. 72      and      R43      are      sound      to      incorporate      BK. One      remaining      issue      is      the      implementation      of      #42      and      R43."
            },
            {
              "id": 1370,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      provide      Alg. [I|to      implement      R42      and      Ry   \n \n3      with      theoret-  \n \n  ical      guarantee      in      Prop. [I]      Essentially,      the      edges      transformed  \n \n  on      Line   \n \n5      of      Alg. [Ijare      triggered      by      R13,      the      edges      trans-  \n \n  formed      on      Line   \n \n9      are      triggered      by      #12."
            },
            {
              "id": 1371,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Line   \n \n8      involves  \n \n  detecting      the      presence      of      unbridged      paths,      during      which  \n \n  new      unshielded      colliders      are      generated      if      such      paths      are  \n \n  found. See      the      proof      of      Prop. [I]      for      the      details. Suppose      the  \n \n  number      of      edges      in      H      is      m,      the      complexity      of      implementing  \n \n  Alg."
            },
            {
              "id": 1372,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "[l]is      O(m*),      detailed      in      Appendix      |C} Proposition      1. Given   \n \na      PMG      H,      Alg. [I|can      transform      all  \n \n  and      only      the      edges      that      can      be      transformed      by      R42      or      R13."
            },
            {
              "id": 1373,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Note      R42      is      quite      different      from      the      previous      rules      Ry   \n \n—       Ri,      which      are      shown      in      Appendix      [A-2|      These      existing  \n \n  rules      transform      an      edge      based      on      just      few      edges      or      few  \n \n  paths."
            },
            {
              "id": 1374,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "R12      is      more      complicated,      since      12      considers      not  \n \n  only      the      unbridged      path,      but      also      the      large      number      of      paths  \n \n  °The      main      focus      of      our      paper      is      not      on      implementation."
            },
            {
              "id": 1375,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "It      is  \n \n  possible      that      there      can      be   \n \na      more      efficient      method      to      implement  \n \n  Rig      and      R13,      which      we      leave      for      future      work. from   \n \nA      in      R42      to      every      vertex      in      the      unbridged      path,      which  \n \n  form   \n \na      sub-graph."
            },
            {
              "id": 1376,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "The      establishment      of      this      rule      implies      the  \n \n  intrinsic      hardness      of      causal      identification      from      observational  \n \n  data      and      BK      in      the      presence      of      latent      variables. 3\n \n \n  Interestingly,      we      find      that      essentially,      Ri2      and      R43      are  \n \n  two      generalizations      of      R3      and      Rz."
            },
            {
              "id": 1377,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "See      Ry      and      R3      in  \n \n  Appendix      [A-2|      Suppose   \n \na      PMG      H."
            },
            {
              "id": 1378,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Consider      there      is      E       Cx      A:      Re      says      if      there      is      an      edge      AcE,      then      we      orient      it  \n \n  as   \n \nA      +*E;      while      R13      says      if      there      is      an      uncovered      possible  \n \n  directed      path      from   \n \nA      to      F      beginning      with   \n \nA      o-*      B,      then      we  \n \n  orient      Ao*«      Bas   \n \nA      +*B."
            },
            {
              "id": 1379,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "R13      generalizes      an      edge      Ao*      EF  \n \n  in      Rz      to      an      uncovered      possible      directed      path      from   \n \nA      to      E       beginning      with   \n \nA      o-*      B. R42      is      also   \n \na      generalization      of      R3."
            },
            {
              "id": 1380,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Consider      there      is      an      unshielded      triple      Cx   \n \nA      «*D      ina  \n \n  PMG      H:      Rs3      says      if      there      is      Co      Box      D      and      an      edge      Aox      B,  \n \n  then      we      orient   \n \nA      o-«   \n \nB      to   \n \nA      <«B."
            },
            {
              "id": 1381,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Here      the      reason      for      the  \n \n  transformation      is,      although   \n \nB      is      not      an      ancestor      of      {C’,      D}  \n \n  in      H,   \n \nB      must      be      an      ancestor      of      either      C      or      D      in      any      MAG  \n \n  consistent      with      H. That      is,      the      vertex   \n \nB      here      has      the      same  \n \n  property      as      the      unbridged      path      we      discuss      above."
            },
            {
              "id": 1382,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Consider  \n \n  Cx—   \n \nA      and      D«x—   \n \nA      in      Rz,      if      there      is   \n \nA   \n \n—      B,      either  \n \n  A,      B,C      or      A,      B,      D      will      form   \n \na      directed      or      almost      directed  \n \n  cycle,      which      violates      the      ancestral      property."
            },
            {
              "id": 1383,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "While      7212      says  \n \n  if      there      is      an      unbridged      path      p      relative      to      {A,      C,      D}      and   \n \nB       is      the      vertex      adjacent      to   \n \nA      in      the      uncovered      path      from   \n \nA      to  \n \n  every      vertex      in      p,      then      we      orient   \n \nA      o-*   \n \nB      to   \n \nA      ¢*«B."
            },
            {
              "id": 1384,
              "title": "We      present      Thm.      [I]      to      imply      the      soundness      of      R42      and      R43 - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "R43  \n \n  generalizes      the      one      vertex   \n \nB      in      R3      to   \n \na      subgraph      induced  \n \n  by   \n \nB      and      all      the      vertices   \n \nV      such      that      there      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to   \n \nV      beginning      with   \n \nA      o-«      B."
            }
          ],
          "content": ""
        },
        {
          "id": 1385,
          "title": "4.      Application      on      Set      Determination",
          "type": "section",
          "children": [
            {
              "id": 1386,
              "title": "4.      Application      on      Set      Determination - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "4. Application      on      Set      Determination\ntion  \n \n  In      this      section,      we      demonstrate      the      applicability      of      the      rules  \n \n  proposed      in      Sec. B]to      causality      tasks      that      rely      solely      on      ob-  \n \n  servational      data."
            },
            {
              "id": 1387,
              "title": "4.      Application      on      Set      Determination - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Specifically,      we      focus      on      set      determination  \n \n  task      in      the      presence      of      latent      confounders,      i.e.,      determin-  \n \n  ing      the      set      of      possible      causal      effects      of      vertex   \n \nX      on      vertex  \n \n  Y      with      observational      data."
            },
            {
              "id": 1388,
              "title": "4.      Application      on      Set      Determination - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "We      will      present   \n \na      rule-based  \n \n  method      by      introducing      the      proposed      rules      into      the      state-of-  \n \n  the-art      method      PAGcauses      (Wang      et      al.,      {2023a),      which      takes  \n \n  a      substantial      improvement      on      efficiency."
            },
            {
              "id": 1389,
              "title": "4.      Application      on      Set      Determination - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "In      set      determination      task,      we      have   \n \na      PAG      P      identified      with  \n \n  observational      data      (Spirtes      et      al.,      2000). Suppose      we      are      in-  \n \n  terested      in      the      causal      effect      of   \n \nX      on   \n \nY      henceforth."
            },
            {
              "id": 1390,
              "title": "4.      Application      on      Set      Determination - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "As      many  \n \n  causal      graphs      are      consistent      with      P      and      possibly      associated  \n \n  with      different      causal      effects,      the      target      of      set      determination  \n \n  is      to      determine      the      set      of      possible      causal      effects,      consisting  \n \n  of      all      the      causal      effects      in      the      DAGs      represented      by      the  \n \n  MAGs      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1391,
              "title": "4.      Application      on      Set      Determination - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Following      previous  \n \n  studies      (Maathuis      et      al. (2009;      |Malinsky   \n \n&      Spirtes)      |2016;  \n \n  Fang   \n \n&      He}      |2020;      |Wang      et      al.)\n[2023a),      we      only      consider  \n \n  the      possible      causal      effects      that      are      estimated      by      covariate  \n \n  adjustment,      and      only      focus      on      finding      all      the      adjustment"
            }
          ],
          "content": ""
        },
        {
          "id": 1392,
          "title": "E      Cy       ZS      (GE",
          "type": "section",
          "children": [
            {
              "id": 1393,
              "title": "E      Cy       ZS      (GE - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "E      Cy       ZS      (GE\n\\\\\\\\= \\\\\\\\E=,. E       WA      \\\\\\\\   \n \n—      om, (c)      Mz      (d)      M’ M’\n(a)      P (b)      Mi\n \nP (b)      Mi\n \n \n  sets      for      estimating      the      possible      causal      effects."
            },
            {
              "id": 1394,
              "title": "E      Cy       ZS      (GE - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Note      there  \n \n  possibly      exist      some      DAGs      with      causal      effects      unidentifiable  \n \n  by      adjustment,      all      the      relevant      methods      cannot      output      these  \n \n  effects      as      it      is      beyond      the      ability      of      covariate      adjustment. We      start      by      revisiting      PAGcauses      in      Sec."
            },
            {
              "id": 1395,
              "title": "E      Cy       ZS      (GE - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "4.1]      Note      PAG-  \n \n  causes      is   \n \na      complicated      method,      which      is      hard      to      introduce  \n \n  in      limited      space. Hence,      we      just      show      the      core      idea      of      PAG-  \n \n  causes      and      the      parts      where      7212      can      take      an      improvement."
            },
            {
              "id": 1396,
              "title": "E      Cy       ZS      (GE - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      details      are      given      in      Appendix      |B}      Then,      we      propose      the  \n \n  theoretical      supports      for      set      determination      based      on      712      in  \n \n  Sec. 4-2)      and      present      the      rule-based      algorithm      in      Sec. 4.3}\n4.1. Revisiting      Latest      Results\nults  \n \n  PAGcauses      is   \n \na      two-step      method. See      PAG      P      in      Fig. for      an      example."
            },
            {
              "id": 1397,
              "title": "E      Cy       ZS      (GE - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      some      circles      at      X,      the      first      step  \n \n  is      to      transform      all      the      circles      at      X. This      step      is      similar      to      the  \n \n  classical      method      IDA      which      applies      for      set      determination  \n \n  without      latent      variables      (Maathuis      et      al.)      [2009)."
            },
            {
              "id": 1398,
              "title": "E      Cy       ZS      (GE - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      each  \n \n  possible      transformations      of      (the      circles      at)      X,      PAGcauses  \n \n  introduces   \n \na      graphical      characterization      to      evaluate      the      va-  \n \n  lidity      of      each      transformation      of      X,      that      is,      whether      there  \n \n  is   \n \na      MAG      consistent      with      the      local      transformation      in      the  \n \n  MEC      represented      by      P."
            },
            {
              "id": 1399,
              "title": "E      Cy       ZS      (GE - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "For      each      valid      transformation,      they  \n \n  obtain      an      updated      PMG      M      called      maximal      local      MAG      with  \n \n  the      proposed      sound      and      complete      orientation      rules. Mj      and       Mb      in      Fig. [2(b)|2(c)|      are      two      examples      of      maximal      local  \n \n  MAGs,      obtained      from      different      local      transformation      of      X."
            },
            {
              "id": 1400,
              "title": "E      Cy       ZS      (GE - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "In      the      presence      of      latent      variables,      obtaining      the      maximal  \n \n  local      MAG      M      by      incorporating      valid      local      transformation      of X\n \n   is      not      sufficient      for      determining      the      causal      effect      of   \n \nX      on  \n \n  Y      in      all      the      MAGs      consistent      with      M,      which      is      quite      differ-  \n \n  ent      from      the      case      absence      of      latent      confounders      (Maathuis  \n \n  et      al.|/2009)."
            },
            {
              "id": 1401,
              "title": "E      Cy       ZS      (GE - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      have      to      further      consider      the      uncer-  \n \n  tain      structures      in      M. However,      enumerating      all      the      MAGs  \n \n  and      then      finding      adjustment      sets      take   \n \na      super-exponential  \n \n  complexity,      which      is      evidently      infeasible."
            },
            {
              "id": 1402,
              "title": "E      Cy       ZS      (GE - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the  \n \n  second      step      of      PAGcauses,      for      each      M,      |Wang      et      al.|      (2023a)  \n \n  established      the      graphical      characterization      in      Prop. [2]      to      di-  \n \n  rectly      evaluate      whether      each      given      set      of      vertices      W      can      be  \n \n  an      adjustment      set      in      some      MAG      consistent      with      M."
            },
            {
              "id": 1403,
              "title": "E      Cy       ZS      (GE - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "With  \n \n  this      result,      instead      of      enumerating      the      super-exponential  \n \n  number      of      MAGs,      PAGcauses      only      needs      to      enumerate  \n \n  exponential      number      of      vertices      set      W      whose      space      is      super-  \n \n  exponentially      less      than      that      of      MAGs,      and      evaluates      whether  \n \n  each      W      is      an      adjustment      set      in      some      MAG      by      Prop."
            },
            {
              "id": 1404,
              "title": "E      Cy       ZS      (GE - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "[2}      Be-  \n \n  fore      presenting      Prop. [2      we      first      show      two      definitions. The  \n \n  definition      of      bridged      in      Prop. QJis      presented      in      Appendix\n \n \n  Definition      2."
            },
            {
              "id": 1405,
              "title": "E      Cy       ZS      (GE - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      W      in   \n \na      maximal      local  \n \n  MAG      M,      define   \n \na      set      of      vertices      W      as   \n \nV   \n \n€      W      if      and      only  \n \n  if   \n \nV   \n \n€      PossAn(Y,      M)\\\\\\\\W      and      there      exists   \n \na      collider      path  \n \n  beginning      with      an      arrowhead      from   \n \nX      to   \n \nV      where      each      non-  \n \n  endpoint      vertex      belongs      to      W."
            },
            {
              "id": 1406,
              "title": "E      Cy       ZS      (GE - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Denote      Anc(Y      UW,      M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      S,nin      and      PossAn(Y      UW,M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      Sax. S      is   \n \na      block      set      if      Smin   \n \nC SC      Sina. Definition      3."
            },
            {
              "id": 1407,
              "title": "E      Cy       ZS      (GE - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      maximal      local      MAG      M,      W      is   \n \na      potential  \n \n  adjustment      set      if\n(1)      VV   \n \n€      W,      there      is   \n \na      collider      path      XY   \n \n+      ---      <*V      such  \n \n  that      each      non-endpoint      belongs      to      W,      and      there      is   \n \na       possible      directed      path      from   \n \nV      to   \n \nY      that      does      not      go  \n \n  through      the      vertices      in      W;\n(2)      WN      PossDe(X,      M)   \n \n=      0;\n(3)      Wn      Anc(Y      UW,M)      =      0\n \n=      0."
            },
            {
              "id": 1408,
              "title": "E      Cy       ZS      (GE - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Proposition      2."
            },
            {
              "id": 1409,
              "title": "E      Cy       ZS      (GE - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      for      any  \n \n  potential      adjustment      set      W,      there      exists   \n \na      MAG      M      consis-  \n \n  tent      with      M      such      that      W      is      an      adjustment      set      in      M      if      there  \n \n  exists   \n \na      block      set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where  \n \n  Sy      ={V\\\\\\'      €S|V      ox      V’      in      M};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M."
            },
            {
              "id": 1410,
              "title": "E      Cy       ZS      (GE - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Prop. 2]      provides   \n \na      sufficient      condition      for      the      existence      of  \n \n  MAGs      consistent      with      M      such      that   \n \na      given      set      W      is      an  \n \n  adjustment      set. When      using      this      condition      in      PAGcauses,  \n \n  it      includes      (1)      enumerate      every      block      set      S;      and      (2)      given  \n \n  each      S,      evaluate      the      three      conditions."
            },
            {
              "id": 1411,
              "title": "E      Cy       ZS      (GE - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  2  \n \n  3  \n \n  4 (2)      is      O(d?),      where      d      denotes      the      number      of      vertices. The\n \n \n  intuition      of      the      sufficient      condition      is,      they      try      to      construct  \n \n  a      MAG      M      such      that      the      adjustment      set      is      W."
            },
            {
              "id": 1412,
              "title": "E      Cy       ZS      (GE - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "To      ensure  \n \n  it,      they      have      to      restrict      that      some      vertices      (characterized      by  \n \n  set      W)      are      not      ancestors      of      W   \n \nU      {Y}      in      M. Hence,      it      is necessary      to      introduce      some      additional      arrowheads      to      block  \n \n  all      the      possible      directed      paths      from      W      to      WU{Y      }."
            },
            {
              "id": 1413,
              "title": "E      Cy       ZS      (GE - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "For      this  \n \n  purpose,      intuitively,      the      block      set      S      in      Def. [2|is      introduced  \n \n  to      characterize      the      position      to      introduce      arrowheads      to      block  \n \n  the      possibly      directed      paths      (See      Alg. 5]in      Appendix      [B]      for  \n \n  MAG      construction      algorithm)."
            },
            {
              "id": 1414,
              "title": "E      Cy       ZS      (GE - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "There      are      exponential      num-  \n \n  ber      (with      respect      to      d)      of      ways      to      introduce      arrowheads  \n \n  to      achieve      it,      hence      there      are      exponential      number      of      block  \n \n  sets      in      Def. Thus,      given      W,      evaluating      the      existence  \n \n  of      MAGs      in      Prop. |2}needs      to      enumerate      every      block      set      S."
            },
            {
              "id": 1415,
              "title": "E      Cy       ZS      (GE - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      the      process      of      enumerating      S      and      evaluating  \n \n  the      three      conditions      is      to      determine      the      existence      of   \n \na      kind  \n \n  of      way      to      introduce      arrowheads      such      that   \n \na      MAG      can      be  \n \n  constructed      with      W      being      the      adjustment      set. 4.2. Utilizing      Proposed      Rules\nules  \n \n  As      discussed      in      Sec."
            },
            {
              "id": 1416,
              "title": "E      Cy       ZS      (GE - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "4      I]      given   \n \na      potential      adjustment      set  \n \n  ‘W,      an      exponential      complexity      of      enumerating      all      the      block  \n \n  sets      is      involved      in      using      Prop."
            },
            {
              "id": 1417,
              "title": "E      Cy       ZS      (GE - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "[2]      because      there      are      expo-  \n \n  nential      number      of      possible      ways      to      block      all      the      possible  \n \n  directed      paths      from      W      to      W   \n \nU      {Y}      such      that      no      vertex  \n \n  in      W      is      an      ancestor      of      W   \n \nU      {Y}      in      the      constructed      MAG."
            },
            {
              "id": 1418,
              "title": "E      Cy       ZS      (GE - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "In      the      following,      we      show      that      enumerating      block      sets      can  \n \n  be      avoided      by      introducing      712,      thus      can      circumvent      the  \n \n  possibly      exponential      computational      burden      here. Note      the      final      target      is      to      find   \n \na      way      to      introduce      arrowheads  \n \n  to      prevent      W      being      ancestors      of      W   \n \nU      {Y}."
            },
            {
              "id": 1419,
              "title": "E      Cy       ZS      (GE - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "At      first      we  \n \n  determine   \n \na      set      of      vertices      So      in      Def. 4}  \n \n  Definition      4."
            },
            {
              "id": 1420,
              "title": "E      Cy       ZS      (GE - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      and   \n \na      po-  \n \n  tential      adjustment      set      W,      we      define      So      as      V’   \n \n€      So      if      and       only      if      there      exists   \n \na      vertex   \n \nV   \n \n€      W      and      there      exists   \n \na      mini-  \n \n  mal      possible      directed      path      p      from   \n \nV      to      Anc(W   \n \nU      {Y      },      M)  \n \n  such      that      V’      is      the      vertex      adjacent      to   \n \nV      in      p      and      each      non-  \n \n  endpoint      in      p      does      not      belong      to      W."
            },
            {
              "id": 1421,
              "title": "E      Cy       ZS      (GE - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      if      we      want      to      obtain   \n \na      MAG      M      consistent  \n \n  with      M      such      that      W      are      not      ancestors      of      W   \n \nU      {Y}      in  \n \n  M,      all      the      edges   \n \nV      o*      S,V   \n \n€      W,S   \n \n©      So      in      M      must      be  \n \n  transformed      to   \n \nV      <«,S,      for      otherwise      there      will      be   \n \na      directed  \n \n  path      from   \n \nV      to      WU      {Y}."
            },
            {
              "id": 1422,
              "title": "E      Cy       ZS      (GE - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Initialize      S   \n \n=      So,      characterizing  \n \n  the      positions      to      introduce      arrowheads,      similar      to      the      block  \n \n  1"
            }
          ],
          "content": ""
        },
        {
          "id": 1423,
          "title": "(a)      P (b)      Mi",
          "type": "section",
          "children": [
            {
              "id": 1424,
              "title": "(a)      P (b)      Mi - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(a)      P (b)      Mi\n \nP (b)      Mi\n \n \n  sets      for      estimating      the      possible      causal      effects. Note      there  \n \n  possibly      exist      some      DAGs      with      causal      effects      unidentifiable  \n \n  by      adjustment,      all      the      relevant      methods      cannot      output      these  \n \n  effects      as      it      is      beyond      the      ability      of      covariate      adjustment."
            },
            {
              "id": 1425,
              "title": "(a)      P (b)      Mi - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      start      by      revisiting      PAGcauses      in      Sec. 4.1]      Note      PAG-  \n \n  causes      is   \n \na      complicated      method,      which      is      hard      to      introduce  \n \n  in      limited      space. Hence,      we      just      show      the      core      idea      of      PAG-  \n \n  causes      and      the      parts      where      7212      can      take      an      improvement."
            },
            {
              "id": 1426,
              "title": "(a)      P (b)      Mi - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "The      details      are      given      in      Appendix      |B}      Then,      we      propose      the  \n \n  theoretical      supports      for      set      determination      based      on      712      in  \n \n  Sec. 4-2)      and      present      the      rule-based      algorithm      in      Sec. 4.3}\n4.1. Revisiting      Latest      Results\nults  \n \n  PAGcauses      is   \n \na      two-step      method. See      PAG      P      in      Fig. for      an      example."
            },
            {
              "id": 1427,
              "title": "(a)      P (b)      Mi - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      some      circles      at      X,      the      first      step  \n \n  is      to      transform      all      the      circles      at      X. This      step      is      similar      to      the  \n \n  classical      method      IDA      which      applies      for      set      determination  \n \n  without      latent      variables      (Maathuis      et      al.)      [2009)."
            },
            {
              "id": 1428,
              "title": "(a)      P (b)      Mi - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "For      each  \n \n  possible      transformations      of      (the      circles      at)      X,      PAGcauses  \n \n  introduces   \n \na      graphical      characterization      to      evaluate      the      va-  \n \n  lidity      of      each      transformation      of      X,      that      is,      whether      there  \n \n  is   \n \na      MAG      consistent      with      the      local      transformation      in      the  \n \n  MEC      represented      by      P."
            },
            {
              "id": 1429,
              "title": "(a)      P (b)      Mi - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      each      valid      transformation,      they  \n \n  obtain      an      updated      PMG      M      called      maximal      local      MAG      with  \n \n  the      proposed      sound      and      complete      orientation      rules. Mj      and       Mb      in      Fig. [2(b)|2(c)|      are      two      examples      of      maximal      local  \n \n  MAGs,      obtained      from      different      local      transformation      of      X."
            },
            {
              "id": 1430,
              "title": "(a)      P (b)      Mi - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "In      the      presence      of      latent      variables,      obtaining      the      maximal  \n \n  local      MAG      M      by      incorporating      valid      local      transformation      of X\n \n   is      not      sufficient      for      determining      the      causal      effect      of   \n \nX      on  \n \n  Y      in      all      the      MAGs      consistent      with      M,      which      is      quite      differ-  \n \n  ent      from      the      case      absence      of      latent      confounders      (Maathuis  \n \n  et      al.|/2009)."
            },
            {
              "id": 1431,
              "title": "(a)      P (b)      Mi - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      have      to      further      consider      the      uncer-  \n \n  tain      structures      in      M. However,      enumerating      all      the      MAGs  \n \n  and      then      finding      adjustment      sets      take   \n \na      super-exponential  \n \n  complexity,      which      is      evidently      infeasible."
            },
            {
              "id": 1432,
              "title": "(a)      P (b)      Mi - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the  \n \n  second      step      of      PAGcauses,      for      each      M,      |Wang      et      al.|      (2023a)  \n \n  established      the      graphical      characterization      in      Prop. [2]      to      di-  \n \n  rectly      evaluate      whether      each      given      set      of      vertices      W      can      be  \n \n  an      adjustment      set      in      some      MAG      consistent      with      M."
            },
            {
              "id": 1433,
              "title": "(a)      P (b)      Mi - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "With  \n \n  this      result,      instead      of      enumerating      the      super-exponential  \n \n  number      of      MAGs,      PAGcauses      only      needs      to      enumerate  \n \n  exponential      number      of      vertices      set      W      whose      space      is      super-  \n \n  exponentially      less      than      that      of      MAGs,      and      evaluates      whether  \n \n  each      W      is      an      adjustment      set      in      some      MAG      by      Prop."
            },
            {
              "id": 1434,
              "title": "(a)      P (b)      Mi - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "[2}      Be-  \n \n  fore      presenting      Prop. [2      we      first      show      two      definitions. The  \n \n  definition      of      bridged      in      Prop. QJis      presented      in      Appendix\n \n \n  Definition      2."
            },
            {
              "id": 1435,
              "title": "(a)      P (b)      Mi - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      W      in   \n \na      maximal      local  \n \n  MAG      M,      define   \n \na      set      of      vertices      W      as   \n \nV   \n \n€      W      if      and      only  \n \n  if   \n \nV   \n \n€      PossAn(Y,      M)\\\\\\\\W      and      there      exists   \n \na      collider      path  \n \n  beginning      with      an      arrowhead      from   \n \nX      to   \n \nV      where      each      non-  \n \n  endpoint      vertex      belongs      to      W."
            },
            {
              "id": 1436,
              "title": "(a)      P (b)      Mi - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Denote      Anc(Y      UW,      M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      S,nin      and      PossAn(Y      UW,M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      Sax. S      is   \n \na      block      set      if      Smin   \n \nC SC      Sina. Definition      3."
            },
            {
              "id": 1437,
              "title": "(a)      P (b)      Mi - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      maximal      local      MAG      M,      W      is   \n \na      potential  \n \n  adjustment      set      if\n(1)      VV   \n \n€      W,      there      is   \n \na      collider      path      XY   \n \n+      ---      <*V      such  \n \n  that      each      non-endpoint      belongs      to      W,      and      there      is   \n \na       possible      directed      path      from   \n \nV      to   \n \nY      that      does      not      go  \n \n  through      the      vertices      in      W;\n(2)      WN      PossDe(X,      M)   \n \n=      0;\n(3)      Wn      Anc(Y      UW,M)      =      0\n \n=      0."
            },
            {
              "id": 1438,
              "title": "(a)      P (b)      Mi - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Proposition      2."
            },
            {
              "id": 1439,
              "title": "(a)      P (b)      Mi - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      for      any  \n \n  potential      adjustment      set      W,      there      exists   \n \na      MAG      M      consis-  \n \n  tent      with      M      such      that      W      is      an      adjustment      set      in      M      if      there  \n \n  exists   \n \na      block      set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where  \n \n  Sy      ={V\\\\\\'      €S|V      ox      V’      in      M};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M."
            },
            {
              "id": 1440,
              "title": "(a)      P (b)      Mi - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Prop. 2]      provides   \n \na      sufficient      condition      for      the      existence      of  \n \n  MAGs      consistent      with      M      such      that   \n \na      given      set      W      is      an  \n \n  adjustment      set. When      using      this      condition      in      PAGcauses,  \n \n  it      includes      (1)      enumerate      every      block      set      S;      and      (2)      given  \n \n  each      S,      evaluate      the      three      conditions."
            },
            {
              "id": 1441,
              "title": "(a)      P (b)      Mi - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  2  \n \n  3  \n \n  4 (2)      is      O(d?),      where      d      denotes      the      number      of      vertices. The\n \n \n  intuition      of      the      sufficient      condition      is,      they      try      to      construct  \n \n  a      MAG      M      such      that      the      adjustment      set      is      W."
            },
            {
              "id": 1442,
              "title": "(a)      P (b)      Mi - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "To      ensure  \n \n  it,      they      have      to      restrict      that      some      vertices      (characterized      by  \n \n  set      W)      are      not      ancestors      of      W   \n \nU      {Y}      in      M. Hence,      it      is necessary      to      introduce      some      additional      arrowheads      to      block  \n \n  all      the      possible      directed      paths      from      W      to      WU{Y      }."
            },
            {
              "id": 1443,
              "title": "(a)      P (b)      Mi - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "For      this  \n \n  purpose,      intuitively,      the      block      set      S      in      Def. [2|is      introduced  \n \n  to      characterize      the      position      to      introduce      arrowheads      to      block  \n \n  the      possibly      directed      paths      (See      Alg. 5]in      Appendix      [B]      for  \n \n  MAG      construction      algorithm)."
            },
            {
              "id": 1444,
              "title": "(a)      P (b)      Mi - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "There      are      exponential      num-  \n \n  ber      (with      respect      to      d)      of      ways      to      introduce      arrowheads  \n \n  to      achieve      it,      hence      there      are      exponential      number      of      block  \n \n  sets      in      Def. Thus,      given      W,      evaluating      the      existence  \n \n  of      MAGs      in      Prop. |2}needs      to      enumerate      every      block      set      S."
            },
            {
              "id": 1445,
              "title": "(a)      P (b)      Mi - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      the      process      of      enumerating      S      and      evaluating  \n \n  the      three      conditions      is      to      determine      the      existence      of   \n \na      kind  \n \n  of      way      to      introduce      arrowheads      such      that   \n \na      MAG      can      be  \n \n  constructed      with      W      being      the      adjustment      set. 4.2. Utilizing      Proposed      Rules\nules  \n \n  As      discussed      in      Sec."
            },
            {
              "id": 1446,
              "title": "(a)      P (b)      Mi - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "4      I]      given   \n \na      potential      adjustment      set  \n \n  ‘W,      an      exponential      complexity      of      enumerating      all      the      block  \n \n  sets      is      involved      in      using      Prop."
            },
            {
              "id": 1447,
              "title": "(a)      P (b)      Mi - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "[2]      because      there      are      expo-  \n \n  nential      number      of      possible      ways      to      block      all      the      possible  \n \n  directed      paths      from      W      to      W   \n \nU      {Y}      such      that      no      vertex  \n \n  in      W      is      an      ancestor      of      W   \n \nU      {Y}      in      the      constructed      MAG."
            },
            {
              "id": 1448,
              "title": "(a)      P (b)      Mi - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "In      the      following,      we      show      that      enumerating      block      sets      can  \n \n  be      avoided      by      introducing      712,      thus      can      circumvent      the  \n \n  possibly      exponential      computational      burden      here. Note      the      final      target      is      to      find   \n \na      way      to      introduce      arrowheads  \n \n  to      prevent      W      being      ancestors      of      W   \n \nU      {Y}."
            },
            {
              "id": 1449,
              "title": "(a)      P (b)      Mi - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "At      first      we  \n \n  determine   \n \na      set      of      vertices      So      in      Def. 4}  \n \n  Definition      4."
            },
            {
              "id": 1450,
              "title": "(a)      P (b)      Mi - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      and   \n \na      po-  \n \n  tential      adjustment      set      W,      we      define      So      as      V’   \n \n€      So      if      and       only      if      there      exists   \n \na      vertex   \n \nV   \n \n€      W      and      there      exists   \n \na      mini-  \n \n  mal      possible      directed      path      p      from   \n \nV      to      Anc(W   \n \nU      {Y      },      M)  \n \n  such      that      V’      is      the      vertex      adjacent      to   \n \nV      in      p      and      each      non-  \n \n  endpoint      in      p      does      not      belong      to      W."
            },
            {
              "id": 1451,
              "title": "(a)      P (b)      Mi - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      if      we      want      to      obtain   \n \na      MAG      M      consistent  \n \n  with      M      such      that      W      are      not      ancestors      of      W   \n \nU      {Y}      in  \n \n  M,      all      the      edges   \n \nV      o*      S,V   \n \n€      W,S   \n \n©      So      in      M      must      be  \n \n  transformed      to   \n \nV      <«,S,      for      otherwise      there      will      be   \n \na      directed  \n \n  path      from   \n \nV      to      WU      {Y}."
            },
            {
              "id": 1452,
              "title": "(a)      P (b)      Mi - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Initialize      S   \n \n=      So,      characterizing  \n \n  the      positions      to      introduce      arrowheads,      similar      to      the      block  \n \n  1"
            }
          ],
          "content": ""
        },
        {
          "id": 1453,
          "title": "4.1.      Revisiting      Latest      Results",
          "type": "section",
          "children": [
            {
              "id": 1454,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "4.1. Revisiting      Latest      Results\nults  \n \n  PAGcauses      is   \n \na      two-step      method. See      PAG      P      in      Fig. for      an      example. As      there      are      some      circles      at      X,      the      first      step  \n \n  is      to      transform      all      the      circles      at      X."
            },
            {
              "id": 1455,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "This      step      is      similar      to      the  \n \n  classical      method      IDA      which      applies      for      set      determination  \n \n  without      latent      variables      (Maathuis      et      al.)      [2009)."
            },
            {
              "id": 1456,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "For      each  \n \n  possible      transformations      of      (the      circles      at)      X,      PAGcauses  \n \n  introduces   \n \na      graphical      characterization      to      evaluate      the      va-  \n \n  lidity      of      each      transformation      of      X,      that      is,      whether      there  \n \n  is   \n \na      MAG      consistent      with      the      local      transformation      in      the  \n \n  MEC      represented      by      P."
            },
            {
              "id": 1457,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "For      each      valid      transformation,      they  \n \n  obtain      an      updated      PMG      M      called      maximal      local      MAG      with  \n \n  the      proposed      sound      and      complete      orientation      rules. Mj      and       Mb      in      Fig. [2(b)|2(c)|      are      two      examples      of      maximal      local  \n \n  MAGs,      obtained      from      different      local      transformation      of      X."
            },
            {
              "id": 1458,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "In      the      presence      of      latent      variables,      obtaining      the      maximal  \n \n  local      MAG      M      by      incorporating      valid      local      transformation      of X\n \n   is      not      sufficient      for      determining      the      causal      effect      of   \n \nX      on  \n \n  Y      in      all      the      MAGs      consistent      with      M,      which      is      quite      differ-  \n \n  ent      from      the      case      absence      of      latent      confounders      (Maathuis  \n \n  et      al.|/2009)."
            },
            {
              "id": 1459,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      have      to      further      consider      the      uncer-  \n \n  tain      structures      in      M. However,      enumerating      all      the      MAGs  \n \n  and      then      finding      adjustment      sets      take   \n \na      super-exponential  \n \n  complexity,      which      is      evidently      infeasible."
            },
            {
              "id": 1460,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the  \n \n  second      step      of      PAGcauses,      for      each      M,      |Wang      et      al.|      (2023a)  \n \n  established      the      graphical      characterization      in      Prop. [2]      to      di-  \n \n  rectly      evaluate      whether      each      given      set      of      vertices      W      can      be  \n \n  an      adjustment      set      in      some      MAG      consistent      with      M."
            },
            {
              "id": 1461,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "With  \n \n  this      result,      instead      of      enumerating      the      super-exponential  \n \n  number      of      MAGs,      PAGcauses      only      needs      to      enumerate  \n \n  exponential      number      of      vertices      set      W      whose      space      is      super-  \n \n  exponentially      less      than      that      of      MAGs,      and      evaluates      whether  \n \n  each      W      is      an      adjustment      set      in      some      MAG      by      Prop."
            },
            {
              "id": 1462,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "[2}      Be-  \n \n  fore      presenting      Prop. [2      we      first      show      two      definitions. The  \n \n  definition      of      bridged      in      Prop. QJis      presented      in      Appendix\n \n \n  Definition      2."
            },
            {
              "id": 1463,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      W      in   \n \na      maximal      local  \n \n  MAG      M,      define   \n \na      set      of      vertices      W      as   \n \nV   \n \n€      W      if      and      only  \n \n  if   \n \nV   \n \n€      PossAn(Y,      M)\\\\\\\\W      and      there      exists   \n \na      collider      path  \n \n  beginning      with      an      arrowhead      from   \n \nX      to   \n \nV      where      each      non-  \n \n  endpoint      vertex      belongs      to      W."
            },
            {
              "id": 1464,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Denote      Anc(Y      UW,      M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      S,nin      and      PossAn(Y      UW,M)  \n \n  [PossDe(W,      M)\\\\\\\\W]      by      Sax. S      is   \n \na      block      set      if      Smin   \n \nC SC      Sina. Definition      3."
            },
            {
              "id": 1465,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      maximal      local      MAG      M,      W      is   \n \na      potential  \n \n  adjustment      set      if\n(1)      VV   \n \n€      W,      there      is   \n \na      collider      path      XY   \n \n+      ---      <*V      such  \n \n  that      each      non-endpoint      belongs      to      W,      and      there      is   \n \na       possible      directed      path      from   \n \nV      to   \n \nY      that      does      not      go  \n \n  through      the      vertices      in      W;\n(2)      WN      PossDe(X,      M)   \n \n=      0;\n(3)      Wn      Anc(Y      UW,M)      =      0\n \n=      0."
            },
            {
              "id": 1466,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Proposition      2."
            },
            {
              "id": 1467,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      for      any  \n \n  potential      adjustment      set      W,      there      exists   \n \na      MAG      M      consis-  \n \n  tent      with      M      such      that      W      is      an      adjustment      set      in      M      if      there  \n \n  exists   \n \na      block      set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where  \n \n  Sy      ={V\\\\\\'      €S|V      ox      V’      in      M};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M."
            },
            {
              "id": 1468,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Prop. 2]      provides   \n \na      sufficient      condition      for      the      existence      of  \n \n  MAGs      consistent      with      M      such      that   \n \na      given      set      W      is      an  \n \n  adjustment      set. When      using      this      condition      in      PAGcauses,  \n \n  it      includes      (1)      enumerate      every      block      set      S;      and      (2)      given  \n \n  each      S,      evaluate      the      three      conditions."
            },
            {
              "id": 1469,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  2  \n \n  3  \n \n  4 (2)      is      O(d?),      where      d      denotes      the      number      of      vertices. The\n \n \n  intuition      of      the      sufficient      condition      is,      they      try      to      construct  \n \n  a      MAG      M      such      that      the      adjustment      set      is      W."
            },
            {
              "id": 1470,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "To      ensure  \n \n  it,      they      have      to      restrict      that      some      vertices      (characterized      by  \n \n  set      W)      are      not      ancestors      of      W   \n \nU      {Y}      in      M. Hence,      it      is necessary      to      introduce      some      additional      arrowheads      to      block  \n \n  all      the      possible      directed      paths      from      W      to      WU{Y      }."
            },
            {
              "id": 1471,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "For      this  \n \n  purpose,      intuitively,      the      block      set      S      in      Def. [2|is      introduced  \n \n  to      characterize      the      position      to      introduce      arrowheads      to      block  \n \n  the      possibly      directed      paths      (See      Alg. 5]in      Appendix      [B]      for  \n \n  MAG      construction      algorithm)."
            },
            {
              "id": 1472,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "There      are      exponential      num-  \n \n  ber      (with      respect      to      d)      of      ways      to      introduce      arrowheads  \n \n  to      achieve      it,      hence      there      are      exponential      number      of      block  \n \n  sets      in      Def. Thus,      given      W,      evaluating      the      existence  \n \n  of      MAGs      in      Prop. |2}needs      to      enumerate      every      block      set      S."
            },
            {
              "id": 1473,
              "title": "4.1.      Revisiting      Latest      Results - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      the      process      of      enumerating      S      and      evaluating  \n \n  the      three      conditions      is      to      determine      the      existence      of   \n \na      kind  \n \n  of      way      to      introduce      arrowheads      such      that   \n \na      MAG      can      be  \n \n  constructed      with      W      being      the      adjustment      set."
            }
          ],
          "content": ""
        },
        {
          "id": 1474,
          "title": "(3)      Wn      Anc(Y      UW,M)      =      0",
          "type": "section",
          "children": [
            {
              "id": 1475,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(3)      Wn      Anc(Y      UW,M)      =      0\n \n=      0. Proposition      2."
            },
            {
              "id": 1476,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      for      any  \n \n  potential      adjustment      set      W,      there      exists   \n \na      MAG      M      consis-  \n \n  tent      with      M      such      that      W      is      an      adjustment      set      in      M      if      there  \n \n  exists   \n \na      block      set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where  \n \n  Sy      ={V\\\\\\'      €S|V      ox      V’      in      M};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M."
            },
            {
              "id": 1477,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Prop. 2]      provides   \n \na      sufficient      condition      for      the      existence      of  \n \n  MAGs      consistent      with      M      such      that   \n \na      given      set      W      is      an  \n \n  adjustment      set. When      using      this      condition      in      PAGcauses,  \n \n  it      includes      (1)      enumerate      every      block      set      S;      and      (2)      given  \n \n  each      S,      evaluate      the      three      conditions."
            },
            {
              "id": 1478,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  2  \n \n  3  \n \n  4 (2)      is      O(d?),      where      d      denotes      the      number      of      vertices. The\n \n \n  intuition      of      the      sufficient      condition      is,      they      try      to      construct  \n \n  a      MAG      M      such      that      the      adjustment      set      is      W."
            },
            {
              "id": 1479,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "To      ensure  \n \n  it,      they      have      to      restrict      that      some      vertices      (characterized      by  \n \n  set      W)      are      not      ancestors      of      W   \n \nU      {Y}      in      M. Hence,      it      is necessary      to      introduce      some      additional      arrowheads      to      block  \n \n  all      the      possible      directed      paths      from      W      to      WU{Y      }."
            },
            {
              "id": 1480,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      this  \n \n  purpose,      intuitively,      the      block      set      S      in      Def. [2|is      introduced  \n \n  to      characterize      the      position      to      introduce      arrowheads      to      block  \n \n  the      possibly      directed      paths      (See      Alg. 5]in      Appendix      [B]      for  \n \n  MAG      construction      algorithm)."
            },
            {
              "id": 1481,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "There      are      exponential      num-  \n \n  ber      (with      respect      to      d)      of      ways      to      introduce      arrowheads  \n \n  to      achieve      it,      hence      there      are      exponential      number      of      block  \n \n  sets      in      Def. Thus,      given      W,      evaluating      the      existence  \n \n  of      MAGs      in      Prop. |2}needs      to      enumerate      every      block      set      S."
            },
            {
              "id": 1482,
              "title": "(3)      Wn      Anc(Y      UW,M)      =      0 - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      the      process      of      enumerating      S      and      evaluating  \n \n  the      three      conditions      is      to      determine      the      existence      of   \n \na      kind  \n \n  of      way      to      introduce      arrowheads      such      that   \n \na      MAG      can      be  \n \n  constructed      with      W      being      the      adjustment      set."
            }
          ],
          "content": ""
        },
        {
          "id": 1483,
          "title": "4.2.      Utilizing      Proposed      Rules",
          "type": "section",
          "children": [
            {
              "id": 1484,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "4.2. Utilizing      Proposed      Rules\nules  \n \n  As      discussed      in      Sec. 4      I]      given   \n \na      potential      adjustment      set  \n \n  ‘W,      an      exponential      complexity      of      enumerating      all      the      block  \n \n  sets      is      involved      in      using      Prop."
            },
            {
              "id": 1485,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "[2]      because      there      are      expo-  \n \n  nential      number      of      possible      ways      to      block      all      the      possible  \n \n  directed      paths      from      W      to      W   \n \nU      {Y}      such      that      no      vertex  \n \n  in      W      is      an      ancestor      of      W   \n \nU      {Y}      in      the      constructed      MAG."
            },
            {
              "id": 1486,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "In      the      following,      we      show      that      enumerating      block      sets      can  \n \n  be      avoided      by      introducing      712,      thus      can      circumvent      the  \n \n  possibly      exponential      computational      burden      here. Note      the      final      target      is      to      find   \n \na      way      to      introduce      arrowheads  \n \n  to      prevent      W      being      ancestors      of      W   \n \nU      {Y}."
            },
            {
              "id": 1487,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "At      first      we  \n \n  determine   \n \na      set      of      vertices      So      in      Def. 4}  \n \n  Definition      4."
            },
            {
              "id": 1488,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      and   \n \na      po-  \n \n  tential      adjustment      set      W,      we      define      So      as      V’   \n \n€      So      if      and       only      if      there      exists   \n \na      vertex   \n \nV   \n \n€      W      and      there      exists   \n \na      mini-  \n \n  mal      possible      directed      path      p      from   \n \nV      to      Anc(W   \n \nU      {Y      },      M)  \n \n  such      that      V’      is      the      vertex      adjacent      to   \n \nV      in      p      and      each      non-  \n \n  endpoint      in      p      does      not      belong      to      W."
            },
            {
              "id": 1489,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      if      we      want      to      obtain   \n \na      MAG      M      consistent  \n \n  with      M      such      that      W      are      not      ancestors      of      W   \n \nU      {Y}      in  \n \n  M,      all      the      edges   \n \nV      o*      S,V   \n \n€      W,S   \n \n©      So      in      M      must      be  \n \n  transformed      to   \n \nV      <«,S,      for      otherwise      there      will      be   \n \na      directed  \n \n  path      from   \n \nV      to      WU      {Y}."
            },
            {
              "id": 1490,
              "title": "4.2.      Utilizing      Proposed      Rules - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Initialize      S   \n \n=      So,      characterizing  \n \n  the      positions      to      introduce      arrowheads,      similar      to      the      block  \n \n  1"
            }
          ],
          "content": ""
        },
        {
          "id": 1491,
          "title": "Algorithm      2:      Updating      S",
          "type": "section",
          "children": [
            {
              "id": 1492,
              "title": "Algorithm      2:      Updating      S - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "Algorithm      2:      Updating      S\n \n \n  Input:      Maximal      local      MAG      M,      X,      Y,      W       Output:      S       S      is      initialized      as      So      in      Def. 4      and      W      is      determined      as Def."
            },
            {
              "id": 1493,
              "title": "Algorithm      2:      Updating      S - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "T\n \n   =\n \n   PossDe(W,      M[—S])\\\\\\\\W;\n \n \n  while   \n \n/      do  \n \n  if      M[Sy]      is      not   \n \na      complete      graph      for      some   \n \nV   \n \n€      W,  \n \n  where      Sy   \n \n=      {V’   \n \n€      S|V      ox      V/or   \n \nV      <«V\\\\\\'      in      M};  \n \n  or      PossDe(W,      M[—S])      M      Pa(S,      M)   \n \n#      0)      then  \n \n  return      “No”;  \n \n  Update      M      by      transforming   \n \nV      o-*      S      to   \n \nV      <«S\\\\\\'      for  \n \n  any   \n \nV   \n \n€      Wand      S      €§;\n \n \n  if      an      edge   \n \nA      +*B      can      be      transformed      by      R12      in      M       then  \n \n  |      S=SU      (Anc(B,M)T)  \n \n  else  \n \n  if      there      is      not      an      unbridged      path      relative      to      S      in  \n \n  M[PossDe(W,      M|[—S]})]      then  \n \n  |      return   \n \nS else  \n \n  |      return      “No”\n \n \n  set      in      Prop."
            },
            {
              "id": 1494,
              "title": "Algorithm      2:      Updating      S - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "2|      The      transformed      edges      above      are      hypothesis  \n \n  BK,      and      can      possibly      trigger      7? to      further      update      the      graph. The      updates      triggered      by      12      help      us      enlarge      the      set      S. Following      the      idea      above,      we      present      Alg.|2}      Note      when      we  \n \n  propose      R42,      the      premise      is      that      BK      is      correct."
            },
            {
              "id": 1495,
              "title": "Algorithm      2:      Updating      S - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "However,  \n \n  the      premise      does      not      necessarily      hold      here. Hence,      in      the  \n \n  process      of      triggering      12,      we      need      to      evaluate      whether      the  \n \n  hypothesis      BK      is      valid,      which      is      achieved      on      Line   \n \n4      and 12."
            },
            {
              "id": 1496,
              "title": "Algorithm      2:      Updating      S - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "When      12      can      no      longer      be      triggered      (Line      8),      roughly  \n \n  speaking,      if      there      is      not      an      unbridged      path      relative      to      S,      S       is   \n \na      block      set      that      satisfies      the      three      conditions      of      Prop. [2\n \n \n  Then,      we      present      relevant      theoretical      guarantees      for      Alg. 2}  \n \n  Thm."
            },
            {
              "id": 1497,
              "title": "Algorithm      2:      Updating      S - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "implies      that      given   \n \na      maximal      local      MAG      M      and   \n \na       potential      adjustment      set      W,      if      we      can      obtain   \n \na      set      by      Alg. then      there      isa      MAG      M      consistent      with      M      such      that      W      is      an  \n \n  adjustment      set      in      M. According      to      Thm. [2      whether      Alg."
            },
            {
              "id": 1498,
              "title": "Algorithm      2:      Updating      S - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "[2]  \n \n  outputs   \n \na      set      of      vertices      or      “No”      is      an      indicator      of      whether  \n \n  the      input      W      is      an      adjustment      set      in      some      MAG      or      not. Hence,      by      executing      Alg.|2|      for      each      potential      adjustment  \n \n  set      W,      we      can      find   \n \na      set      of      adjustment      sets      in      the      MAGs  \n \n  consistent      with      M."
            },
            {
              "id": 1499,
              "title": "Algorithm      2:      Updating      S - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "To      further      ensure      that      we      can      estimate  \n \n  all      the      causal      effects      identifiable      by      covariate      adjustment,  \n \n  we      provide      Thm."
            },
            {
              "id": 1500,
              "title": "Algorithm      2:      Updating      S - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "3}      to      indicate      that      if      there      exists   \n \na      MAG      M       consistent      with      M      such      that      the      causal      effect      is      identifiable  \n \n  by      covariate      adjustment,      then      there      is      an      adjustment      set      in  \n \n  M      being   \n \na      potential      adjustment      set      such      that      Alg. 2]      can  \n \n  return   \n \na      set      of      vertices."
            },
            {
              "id": 1501,
              "title": "Algorithm      2:      Updating      S - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "It      ensures      that      via      using      Alg. 2]      for  \n \n  each      potential      adjustment      set      W,      we      can      estimate      all      the possible      causal      effects      that      are      identifiable      by      adjustment. Theorem      2. Given   \n \na      maximal      local      MAG      M,      for      any      poten-  \n \n  tial      adjustment      set      W,      if      Alg."
            },
            {
              "id": 1502,
              "title": "Algorithm      2:      Updating      S - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "2]      could      return   \n \na      set      of      vertices S,      then      there      exists   \n \na      MAG      M      consistent      with      MI      such      that  \n \n  W      is      an      adjustment      set      in      M. Theorem      3. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na       MAG   \n \n™      consistent      with      M      such      that      there      exists      an      adjust-  \n \n  ment      set      relative      to      (X,Y)."
            },
            {
              "id": 1503,
              "title": "Algorithm      2:      Updating      S - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)  \n \n  as      Def. [8]      Then      W      is   \n \na      potential      adjustment      set      in      M      and       Alg.2|can      return   \n \na      set      of      vertices      S      given      W      as      the      input."
            },
            {
              "id": 1504,
              "title": "Algorithm      2:      Updating      S - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Algorithm      3:      PAGrules Input:      PAG      P,      X,   \n \nY       Output:      AS(P)//      Adjustment      sets      in      MAGs      consistent with      P       AS(P)      =)      //      Record      all      the      valid      adjustment      sets;\n \n \n  Obtain   \n \na      maximal      local      MAG      M      based      on      P       and      C;  \n \n  Find      all      potential      adjustment      sets  \n \n  W),,      W2,---   \n \n,      that      contains  \n \n  DD-SEP(X,      Y,      M)      given      M;  \n \n  for      each      potential      adjustment      set      W;,      do  \n \n  Obtain      Sp      and      W      as      Def."
            },
            {
              "id": 1505,
              "title": "Algorithm      2:      Updating      S - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "and      Def. if      the      conditions      in      Prop. Hare      satisfied      for      P      then  \n \n  |      return      AS(P)   \n \n<      {D-SEP(X,Y,Px)}  \n \n  //      Prop. [4 w ya   \n \na      wis for      each      setC      C      {V   \n \n|   \n \nV      +0   \n \nX      in      P}      do  \n \n  if      the      three      conditions      in      Prop. (dare      satisfied      then  \n \n  Remark      2."
            },
            {
              "id": 1506,
              "title": "Algorithm      2:      Updating      S - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "There      are      at      most      d(d   \n \n—      1)/2      circles      that      could  \n \n  be      transformed      on      Line   \n \n6      of      Alg. |2|      where      d      denotes      the  \n \n  number      of      vertices. And      the      transformation      on      Line   \n \n6      is  \n \n  a      necessary      condition      for      entering      the      next      round      of      loop."
            },
            {
              "id": 1507,
              "title": "Algorithm      2:      Updating      S - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Hence,      the      number      of      loop      in      Alg.2Jis      at      most      O(d?). For  \n \n  the      other      parts      in      Alg|2}      the      complexity      is      at      most      O(d?). Hence      Alg. |2}can      be      implemented      in      polynomial      time. Remark      3."
            },
            {
              "id": 1508,
              "title": "Algorithm      2:      Updating      S - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "One      may      wonder      given   \n \na      maximal      local      MAG  \n \n  M      and   \n \na      potential      adjustment      set      W,      whether      we      could  \n \n  determine      whether      W      can      be      an      adjustment      set      in      some  \n \n  MAG      consistent      with      M      by      judging      the      three      conditions  \n \n  in      Prop."
            },
            {
              "id": 1509,
              "title": "Algorithm      2:      Updating      S - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "2]      with   \n \na      prescribed      S,      such      as      S   \n \n=      S,,;n      or      S   \n \n=       Snax      in      Def. 2      It      is      infeasible. Consider      My      in      Fig. 10  \n \n  11 12\nadjustment      set      D-SEP(X,      Y,      Mx)      in      any      MAG      M      (See  \n \n  Appendix      for      D-SEP(X,      Y,Mx)). In      the      following,  \n \n  we      present      Def."
            },
            {
              "id": 1510,
              "title": "Algorithm      2:      Updating      S - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "5]      to      characterize      these      vertices,      and      show  \n \n  DD-SEP(X,      Y,      Mx)      C      D-SEP(X,      Y,      Mx)      in      Prop. if      Alg. PJ      can      return   \n \na      set      of      vertices      given W;      and      M      then  \n \n  |      AS(P)   \n \n—      AS(P)   \n \nU      {Wi};\n \n \n  and      W   \n \n=      9),      the      three      conditions      (in      Prop."
            },
            {
              "id": 1511,
              "title": "Algorithm      2:      Updating      S - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "|2))      hold      when  \n \n  S   \n \n=      Snin   \n \n=      {EF},      but      do      not      hold      when      S   \n \n=      Spaz   \n \n=       {B,      D,      E}. While      consider      M! in      Fig. 2(@)and      W   \n \n=      0,      the  \n \n  three      conditions      do      not      hold      when      S   \n \n=      Syrin   \n \n=      {C1,      C2},  \n \n  but      hold      when      S   \n \n=      {C,      C2,      B}."
            },
            {
              "id": 1512,
              "title": "Algorithm      2:      Updating      S - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Hence,      it      is      not      direct      that  \n \n  which      block      set      can      satisfy      the      three      conditions. Intuitively,  \n \n  the      benefit      taken      by      utilizing      712      is      that      it      implies      which  \n \n  vertex      should      be      added      into      S,      instead      of      enumerating      all  \n \n  block      sets      as      Prop. 2|      For      example,      when      using      Alg."
            },
            {
              "id": 1513,
              "title": "Algorithm      2:      Updating      S - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "2]      for  \n \n  Mb      in      Fig. 2(c)]      given      W   \n \n=      9,      there      is      Sy   \n \n=      {E}      and      no       unbridged      paths,      thus      S   \n \n=      {E£}      is      returned;      while      for      M’  \n \n  in      Fig."
            },
            {
              "id": 1514,
              "title": "Algorithm      2:      Updating      S - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "2@)]      given      W   \n \n=      0),      there      is      Sp   \n \n=      {C,,      C2}      and      an  \n \n  unbridged      path      D      o-0      E,      thus      S   \n \n=      {C1,      C2,      B}      is      returned. 4.3. The      Algorithm      for      Set      Determination\ntion  \n \n  In      this      part,      we      present      the      improved      algorithm      for      set      deter-  \n \n  mination,      through      utilizing      the      proposed      rules."
            },
            {
              "id": 1515,
              "title": "Algorithm      2:      Updating      S - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG  \n \n  P,      we      can      obtain      several      maximal      local      MAGs      M      based  \n \n  on      different      local      transformations      of      X. Then      in      each      M,   \n \na       direct      method      is      to      find      each      subset      W      C      V(M)\\\\\\\\{X,Y},  \n \n  and      then      evaluate      whether      it      is   \n \na      potential      adjustment      set."
            },
            {
              "id": 1516,
              "title": "Algorithm      2:      Updating      S - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "If  \n \n  it      is   \n \na      potential      adjustment      set,      we      further      evaluate      whether  \n \n  a      set      of      vertices      can      be      returned      by      Alg. 2]      By      this      direct  \n \n  method,      we      can      find      all      the      adjustment      sets      according      to  \n \n  Thm. 2land      Thm. Bl Definition   \n \n5      (DD-SEP(X,      Y,      Mx)). Let      M      be   \n \na      maximal local      MAG."
            },
            {
              "id": 1517,
              "title": "Algorithm      2:      Updating      S - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "V   \n \n€      DD-SEP(X,      Y,      Mx)      if      and      only      if      there  \n \n  is   \n \na      collider      path   \n \nX   \n \n4      Vi   \n \n©      ar      Ve-1      <—*V      in Mx,      where      (1)   \n \nY   \n \n€      PossDe(X,      Ml);      (2)      Vi,---      ,Ve—-1   \n \n€ DD-SEP(X,      Y,      Mx);      (3)   \n \nV   \n \n€      Anc(Y,      M1)      or      the      subgraph M|Qy]      is      not   \n \na      complete      graph,      where      Qy   \n \n=      {V’   \n \n€       Anc(Y,      M)   \n \n|   \n \nV      o«      V’      in      M}."
            },
            {
              "id": 1518,
              "title": "Algorithm      2:      Updating      S - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Proposition      3. Given   \n \na      maximal      local      MAG      M,      if   \n \nV   \n \n€       DD-SEP(X,      Y,      Mx),      then   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)      in      any MAG      M      consistent      with      M      such      that      there      exists      an      adjust-  \n \n  ment      set      relative      to      (X,Y). Combining      the      parts      above,      we      provide      PAGrules      in      Alg."
            },
            {
              "id": 1519,
              "title": "Algorithm      2:      Updating      S - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "8]  \n \n  for      set      determination,      based      on      the      framework      of      PAGcauses. Note      if   \n \nX   \n \n¢      PossAn(Y,      ?)      on      Line      2,   \n \nX      has      no      causal      ef-  \n \n  fect      on   \n \nY      in      all      the      MAGs      consistent      with      P,      thus      there      is      no       need      to      consider      the      set      of      possible      causal      effects."
            },
            {
              "id": 1520,
              "title": "Algorithm      2:      Updating      S - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Similarly,  \n \n  if      the      causal      effect      is      identifiable      by      covariate      adjustment      in  \n \n  P,      we      can      directly      return      the      causal      effect      by      Prop.)\nwhich  \n \n  is      detailed      in      Appendix      [A.3|      On      Line      5,      we      enumerate      all  \n \n  possible      local      transformations      of      X,      which      is      represented  \n \n  by   \n \na      set      of      vertices      C      that      implies      transforming      the      edge  \n \n  Xo   \n \nV      to   \n \nX      ¢xV      if   \n \nV   \n \n€      Candto   \n \nX   \n \n>      VifV      ¢C."
            },
            {
              "id": 1521,
              "title": "Algorithm      2:      Updating      S - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Evidently,      all      the      sets      C      can      represent      all      the      possible      local  \n \n  transformations      of      X."
            },
            {
              "id": 1522,
              "title": "Algorithm      2:      Updating      S - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "On      Line      6-7,      we      obtain      all      the      valid  \n \n  local      transformations      of   \n \nX      and      obtain      the      maximal      local  \n \n  However,      the      method      above      is      still      somewhat      inefficient,      be-  \n \n  cause      the      enumeration      of      all      the      subsets      of      V(M)\\\\\\\\{X,      Y}  \n \n  is      not      always      necessary."
            },
            {
              "id": 1523,
              "title": "Algorithm      2:      Updating      S - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "In      fact,      given   \n \na      maximal      local  \n \n  MAG,      some      vertices      can      be      determined      to      belong      to      the  \n \n  _  \n \n  MAGs      based      on      each      valid      local      transformation. According  \n \n  to      Prop. B|      we      only      need      to      consider      the      potential      adjust-  \n \n  ment      set      containing      DD-SEP(X,      Y,      M),      which      is      executed  \n \n  on      Line      8."
            },
            {
              "id": 1524,
              "title": "Algorithm      2:      Updating      S - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "And      from      Line      9-12,      we      evaluate      whether      each  \n \n  potential      adjustment      set      is      an      adjustment      set      by      Alg. Finally,      Cor. [i]implies      that      PAGrules      can      return      the      set      of  \n \n  causal      effects      that      are      identifiable      by      covariate      adjustment  \n \n  in      the      DAGs      represented      by      the      MAGs      consistent      with      P."
            },
            {
              "id": 1525,
              "title": "Algorithm      2:      Updating      S - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Corollary      1."
            },
            {
              "id": 1526,
              "title": "Algorithm      2:      Updating      S - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      PAG      P,      denote      CE(P)      and      CE(P)      the  \n \n  set      of      causal      effects      in      the      DAGs      represented      by      the      MAGs  \n \n  consistent      with      P      that      can      be      estimated      by      covariate      adjust-  \n \n  ment      with      obseryable      variables      and      the      set      of      causal      effects  \n \n  set      AG  \n \n  output      by      Alg.|3}      It      holds      that      CE(P)   \n \n=      CE(P)."
            },
            {
              "id": 1527,
              "title": "Algorithm      2:      Updating      S - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "5. Conclusion\nsion  \n \n  It      remains      an      open      problem      for   \n \na      long      time      that      what      causal  \n \n  relations      are      identifiable      from      observational      data      and      back-  \n \n  ground      knowledge      (BK)      in      the      presence      of      latent      variables. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK."
            },
            {
              "id": 1528,
              "title": "Algorithm      2:      Updating      S - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "The      rules      are      quite      different      from      the      existing      rules      in  \n \n  the      form. We      believe      the      proposed      rules      can      take      some      new       insights      to      the      open      problem      and      could      possibly      inspire      the  \n \n  establishment      of      the      sound      and      complete      rules      in      the      future."
            },
            {
              "id": 1529,
              "title": "Algorithm      2:      Updating      S - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Further,      by      utilizing      the      proposed      rules,      we      present   \n \na      novel  \n \n  algorithm      to      determine      the      set      of      possible      causal      effects  \n \n  given   \n \na      PAG. The      rules      can      help      improve      the      efficiency      of  \n \n  the      state-of-the-art      method."
            },
            {
              "id": 1530,
              "title": "Algorithm      2:      Updating      S - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "In      the      future,      it      is      worthy      to      continue      investigating      the      sound  \n \n  and      complete      rules      to      incorporate      BK,      based      on      the      rules  \n \n  that      have      been      established."
            },
            {
              "id": 1531,
              "title": "Algorithm      2:      Updating      S - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "In      addition,      in      light      of      the      fact  \n \n  that      only   \n \na      Markov      equivalence      class      (MEC)      is      identifiable  \n \n  given      observational      data,      the      causal      effect      is      usually      uniden-  \n \n  tifiable      within   \n \na      MEC."
            },
            {
              "id": 1532,
              "title": "Algorithm      2:      Updating      S - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Hence,      exploring      and      exploiting      the  \n \n  additional      knowledge      that      is      available      in      practice      may      be  \n \n  helpful      to      causal      effect      estimation      tasks."
            }
          ],
          "content": ""
        },
        {
          "id": 1533,
          "title": "4.3.      The      Algorithm      for      Set      Determination",
          "type": "section",
          "children": [
            {
              "id": 1534,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "4.3. The      Algorithm      for      Set      Determination\ntion  \n \n  In      this      part,      we      present      the      improved      algorithm      for      set      deter-  \n \n  mination,      through      utilizing      the      proposed      rules. Given   \n \na      PAG  \n \n  P,      we      can      obtain      several      maximal      local      MAGs      M      based  \n \n  on      different      local      transformations      of      X."
            },
            {
              "id": 1535,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Then      in      each      M,   \n \na       direct      method      is      to      find      each      subset      W      C      V(M)\\\\\\\\{X,Y},  \n \n  and      then      evaluate      whether      it      is   \n \na      potential      adjustment      set. If  \n \n  it      is   \n \na      potential      adjustment      set,      we      further      evaluate      whether  \n \n  a      set      of      vertices      can      be      returned      by      Alg."
            },
            {
              "id": 1536,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "2]      By      this      direct  \n \n  method,      we      can      find      all      the      adjustment      sets      according      to  \n \n  Thm. 2land      Thm. Bl Definition   \n \n5      (DD-SEP(X,      Y,      Mx)). Let      M      be   \n \na      maximal local      MAG."
            },
            {
              "id": 1537,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "V   \n \n€      DD-SEP(X,      Y,      Mx)      if      and      only      if      there  \n \n  is   \n \na      collider      path   \n \nX   \n \n4      Vi   \n \n©      ar      Ve-1      <—*V      in Mx,      where      (1)   \n \nY   \n \n€      PossDe(X,      Ml);      (2)      Vi,---      ,Ve—-1   \n \n€ DD-SEP(X,      Y,      Mx);      (3)   \n \nV   \n \n€      Anc(Y,      M1)      or      the      subgraph M|Qy]      is      not   \n \na      complete      graph,      where      Qy   \n \n=      {V’   \n \n€       Anc(Y,      M)   \n \n|   \n \nV      o«      V’      in      M}."
            },
            {
              "id": 1538,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Proposition      3. Given   \n \na      maximal      local      MAG      M,      if   \n \nV   \n \n€       DD-SEP(X,      Y,      Mx),      then   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)      in      any MAG      M      consistent      with      M      such      that      there      exists      an      adjust-  \n \n  ment      set      relative      to      (X,Y). Combining      the      parts      above,      we      provide      PAGrules      in      Alg."
            },
            {
              "id": 1539,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "8]  \n \n  for      set      determination,      based      on      the      framework      of      PAGcauses. Note      if   \n \nX   \n \n¢      PossAn(Y,      ?)      on      Line      2,   \n \nX      has      no      causal      ef-  \n \n  fect      on   \n \nY      in      all      the      MAGs      consistent      with      P,      thus      there      is      no       need      to      consider      the      set      of      possible      causal      effects."
            },
            {
              "id": 1540,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Similarly,  \n \n  if      the      causal      effect      is      identifiable      by      covariate      adjustment      in  \n \n  P,      we      can      directly      return      the      causal      effect      by      Prop.)\nwhich  \n \n  is      detailed      in      Appendix      [A.3|      On      Line      5,      we      enumerate      all  \n \n  possible      local      transformations      of      X,      which      is      represented  \n \n  by   \n \na      set      of      vertices      C      that      implies      transforming      the      edge  \n \n  Xo   \n \nV      to   \n \nX      ¢xV      if   \n \nV   \n \n€      Candto   \n \nX   \n \n>      VifV      ¢C."
            },
            {
              "id": 1541,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Evidently,      all      the      sets      C      can      represent      all      the      possible      local  \n \n  transformations      of      X."
            },
            {
              "id": 1542,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "On      Line      6-7,      we      obtain      all      the      valid  \n \n  local      transformations      of   \n \nX      and      obtain      the      maximal      local  \n \n  However,      the      method      above      is      still      somewhat      inefficient,      be-  \n \n  cause      the      enumeration      of      all      the      subsets      of      V(M)\\\\\\\\{X,      Y}  \n \n  is      not      always      necessary."
            },
            {
              "id": 1543,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "In      fact,      given   \n \na      maximal      local  \n \n  MAG,      some      vertices      can      be      determined      to      belong      to      the  \n \n  _  \n \n  MAGs      based      on      each      valid      local      transformation. According  \n \n  to      Prop. B|      we      only      need      to      consider      the      potential      adjust-  \n \n  ment      set      containing      DD-SEP(X,      Y,      M),      which      is      executed  \n \n  on      Line      8."
            },
            {
              "id": 1544,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "And      from      Line      9-12,      we      evaluate      whether      each  \n \n  potential      adjustment      set      is      an      adjustment      set      by      Alg. Finally,      Cor. [i]implies      that      PAGrules      can      return      the      set      of  \n \n  causal      effects      that      are      identifiable      by      covariate      adjustment  \n \n  in      the      DAGs      represented      by      the      MAGs      consistent      with      P."
            },
            {
              "id": 1545,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Corollary      1."
            },
            {
              "id": 1546,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "For   \n \na      PAG      P,      denote      CE(P)      and      CE(P)      the  \n \n  set      of      causal      effects      in      the      DAGs      represented      by      the      MAGs  \n \n  consistent      with      P      that      can      be      estimated      by      covariate      adjust-  \n \n  ment      with      obseryable      variables      and      the      set      of      causal      effects  \n \n  set      AG  \n \n  output      by      Alg.|3}      It      holds      that      CE(P)   \n \n=      CE(P)."
            },
            {
              "id": 1547,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "5. Conclusion\nsion  \n \n  It      remains      an      open      problem      for   \n \na      long      time      that      what      causal  \n \n  relations      are      identifiable      from      observational      data      and      back-  \n \n  ground      knowledge      (BK)      in      the      presence      of      latent      variables. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK."
            },
            {
              "id": 1548,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "The      rules      are      quite      different      from      the      existing      rules      in  \n \n  the      form. We      believe      the      proposed      rules      can      take      some      new       insights      to      the      open      problem      and      could      possibly      inspire      the  \n \n  establishment      of      the      sound      and      complete      rules      in      the      future."
            },
            {
              "id": 1549,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Further,      by      utilizing      the      proposed      rules,      we      present   \n \na      novel  \n \n  algorithm      to      determine      the      set      of      possible      causal      effects  \n \n  given   \n \na      PAG. The      rules      can      help      improve      the      efficiency      of  \n \n  the      state-of-the-art      method."
            },
            {
              "id": 1550,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "In      the      future,      it      is      worthy      to      continue      investigating      the      sound  \n \n  and      complete      rules      to      incorporate      BK,      based      on      the      rules  \n \n  that      have      been      established."
            },
            {
              "id": 1551,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In      addition,      in      light      of      the      fact  \n \n  that      only   \n \na      Markov      equivalence      class      (MEC)      is      identifiable  \n \n  given      observational      data,      the      causal      effect      is      usually      uniden-  \n \n  tifiable      within   \n \na      MEC."
            },
            {
              "id": 1552,
              "title": "4.3.      The      Algorithm      for      Set      Determination - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Hence,      exploring      and      exploiting      the  \n \n  additional      knowledge      that      is      available      in      practice      may      be  \n \n  helpful      to      causal      effect      estimation      tasks."
            }
          ],
          "content": ""
        },
        {
          "id": 1553,
          "title": "5.      Conclusion",
          "type": "section",
          "children": [
            {
              "id": 1554,
              "title": "5.      Conclusion - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "5. Conclusion\nsion  \n \n  It      remains      an      open      problem      for   \n \na      long      time      that      what      causal  \n \n  relations      are      identifiable      from      observational      data      and      back-  \n \n  ground      knowledge      (BK)      in      the      presence      of      latent      variables. In      this      paper,      we      propose      two      novel      rules      for      incorporating  \n \n  BK."
            },
            {
              "id": 1555,
              "title": "5.      Conclusion - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "The      rules      are      quite      different      from      the      existing      rules      in  \n \n  the      form. We      believe      the      proposed      rules      can      take      some      new       insights      to      the      open      problem      and      could      possibly      inspire      the  \n \n  establishment      of      the      sound      and      complete      rules      in      the      future."
            },
            {
              "id": 1556,
              "title": "5.      Conclusion - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Further,      by      utilizing      the      proposed      rules,      we      present   \n \na      novel  \n \n  algorithm      to      determine      the      set      of      possible      causal      effects  \n \n  given   \n \na      PAG. The      rules      can      help      improve      the      efficiency      of  \n \n  the      state-of-the-art      method."
            },
            {
              "id": 1557,
              "title": "5.      Conclusion - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "In      the      future,      it      is      worthy      to      continue      investigating      the      sound  \n \n  and      complete      rules      to      incorporate      BK,      based      on      the      rules  \n \n  that      have      been      established."
            },
            {
              "id": 1558,
              "title": "5.      Conclusion - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "In      addition,      in      light      of      the      fact  \n \n  that      only   \n \na      Markov      equivalence      class      (MEC)      is      identifiable  \n \n  given      observational      data,      the      causal      effect      is      usually      uniden-  \n \n  tifiable      within   \n \na      MEC."
            },
            {
              "id": 1559,
              "title": "5.      Conclusion - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Hence,      exploring      and      exploiting      the  \n \n  additional      knowledge      that      is      available      in      practice      may      be  \n \n  helpful      to      causal      effect      estimation      tasks."
            }
          ],
          "content": ""
        },
        {
          "id": 1560,
          "title": "References",
          "type": "section",
          "children": [
            {
              "id": 1561,
              "title": "References - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "References\n \n \n  Ali,      R. A.,      Richardson,      T.,      Spirtes,      P.,      and      Zhang,      J. Orien-  \n \n  tation      rules      for      constructing      markov      equivalence      classes  \n \n  of      maximal      ancestral      graphs. Technical      report,      2005. Andrews,      B.,      Spirtes,      P.,      and      Cooper,      G. F."
            },
            {
              "id": 1562,
              "title": "References - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "On      the      com-  \n \n  pleteness      of      causal      discovery      in      the      presence      of      latent  \n \n  confounding      with      tiered      background      knowledge. In      Pro-  \n \n  ceedings      of      the      23rd      International      Conference      on      Artifi-  \n \n  cial      Intelligence      and      Statistics,      pp. 4002-4011,      2020."
            },
            {
              "id": 1563,
              "title": "References - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Cai,      R.,      Chen,      J.,      Li,      Z.,      Chen,      W.,      Zhang,      K.,      Ye,      J.,      Li,      Z.,  \n \n  Yang,      X.,      and      Zhang,      Z. Time      series      domain      adaptation  \n \n  via      sparse      associative      structure      alignment. In      Proceedings  \n \n  of      the      35th      AAAI      Conference      on      Artificial      Intelligence,      pp. 6859-6867,      2021. Fang,      Z. and      He,      Y."
            },
            {
              "id": 1564,
              "title": "References - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "IDA      with      background      knowledge. In  \n \n  Proceedings      of      the      Thirty-Sixth      Conference      on      Uncer-  \n \n  tainty      in      Artificial      Intelligence,      volume      124      of      Proceed-  \n \n  ings      of      Machine      Learning      Research,      pp. 270-279. AUAI  \n \n  Press,      2020. Gong,      M.,      Zhang,      K.,      Liu,      T.,      Tao,      D.,      Glymour,      C.,      and       Scholkopf,      B."
            },
            {
              "id": 1565,
              "title": "References - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Domain      adaptation      with      conditional      trans-  \n \n  ferable      components. In      Balcan,      M. and      Weinberger,      K. Q. (eds.),      Proceedings      of      the      33nd      International      Conference  \n \n  on      Machine      Learning,      pp. 2839-2848,      2016. Hauser,      A. and      Bithlmann,      P. Two      optimal      strategies      for  \n \n  active      learning      of      causal      models      from      interventional      data."
            }
          ],
          "content": ""
        },
        {
          "id": 1566,
          "title": "      International      Journal      of      Approximate      Reasoning,      55(4):",
          "type": "section",
          "children": [
            {
              "id": 1567,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "International      Journal      of      Approximate      Reasoning,      55(4):\n \n \n  926-939,      2014. He,      Y. and      Geng,      Z. Active      learning      of      causal      networks      with  \n \n  intervention      experiments      and      optimal      designs. Journal      of  \n \n  Machine      Learning      Research,      9:2523-2547,      2008. Huang,      B.,      Feng,      F.,      Lu,      C.,      Magliacane,      S.,      and      Zhang, K."
            },
            {
              "id": 1568,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Adarl:      What,      where,      and      how      to      adapt      in      transfer  \n \n  reinforcement      learning. In      Proceedings      of      the      10th      Inter-  \n \n  national      Conference      on      Learning      Representations,      2022. Jaber,      A.,      Kocaoglu,      M.,      Shanmugam,      K.,      and      Bareinboim, E."
            },
            {
              "id": 1569,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Causal      discovery      from      soft      interventions      with      un-  \n \n  known      targets:      Characterization      and      learning. In      Ad-  \n \n  vances      in      Neural      Information      Processing      Systems,      2020. Maathuis,      M. H.,      Kalisch,      M.,      Biihlmann,      P,      et      al. Estimat-  \n \n  ing      high-dimensional      intervention      effects      from      observa-  \n \n  tional      data."
            },
            {
              "id": 1570,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "The      Annals      of      Statistics,      37(6A):3133-3164,  \n \n  2009. Maathuis,      M. H.,      Colombo,      D.,      et      al. A      generalized      back-  \n \n  door      criterion. The      Annals      of      Statistics,      43(3):1060—-1088,  \n \n  2015. Malinsky,      D. and      Spirtes,      P. Estimating      causal      effects      with  \n \n  ancestral      graph      markov      models."
            },
            {
              "id": 1571,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "In      Conference      on      Proba-  \n \n  bilistic      Graphical      Models,      pp. 299-309,      2016. Meek,      C. Causal      inference      and      causal      explanation      with  \n \n  background      knowledge. In      Proceedings      of      the      I1st      An-  \n \n  nual      Conference      on      Uncertainty      in      Artificial      Intelligence,  \n \n  pp. 403-410,      1995. Pearl,      J. Causality. Cambridge      University      Press,      2009."
            },
            {
              "id": 1572,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Perkovic,      E.,      Kalisch,      M.,      and      Maathuis,      M. H. Interpret-  \n \n  ing      and      using      cpdags      with      background      knowledge. In  \n \n  Proceedings      of      the      33rd      Conference      on      Uncertainty      in  \n \n  Artificial      Intelligence,      2017a. Perkovic,      E.,      Textor,      J.,      Kalisch,      M.,      and      Maathuis,      M. H."
            },
            {
              "id": 1573,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Complete      graphical      characterization      and      construction      of  \n \n  adjustment      sets      in      markov      equivalence      classes      of      ancestral  \n \n  graphs. Journal      of      Machine      Learning      Research,      18:220:1-  \n \n  220:62,      2017b. Richardson,      T.,      Spirtes,      P.,      et      al. Ancestral      graph      markov  \n \n  models. The      Annals      of      Statistics,      30(4):962—1030,      2002."
            },
            {
              "id": 1574,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Ruan,      K.,      Zhang,      J.,      Di,      X.,      and      Bareinboim,      E. Causal      imi-  \n \n  tation      learning      via      inverse      reinforcement      learning. In      Pro-  \n \n  ceedings      of      the      11st      International      Conference      on      Learn-  \n \n  ing      Representations,      2023. Schélkopf,      B.,      Janzing,      D.,      Peters,      J.,      Sgouritsa,      E.,      Zhang,  \n \n  K.,      and      Mooij,      J. M."
            },
            {
              "id": 1575,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "On      causal      and      anticausal      learning. In      Proceedings      of      the      29th      International      Conference      on  \n \n  Machine      Learning,      pp. 459-466,      2012. Spirtes,      P.,      Glymour,      C. N.,      and      Scheines,      R. Causation,  \n \n  prediction,      and      search. MIT      Press,      2000. van      der      Zander,      B.,      Liskiewicz,      M.,      and      Textor,      J."
            },
            {
              "id": 1576,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Construct-  \n \n  ing      separators      and      adjustment      sets      in      ancestral      graphs. In  \n \n  Proceedings      of      the      Thirtieth      Conference      on      Uncertainty  \n \n  in      Artificial      Intelligence,      pp. 907-916,      2014. Venkateswaran,      A. and      Perkovic,      E. Towards      complete  \n \n  causal      explanation      with      expert      knowledge. arXiv      preprint  \n \n  arXiv:      2407.07338,      2024. Verma,      T."
            },
            {
              "id": 1577,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "and      Pearl,      J. Equivalence      and      synthesis      of      causal  \n \n  models. In      Proceedings      of      the      Sixth      Annual      Conference  \n \n  on      Uncertainty      in      Artificial      Intelligence,      pp. 255-270,  \n \n  1990. Verma,      T. and      Pearl,      J. An      algorithm      for      deciding      if   \n \na      set  \n \n  of      observed      independencies      has   \n \na      causal      explanation."
            },
            {
              "id": 1578,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "In  \n \n  Proceedings      of      the      8th      Annual      Conference      on      Uncertainty  \n \n  in      Artificial      Intelligence,      pp. 323-330,      1992. von      Kiigelgen,      J.,      Mey,      A.,      Loog,      M.,      and      Schdélkopf,      B. Semi-supervised      learning,      causality,      and      the      conditional  \n \n  cluster      assumption."
            },
            {
              "id": 1579,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of      the      36th      Confer-  \n \n  ence      on      Uncertainty      in      Artificial      Intelligence,      pp. 1-10,  \n \n  2020. Wang,      T.-Z.,      Qin,      T.,      and      Zhou,      Z.-H. Estimating      possi-  \n \n  ble      causal      effects      with      latent      variables      via      adjustment. In      Proceedings      of      the      40th      International      Conference      on  \n \n  Machine      Learning,      pp."
            },
            {
              "id": 1580,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "36308-36335,      2023a. Wang,      T.-Z.,      Qin,      T.,      and      Zhou,      Z.-H. Sound      and      complete  \n \n  causal      identification      with      latent      variables      given      local      back-  \n \n  ground      knowledge. Artificial      Intelligence,      322:103964,  \n \n  2023b. Wang,      T.-Z.,      Du,      W.-B.,      and      Zhou,      Z.-H. An      efficient      maxi-  \n \n  mal      ancestral      graph      listing      algorithm."
            },
            {
              "id": 1581,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "In      Proceedings      of  \n \n  the      41st      International      Conference      on      Machine      Learning,  \n \n  2024. Wiendbst,      M.,      Luttermann,      M.,      Bannach,      M.,      and       Liskiewicz,      M. Efficient      enumeration      of      markov      equiva-  \n \n  lent      dags. In      Proceedings      of      the      37th      AAAI      Conference  \n \n  on      Artificial      Intelligence,      pp. 12313-12320,      2023."
            },
            {
              "id": 1582,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Witte,      J.,      Henckel,      L.,      Maathuis,      M. H.,      and      Didelez,      V. On      efficient      adjustment      in      causal      graphs. The      Journal      of  \n \n  Machine      Learning      Research,      21(1):9956—10000,      2020. Zhang,      J. On      the      completeness      of      orientation      rules      for  \n \n  causal      discovery      in      the      presence      of      latent      confounders  \n \n  and      selection      bias."
            },
            {
              "id": 1583,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Artificial      Intelligence,      172(16-17):\n \n \n  1873-1896,      2008. Zhang,      K.,      Gong,      M.,      Stojanov,      P.,      Huang,      B.,      Liu,      Q.,      and       Glymour,      C. Domain      adaptation      as   \n \na      problem      of      inference  \n \n  on      graphical      models. In      Advances      in      Neural      Information  \n \n  Processing      Systems      33,      2020. A. Detailed      Preliminary\nA.1."
            },
            {
              "id": 1584,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Graphs\n \n \n  In   \n \na      graph      G,      consider   \n \na      path      p   \n \n=      (Vi,      V2,---   \n \n,      Vx),      p      is   \n \na      directed      path      if      there      is      V;   \n \n>      Vizi,      V1      <i   \n \n<      k-—1;      pisa  \n \n  collider      path      if      there      is      V;_1*—      V;      <+*Vj41,      V2      <i   \n \n<   \n \nk   \n \n—      1;      p      is      minimal      if      any      two      non-consecutive      vertices      are      not  \n \n  adjacent."
            },
            {
              "id": 1585,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "A      vertex      Vj      is   \n \na      parent      of      V2      if      there      is      Vi   \n \n—      V2. V;      is      an      ancestor/descendant      of      V2      if      there      is   \n \na      directed      path  \n \n  from      V\\\\\\\\/V2      to      V2/V,. V,      is   \n \na      possible      ancestor/possible      descendant      of      V2      if      there      is   \n \na      possible      directed      path      from      V/V  \n \n  to      V2/V,."
            },
            {
              "id": 1586,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Note      each      vertex      is      an      ancestor/descendant/possible      ancestor/possible      descendant      of      itself. An      edge      in      the      form  \n \n  of      o—o      is   \n \na      circle      edge. The      circle      component      of   \n \na      graph      G      is      the      subgraph      of      G   \n \n=      (V,E)      consisting      of      the      vertices V\n \n   and      all      the      circle      edges."
            },
            {
              "id": 1587,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "We      say      two      vertices      V;      and      V;      is   \n \na      connected      circle      component      in      G      if      there      is   \n \na      circle      path  \n \n  Vj;      0-0      ---      0-0      V;      from      V;      to      V;      in      G."
            },
            {
              "id": 1588,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "For      two      paths      p;   \n \n=      (Vi,      Vo,---   \n \n,      Va)      and      po   \n \n=      ($1,      S2,---   \n \n,      Sn),      we      use      pi   \n \n@      pe      to  \n \n  denote      the      concatenate      path      (Vi,---   \n \n,      Va,      S1,-+-   \n \n,      Sn)."
            },
            {
              "id": 1589,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \na      path      V;   \n \n—      V2   \n \n>      ---   \n \n>      Vy      and      an      edge      Vg   \n \n—      V\\\\\\\\/Vq   \n \n+      V,,      then      there      is   \n \na      directed      cycle/almost      directed      cycle. For   \n \na      mixed      graph,      if      there      is      not   \n \na      directed      cycle      or      almost      directed      cycle,      then      it      is      ancestral."
            },
            {
              "id": 1590,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "For      an      ancestral      graph,      if      for  \n \n  any      two      non-adjacent      vertices,      there      is   \n \na      set      of      vertices      that      m-seperates      them,      then      the      graph      is      maximal. If   \n \na      mixed      graph      is  \n \n  both      ancestral      and      maximal,      it      is   \n \na      maximal      ancestral      graph      (MAG),      denoted      by      M."
            },
            {
              "id": 1591,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is   \n \na      projection      graph      on      the      observable      variables      of      some      underlying      DAGs      containing      both      observable  \n \n  and      latent      variables."
            },
            {
              "id": 1592,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "|Spirtes      et      al.|      (2000);      [Zhang|      (2008)      presented      the      algorithm      to      obtain   \n \na      MAG      with      vertices   \n \nO      from   \n \na       DAG      with      vertices   \n \nO      UL      US,      where      O,      L,      S      denote      the      observable      vertices      set,      latent      vertices      set,      and      selection      vertices  \n \n  set."
            },
            {
              "id": 1593,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Since      we      do      not      consider      selection      bias      in      this      paper,      we      do      not      consider      S      in      the      following. Next      we      show      inducing  \n \n  path      in      Def. 6,      followed      by      the      algorithm      to      obtain   \n \na      MAG      based      on   \n \na      DAG."
            },
            {
              "id": 1594,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      algorithm,      as      the      number      of  \n \n  latent      vertices      can      be      arbitrary,      there      can      be      infinite      number      of      DAGs      which      could      lead      to      one      MAG      by      the      algorithm. Definition   \n \n6      (Inducing      path;      |Spirtes      et      al.|      (2000). Let      X,   \n \nY      be      two      vertices      in      an      maximal      ancestral      graph."
            },
            {
              "id": 1595,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Denote      L,S  \n \n  two      disjoint      sets      of      vertices      that      X,   \n \nY      do      not      belong      to."
            },
            {
              "id": 1596,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "A      path      p      from   \n \nX      to   \n \nY      is      an      inducing      path      relative      to      (L,      S$)      if      every  \n \n  non-endpoint      vertex      on      p      is      either      in      L      or   \n \na      collider,      and      every      collider      on      p      is      an      ancestor      of      either      _X,      Y,      or   \n \na      member      of      S."
            },
            {
              "id": 1597,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Input:   \n \na      DAG      D      over   \n \nV   \n \n=      OUL;  \n \n  Output:   \n \na      MAG      M      over      O."
            },
            {
              "id": 1598,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "(1)      for      each      pair      of      vertices      A,   \n \nB   \n \n€      O,   \n \nA      and   \n \nB      are      adjacent      in      M      if      and      only      if      there      is      an      inducing      path      relative      to      (L,      0)  \n \n  from   \n \nA      to   \n \nB      in      D;\n(2)      for      each      pair      of      adjacent      vertices      A,   \n \nB      in      M,      orient      the      edge      between   \n \nA      and   \n \nB      according      to      the      following      steps:\n(a)      orient      A>      Bin      M      if   \n \nA   \n \n€      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D);\n(b)      orient      A+      Bin      M      if   \n \nB   \n \n€      Anc(A,D)      and   \n \nA   \n \n¢      Anc(B,D);\n(c)      orient   \n \nA      Bin      M      if   \n \nA   \n \n¢      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D)."
            },
            {
              "id": 1599,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      we      can      only      identify   \n \na      Markov      equivalence      class      (MEC)      of      MAGs,      which      is      represented      by   \n \na       partial      ancestral      graph      (PAG)      and      denoted      by      P."
            },
            {
              "id": 1600,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      PAG,      there      is      an      arrowhead/tail      at      some      position      if      and      only      if      there      is  \n \n  an      arrowhead/tail      at      this      position      in      all      the      MAGs      in      the      MEC;      and      there      is   \n \na      circle      at      some      position      if      and      only      if      there      are  \n \n  both      arrowheads      and      tails      at      this      position      in      all      the      MAGs      in      the      MEC."
            },
            {
              "id": 1601,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "A.2. Preliminary      about      Orientation      Rules\n \n \n  Ali      et      al.|      (2005);      Zhang)      (2008)      proposed      ten      rules      7;   \n \n—      R40      to      identify   \n \na      PAG      with      observational      data."
            },
            {
              "id": 1602,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Jaber      et      al.|      (2020)  \n \n  presented      the      solid      result      to      imply      that      when      there      is      additional      interventional      data      and      selection      bias      is      not      allowed      for,      the  \n \n  ten      rules      are      also      complete."
            },
            {
              "id": 1603,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "Another      study      (Andrews      et      al.|      /2020)      indicates      that      the      ten      rules      are      complete      if      we      incorporate  \n \n  tiered      background      knowledge,      which      means      that      the      BK      can      classify      the      variables      into      distinct      parts,      where      the      causal      order  \n \n  between      different      parts      is      explicit,      but      the      structural      information      within      each      part      cannot      be      directly      known      according      to      the  \n \n  BK."
            },
            {
              "id": 1604,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Further,      when      we      have      obtained   \n \na      PAG      and      incorporate      local      background      knowledge      (local      BK),      i.e.,      the      full      structural  \n \n  knowledge      regarding      some      specific      variables,      Wang      et      al.|(2023b)      proposed   \n \na      rule      R4,      to      replace   \n \n4      and      an      additional      rule  \n \n  Ri."
            },
            {
              "id": 1605,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "|Wang      et      al.|      (2023b)      proved      that      the      rules      are      sound      and      complete      to      incorporate      local      BK      into   \n \na      PAG. We      show      these  \n \n  tules      in      the      following."
            },
            {
              "id": 1606,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Since      R;   \n \n—      R7      are      triggered      only      if      the      selection      bias      is      involved      and      we      assume      the      absence      of  \n \n  selection      bias,      we      omit      these      three      rules. R1:      If      Ax>      Box      R,      and   \n \nA      and   \n \nR      are      not      adjacent,      then      orient      the      triple      as      Ax>      B—      R."
            },
            {
              "id": 1607,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Reo:      If   \n \nA   \n \n>      Bx>      Ror      At>   \n \nB   \n \n>      R,      and   \n \nA      +~      R,      then      orient   \n \nA      «©      Ras      Ax>      R. Rs3:      If      Ax>      BorR,   \n \nA      x0      Do      R,   \n \nA      and   \n \nR      are      not      adjacent,      and      D      +o      B,      then      orient      D      *-o   \n \nB      as      Dx      B."
            },
            {
              "id": 1608,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Ra: If (k,,A,B, R) is a discriminating path between K and R for B, and B o-* R; then if B € Sepset(K, R),  \n \n  orient   \n \nB      o-«      -R      as   \n \nB   \n \n+      R;      otherwise      orient      the      triple      (A,      B,      R)      as   \n \nA      Bo      R. Res:      If   \n \nA   \n \nB      —-      R,      and      Ao>      R,      orient      Ao>      Ras      A-      R."
            },
            {
              "id": 1609,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "Ro: If Ao R, and p = (A, B, D,, R) is an uncovered possible directed path from A to R such that R and B are  \n \n  not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R. Rio:      Suppose      Ao>      R,   \n \nB   \n \n+   \n \nR   \n \n«      D,      p;      is      an      uncovered      possible      directed      path      from   \n \nA      to      B,      and      pz      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to      D."
            },
            {
              "id": 1610,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Let   \n \nU      be      the      vertex      adjacent      to   \n \nA      on      p;      (U      could      be      B),      and      W      be      the      vertex  \n \n  adjacent      to   \n \nA      on      pz      (W      could      be      D). If   \n \nU      and      W      are      distinct,      and      are      not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R."
            },
            {
              "id": 1611,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Ri:      If      (K,---   \n \n,      A,      B,      R)      is   \n \na      discriminating      path      between   \n \nK      and   \n \nR      for      B,      and   \n \nB      o-*      R,      then      orient      Bo-*«      Ras   \n \nB   \n \n>      R. Ri:      If      A-©B,      then   \n \nA   \n \n>      B. A.3."
            },
            {
              "id": 1612,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Causal      Effect      Estimation\nDefinition   \n \n7      (Adjustment      set;      Pearl]      (2009);      /van      der      Zander      et      al|      (2014)."
            },
            {
              "id": 1613,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      DAG,      MAG,      or      PAG      G,,   \n \nZ      is      an      adjustment  \n \n  set      relative      to      (X,Y)      if      for      any      probability      density      f      compatible      with      G,      the      causal      effect      of   \n \nX      on   \n \nY (YX),      ifZ      =,  \n \n  P(Y|do(X))   \n \n=   \n \n|      poet      P(Y|Z,      X)P(Z)dZ,   \n \n_      otherwise."
            },
            {
              "id": 1614,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "©\n \n \n  Maathuis      et      al.|      (2015);      |Perkovic      et      al.|(2017b)      presented      the      necessary      and      sufficient      graphical      characterization      for      the      causal  \n \n  effect      identifiablility      via      covariate      adjustment      given   \n \na      DAG/CPDAG/MAG/PAG. We      show      them      in      Prop. 4]      See      Maathuis  \n \n  et      al.|      (2015)      for      the      notation      Gx."
            },
            {
              "id": 1615,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "At      first,      we      introduce      an      important      concept      D-SEP(X,      Y,      G)      in      Def.|8}      D-SEP(X,      Y,      G)  \n \n  is      essentially   \n \na      set      of      vertices. Definition   \n \n8      (D-SEP(X,      Y,      G);|Spirtes      et      al.|(2000)). Let   \n \nX      and   \n \nY      be      two      distinct      vertices      in   \n \na      mixed      graph      G."
            },
            {
              "id": 1616,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "We      say  \n \n  that   \n \nV   \n \n€      D-SEP(X,      Y,      G)      if   \n \nV   \n \n4      X,      and      there      is   \n \na      collider      path      between   \n \nX      and   \n \nV      in      G,      such      that      every      vertex      on      this      path  \n \n  (including      V)      is      an      ancestor      of   \n \nX      or   \n \nY      inG. Proposition   \n \n4      (Maathuis      et      al.|      (2015);      Perkovic      et      al.|(2017b))."
            },
            {
              "id": 1617,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Let      G      be   \n \na      MAG      or      PAG,      and   \n \nX      and   \n \nY      be      two      distinct  \n \n  vertices      in      G. There      exists      an      adjustment      set      relative      to      (X,Y)      in      G      ifand      only      ifY   \n \n¢      Adj(X,      Gx)      and      D-SEP(X,      Y,Gx)N  \n \n  PossDe(X,      G)   \n \n=      9."
            },
            {
              "id": 1618,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      if      an      adjustment      set      exists,      then      D-SEP(X,      Y,      Gx)      is      such   \n \na      set. Denote      D-SEP(X,      Y,      Gx)  \n \n  by      D,      then f(V      |do(X      =f      f(D)      f(V|D,   \n \nX      =a)      dD. (2) B. A      Detailed      Introduction      to      PAGcauses      (Wang      et      al."
            },
            {
              "id": 1619,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "2023a)\n \n \n  In      this      part,      we      introduce      the      method      PAGcaused      to      determine      the      set      of      possible      causal      effects      given   \n \na      PAG,      which      is  \n \n  proposed      by      |Wang      et      al. (2023a). We      first      show      some      theoretical      results      of      Wang      et      al. (2023a). Some      of      these      results      are  \n \n  needed      in      our      proof."
            },
            {
              "id": 1620,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "The      first      important      result      is      Prop. 5}      It      provides   \n \na      graphical      characterization      for      the      adjustment      set      comprised      of      observable  \n \n  variables      in      all      the      DAGs      represented      by   \n \na      given      MAG."
            },
            {
              "id": 1621,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "It      implies      that      there      exists   \n \na      DAG      where      the      causal      effect      of   \n \nX       on   \n \nY      is      identifiable      by      covariate      adjustment      and      the      adjustment      set      is      comprised      of      some      observable      variables      if      and      only  \n \n  if      D-SEP(X,      Y,      Mx)      De(X,      M)   \n \n=      0,      and      D-SEP(X,      Y,      Mx)      is      the      adjustment      set."
            },
            {
              "id": 1622,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Hence,      given   \n \na      MAG      M,      we      can determine      whether      there      exists      some      DAG      where      the      causal      effect      is      identifiable      by      adjusting      for      observable      variables  \n \n  without      the      need      the      enumerate      the      DAGs. And      for      all      the      DAGs      above,      they      are      associated      with      the      same      causal      effect. Proposition      5."
            },
            {
              "id": 1623,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "Suppose   \n \na      MAG      M      where   \n \nX   \n \n©      Anc(Y,      M). There      exists   \n \na      DAG      D      represented      by      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      in      D      can      be      identified      by      adjusting      for   \n \na      set      comprised      of      V(M)      if      and      only      if      D-SEP(X,      Y,      Mx)   \n \n9 De(X,      M)   \n \n=      @."
            },
            {
              "id": 1624,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      such   \n \na      set      exists,      D-SEP(X,      Y,      Mx)      is      an      adjustment      set."
            },
            {
              "id": 1625,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the      following,      when we      say      an      adjustment      set      in      M,      it      means      the      adjustment      set      in      the      DAGs      represented      by      the      MAG      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      can      be      identified      by      adjusting      for      this      adjustment      set. According      to      Prop."
            },
            {
              "id": 1626,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "5,      when      addressing      the      set      determination      task      for      the      causal      effect      of   \n \nX      on      Y,      we      only      need      to      consider  \n \n  the      MAG      in      the      MEC      presented      by      ?,      without      the      need      to      consider      the      DAGs."
            },
            {
              "id": 1627,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Considering      there      are      many      circles      ina      PAG  \n \n  P,      PAGcauses      considers      transforming      the      circles      of   \n \nX      at      first."
            },
            {
              "id": 1628,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "They      use   \n \na      set      of      vertices      C      to      represent   \n \na      local      transformation  \n \n  of      X,      i.e.,      transform   \n \nX      o*   \n \nV      to   \n \nX      <«V      if   \n \nV   \n \n€      C      and      transform   \n \nX      o*«   \n \nV      to   \n \nX      -*«V      if   \n \nV   \n \n€      {V   \n \n€      V(P)|X      o*   \n \nV      in      P}\\\\\\\\C."
            },
            {
              "id": 1629,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "An      important      problem      here      is      to      evaluate      the      validity      of      each      local      transformation,      i.e.,      whether      there      is   \n \na      MAG      consistent  \n \n  with      this      local      transformation      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1630,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "For      this      purpose,      they      presented   \n \na      graphical      characterization  \n \n  for      the      valid      local      transformation      of   \n \nX      implied      by      C      given      the      PAG      P,      which      is      shown      in      Prop. 6,      The      three      conditions      in  \n \n  Prop. (6|      can      be      evaluated      in      O(d?),      where      d      denotes      the      number      of      vertices. In      Prop."
            },
            {
              "id": 1631,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "(6      the      concept      of      bridged      is      involved, which      is      shown      in      Def. 9       Definition   \n \n9      (Bridged      relative      to      V’      in      H;      |Wang      et      al.||2023a). Let      H      be   \n \na      partial      mixed      graph. Denote      H’   \n \na      subgraph  \n \n  of      H      induced      by   \n \na      set      of      vertices      K."
            },
            {
              "id": 1632,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      V’      in      H      that      is      disjoint      of      K,      two      vertices   \n \nA      and   \n \nB       in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V\\\\\\'      if      either   \n \nA   \n \n=   \n \nB      or      in      each      minimal      circle      path  \n \n  A(=      Vo)      o-0      Vj      o-0---      0-0      V,,      o-0      B(=      V,,41)      from   \n \nA      to   \n \nB      in      H’,      there      exists      one      vertex      V;,0   \n \n<      s   \n \n<      n+      1,      such      that  \n \n  Fy,   \n \n©      Fv,,,,0<i<s—land      Fy,,,      C      Fy,,s      <i      <n,      where      Fy,   \n \n=      {V   \n \n€      V’   \n \n|   \n \nV      +0      V;      or      Vx>      V;      in      H}."
            },
            {
              "id": 1633,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "Further,  \n \n  H\\\\\\'      is      bridged      relative      to      V’      in      H      if      any      two      vertices      in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V’. Proposition      6."
            },
            {
              "id": 1634,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG      P,      for      any      set      of      vertices      C      C      {V   \n \n|   \n \nX      o-*   \n \nV      in      P},      there      exists   \n \na      MAG      M      consistent      with      P       with   \n \nX      +*V,      VV   \n \n€      Cand   \n \nX   \n \n>      V,VV   \n \n€      {V   \n \n|   \n \nX      o«V      in      P}\\\\\\\\C      ifand      only      if\n(1)      PossDe(X,      P{[—C])      N      Pa(C,      P)   \n \n=      0;\n(2)      the      subgraph      P|C]      of      P      induced      by      C      is   \n \na      complete      graph;\n(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P\n \n{   \n \nX      }]      is      bridged      relative      to      C   \n \nU      {X}      in      P."
            },
            {
              "id": 1635,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "After      incorporating   \n \na      valid      local      transformation      into      the      PAG      ?,      [Wang      et      al.|(2023a)      used      the      sound      and      complete      orientation  \n \n  rules      Ry   \n \n—      R3,R4,Rz   \n \n—      Rio,      R11      to      further      update      the      graph. And      the      obtained      graph      is      called      by      maximal      local      MAG,  \n \n  denoted      by      M."
            },
            {
              "id": 1636,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "By      incorporating      different      valid      local      transformations,      PAGcauses      can      obtain      different      maximal      local      MAGs. However,      determining   \n \na      maximal      local      MAG      M      is      not      sufficient      for      determining      the      only      adjustment      set      in      all      the      MAGs  \n \n  consistent      with      MI."
            },
            {
              "id": 1637,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      established      the      graphical      characterization      for      the      adjustment      set      in      the      MAGs      consistent  \n \n  with      M      in      Prop. 2)and      Prop. {7}      Both      Prop. [2]and      Prop."
            },
            {
              "id": 1638,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "[/]ensure      that      PAGcauses      can      find      the      same      set      of      causal      effects      given  \n \n  M      as      methods      to      enumerate      all      the      MAGs      consistent      with      M. Proposition      7. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y)."
            },
            {
              "id": 1639,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1640,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": "Then      W      is   \n \na      potential      adjustment      set      in      M      and      there      exists   \n \na      block set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      V’      inM};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M\nM."
            },
            {
              "id": 1641,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "With      the      results      above,      they      proposed      their      method      PAGcauses      in      Alg. A}  \n \n  In      the      proof      of      Prop. |2}      if      the      three      conditions      are      satisfied,      they      present      an      algorithm      to      construct   \n \na      MAG      consistent      with      M       such      that      the      adjustment      set      is      W. We      show      the      algorithm      in      Alg."
            },
            {
              "id": 1642,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 76",
              "type": "chunk",
              "children": [],
              "content": "[5}  \n \n  3\nAlgorithm      4:      PAGcauses Input:      PAG      P,      X,Y  \n \n  AS(P)      =0)      //      Record      all      the      valid      adjustment      sets;\n      if      X      ¢      PossAn(Y,      ?)      then      return      No      causal      effects;       if      the      conditions      in      Prop.\\\\\\\\4      Hare      satisfied      for      P      then       |      return      AS(P)      +      {D-SEP(X,      Y,      Px)}      //      Prop."
            },
            {
              "id": 1643,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 77",
              "type": "chunk",
              "children": [],
              "content": "[4       4       5       6       7       8       9       10       11 for      each      setC      C{V      |      V      «0      X      in      P}      do       if      the      three      conditions      in      Prop. (dare      satisfied      then       Obtain      a      maximal      local      MAG      M      based      on      P      and      C;       Find      all      potential      adjustment      sets      W,,      W2,---      given      M      according      to      Def."
            },
            {
              "id": 1644,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 78",
              "type": "chunk",
              "children": [],
              "content": "for      each      potential      adjustment      set      W;,      do       for      each      block      set      S      do       if      the      three      conditions      in      Prop."
            },
            {
              "id": 1645,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 79",
              "type": "chunk",
              "children": [],
              "content": "2Jare      satisfied      given      S      then AS(P)      +      AS(P)      U      {Wi}: 12       13 break      //      Break      the      loop      of      S;       Output:      Set      of      causal      effects      via      adjustment      in      the      given      PAG      P      identified      with      AS(P)      by      (i)\nAlgorithm      5:      Orient   \n \na      maximal      local      MAG      of   \n \nX      as   \n \na      MAG  \n \n  input:      Maximal      local      MAG      M,      potential      adjustment      set      W      and      corresponding      W      according      to      Def."
            },
            {
              "id": 1646,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 80",
              "type": "chunk",
              "children": [],
              "content": "2}      PI      block      set      S       1:      for      VK   \n \n€      PossDe(W,      M[—S])      and      VT   \n \n€      S      such      that   \n \nK      o~*   \n \nT      in      M,      orient      it      as   \n \nK      <+*T\\\\\\'      (the      mark      at   \n \nT      remains);  \n \n  2:      update      the      subgraph      M[PossDe(W,      M[—S])]      as      follows      until      no      feasible      updates:      for      any      two      vertices      V;      and      V;      such  \n \n  that      V;      0-0      V;,      orient      itas      V;   \n \n+      V;      if      (1)      Fy,      \\\\\\\\Fv;   \n \n#      or      (2)      Fy,   \n \n=      Fy,      as      well      as      there      is   \n \na      vertex  \n \n  V;,   \n \n€      PossDe(W,      M[—S})      not      adjacent      to      V;      such      that      V;,   \n \n>      V;      o-o      V;,      where      Fy,   \n \n=      {V   \n \n€      S|   \n \nV      +0      V;      in      M};  \n \n  3:      orient      the      circles      on      the      remaining      o—      edges      as      tails;  \n \n  4:      in      subgraph      M[PossDe(W,      M[—S])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders;  \n \n  5:      in      subgraph      M[—PossDe(W,      M[-S]])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders."
            },
            {
              "id": 1647,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 81",
              "type": "chunk",
              "children": [],
              "content": "output:   \n \nA      MAG      M\n[I]  \n \n  Suppose      there      are      m      edges      and      d      vertices      in      H. There      are      m      edges      that      can      be      transformed. Hence      the      round      of      loop      is  \n \n  O(m). In      each      round,      suppose      we      want      to      detect      whether   \n \nA      o-*«   \n \nB      can      be      transformed      by      Ry2      or      R13."
            },
            {
              "id": 1648,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 82",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  Line   \n \n2      and      Line   \n \n3      is      O(d). And      determining      the      set      Anc(S      4,      H)      takes   \n \na      O(md)      complexity. Executing      Line   \n \n7      and      Line   \n \n9       take   \n \na      O(m)      complexity. And      the      complexity      of      Line   \n \n8      is      O(m). Hence      the      complexity      of      Alg. [lis      O(m?3),. roof\nD.1. Proof      of      Proposition\nC."
            },
            {
              "id": 1649,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 83",
              "type": "chunk",
              "children": [],
              "content": "Complexity      Analysis      of      Algorithm      [I]\n[I]\nD. Proof\nroof\n \n \n  Then      we      prove      that      if      Alg. [I]      transforms      an      edge   \n \nA      o-*«   \n \nB      to   \n \nA      +*B      on      Line      9,      then      R42      can      be      triggered. Since      the      rigorous  \n \n  proof      is      somewhat      tedious,      we      just      show   \n \na      proof      sketch      here. If      Alg."
            },
            {
              "id": 1650,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 84",
              "type": "chunk",
              "children": [],
              "content": "[I]transforms      an      edge   \n \nA      o-   \n \nB      to   \n \nA      +*B      on      Line      9,  \n \n  then      there      is      an      unshielded      collider      formed      in      H’      on      Line      8. In      this      case,      according      to      the      proof      idea      of      Lemma   \n \n5      of      [Wang  \n \n  et      al.|(2023a)),      we      can      prove      that      H[D]      is      not      bridged      relative      to      S4."
            },
            {
              "id": 1651,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 85",
              "type": "chunk",
              "children": [],
              "content": "Then,      we      will      prove      that      there      is      an      unbridged      path      in  \n \n  H[D|      relative      to      S      4. Suppose      there      is   \n \na      minimal      path      p   \n \n=      Vo      o-0---o-o      V,,41      in      H[D]      where      there      is      not   \n \na      vertex      V,      such      that      Fy,      C      Fy,      yO  \n \n  i<s—landfy,,,      C      Fy,,8      <i      <n."
            },
            {
              "id": 1652,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 86",
              "type": "chunk",
              "children": [],
              "content": "As      Line   \n \n9      is      triggered,      no      vertex      in      D      belongs      to      Anc(S.,      H). Hence      if      there      is  \n \n  some      vertex   \n \nV   \n \n¢      Fy,,   \n \nV      is      not      adjacent      to      V;. Next,      we      consider      the      path      p. We      discuss      whether      Fy,      \\\\\\\\Fv,   \n \n=      0. If      empty,      we  \n \n  consider      whether      Fy,      \\\\\\\\Fy,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1653,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 87",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process      above      until      we      find      the      first      index   \n \nj      such      that      Fy,\\\\\\\\Fv,,,   \n \n4      9."
            },
            {
              "id": 1654,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 88",
              "type": "chunk",
              "children": [],
              "content": "Note      such   \n \n7      must      exist,      for      otherwise,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +:   \n \n©      Fy,,,,      in      which      case      there      is      s   \n \n=      n+1  \n \n  such      that      Fy,   \n \n©      Fy,,,,0      <7      <s—land      fy,,,   \n \n©      Fy,,8      <7   \n \n<      n,      contradiction. Then,      we      consider      the      sub-path  \n \n  V;      0-0      ---      0-0      V4."
            },
            {
              "id": 1655,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 89",
              "type": "chunk",
              "children": [],
              "content": "Note      according      to      the      process      above,      there      is      Fy,      C      Fy,      C      Fy,   \n \n©      +++   \n \n©      Fy,      and      Fy,      \\\\\\\\FVja1      #. Then,      we      consider      whether      Fy,      ,,\\\\\\\\Fv,,   \n \n=      9. If      empty,      we      consider      whether      Fy,      \\\\\\\\Fy,,_,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1656,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 90",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process  \n \n  above      until      we      find      the      first      index   \n \n&      such      that      Fy,      \\\\\\\\Fy,_,   \n \n4      @. Similar      to      the      proof      above,      such      index   \n \nk      must      exist. And       there      is      Fy,      D2      Fy,,,      2---   \n \n2      Fv,,,      and      Fy,_,   \n \n#      0. Next      we      discuss      the      relationship      between   \n \nj      and      k."
            },
            {
              "id": 1657,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 91",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove  \n \n  the      impossibility      of   \n \nk   \n \n<      j. Suppose   \n \nk   \n \n<      7."
            },
            {
              "id": 1658,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 92",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      result      above,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +++   \n \n©      Fy,      and       Fv,      »)      F      Views      Des      D      F      Vina      Hence,      there      is      Fy,      C      Fy,      C      Fy,      rae      Fy,   \n \n=      FV      nas      See   \n \n=      Fy,      DD      FVngt:      In  \n \n  this      case,      there      is      s   \n \n=   \n \n7      such      that      Fy,      C      Fy,,,,0      <i<s—Jland      Fy,,,      C      Fy,,8      <i      <n,      contradiction."
            },
            {
              "id": 1659,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 93",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is  \n \n  k   \n \n>   \n \nj      +1. In      this      case,      there      is   \n \na      minimal      path      V;      0-0      Vj,      0-0      ---      o-o      Vj,      such      that      Fy,\\\\\\\\Fy,,,   \n \n#   \n \nO      and      Fy,\\\\\\\\Fy,_,      #0  \n \n  in      H[D]. It      is      an      unbridged      path      relative      to      S.4      in      H[D]."
            },
            {
              "id": 1660,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 94",
              "type": "chunk",
              "children": [],
              "content": "And      since      there      are      an      uncovered      possible      directed      paths      from   \n \nA      to      any      vertice      in      D      and      at      the      same      time   \n \nB      is      the      vertex  \n \n  adjacent      to   \n \nA      in      the      paths,      7212      can      be      triggered      to      transform   \n \nA      o-«   \n \nB      to   \n \nA      +*B. The      proof      completes. O\nD.2. Proof      of      Theorem[I]\nProof."
            },
            {
              "id": 1661,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 95",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      the      soundness      of      7213,      then      prove      the      soundness      of      R12. For      R13,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B. It      is      evident      that      the      uncovered      path      is   \n \nA   \n \n>   \n \nB   \n \n>      --. —      K."
            },
            {
              "id": 1662,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 96",
              "type": "chunk",
              "children": [],
              "content": "According  \n \n  to      the      definition      of      S   \n \n,      and      the      conditions      in      713,      there      must      be   \n \na      vertex      C\\\\\\'   \n \n€      Sy      such      that      thereis      C+>      A—>---K      >---C,  \n \n  which      contradicts      with      the      ancestral      property,      contradiction. For      R12,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B."
            },
            {
              "id": 1663,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 97",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      condition      of      R12,      it      is      evident      that      for      each      vertex  \n \n  K;,1      <4      <m,      there      is   \n \na      minimal      directed      path   \n \nA   \n \n>   \n \nB   \n \n>      ---   \n \n+      K;      in      M."
            },
            {
              "id": 1664,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 98",
              "type": "chunk",
              "children": [],
              "content": "And      for      any   \n \nT   \n \n€      S,4      and      K;j,1      <<i<m  \n \n  such      that      there      is      an      edge      between   \n \nT      and      K;      in      the      PMG      H,      there      must      be      Tx—      K;      in      M,      for      otherwise      there      is  \n \n  A>      B-.-.—      K;   \n \n~      T*>      A,      contradicting      with      ancestral      property. According      to      Def."
            },
            {
              "id": 1665,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 99",
              "type": "chunk",
              "children": [],
              "content": "[I]      there      is      an      unbridged      path  \n \n  p:      K,      0-0      Ky      0-0---o-0      K,,,      such      that      Fx,      \\\\\\\\Fr,      #0      and      Fr,,\\\\\\\\Fr,,_,      #0. Suppose      Cy   \n \n€      Fx,\\\\\\\\F      x,      and      C2   \n \n€      Fx,,\\\\\\\\Fx,,,_,-      If      Ci      is      adjacent      to      Ko,      as      Cy   \n \n¢      Fx,,      there      is      Ky   \n \n—      C,      in      H."
            },
            {
              "id": 1666,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 100",
              "type": "chunk",
              "children": [],
              "content": "In      this  \n \n  case      there      must      be   \n \nA      +«*B      according      to      R43,      the      soundness      of      which      has      been      proven. Thus   \n \nA   \n \n—   \n \nB      and      that      C{      is      adjacent  \n \n  to      K2      are      impossible. In      the      following,      we      consider      the      case      that      C\\\\\\';      is      not      adjacent      to      K2      and      C2      is      not      adjacent      to      K,,_}."
            },
            {
              "id": 1667,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 101",
              "type": "chunk",
              "children": [],
              "content": "We      have      shown      before      that      if      there      is      an      edge   \n \nA   \n \n>   \n \nB      in      M,      there      must      be      C)*>      Ky      and      C2*—>      K,,      in      M."
            },
            {
              "id": 1668,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 102",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,  \n \n  no      matter      how      we      transform      the      circles      in      C,+—3      Ky      0-0      Ky      0-0      ---      0-0      K,,      <+Co,      there      will      be   \n \na      new      unshielded      collider  \n \n  in      M,      which      contradicts      with      the      fact      that      M      is      consistent      with      H. O\nD.3."
            },
            {
              "id": 1669,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 103",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Theorem      [Z|\n \n \n  Proof      of      Theorem{2|      Note      the      graph      M      is      updated      in      every      round      of      Alg. 2]      To      distinguish      them,      we      use      M,      to      denote  \n \n  the      graph      obtained      after      Line   \n \n5      of      Alg. /2}in      the      7-th      round. Denote      M      the      original      maximal      local      MAG."
            },
            {
              "id": 1670,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 104",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the  \n \n  whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      i,      Anc(Y,M;)   \n \n=      Anc(Y,M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nT      rounds      in      Alg."
            },
            {
              "id": 1671,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 105",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge      A;      «+S;      is      transformed      by      Rj2      on      Line   \n \n6      of      Alg. [2](A;      just      denotes      any   \n \na      vertex),      and      thus  \n \n  Anc(5;,      M;)   \n \n9   \n \nT      is      incorporated      to      S      on      Line   \n \n7      of      Alg."
            },
            {
              "id": 1672,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 106",
              "type": "chunk",
              "children": [],
              "content": "Since      the      algorithm      returns   \n \na      set      of      vertices      S      after      T’      rounds,      according      to      Line      4,      6,      and   \n \n9      of      Alg."
            },
            {
              "id": 1673,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 107",
              "type": "chunk",
              "children": [],
              "content": "2}      we      conclude  \n \n  that      (1)      M7[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V\\\\\\'   \n \n©      S|V      o-*      VlorV      <#V’      in      Mr},      (2)  \n \n  PossDe(W,      Mr[—S])   \n \n7      Pa(S,      Mr)   \n \n=      @,      (3)      there      is      no      unbridged      path      relative      to      S      in      M7|PossDe(W,      Mr[—S])]."
            },
            {
              "id": 1674,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 108",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  will      prove      that      the      three      conditions      in      Prop. 2Jare      satisfied      given      the      set      S,      thus      we      can      conclude      the      desired      result      by      Prop."
            },
            {
              "id": 1675,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 109",
              "type": "chunk",
              "children": [],
              "content": "[2\n(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}\n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      Vor   \n \nV      ¢*V’      in      M}. In  \n \n  the      process      of      Alg."
            },
            {
              "id": 1676,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 110",
              "type": "chunk",
              "children": [],
              "content": "2}      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads,      hence      M[Sy]   \n \n=      M,[Sy]      for      any   \n \nV   \n \n€      W. Hence      given      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W."
            },
            {
              "id": 1677,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 111",
              "type": "chunk",
              "children": [],
              "content": "(2)      We      will      prove      that      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      0. Suppose   \n \nA   \n \n=      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)."
            },
            {
              "id": 1678,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 112",
              "type": "chunk",
              "children": [],
              "content": "Without      loss  \n \n  of      generality,      suppose      there      is   \n \nV   \n \n€      W      and   \n \na      minimal      possible      directed      path      p   \n \n=      (V,      Ji,---   \n \n,      Jz,      A)      from   \n \nV      to   \n \nA      in      M      such  \n \n  that      each      non-endpoint      in      p      does      not      belong      to      W      (If      there      is      V’   \n \n€      W      in      the      path      p,      we      consider      V’      instead      of   \n \nV      and      the  \n \n  sub-path      from      V’      to   \n \nA      instead      of      p)."
            },
            {
              "id": 1679,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 113",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the      process      of      Alg.|2|      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads  \n \n  on      the      edges      connecting      W      and      S. Hence,      since      p      is      not   \n \na      minimal      possible      directed      path      in      My,      and      each      non-endpoint  \n \n  does      not      belong      to      W,      there      must      be      J,   \n \n€      S."
            },
            {
              "id": 1680,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 114",
              "type": "chunk",
              "children": [],
              "content": "However,      in      this      case      the      path      p      is      not      in      M[—S]      since      J,   \n \n€      S,      contradiction. Hence      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9. (3)      We      will      prove      that      there      is      no      unbridged      path      relative      to      S      in      M[PossDe(W,      M[-—S])}. Note      in      the      process      of      Alg."
            },
            {
              "id": 1681,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 115",
              "type": "chunk",
              "children": [],
              "content": "2|      we\n \n \n  only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads      on      the      edges      connecting      W      and      S."
            },
            {
              "id": 1682,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 116",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      there      is      an      unbridged  \n \n  path      relative      to      S      in      M,      this      path      still      exists      in      Mr      since      each      vertex      in      this      path      cannot      belong      to      S,      which      concludes      that  \n \n  M-[PossDe(W,      Mr[—S])]      is      not      bridged      relative      to      S      in      Mr,      contradiction."
            },
            {
              "id": 1683,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 117",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is      no      unbridged      path      relative      to      S       in      M[PossDe(W,      M[—S})],      that      is,      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M      according      to      Def. (o}      0\nD.4. Proof      of      Theorem      B]\n \n \n  The      proof      relied      on      some      results      by      {Wang      et      al.|      (2023a))."
            },
            {
              "id": 1684,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 118",
              "type": "chunk",
              "children": [],
              "content": "We      first      present      two      supporting      results      in      Lemma[I]and      Lemma]  \n \n  Lemma      [2]      implies      that      if      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in   \n \na      maximal      local      MAG      M,      then      we      can      find   \n \na       minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma   \n \n1      (Wang      et      al.|(2023a))."
            },
            {
              "id": 1685,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 119",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      obtained      from   \n \na      PAG      P      and   \n \na      valid      local      transformation  \n \n  of   \n \nX      represented      by      C,      the      following      properties      are      satisfied:\n(Invariant)      The      arrowheads      and      tails      in      M      are      invariant      in      all      the      MAGs      consistent      with      P      and      the      local      transformation  \n \n  of   \n \nX      represented      by      C;\n(Chordal)      the      circle      component      in      M      is      chordal;\n \n \n  (Balanced)      for      any      three      vertices      A,      B,C      in      M,      if      Ax—   \n \nB      o-*      C,      then      there      is      an      edge      between   \n \nA      and      C      with      an  \n \n  arrowhead      at      C’,      namely,      Ax      C."
            },
            {
              "id": 1686,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 120",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      the      edge      between   \n \nA      and   \n \nB      is   \n \nA   \n \n—      B,      then      the      edge      between   \n \nA      and       C      is      either   \n \nA      C      or      Ao      C      (i.e,      itis      not      A&C);\n(Complete)      for      each      circle      at      vertex   \n \nA      on      any      edge   \n \nA      o-*   \n \nB      in      M,      there      exist      MAGs      M,      and      Mg      consistent      with      M       with   \n \nA      +*B   \n \n€      E(M,)      and      A>      BE      E(Mg);\n(P6)      we      can      always      obtain   \n \na      MAG      consistent      with      P      and      the      local      transformation      of   \n \nX      represented      by      C,      by  \n \n  transforming      the      circle      component      into   \n \na      DAG      without      unshielded      colliders      and      transforming      Ao>      Bas   \n \nA   \n \n>      B."
            },
            {
              "id": 1687,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 121",
              "type": "chunk",
              "children": [],
              "content": "Lemma   \n \n2      (Wang      et      al.|      (2023a)). Consider   \n \na      maximal      local      MAG      MA. If      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in      M,  \n \n  then      there      is   \n \na      minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma      3."
            },
            {
              "id": 1688,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 122",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y). Let      W      be      D-SEP(X,Y,      Mx)."
            },
            {
              "id": 1689,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 123",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (Jo(= V),      Ji,-:+      ,Js(=      T)      from   \n \nV   \n \n€      W      to   \n \na      vertex   \n \nT      in      M,      where      each      non-endpoint      in      p      does      not      belong      to      W      UW. If  \n \n  T   \n \n€      Anc(Y,      M),      then      p      can      only      be      as      Jyo>      Jy   \n \n>      +++   \n \n+      J,      in      M."
            },
            {
              "id": 1690,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 124",
              "type": "chunk",
              "children": [],
              "content": "And      there      exists   \n \na      collider      path      X(=      Fo)   \n \n&      Fi   \n \n& »   \n \n>      Fi      <*V      in      M      with      edges      F;   \n \n>      J,,0<i<n-1. Proof. According      to      Def. there      exists   \n \na      collider      path   \n \nX      (=      Fo)   \n \n@      Fy      +++      Fy_y      +#V      in      M,      where      F),---   \n \n,      Fy-1   \n \n€ W."
            },
            {
              "id": 1691,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 125",
              "type": "chunk",
              "children": [],
              "content": "There      cannot      be      an      edge      F;      <+*J;      in      M      for      any   \n \n0      <2   \n \n<   \n \nt   \n \n—      1,      for      otherwise      J,   \n \n©      WU      W. Since   \n \nV      is      not      an      ancestor      of   \n \nY      in      M      and      p      is   \n \na      minimal      possible      directed      path,      there      must      be      Fy_;   \n \n©   \n \nV      <+*J,      in      M."
            },
            {
              "id": 1692,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 126",
              "type": "chunk",
              "children": [],
              "content": "Hence      F;_,      is      adjacent      to      J;,      for      otherwise      there      is   \n \na      new      unshielded      collider      in      M      relative      to      M."
            },
            {
              "id": 1693,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 127",
              "type": "chunk",
              "children": [],
              "content": "Since      (1)      for      each  \n \n  F;,0      <i<t-—1,      there      cannot      be      F;      <+*.J,      in      M,      and      (2)      the      balanced      property      is      fulfilled      in      M,      we      can      conclude      that  \n \n  there      is      there      is      F;   \n \n>      J,      or      Fjo3      Jy,V1      <1      <n-—1      and   \n \nX   \n \n—      Jj,      otherwise      there      is      always   \n \na      discriminating      path      for Lemma      4."
            },
            {
              "id": 1694,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 128",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment      set  \n \n  relative      to      (X,Y). Let      W      be      D-SEP(X,      Y,      Mx). For      any      S      incorporated      into      the      set      of      vertices      S      in      the      process      of      Alg."
            },
            {
              "id": 1695,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 129",
              "type": "chunk",
              "children": [],
              "content": "2) (on      Line      7),      there      is      S   \n \n€      Anc(Y,      M). V\n \n   which      leads      to   \n \na      non-circle      mark      at   \n \nV      on      the      edge      between   \n \nV      and      J;      in      P. Due      to      Vx—      F,,_;   \n \n—      J;      in      M      and      the  \n \n  balanced      property      of      M,      there      is      Vo—      J;."
            },
            {
              "id": 1696,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 130",
              "type": "chunk",
              "children": [],
              "content": "Since      the      path      p      is   \n \na      minimal      possible      directed      path,      the      path      can      only      be      as  \n \n  Vo      J,      7-3      Is. CI\n \n \n  Proof. Note      the      graph      M      is      updated      in      every      round      of      Alg.|2|      To      distinguish      them,      we      use      M1;      to      denote      the      graph      obtained  \n \n  after      Line   \n \n5      of      Alg."
            },
            {
              "id": 1697,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 131",
              "type": "chunk",
              "children": [],
              "content": "/2|/in      the      i-th      round. Denote      M      the      original      maximal      local      MAG. Note      in      the      whole      process,      there      are      no       new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      S   \n \n€      W,      since      W   \n \n=      D-SEP(X,      Y,      Mx),      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)      and      S   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1698,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 132",
              "type": "chunk",
              "children": [],
              "content": "For      S   \n \n€      So      defined  \n \n  in      Def. |4}      according      to      Lemma[3}      since      $\\\\\\'      is      the      vertex      adjacent      to   \n \na      vertex   \n \nV   \n \n€      W      ina      minimal      possible      directed      path  \n \n  from   \n \nV      to   \n \na      vertex      in      Anc(Y,      M),      there      is      S   \n \n€      Anc(Y,M)."
            },
            {
              "id": 1699,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 133",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      are   \n \nT      rounds      in      Alg.|2)      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge   \n \nA      ++5S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2      and      thus      Anc(S;,      M,)      N   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg.|2|      For      brevity,      denote   \n \nT   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg."
            },
            {
              "id": 1700,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 134",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      S;   \n \n€      Anc(Y,M). Since      R12      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (K1,---   \n \n,      Km)      relative      to      So  \n \n  and      there      exists      an      uncovered      possible      directed      path      (V,      S,,---   \n \n,      Kj)      for   \n \n1   \n \n<   \n \n7   \n \n<      min      M),      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1701,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 135",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is      C_      *-o      Ky      0-0      ---      0-0      Ky,      o-*«      Din      M,  \n \n  where      C   \n \n€      Fx,\\\\\\\\Fr,,D   \n \n©      Fr,,\\\\\\\\Fr,_,»      Fk;   \n \n=      {V   \n \n€      VW’   \n \n|   \n \nV      +0      Kj      or      Vx      K;      in      My}."
            },
            {
              "id": 1702,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 136",
              "type": "chunk",
              "children": [],
              "content": "Next      we      prove      there      is  \n \n  not      kK;   \n \n+      Cin      M,. Suppose      kK,   \n \n—      C      in      M,      for      contradiction. As      in      the      process      of      Alg. 2]      we      never      add   \n \na      tail,      there      is  \n \n  K,      €—>      CinM. In      this      case,      there      is   \n \na      directed      path      S;   \n \n>      ---   \n \n—      kK,   \n \n>      CinMandC   \n \n€      So      C      Anc(WU      {Y},M)."
            },
            {
              "id": 1703,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 137",
              "type": "chunk",
              "children": [],
              "content": "Hence      S$,   \n \n€      Anc(W   \n \nU      {Y},M). Since   \n \nV   \n \n€      W      is      adjacent      to      91,      9;      should      belong      to      So,      contradiction. Hence      there  \n \n  cannot      be      an      edge      Ky   \n \n>      Cin      My."
            },
            {
              "id": 1704,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 138",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      F’;,1   \n \n<   \n \n7   \n \n<      m,      it      is      easy      to      prove      that      F’;      is      an      ancestor      of      either      C      or      D,  \n \n  for      otherwise      there      will      be      an      unshielded      collider      in      the      path      (C,      Ky,---   \n \n,      Km,      D)      in      M."
            },
            {
              "id": 1705,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 139",
              "type": "chunk",
              "children": [],
              "content": "And      since      C,      D   \n \n€      So,      and      C,      D       are      ancestors      of   \n \nY      in      M,      it      holds      C,      D   \n \n€      Anc(Y,M). And      since      there      is      Vo>      5;   \n \n—      ---   \n \n+      K,      in      M,      5;      is      an      ancestor      of  \n \n  Y      in      M. Thus      S;   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1706,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 140",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      all      the      vertices      in      Anc(.S,,      My)      M   \n \nT      are      ancestors      of      Y. Next      we      prove      the      induction      result. Suppose      in      the      first   \n \ni      round,      each      vertex      in      So,      Anc(S;,M),---   \n \n,      Anc(.S;,      M1)      is      an  \n \n  ancestor      of   \n \nY      in      M. We      will      prove      S;,1   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1707,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 141",
              "type": "chunk",
              "children": [],
              "content": "Since      R49      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (7,---   \n \n,      T\\\\\\')      relative      to      Sp      UU,      <,<;(Ane(Sq,      Mi)      N      T)      and      there  \n \n  exists      an      uncovered      possible      directed      path      (V,      $;41,---      ,7;)      forl   \n \n<      s   \n \n<      f      in      M,,1      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1708,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 142",
              "type": "chunk",
              "children": [],
              "content": "Without      loss      of  \n \n  generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is   \n \nJ      *-o      T;      o-o      ---      0-0      Ty      o-*   \n \nK      in      M;41,      where  \n \n  J   \n \n€      Fr,\\\\\\\\Fr,,   \n \nK   \n \n€      Fr;      \\\\\\\\Frj_1:      Next      we      prove      there      is      not      T;   \n \n—   \n \nJ      in      M;,,."
            },
            {
              "id": 1709,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 143",
              "type": "chunk",
              "children": [],
              "content": "Suppose      J;   \n \n—   \n \nJ      in      M      for      contradiction. Note      in      the      whole      process      of      Alg. 2}      we      never      add   \n \na      tail,      hence      there      is      T;      —>   \n \nJ      in      M. In      this      case,      there      is   \n \na      directed      path  \n \n  Sig1      3-1:   \n \n>      T,   \n \n>      JinMand   \n \nJ   \n \n€      So      UU      <g<;(Ane(Sq,      Mg)      OT)."
            },
            {
              "id": 1710,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 144",
              "type": "chunk",
              "children": [],
              "content": "If   \n \nJ   \n \n€      So,      then      S341   \n \n€      Anc(WU{Y},M),      Sizi  \n \n  should      belong      to      So,      contradiction. If      5,4;   \n \n€      Anc(S,,M,)   \n \n7      T,1      <q      <3,      then      S;,1      should      have      been      incorporated      into  \n \n  S      in      the      g-round      of      Alg.|2}      contradiction. Hence      there      cannot      be      an      edge      T;   \n \n>   \n \nJ      in      M41."
            },
            {
              "id": 1711,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 145",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      T,,1   \n \n<      s   \n \n<      f,      itis      an      ancestor      of      either   \n \nJ      or      K,      for      otherwise      there      will  \n \n  be      an      unshielded      collider      in      the      path      (J,T1,---      ,T,      A)      in      M."
            },
            {
              "id": 1712,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 146",
              "type": "chunk",
              "children": [],
              "content": "And      since      J,   \n \n€      So      UUy<<;(Ane(Sq,M,)   \n \n9      T),      and       J,   \n \nK      are      ancestors      of   \n \nY      in      M,      it      holds      J,      kK   \n \n€      Anc(Y,M). And      since      there      is      Vo>      S;4;   \n \n>      ---   \n \n>      T,      in      M,      $;4,      is      an  \n \n  ancestor      of      Y. Thus      S;41;   \n \n€      Anc(Y,M)."
            },
            {
              "id": 1713,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 147",
              "type": "chunk",
              "children": [],
              "content": "Hence      all      the      vertices      in      Anc(.$;41,      M41)      M   \n \nT      are      ancestors      of   \n \nY      in      M. By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M. O\nTheorem.B]      Prop. {/has      implied      that      W   \n \n=      D-SEP(X,      Y,      M.x)      is   \n \na      potential      adjustment      set."
            },
            {
              "id": 1714,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 148",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      that   \n \na      set      of vertices      S$      will      be      returned      by      Alg. Note      the      graph      M      is      updated      in      every      round      of      Alg."
            },
            {
              "id": 1715,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 149",
              "type": "chunk",
              "children": [],
              "content": "[2|      To      distinguish      them,      we      use      M|;      to      denote      the      graph      obtained      after  \n \n  Line   \n \n5      of      Alg.2|in      the      i-th      round,      use      S;      to      denote      the      set      of      vertices      obtained      after      Line   \n \n7      of      Alg. [2|in      the      i-th      round. Denote  \n \n  M      the      original      maximal      local      MAG. For      S   \n \n€      So      in      Def."
            },
            {
              "id": 1716,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 150",
              "type": "chunk",
              "children": [],
              "content": "4}      there      must      be   \n \nV      <*S      in      M      if      there      is   \n \nV      o-*      S      in      M. Hence      the  \n \n  arrowheads      introduced      in      the      first      round      of      Alg. 2]      must      exist      in      /. And      due      to      the      soundness      of      Ri2      by      Thm. [I]      all      the  \n \n  arrowheads      introduced      in      Alg. RJexist      in      M."
            },
            {
              "id": 1717,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 151",
              "type": "chunk",
              "children": [],
              "content": "In      the      whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nJ      rounds      in      Alg."
            },
            {
              "id": 1718,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 152",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<J-—1,anedge   \n \nA      +S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2}      and      thus      Anc(S;,      M;)      M   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg. 2}      Hence      there      is      evidently      S;,;   \n \n=      S;   \n \nU      (Anc($;41,Mi41)      NT),      forO      <i<      J—1."
            },
            {
              "id": 1719,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 153",
              "type": "chunk",
              "children": [],
              "content": "It      suffices      to      show      that      in      the      i-th      round   \n \n1   \n \n<   \n \ni   \n \n<      J,      there      is      (1)      PossDe(W,      M;;[—S,])      N      Pa(S;,      Mi)   \n \n=      0,      (2)      M;      [Sy]      is   \n \na       complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S;|V      o«      V’or   \n \nV      ¢*V’      in      Mj},      and      (3)      there      is      not      an      unbridged      path  \n \n  relative      to      S;      in      M;[PossDe(W,      M;[—S,])]."
            },
            {
              "id": 1720,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 154",
              "type": "chunk",
              "children": [],
              "content": "As      when      these      three      conditions      are      satisfied      in      each      round,      Alg.|2|could      output a\n \n   set      of      vertices. Suppose      in      the   \n \n2      round,      the      algorithm      output      “No”. According      to      Alg.|2}      at      least      one      of      the      three      conditions  \n \n  is      violated."
            },
            {
              "id": 1721,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 155",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      the      impossibility      of      the      violations      of      the      three      conditions      in      the      following."
            },
            {
              "id": 1722,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 156",
              "type": "chunk",
              "children": [],
              "content": "If      PossDe(W,      M;[—S;])  \n \n  Pa(S;,M;)   \n \n4      T,      suppose      there      is   \n \na      minimal      possible      directed      path      p      from   \n \nV   \n \n€      W      to   \n \nT      in  \n \n  M;[—S,]      such      that      each      non-endpoint      does      not      belong      to      W,      and      there      is      an      edge   \n \nT   \n \n+      S      in      M;      for      S   \n \n€      S;. Hence  \n \n  T   \n \n€      Anc(S,M;)."
            },
            {
              "id": 1723,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 157",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma}      p      is      Vo>—      --. +   \n \nT      in      M. In      this      case,      if      S   \n \n€      So,      according      to      Def. 4]      and       Lemmaj}}      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)."
            },
            {
              "id": 1724,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 158",
              "type": "chunk",
              "children": [],
              "content": "Thus   \n \nT   \n \n€      Anc(W   \n \nU      {Y},      M),      which      implies      that      there      is   \n \na      minimal      possible  \n \n  directed      path      p\\\\\\'      from   \n \nV   \n \n€      W      to   \n \nT   \n \n€      Anc(W   \n \nU      {Y},M)      such      that      p’      is   \n \na      sub-path      of      p. However,      according      to      Def."
            },
            {
              "id": 1725,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 159",
              "type": "chunk",
              "children": [],
              "content": "in      the      case      above,      the      vertex      adjacent      to   \n \nV      in      p’      should      belong      to      So,      contradicting      with      the      fact      that      the      path      p      is      in  \n \n  M,[—S,]. If      S;      is      incorporated      into      S      in      Alg."
            },
            {
              "id": 1726,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 160",
              "type": "chunk",
              "children": [],
              "content": "Qin      the      7,7   \n \n<   \n \n7      round,      since      there      is   \n \nT   \n \n€      Anc(S,M),   \n \nT      should      belong      to  \n \n  S541,S;+42,:--      ,8;,      contradicting      with      the      fact      that      the      path      p      is      in      M;|—S,]. Hence      there      is      always   \n \na      contradiction      if      there  \n \n  is      PossDe(W,      M;;[—S;])      M      Pa(S;,M;)   \n \n4      0."
            },
            {
              "id": 1727,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 161",
              "type": "chunk",
              "children": [],
              "content": "Since      W   \n \n=      D-SEP(X,      Y,      Mx),      for      any   \n \nV   \n \n€      W,   \n \nV      is      not      an      ancestor      of   \n \nY      in      M. If      M,[Sy]      is      not   \n \na      complete      graph for      some   \n \nV   \n \n€      W,      there      must      be      an      edge   \n \nV   \n \n>      Sin      M,      for      otherwise      there      will      be      new      unshielded      collider      at      V."
            },
            {
              "id": 1728,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 162",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  Lemma}      S      is      an      ancestor      of      Y. Thus   \n \nV      is      an      ancestor      of      Y,      thus   \n \nV   \n \n€      WW,      contradicting      with      W   \n \n9      W   \n \n=      9. Finally,      we      prove      that      there      is      not      an      unbridged      path      relative      to      S;      in      M;[PossDe(W,M,[—S,])]."
            },
            {
              "id": 1729,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 163",
              "type": "chunk",
              "children": [],
              "content": "Suppose  \n \n  M;{[PossDe(W,      M[—S,])]      is      not      bridged      relative      to      S;      in      M. Since      M;[PossDe(W,M,{—S;])]      is      not      bridged      relative  \n \n  to      S;      in      M;,      without      loss      of      generality,      suppose      an      unbridged      path      Ky,      o—o      ---      o—o      K,,,      relative      to      S;,      and      there      is  \n \n  AE      W."
            },
            {
              "id": 1730,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 164",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma      4}      all      the      vertices      in      S;      are      ancestors      of   \n \nY      in      M. At      first,      we      prove      Ky,---   \n \n,      Ky      are  \n \n  ancestors      of   \n \nY      in      M."
            },
            {
              "id": 1731,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 165",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      vertices      S),.S_   \n \n€      S;      such      that      S$;   \n \n€      Fx,      \\\\\\\\Fr,      and      Sy   \n \n€      Fr,,\\\\\\\\Fr      where  \n \n  Fy      ={V\\\\\\'      €S,|V      o*      V’      or   \n \nV      «V’      in      M;}      as      Def. [I] m—1? If      S   \n \n€      So,      according      to      Def."
            },
            {
              "id": 1732,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 166",
              "type": "chunk",
              "children": [],
              "content": "|4}      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (V’,S,---      ,T)      from      V’   \n \n€      WtoT   \n \n€       Anc(W   \n \nU      {Y},M)      where      each      non-endpoint      does      not      belong      to      W      in      M;. According      to      Def. |2}      there      exists   \n \na      collider      path X\n \n   OF      O---&      Fy_   \n \n1      <V’      where      F\\\\\\\\,---   \n \n,      F;_1   \n \n€      W."
            },
            {
              "id": 1733,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 167",
              "type": "chunk",
              "children": [],
              "content": "And      according      to      the      result      (2)      above,      M;|Sy-]      is   \n \na      complete  \n \n  graph. Hence      F;_,      is      adjacent      to      S. In      this      case      if      there      is      an      edge      F;_;      «+S      in      Mj,      there      is      F;_;      «+S      in      M,      thus      there  \n \n  is      S   \n \n€      WUW. And      due      to      S   \n \n¢      W,      there      is      S   \n \n€      W."
            },
            {
              "id": 1734,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 168",
              "type": "chunk",
              "children": [],
              "content": "And      if      there      is      an      edge      F,_      o-*      S      or      F;_1   \n \n>      S\\\\\\'      in      Mj,      there      is\n \n \n  F,_,      o*      S      or      Fy_;   \n \n—      S      in      M,      there      must      be      Vo  \n \n  S      in      M."
            },
            {
              "id": 1735,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 169",
              "type": "chunk",
              "children": [],
              "content": "Due      the      p      is   \n \na      minimal      possible      directed      path      in      Mj,      p      is      also   \n \na       minimal      possible      directed      path      in      M,      pis      V’o>      S   \n \n>      ---   \n \n>      Tin      M,      thus      S   \n \n€      Anc(W   \n \nU      {Y},      M)."
            },
            {
              "id": 1736,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 170",
              "type": "chunk",
              "children": [],
              "content": "Hence,      no      matter      what  \n \n  the      edge      is      between      S      and      F;_1,      there      is      S   \n \n€      Anc(W   \n \nU      {Y},      M). In      this      case,      if      there      is      kK;   \n \n—      5S      in      M,      there      is      kK;   \n \n€      So  \n \n  due      to      S\\\\\\'   \n \n€      So,      contradicting      with      K;   \n \n€      PossDe(W,      M;[-S,])."
            },
            {
              "id": 1737,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 171",
              "type": "chunk",
              "children": [],
              "content": "If      S      is      incorporated      into      S      in      the      j,   \n \n7   \n \n<   \n \ni      round      on      Line   \n \n7      of  \n \n  Alg. [2|   \n \nK      is      also      incorporated      into      S      in      this      round      due      to   \n \nK   \n \n€      Anc(S,M),      contradicting      with      K;   \n \n€      PossDe(W,      M;[—S;]). Hence      for      any      K;,1      <j   \n \n<      mand      5S   \n \n€      §,      in      the      process      of      Alg."
            },
            {
              "id": 1738,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 172",
              "type": "chunk",
              "children": [],
              "content": "(2)      there      cannot      be      an      edge      S   \n \n+      K;. Hence,      consider      the      uncovered      path      py   \n \n=      ($1,      Ky,      Ko,--+   \n \n,      Km,      S2)      in      M;      where      the      sub-path      from      K,      to      K,,,      is   \n \na      circle  \n \n  path."
            },
            {
              "id": 1739,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 173",
              "type": "chunk",
              "children": [],
              "content": "Note      the      non-circle      marks      in      M;      also      exist      in      M      due      to      the      soundness      of   \n \nR   \n \n2      according      to      Thm. {i}      Since      M      cannot have      new      unshielded      colliders      relative      to      M;,      there      is      each      vertex      in      K,,      K2,---   \n \n,      Km      is      an      ancestor      of      either      S;      or      So      in M."
            },
            {
              "id": 1740,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 174",
              "type": "chunk",
              "children": [],
              "content": "Since      S;      and      S2      are      ancestors      of   \n \nY      according      to      Lemma      any      vertex      in      K,,---   \n \n,      Kj,      are      ancestors      of   \n \nY      in      M. Note      in      the      process      of      Alg."
            },
            {
              "id": 1741,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 175",
              "type": "chunk",
              "children": [],
              "content": "2)      we      only      add      arrowheads      at      W,      which      are      not      ancestors      of   \n \nY      in      M,      hence      we      will  \n \n  never      introduce      any      arrowheads      at      K;,V1   \n \n<   \n \nj   \n \n<      min      Alg."
            },
            {
              "id": 1742,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 176",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence      in      M;,      the      uncovered      path      p,      is      in      the      form      of S,      #0      Ky      0-0:      ++      0-0      Ky,      o-*      So,      that      is,      there      cannot      be      S$;   \n \n>      Ky,      or      Ky,      <*S>      in      M;."
            },
            {
              "id": 1743,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 177",
              "type": "chunk",
              "children": [],
              "content": "Next,      for      any      K;,1   \n \n<   \n \n7   \n \n<      _m,      consider      the      minimal      possible      directed      path      p   \n \n=      (A,      Bj,  \n \n  K      A)      from   \n \nA      to      K;. Note      we  \n \n  use      notation   \n \nB      to      denote      the      vertex      adjacent      to   \n \nA      in      the      minimal      possible      directed      path      from   \n \nA      to      K;,1      <7      <m."
            },
            {
              "id": 1744,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 178",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      we      suppose      each      non-endpoint      in      p      does      not      belong      to      W,      since      if      there      is      another      vertex      A’   \n \n€      W      in      p,  \n \n  we      can      consider      A’      instead      of      A,      it      is      evidently      that      K1,---   \n \n,      Ky,      are      possible      descendants      of      A’      as      well      since      there      is   \n \na       minimal      possible      directed      path      from      A’      to      A;      and      there      are      circle      paths      from      KX;      to      each      vertex      in      Ky,---   \n \n,      Km."
            },
            {
              "id": 1745,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 179",
              "type": "chunk",
              "children": [],
              "content": "Note      it      is      possible      that      there      are      many      minimal      possible      directed      paths      from   \n \nA      to      K;."
            },
            {
              "id": 1746,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 180",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      prove      that      for      any  \n \n  B;,B;,1<i<   \n \nJ      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;,      and      B;      is      adjacent      to      each  \n \n  vertex      in      S      in      M. Suppose      B;      is      not      adjacent      to      B;      or      S   \n \n€      S      in      M."
            },
            {
              "id": 1747,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 181",
              "type": "chunk",
              "children": [],
              "content": "Since      S      is      an      ancestor      of   \n \nY      in      any      MAG      M      consistent  \n \n  with      M      such      that      W   \n \n=      D-SEP(X,Y,      Mx),      and   \n \nA   \n \n€      W,      there      is   \n \nA      +*S      in      M. Since      there      is      not   \n \nA      +*B;      or   \n \nA      *B;      in  \n \n  M,      there      is      either   \n \nA   \n \n+      B;      or   \n \nA   \n \n>      B;      in      M."
            },
            {
              "id": 1748,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 182",
              "type": "chunk",
              "children": [],
              "content": "And      since      B;      and      B;      are      located      at      minimal      possible      directed      paths      from   \n \nA       to      K;      and      K;,      respectively,      there      must      be   \n \nA   \n \n€      Anc(.A;,      M)      or   \n \nA   \n \n€      Anc(;,      M)."
            },
            {
              "id": 1749,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 183",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      that      K;,.K;      are  \n \n  ancestors      of   \n \nY      in      M,   \n \nA      is      an      ancestors      of   \n \nY      in      M,      in      which      case      there      is   \n \nA   \n \n©      WNW,      contradicting      with      WM      W      =Oin  \n \n  Def."
            },
            {
              "id": 1750,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 184",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence,      for      any      B;,B;,1      <7   \n \n<   \n \n7      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;, and      B;      is      adjacent      to      each      vertex      in      S      in      M. Next,      we      prove      that      for      any   \n \n1   \n \n<   \n \nj   \n \n<      m,      there      is      not      B;   \n \n=      K,."
            },
            {
              "id": 1751,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 185",
              "type": "chunk",
              "children": [],
              "content": "That      is,      the      minimal      possible      directed      path      from   \n \nA      to  \n \n  kK;      cannot      be   \n \nA      o—*      Kk;      in      M;. Suppose      there      is   \n \nA      o-*      A’;      in      M;. According      to      the      result      above,      for      any      S   \n \n€      S,      K;      is  \n \n  adjacent      to      S."
            },
            {
              "id": 1752,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 186",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,      there      must      be      m   \n \n>      3,      for      otherwise      if      the      unbridged      path      is      just      Ky      o-o      K2,      suppose   \n \nj   \n \n=      1,  \n \n  then      there      must      be      Fx,      D      Fxx,,      contradicting      with      the      definition      of      unbridged      path      in      Def."
            },
            {
              "id": 1753,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 187",
              "type": "chunk",
              "children": [],
              "content": "[I]      We      consider      the      circle  \n \n  path      kK;      o-      Kj4,0~©---co-0      K,,      inM      (If   \n \n7      =>      m   \n \n—      1,      then      we      consider      the      circle      path      Ky      o-0      ---      K;      instead. And      it  \n \n  is      impossible      that      m   \n \n=   \n \n3      and   \n \nj   \n \n=      2,      for      otherwise      the      path      cannot      be      unbridged). There      is      Sy   \n \n€      Fx,,\\\\\\\\Fx,,_,."
            },
            {
              "id": 1754,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 188",
              "type": "chunk",
              "children": [],
              "content": "Since  \n \n  there      cannot      be      an      edge      K,,-1   \n \n—      52      in      M;      and      M,      which      we      have      proven      before,      and      S2   \n \n€      Fx,,      \\\\\\\\Fx,,_,,      52      cannot      be  \n \n  adjacent      to      K,,-1."
            },
            {
              "id": 1755,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 189",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      can      conclude      that      K,,,_2      is      not      adjacent      to      S2,      for      otherwise      in      the      substructure      comprised      of  \n \n  Km—2,      Km—1,      Km,      S2,      there      must      be      K,,   \n \n>      Sg   \n \n+      K,,—2      oriented      by      Rg      in      P,      which      leads      to      K,,-2   \n \n>      Sin      M      and      M,,  \n \n  contradiction."
            },
            {
              "id": 1756,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 190",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      conclude      that      no      vertices      in      K;,      Kj41,---   \n \n,      Km      is      adjacent      to      S. However,      we      have      proven  \n \n  that      K;      is      adjacent      to      S,      contradiction. Hence,      for      any      B;,1      <j      <_m,      Bj   \n \n4      K;."
            },
            {
              "id": 1757,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 191",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      will      prove      that      for      any      B;,1   \n \n<   \n \nj   \n \n<      m,      B;      is      also      in      the      minimal      possible      directed      path      from   \n \nA      to      Kj,  \n \n  where   \n \n1   \n \n<   \n \ni   \n \n<      mandi   \n \n¥      j. Without      loss      of      generality,      suppose   \n \n7   \n \n>      7."
            },
            {
              "id": 1758,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 192",
              "type": "chunk",
              "children": [],
              "content": "Consider      the      minimal      possible      directed      path  \n \n  (A,      By41,-+-   \n \n,      541)      from   \n \nA      to      Kj+41      in      M. We      will      prove      that      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible  \n \n  directed      path      from   \n \nA      to      Kj+1. If      Bj,      and      B;      denote      the      same      vertex,      the      result      evidently      holds."
            },
            {
              "id": 1759,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 193",
              "type": "chunk",
              "children": [],
              "content": "We      just      consider      the      case  \n \n  Bj41   \n \n4      B;. We      have      proven      that      B;      is      adjacent      to      B;+1      before. Note      each      vertex      in      Ky,---   \n \n,      Ky,      is      an      ancestor      of   \n \nY      in      M. According      to      Lemma      3}      there      must      be      p)   \n \n=      Ao      B;   \n \n>       -++      —>      Kj      and      po   \n \n=      Ao      By,   \n \n—      ---   \n \n—      Kj41."
            },
            {
              "id": 1760,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 194",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      Kj;   \n \n#      Bj,      above,   \n \nA      cannot      be      adjacent      to  \n \n  Kj+41,      for      otherwise      p      is      not   \n \na      minimal      possible      directed      path."
            },
            {
              "id": 1761,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 195",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      adjacent      to      Kj;      in      M,      it      is      evident      that      there      is   \n \na       minimal      possible      directed      path      (A,      B;,      Kj+1),      thus      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path  \n \n  from   \n \nA      to      K;41."
            },
            {
              "id": 1762,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 196",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      not      adjacent      to      K;+1,      due      to      the      possible      directed      path      B;   \n \n>      ---   \n \n>      K,;      o-0      Kj,      in      Mj,      the  \n \n  corresponding      path      in      M      is      also   \n \na      possible      directed      path,      there      must      be   \n \na      minimal      possible      directed      path      p’      from      B;      to      Kj41  \n \n  in      M      according      to      Lemma|2}      and      thus      the      corresponding      path      of      p’      in      M;      must      be      also   \n \na      minimal      possible      directed      path      since  \n \n  in      Alg."
            },
            {
              "id": 1763,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 197",
              "type": "chunk",
              "children": [],
              "content": "2|      we      only      transform      some      edge   \n \nV      o-*      S      to   \n \nV      <*S\\\\\\'      for   \n \nV   \n \n€      W      and      S   \n \n€      S;,      while      each      vertex      in      p’      does      not      belong  \n \n  to      S      since      it      is      in      M;[—S,]."
            },
            {
              "id": 1764,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 198",
              "type": "chunk",
              "children": [],
              "content": "And   \n \nA      is      not      adjacent      to      any      non-endpoint      in      p’      since      Ao      B;   \n \n>      ---   \n \n>      K;      is   \n \na      minimal  \n \n  possible      directed      path      and   \n \nA      is      not      adjacent      to      K;41."
            },
            {
              "id": 1765,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 199",
              "type": "chunk",
              "children": [],
              "content": "Hence,      we      have   \n \na      new      minimal      possible      directed      path      Ao>      B;      Op’,  \n \n  where      B,      is      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      A’;+1."
            },
            {
              "id": 1766,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 200",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      prove      that      B;      is  \n \n  also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      Kj42."
            },
            {
              "id": 1767,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 201",
              "type": "chunk",
              "children": [],
              "content": "Repeat      the      process,      we      can      prove      that      B;  \n \n  is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      K;,      for      any   \n \n1      <i   \n \n<      mandi      F      7."
            },
            {
              "id": 1768,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 202",
              "type": "chunk",
              "children": [],
              "content": "Till      now,      we      have      proven      that      there      exists   \n \na      minimal      possible      directed      path      from   \n \nA      to      each      vertex      in      Ky,---   \n \n,      Ky,      such      that  \n \n  B;      is      the      common      vertex      adjacent      to   \n \nA      in      all      paths. And      it      is      evidently      that      the      minimal      possible      directed      path      is      an      uncovered  \n \n  path."
            },
            {
              "id": 1769,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 203",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      B;   \n \n¢      S;,      the      edge   \n \nA      o-«      B;      should      be      transformed      by      R42      in      M;      on      Line   \n \n6      of      Alg. [2|      thus      the      algorithm      will enter the next loop, contradiction. Hence there is not an unbridged path relative to S; in M;[PossDe(W, M;[—S,])] O\nD.5. Proof      of      Proposition\nProof. We      prove      it      by      mathematical      induction."
            },
            {
              "id": 1770,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 204",
              "type": "chunk",
              "children": [],
              "content": "For      each   \n \nV   \n \n€      DD-SEP(X,      Y,      MLx      ),      we      consider      the      minimal      collider      path  \n \n  satisfying      the      three      conditions      of      Definition   \n \n|      in      M. If      the      length      is      1,      there      is   \n \nX      <-*V      in      My      since      there      cannot      be   \n \nX      -«V  \n \n  in      Mx      according      to      the      definition      of      Mx."
            },
            {
              "id": 1771,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 205",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \nV   \n \n¢      Anc(Y,      M),      it      trivially      concludes      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)  \n \n  according      to      the      definition. If      M[Qy]      is      not   \n \na      complete      graph,      evidently      there      are      at      least      two      vertices      in      Oy. Suppose  \n \n  S1,S2   \n \n€      Oy      are      not      adjacent."
            },
            {
              "id": 1772,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 206",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      there      is      either   \n \nV   \n \n>      5S;      or   \n \nV   \n \n—      S      in      M,      otherwise      there      is   \n \na      new      unshielded  \n \n  collider      in      M      relative      to      M      and      P,      which      contradicts      with      that      M      is      consistent      with      MI."
            },
            {
              "id": 1773,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 207",
              "type": "chunk",
              "children": [],
              "content": "Thus      there      is      also   \n \nV   \n \n€      Anc(Y,      M)  \n \n  such      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Hence      if      the      length      is      1,      there      is   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Suppose      the      result      holds  \n \n  when      the      length      of      the      minimal      collider      path      mentioned      above      is      k."
            },
            {
              "id": 1774,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 208",
              "type": "chunk",
              "children": [],
              "content": "For      the      vertex   \n \nV      with   \n \na      minimal      collider      path      satisfying  \n \n  the      three      conditions      of      Definition      [5]      whose      length      is   \n \nk   \n \n+      1,      suppose      the      path      is      comprised      of      X,V;,V2,-+-      ,Ve41. We  \n \n  have      Vi,      V2,---   \n \n,      Ve   \n \n€      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1775,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 209",
              "type": "chunk",
              "children": [],
              "content": "For      Vi.41,      similar      to      the      proof      above,      no      matter      whether      V.+1   \n \n€      Anc(Y,      M) or      M[Qy,.,,]      is      not   \n \na      complete      graph,      there      is      always      Vii   \n \n€      Anc(Y,M),      thus      V4;   \n \n€      D-SEP(X,Y,      M4)      due      to      the collider      path      where      each      non-endpoint      belongs      to      D-SEP(X,      Y,      Mx). O\nD.6."
            },
            {
              "id": 1776,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 210",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Corollary      {I|\nProof. The      proof      follows      Thm. 4      of|Wang      et      al! (2023a)      based      on      Thm. 2]      and      Thm. 3}      Thm. 2)and      Thm. 3)can      ensure      that  \n \n  by      using      Alg."
            },
            {
              "id": 1777,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 211",
              "type": "chunk",
              "children": [],
              "content": "2]      for      each      potential      adjustment      set,      we      can      find      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the  \n \n  MAGs      consistent      with      M."
            },
            {
              "id": 1778,
              "title": "      International      Journal      of      Approximate      Reasoning,      55(4): - Chunk 212",
              "type": "chunk",
              "children": [],
              "content": "And      since      in      PAGrules,      all      possible      local      transformation      are      considered      on      Line      5,      PAGrules      can  \n \n  return      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the      MAGs      consistent      with      P. C"
            }
          ],
          "content": ""
        },
        {
          "id": 1779,
          "title": "A.      Detailed      Preliminary",
          "type": "section",
          "children": [
            {
              "id": 1780,
              "title": "A.      Detailed      Preliminary - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A. Detailed      Preliminary\nA.1."
            },
            {
              "id": 1781,
              "title": "A.      Detailed      Preliminary - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Graphs\n \n \n  In   \n \na      graph      G,      consider   \n \na      path      p   \n \n=      (Vi,      V2,---   \n \n,      Vx),      p      is   \n \na      directed      path      if      there      is      V;   \n \n>      Vizi,      V1      <i   \n \n<      k-—1;      pisa  \n \n  collider      path      if      there      is      V;_1*—      V;      <+*Vj41,      V2      <i   \n \n<   \n \nk   \n \n—      1;      p      is      minimal      if      any      two      non-consecutive      vertices      are      not  \n \n  adjacent."
            },
            {
              "id": 1782,
              "title": "A.      Detailed      Preliminary - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "A      vertex      Vj      is   \n \na      parent      of      V2      if      there      is      Vi   \n \n—      V2. V;      is      an      ancestor/descendant      of      V2      if      there      is   \n \na      directed      path  \n \n  from      V\\\\\\\\/V2      to      V2/V,. V,      is   \n \na      possible      ancestor/possible      descendant      of      V2      if      there      is   \n \na      possible      directed      path      from      V/V  \n \n  to      V2/V,."
            },
            {
              "id": 1783,
              "title": "A.      Detailed      Preliminary - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Note      each      vertex      is      an      ancestor/descendant/possible      ancestor/possible      descendant      of      itself. An      edge      in      the      form  \n \n  of      o—o      is   \n \na      circle      edge. The      circle      component      of   \n \na      graph      G      is      the      subgraph      of      G   \n \n=      (V,E)      consisting      of      the      vertices V\n \n   and      all      the      circle      edges."
            },
            {
              "id": 1784,
              "title": "A.      Detailed      Preliminary - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      say      two      vertices      V;      and      V;      is   \n \na      connected      circle      component      in      G      if      there      is   \n \na      circle      path  \n \n  Vj;      0-0      ---      0-0      V;      from      V;      to      V;      in      G."
            },
            {
              "id": 1785,
              "title": "A.      Detailed      Preliminary - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      two      paths      p;   \n \n=      (Vi,      Vo,---   \n \n,      Va)      and      po   \n \n=      ($1,      S2,---   \n \n,      Sn),      we      use      pi   \n \n@      pe      to  \n \n  denote      the      concatenate      path      (Vi,---   \n \n,      Va,      S1,-+-   \n \n,      Sn)."
            },
            {
              "id": 1786,
              "title": "A.      Detailed      Preliminary - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \na      path      V;   \n \n—      V2   \n \n>      ---   \n \n>      Vy      and      an      edge      Vg   \n \n—      V\\\\\\\\/Vq   \n \n+      V,,      then      there      is   \n \na      directed      cycle/almost      directed      cycle. For   \n \na      mixed      graph,      if      there      is      not   \n \na      directed      cycle      or      almost      directed      cycle,      then      it      is      ancestral."
            },
            {
              "id": 1787,
              "title": "A.      Detailed      Preliminary - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "For      an      ancestral      graph,      if      for  \n \n  any      two      non-adjacent      vertices,      there      is   \n \na      set      of      vertices      that      m-seperates      them,      then      the      graph      is      maximal. If   \n \na      mixed      graph      is  \n \n  both      ancestral      and      maximal,      it      is   \n \na      maximal      ancestral      graph      (MAG),      denoted      by      M."
            },
            {
              "id": 1788,
              "title": "A.      Detailed      Preliminary - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is   \n \na      projection      graph      on      the      observable      variables      of      some      underlying      DAGs      containing      both      observable  \n \n  and      latent      variables."
            },
            {
              "id": 1789,
              "title": "A.      Detailed      Preliminary - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "|Spirtes      et      al.|      (2000);      [Zhang|      (2008)      presented      the      algorithm      to      obtain   \n \na      MAG      with      vertices   \n \nO      from   \n \na       DAG      with      vertices   \n \nO      UL      US,      where      O,      L,      S      denote      the      observable      vertices      set,      latent      vertices      set,      and      selection      vertices  \n \n  set."
            },
            {
              "id": 1790,
              "title": "A.      Detailed      Preliminary - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Since      we      do      not      consider      selection      bias      in      this      paper,      we      do      not      consider      S      in      the      following. Next      we      show      inducing  \n \n  path      in      Def. 6,      followed      by      the      algorithm      to      obtain   \n \na      MAG      based      on   \n \na      DAG."
            },
            {
              "id": 1791,
              "title": "A.      Detailed      Preliminary - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      algorithm,      as      the      number      of  \n \n  latent      vertices      can      be      arbitrary,      there      can      be      infinite      number      of      DAGs      which      could      lead      to      one      MAG      by      the      algorithm. Definition   \n \n6      (Inducing      path;      |Spirtes      et      al.|      (2000). Let      X,   \n \nY      be      two      vertices      in      an      maximal      ancestral      graph."
            },
            {
              "id": 1792,
              "title": "A.      Detailed      Preliminary - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Denote      L,S  \n \n  two      disjoint      sets      of      vertices      that      X,   \n \nY      do      not      belong      to."
            },
            {
              "id": 1793,
              "title": "A.      Detailed      Preliminary - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "A      path      p      from   \n \nX      to   \n \nY      is      an      inducing      path      relative      to      (L,      S$)      if      every  \n \n  non-endpoint      vertex      on      p      is      either      in      L      or   \n \na      collider,      and      every      collider      on      p      is      an      ancestor      of      either      _X,      Y,      or   \n \na      member      of      S."
            },
            {
              "id": 1794,
              "title": "A.      Detailed      Preliminary - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Input:   \n \na      DAG      D      over   \n \nV   \n \n=      OUL;  \n \n  Output:   \n \na      MAG      M      over      O."
            },
            {
              "id": 1795,
              "title": "A.      Detailed      Preliminary - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "(1)      for      each      pair      of      vertices      A,   \n \nB   \n \n€      O,   \n \nA      and   \n \nB      are      adjacent      in      M      if      and      only      if      there      is      an      inducing      path      relative      to      (L,      0)  \n \n  from   \n \nA      to   \n \nB      in      D;\n(2)      for      each      pair      of      adjacent      vertices      A,   \n \nB      in      M,      orient      the      edge      between   \n \nA      and   \n \nB      according      to      the      following      steps:\n(a)      orient      A>      Bin      M      if   \n \nA   \n \n€      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D);\n(b)      orient      A+      Bin      M      if   \n \nB   \n \n€      Anc(A,D)      and   \n \nA   \n \n¢      Anc(B,D);\n(c)      orient   \n \nA      Bin      M      if   \n \nA   \n \n¢      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D)."
            },
            {
              "id": 1796,
              "title": "A.      Detailed      Preliminary - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      we      can      only      identify   \n \na      Markov      equivalence      class      (MEC)      of      MAGs,      which      is      represented      by   \n \na       partial      ancestral      graph      (PAG)      and      denoted      by      P."
            },
            {
              "id": 1797,
              "title": "A.      Detailed      Preliminary - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      PAG,      there      is      an      arrowhead/tail      at      some      position      if      and      only      if      there      is  \n \n  an      arrowhead/tail      at      this      position      in      all      the      MAGs      in      the      MEC;      and      there      is   \n \na      circle      at      some      position      if      and      only      if      there      are  \n \n  both      arrowheads      and      tails      at      this      position      in      all      the      MAGs      in      the      MEC."
            },
            {
              "id": 1798,
              "title": "A.      Detailed      Preliminary - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "A.2. Preliminary      about      Orientation      Rules\n \n \n  Ali      et      al.|      (2005);      Zhang)      (2008)      proposed      ten      rules      7;   \n \n—      R40      to      identify   \n \na      PAG      with      observational      data."
            },
            {
              "id": 1799,
              "title": "A.      Detailed      Preliminary - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Jaber      et      al.|      (2020)  \n \n  presented      the      solid      result      to      imply      that      when      there      is      additional      interventional      data      and      selection      bias      is      not      allowed      for,      the  \n \n  ten      rules      are      also      complete."
            },
            {
              "id": 1800,
              "title": "A.      Detailed      Preliminary - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Another      study      (Andrews      et      al.|      /2020)      indicates      that      the      ten      rules      are      complete      if      we      incorporate  \n \n  tiered      background      knowledge,      which      means      that      the      BK      can      classify      the      variables      into      distinct      parts,      where      the      causal      order  \n \n  between      different      parts      is      explicit,      but      the      structural      information      within      each      part      cannot      be      directly      known      according      to      the  \n \n  BK."
            },
            {
              "id": 1801,
              "title": "A.      Detailed      Preliminary - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Further,      when      we      have      obtained   \n \na      PAG      and      incorporate      local      background      knowledge      (local      BK),      i.e.,      the      full      structural  \n \n  knowledge      regarding      some      specific      variables,      Wang      et      al.|(2023b)      proposed   \n \na      rule      R4,      to      replace   \n \n4      and      an      additional      rule  \n \n  Ri."
            },
            {
              "id": 1802,
              "title": "A.      Detailed      Preliminary - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "|Wang      et      al.|      (2023b)      proved      that      the      rules      are      sound      and      complete      to      incorporate      local      BK      into   \n \na      PAG. We      show      these  \n \n  tules      in      the      following."
            },
            {
              "id": 1803,
              "title": "A.      Detailed      Preliminary - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "Since      R;   \n \n—      R7      are      triggered      only      if      the      selection      bias      is      involved      and      we      assume      the      absence      of  \n \n  selection      bias,      we      omit      these      three      rules. R1:      If      Ax>      Box      R,      and   \n \nA      and   \n \nR      are      not      adjacent,      then      orient      the      triple      as      Ax>      B—      R."
            },
            {
              "id": 1804,
              "title": "A.      Detailed      Preliminary - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "Reo:      If   \n \nA   \n \n>      Bx>      Ror      At>   \n \nB   \n \n>      R,      and   \n \nA      +~      R,      then      orient   \n \nA      «©      Ras      Ax>      R. Rs3:      If      Ax>      BorR,   \n \nA      x0      Do      R,   \n \nA      and   \n \nR      are      not      adjacent,      and      D      +o      B,      then      orient      D      *-o   \n \nB      as      Dx      B."
            },
            {
              "id": 1805,
              "title": "A.      Detailed      Preliminary - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Ra: If (k,,A,B, R) is a discriminating path between K and R for B, and B o-* R; then if B € Sepset(K, R),  \n \n  orient   \n \nB      o-«      -R      as   \n \nB   \n \n+      R;      otherwise      orient      the      triple      (A,      B,      R)      as   \n \nA      Bo      R. Res:      If   \n \nA   \n \nB      —-      R,      and      Ao>      R,      orient      Ao>      Ras      A-      R."
            },
            {
              "id": 1806,
              "title": "A.      Detailed      Preliminary - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Ro: If Ao R, and p = (A, B, D,, R) is an uncovered possible directed path from A to R such that R and B are  \n \n  not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R. Rio:      Suppose      Ao>      R,   \n \nB   \n \n+   \n \nR   \n \n«      D,      p;      is      an      uncovered      possible      directed      path      from   \n \nA      to      B,      and      pz      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to      D."
            },
            {
              "id": 1807,
              "title": "A.      Detailed      Preliminary - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Let   \n \nU      be      the      vertex      adjacent      to   \n \nA      on      p;      (U      could      be      B),      and      W      be      the      vertex  \n \n  adjacent      to   \n \nA      on      pz      (W      could      be      D). If   \n \nU      and      W      are      distinct,      and      are      not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R."
            },
            {
              "id": 1808,
              "title": "A.      Detailed      Preliminary - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Ri:      If      (K,---   \n \n,      A,      B,      R)      is   \n \na      discriminating      path      between   \n \nK      and   \n \nR      for      B,      and   \n \nB      o-*      R,      then      orient      Bo-*«      Ras   \n \nB   \n \n>      R. Ri:      If      A-©B,      then   \n \nA   \n \n>      B. A.3."
            },
            {
              "id": 1809,
              "title": "A.      Detailed      Preliminary - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Causal      Effect      Estimation\nDefinition   \n \n7      (Adjustment      set;      Pearl]      (2009);      /van      der      Zander      et      al|      (2014)."
            },
            {
              "id": 1810,
              "title": "A.      Detailed      Preliminary - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      DAG,      MAG,      or      PAG      G,,   \n \nZ      is      an      adjustment  \n \n  set      relative      to      (X,Y)      if      for      any      probability      density      f      compatible      with      G,      the      causal      effect      of   \n \nX      on   \n \nY (YX),      ifZ      =,  \n \n  P(Y|do(X))   \n \n=   \n \n|      poet      P(Y|Z,      X)P(Z)dZ,   \n \n_      otherwise."
            },
            {
              "id": 1811,
              "title": "A.      Detailed      Preliminary - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "©\n \n \n  Maathuis      et      al.|      (2015);      |Perkovic      et      al.|(2017b)      presented      the      necessary      and      sufficient      graphical      characterization      for      the      causal  \n \n  effect      identifiablility      via      covariate      adjustment      given   \n \na      DAG/CPDAG/MAG/PAG. We      show      them      in      Prop. 4]      See      Maathuis  \n \n  et      al.|      (2015)      for      the      notation      Gx."
            },
            {
              "id": 1812,
              "title": "A.      Detailed      Preliminary - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "At      first,      we      introduce      an      important      concept      D-SEP(X,      Y,      G)      in      Def.|8}      D-SEP(X,      Y,      G)  \n \n  is      essentially   \n \na      set      of      vertices. Definition   \n \n8      (D-SEP(X,      Y,      G);|Spirtes      et      al.|(2000)). Let   \n \nX      and   \n \nY      be      two      distinct      vertices      in   \n \na      mixed      graph      G."
            },
            {
              "id": 1813,
              "title": "A.      Detailed      Preliminary - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "We      say  \n \n  that   \n \nV   \n \n€      D-SEP(X,      Y,      G)      if   \n \nV   \n \n4      X,      and      there      is   \n \na      collider      path      between   \n \nX      and   \n \nV      in      G,      such      that      every      vertex      on      this      path  \n \n  (including      V)      is      an      ancestor      of   \n \nX      or   \n \nY      inG. Proposition   \n \n4      (Maathuis      et      al.|      (2015);      Perkovic      et      al.|(2017b))."
            },
            {
              "id": 1814,
              "title": "A.      Detailed      Preliminary - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Let      G      be   \n \na      MAG      or      PAG,      and   \n \nX      and   \n \nY      be      two      distinct  \n \n  vertices      in      G. There      exists      an      adjustment      set      relative      to      (X,Y)      in      G      ifand      only      ifY   \n \n¢      Adj(X,      Gx)      and      D-SEP(X,      Y,Gx)N  \n \n  PossDe(X,      G)   \n \n=      9."
            },
            {
              "id": 1815,
              "title": "A.      Detailed      Preliminary - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      if      an      adjustment      set      exists,      then      D-SEP(X,      Y,      Gx)      is      such   \n \na      set. Denote      D-SEP(X,      Y,      Gx)  \n \n  by      D,      then f(V      |do(X      =f      f(D)      f(V|D,   \n \nX      =a)      dD. (2) B. A      Detailed      Introduction      to      PAGcauses      (Wang      et      al."
            },
            {
              "id": 1816,
              "title": "A.      Detailed      Preliminary - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "2023a)\n \n \n  In      this      part,      we      introduce      the      method      PAGcaused      to      determine      the      set      of      possible      causal      effects      given   \n \na      PAG,      which      is  \n \n  proposed      by      |Wang      et      al. (2023a). We      first      show      some      theoretical      results      of      Wang      et      al. (2023a). Some      of      these      results      are  \n \n  needed      in      our      proof."
            },
            {
              "id": 1817,
              "title": "A.      Detailed      Preliminary - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "The      first      important      result      is      Prop. 5}      It      provides   \n \na      graphical      characterization      for      the      adjustment      set      comprised      of      observable  \n \n  variables      in      all      the      DAGs      represented      by   \n \na      given      MAG."
            },
            {
              "id": 1818,
              "title": "A.      Detailed      Preliminary - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "It      implies      that      there      exists   \n \na      DAG      where      the      causal      effect      of   \n \nX       on   \n \nY      is      identifiable      by      covariate      adjustment      and      the      adjustment      set      is      comprised      of      some      observable      variables      if      and      only  \n \n  if      D-SEP(X,      Y,      Mx)      De(X,      M)   \n \n=      0,      and      D-SEP(X,      Y,      Mx)      is      the      adjustment      set."
            },
            {
              "id": 1819,
              "title": "A.      Detailed      Preliminary - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Hence,      given   \n \na      MAG      M,      we      can determine      whether      there      exists      some      DAG      where      the      causal      effect      is      identifiable      by      adjusting      for      observable      variables  \n \n  without      the      need      the      enumerate      the      DAGs. And      for      all      the      DAGs      above,      they      are      associated      with      the      same      causal      effect. Proposition      5."
            },
            {
              "id": 1820,
              "title": "A.      Detailed      Preliminary - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Suppose   \n \na      MAG      M      where   \n \nX   \n \n©      Anc(Y,      M). There      exists   \n \na      DAG      D      represented      by      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      in      D      can      be      identified      by      adjusting      for   \n \na      set      comprised      of      V(M)      if      and      only      if      D-SEP(X,      Y,      Mx)   \n \n9 De(X,      M)   \n \n=      @."
            },
            {
              "id": 1821,
              "title": "A.      Detailed      Preliminary - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      such   \n \na      set      exists,      D-SEP(X,      Y,      Mx)      is      an      adjustment      set."
            },
            {
              "id": 1822,
              "title": "A.      Detailed      Preliminary - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the      following,      when we      say      an      adjustment      set      in      M,      it      means      the      adjustment      set      in      the      DAGs      represented      by      the      MAG      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      can      be      identified      by      adjusting      for      this      adjustment      set. According      to      Prop."
            },
            {
              "id": 1823,
              "title": "A.      Detailed      Preliminary - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "5,      when      addressing      the      set      determination      task      for      the      causal      effect      of   \n \nX      on      Y,      we      only      need      to      consider  \n \n  the      MAG      in      the      MEC      presented      by      ?,      without      the      need      to      consider      the      DAGs."
            },
            {
              "id": 1824,
              "title": "A.      Detailed      Preliminary - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Considering      there      are      many      circles      ina      PAG  \n \n  P,      PAGcauses      considers      transforming      the      circles      of   \n \nX      at      first."
            },
            {
              "id": 1825,
              "title": "A.      Detailed      Preliminary - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "They      use   \n \na      set      of      vertices      C      to      represent   \n \na      local      transformation  \n \n  of      X,      i.e.,      transform   \n \nX      o*   \n \nV      to   \n \nX      <«V      if   \n \nV   \n \n€      C      and      transform   \n \nX      o*«   \n \nV      to   \n \nX      -*«V      if   \n \nV   \n \n€      {V   \n \n€      V(P)|X      o*   \n \nV      in      P}\\\\\\\\C."
            },
            {
              "id": 1826,
              "title": "A.      Detailed      Preliminary - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "An      important      problem      here      is      to      evaluate      the      validity      of      each      local      transformation,      i.e.,      whether      there      is   \n \na      MAG      consistent  \n \n  with      this      local      transformation      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1827,
              "title": "A.      Detailed      Preliminary - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "For      this      purpose,      they      presented   \n \na      graphical      characterization  \n \n  for      the      valid      local      transformation      of   \n \nX      implied      by      C      given      the      PAG      P,      which      is      shown      in      Prop. 6,      The      three      conditions      in  \n \n  Prop. (6|      can      be      evaluated      in      O(d?),      where      d      denotes      the      number      of      vertices. In      Prop."
            },
            {
              "id": 1828,
              "title": "A.      Detailed      Preliminary - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "(6      the      concept      of      bridged      is      involved, which      is      shown      in      Def. 9       Definition   \n \n9      (Bridged      relative      to      V’      in      H;      |Wang      et      al.||2023a). Let      H      be   \n \na      partial      mixed      graph. Denote      H’   \n \na      subgraph  \n \n  of      H      induced      by   \n \na      set      of      vertices      K."
            },
            {
              "id": 1829,
              "title": "A.      Detailed      Preliminary - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      V’      in      H      that      is      disjoint      of      K,      two      vertices   \n \nA      and   \n \nB       in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V\\\\\\'      if      either   \n \nA   \n \n=   \n \nB      or      in      each      minimal      circle      path  \n \n  A(=      Vo)      o-0      Vj      o-0---      0-0      V,,      o-0      B(=      V,,41)      from   \n \nA      to   \n \nB      in      H’,      there      exists      one      vertex      V;,0   \n \n<      s   \n \n<      n+      1,      such      that  \n \n  Fy,   \n \n©      Fv,,,,0<i<s—land      Fy,,,      C      Fy,,s      <i      <n,      where      Fy,   \n \n=      {V   \n \n€      V’   \n \n|   \n \nV      +0      V;      or      Vx>      V;      in      H}."
            },
            {
              "id": 1830,
              "title": "A.      Detailed      Preliminary - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Further,  \n \n  H\\\\\\'      is      bridged      relative      to      V’      in      H      if      any      two      vertices      in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V’. Proposition      6."
            },
            {
              "id": 1831,
              "title": "A.      Detailed      Preliminary - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG      P,      for      any      set      of      vertices      C      C      {V   \n \n|   \n \nX      o-*   \n \nV      in      P},      there      exists   \n \na      MAG      M      consistent      with      P       with   \n \nX      +*V,      VV   \n \n€      Cand   \n \nX   \n \n>      V,VV   \n \n€      {V   \n \n|   \n \nX      o«V      in      P}\\\\\\\\C      ifand      only      if\n(1)      PossDe(X,      P{[—C])      N      Pa(C,      P)   \n \n=      0;\n(2)      the      subgraph      P|C]      of      P      induced      by      C      is   \n \na      complete      graph;\n(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P\n \n{   \n \nX      }]      is      bridged      relative      to      C   \n \nU      {X}      in      P."
            },
            {
              "id": 1832,
              "title": "A.      Detailed      Preliminary - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "After      incorporating   \n \na      valid      local      transformation      into      the      PAG      ?,      [Wang      et      al.|(2023a)      used      the      sound      and      complete      orientation  \n \n  rules      Ry   \n \n—      R3,R4,Rz   \n \n—      Rio,      R11      to      further      update      the      graph. And      the      obtained      graph      is      called      by      maximal      local      MAG,  \n \n  denoted      by      M."
            },
            {
              "id": 1833,
              "title": "A.      Detailed      Preliminary - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "By      incorporating      different      valid      local      transformations,      PAGcauses      can      obtain      different      maximal      local      MAGs. However,      determining   \n \na      maximal      local      MAG      M      is      not      sufficient      for      determining      the      only      adjustment      set      in      all      the      MAGs  \n \n  consistent      with      MI."
            },
            {
              "id": 1834,
              "title": "A.      Detailed      Preliminary - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      established      the      graphical      characterization      for      the      adjustment      set      in      the      MAGs      consistent  \n \n  with      M      in      Prop. 2)and      Prop. {7}      Both      Prop. [2]and      Prop."
            },
            {
              "id": 1835,
              "title": "A.      Detailed      Preliminary - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "[/]ensure      that      PAGcauses      can      find      the      same      set      of      causal      effects      given  \n \n  M      as      methods      to      enumerate      all      the      MAGs      consistent      with      M. Proposition      7. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y)."
            },
            {
              "id": 1836,
              "title": "A.      Detailed      Preliminary - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1837,
              "title": "A.      Detailed      Preliminary - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "Then      W      is   \n \na      potential      adjustment      set      in      M      and      there      exists   \n \na      block set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      V’      inM};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M\nM."
            },
            {
              "id": 1838,
              "title": "A.      Detailed      Preliminary - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "With      the      results      above,      they      proposed      their      method      PAGcauses      in      Alg. A}  \n \n  In      the      proof      of      Prop. |2}      if      the      three      conditions      are      satisfied,      they      present      an      algorithm      to      construct   \n \na      MAG      consistent      with      M       such      that      the      adjustment      set      is      W. We      show      the      algorithm      in      Alg."
            },
            {
              "id": 1839,
              "title": "A.      Detailed      Preliminary - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "[5}  \n \n  3\nAlgorithm      4:      PAGcauses Input:      PAG      P,      X,Y  \n \n  AS(P)      =0)      //      Record      all      the      valid      adjustment      sets;\n      if      X      ¢      PossAn(Y,      ?)      then      return      No      causal      effects;       if      the      conditions      in      Prop.\\\\\\\\4      Hare      satisfied      for      P      then       |      return      AS(P)      +      {D-SEP(X,      Y,      Px)}      //      Prop."
            },
            {
              "id": 1840,
              "title": "A.      Detailed      Preliminary - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "[4       4       5       6       7       8       9       10       11 for      each      setC      C{V      |      V      «0      X      in      P}      do       if      the      three      conditions      in      Prop. (dare      satisfied      then       Obtain      a      maximal      local      MAG      M      based      on      P      and      C;       Find      all      potential      adjustment      sets      W,,      W2,---      given      M      according      to      Def."
            },
            {
              "id": 1841,
              "title": "A.      Detailed      Preliminary - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "for      each      potential      adjustment      set      W;,      do       for      each      block      set      S      do       if      the      three      conditions      in      Prop."
            },
            {
              "id": 1842,
              "title": "A.      Detailed      Preliminary - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "2Jare      satisfied      given      S      then AS(P)      +      AS(P)      U      {Wi}: 12       13 break      //      Break      the      loop      of      S;       Output:      Set      of      causal      effects      via      adjustment      in      the      given      PAG      P      identified      with      AS(P)      by      (i)\nAlgorithm      5:      Orient   \n \na      maximal      local      MAG      of   \n \nX      as   \n \na      MAG  \n \n  input:      Maximal      local      MAG      M,      potential      adjustment      set      W      and      corresponding      W      according      to      Def."
            },
            {
              "id": 1843,
              "title": "A.      Detailed      Preliminary - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "2}      PI      block      set      S       1:      for      VK   \n \n€      PossDe(W,      M[—S])      and      VT   \n \n€      S      such      that   \n \nK      o~*   \n \nT      in      M,      orient      it      as   \n \nK      <+*T\\\\\\'      (the      mark      at   \n \nT      remains);  \n \n  2:      update      the      subgraph      M[PossDe(W,      M[—S])]      as      follows      until      no      feasible      updates:      for      any      two      vertices      V;      and      V;      such  \n \n  that      V;      0-0      V;,      orient      itas      V;   \n \n+      V;      if      (1)      Fy,      \\\\\\\\Fv;   \n \n#      or      (2)      Fy,   \n \n=      Fy,      as      well      as      there      is   \n \na      vertex  \n \n  V;,   \n \n€      PossDe(W,      M[—S})      not      adjacent      to      V;      such      that      V;,   \n \n>      V;      o-o      V;,      where      Fy,   \n \n=      {V   \n \n€      S|   \n \nV      +0      V;      in      M};  \n \n  3:      orient      the      circles      on      the      remaining      o—      edges      as      tails;  \n \n  4:      in      subgraph      M[PossDe(W,      M[—S])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders;  \n \n  5:      in      subgraph      M[—PossDe(W,      M[-S]])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders."
            },
            {
              "id": 1844,
              "title": "A.      Detailed      Preliminary - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "output:   \n \nA      MAG      M\n[I]  \n \n  Suppose      there      are      m      edges      and      d      vertices      in      H. There      are      m      edges      that      can      be      transformed. Hence      the      round      of      loop      is  \n \n  O(m). In      each      round,      suppose      we      want      to      detect      whether   \n \nA      o-*«   \n \nB      can      be      transformed      by      Ry2      or      R13."
            },
            {
              "id": 1845,
              "title": "A.      Detailed      Preliminary - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  Line   \n \n2      and      Line   \n \n3      is      O(d). And      determining      the      set      Anc(S      4,      H)      takes   \n \na      O(md)      complexity. Executing      Line   \n \n7      and      Line   \n \n9       take   \n \na      O(m)      complexity. And      the      complexity      of      Line   \n \n8      is      O(m). Hence      the      complexity      of      Alg. [lis      O(m?3),. roof\nD.1. Proof      of      Proposition"
            }
          ],
          "content": ""
        },
        {
          "id": 1846,
          "title": "A.1.      Preliminary      about      Graphs",
          "type": "section",
          "children": [
            {
              "id": 1847,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A.1."
            },
            {
              "id": 1848,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Preliminary      about      Graphs\n \n \n  In   \n \na      graph      G,      consider   \n \na      path      p   \n \n=      (Vi,      V2,---   \n \n,      Vx),      p      is   \n \na      directed      path      if      there      is      V;   \n \n>      Vizi,      V1      <i   \n \n<      k-—1;      pisa  \n \n  collider      path      if      there      is      V;_1*—      V;      <+*Vj41,      V2      <i   \n \n<   \n \nk   \n \n—      1;      p      is      minimal      if      any      two      non-consecutive      vertices      are      not  \n \n  adjacent."
            },
            {
              "id": 1849,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "A      vertex      Vj      is   \n \na      parent      of      V2      if      there      is      Vi   \n \n—      V2. V;      is      an      ancestor/descendant      of      V2      if      there      is   \n \na      directed      path  \n \n  from      V\\\\\\\\/V2      to      V2/V,. V,      is   \n \na      possible      ancestor/possible      descendant      of      V2      if      there      is   \n \na      possible      directed      path      from      V/V  \n \n  to      V2/V,."
            },
            {
              "id": 1850,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Note      each      vertex      is      an      ancestor/descendant/possible      ancestor/possible      descendant      of      itself. An      edge      in      the      form  \n \n  of      o—o      is   \n \na      circle      edge. The      circle      component      of   \n \na      graph      G      is      the      subgraph      of      G   \n \n=      (V,E)      consisting      of      the      vertices V\n \n   and      all      the      circle      edges."
            },
            {
              "id": 1851,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      say      two      vertices      V;      and      V;      is   \n \na      connected      circle      component      in      G      if      there      is   \n \na      circle      path  \n \n  Vj;      0-0      ---      0-0      V;      from      V;      to      V;      in      G."
            },
            {
              "id": 1852,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      two      paths      p;   \n \n=      (Vi,      Vo,---   \n \n,      Va)      and      po   \n \n=      ($1,      S2,---   \n \n,      Sn),      we      use      pi   \n \n@      pe      to  \n \n  denote      the      concatenate      path      (Vi,---   \n \n,      Va,      S1,-+-   \n \n,      Sn)."
            },
            {
              "id": 1853,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \na      path      V;   \n \n—      V2   \n \n>      ---   \n \n>      Vy      and      an      edge      Vg   \n \n—      V\\\\\\\\/Vq   \n \n+      V,,      then      there      is   \n \na      directed      cycle/almost      directed      cycle. For   \n \na      mixed      graph,      if      there      is      not   \n \na      directed      cycle      or      almost      directed      cycle,      then      it      is      ancestral."
            },
            {
              "id": 1854,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "For      an      ancestral      graph,      if      for  \n \n  any      two      non-adjacent      vertices,      there      is   \n \na      set      of      vertices      that      m-seperates      them,      then      the      graph      is      maximal. If   \n \na      mixed      graph      is  \n \n  both      ancestral      and      maximal,      it      is   \n \na      maximal      ancestral      graph      (MAG),      denoted      by      M."
            },
            {
              "id": 1855,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Essentially,      MAG      is   \n \na      projection      graph      on      the      observable      variables      of      some      underlying      DAGs      containing      both      observable  \n \n  and      latent      variables."
            },
            {
              "id": 1856,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "|Spirtes      et      al.|      (2000);      [Zhang|      (2008)      presented      the      algorithm      to      obtain   \n \na      MAG      with      vertices   \n \nO      from   \n \na       DAG      with      vertices   \n \nO      UL      US,      where      O,      L,      S      denote      the      observable      vertices      set,      latent      vertices      set,      and      selection      vertices  \n \n  set."
            },
            {
              "id": 1857,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Since      we      do      not      consider      selection      bias      in      this      paper,      we      do      not      consider      S      in      the      following. Next      we      show      inducing  \n \n  path      in      Def. 6,      followed      by      the      algorithm      to      obtain   \n \na      MAG      based      on   \n \na      DAG."
            },
            {
              "id": 1858,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      algorithm,      as      the      number      of  \n \n  latent      vertices      can      be      arbitrary,      there      can      be      infinite      number      of      DAGs      which      could      lead      to      one      MAG      by      the      algorithm. Definition   \n \n6      (Inducing      path;      |Spirtes      et      al.|      (2000). Let      X,   \n \nY      be      two      vertices      in      an      maximal      ancestral      graph."
            },
            {
              "id": 1859,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Denote      L,S  \n \n  two      disjoint      sets      of      vertices      that      X,   \n \nY      do      not      belong      to."
            },
            {
              "id": 1860,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "A      path      p      from   \n \nX      to   \n \nY      is      an      inducing      path      relative      to      (L,      S$)      if      every  \n \n  non-endpoint      vertex      on      p      is      either      in      L      or   \n \na      collider,      and      every      collider      on      p      is      an      ancestor      of      either      _X,      Y,      or   \n \na      member      of      S."
            },
            {
              "id": 1861,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Input:   \n \na      DAG      D      over   \n \nV   \n \n=      OUL;  \n \n  Output:   \n \na      MAG      M      over      O."
            },
            {
              "id": 1862,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "(1)      for      each      pair      of      vertices      A,   \n \nB   \n \n€      O,   \n \nA      and   \n \nB      are      adjacent      in      M      if      and      only      if      there      is      an      inducing      path      relative      to      (L,      0)  \n \n  from   \n \nA      to   \n \nB      in      D;\n(2)      for      each      pair      of      adjacent      vertices      A,   \n \nB      in      M,      orient      the      edge      between   \n \nA      and   \n \nB      according      to      the      following      steps:\n(a)      orient      A>      Bin      M      if   \n \nA   \n \n€      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D);\n(b)      orient      A+      Bin      M      if   \n \nB   \n \n€      Anc(A,D)      and   \n \nA   \n \n¢      Anc(B,D);\n(c)      orient   \n \nA      Bin      M      if   \n \nA   \n \n¢      Anc(B,D)      and   \n \nB   \n \n¢      Anc(A,      D)."
            },
            {
              "id": 1863,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Given      observational      data,      we      can      only      identify   \n \na      Markov      equivalence      class      (MEC)      of      MAGs,      which      is      represented      by   \n \na       partial      ancestral      graph      (PAG)      and      denoted      by      P."
            },
            {
              "id": 1864,
              "title": "A.1.      Preliminary      about      Graphs - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In   \n \na      PAG,      there      is      an      arrowhead/tail      at      some      position      if      and      only      if      there      is  \n \n  an      arrowhead/tail      at      this      position      in      all      the      MAGs      in      the      MEC;      and      there      is   \n \na      circle      at      some      position      if      and      only      if      there      are  \n \n  both      arrowheads      and      tails      at      this      position      in      all      the      MAGs      in      the      MEC."
            }
          ],
          "content": ""
        },
        {
          "id": 1865,
          "title": "A.2.      Preliminary      about      Orientation      Rules",
          "type": "section",
          "children": [
            {
              "id": 1866,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A.2. Preliminary      about      Orientation      Rules\n \n \n  Ali      et      al.|      (2005);      Zhang)      (2008)      proposed      ten      rules      7;   \n \n—      R40      to      identify   \n \na      PAG      with      observational      data."
            },
            {
              "id": 1867,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Jaber      et      al.|      (2020)  \n \n  presented      the      solid      result      to      imply      that      when      there      is      additional      interventional      data      and      selection      bias      is      not      allowed      for,      the  \n \n  ten      rules      are      also      complete."
            },
            {
              "id": 1868,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Another      study      (Andrews      et      al.|      /2020)      indicates      that      the      ten      rules      are      complete      if      we      incorporate  \n \n  tiered      background      knowledge,      which      means      that      the      BK      can      classify      the      variables      into      distinct      parts,      where      the      causal      order  \n \n  between      different      parts      is      explicit,      but      the      structural      information      within      each      part      cannot      be      directly      known      according      to      the  \n \n  BK."
            },
            {
              "id": 1869,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Further,      when      we      have      obtained   \n \na      PAG      and      incorporate      local      background      knowledge      (local      BK),      i.e.,      the      full      structural  \n \n  knowledge      regarding      some      specific      variables,      Wang      et      al.|(2023b)      proposed   \n \na      rule      R4,      to      replace   \n \n4      and      an      additional      rule  \n \n  Ri."
            },
            {
              "id": 1870,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "|Wang      et      al.|      (2023b)      proved      that      the      rules      are      sound      and      complete      to      incorporate      local      BK      into   \n \na      PAG. We      show      these  \n \n  tules      in      the      following."
            },
            {
              "id": 1871,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Since      R;   \n \n—      R7      are      triggered      only      if      the      selection      bias      is      involved      and      we      assume      the      absence      of  \n \n  selection      bias,      we      omit      these      three      rules. R1:      If      Ax>      Box      R,      and   \n \nA      and   \n \nR      are      not      adjacent,      then      orient      the      triple      as      Ax>      B—      R."
            },
            {
              "id": 1872,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Reo:      If   \n \nA   \n \n>      Bx>      Ror      At>   \n \nB   \n \n>      R,      and   \n \nA      +~      R,      then      orient   \n \nA      «©      Ras      Ax>      R. Rs3:      If      Ax>      BorR,   \n \nA      x0      Do      R,   \n \nA      and   \n \nR      are      not      adjacent,      and      D      +o      B,      then      orient      D      *-o   \n \nB      as      Dx      B."
            },
            {
              "id": 1873,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Ra: If (k,,A,B, R) is a discriminating path between K and R for B, and B o-* R; then if B € Sepset(K, R),  \n \n  orient   \n \nB      o-«      -R      as   \n \nB   \n \n+      R;      otherwise      orient      the      triple      (A,      B,      R)      as   \n \nA      Bo      R. Res:      If   \n \nA   \n \nB      —-      R,      and      Ao>      R,      orient      Ao>      Ras      A-      R."
            },
            {
              "id": 1874,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Ro: If Ao R, and p = (A, B, D,, R) is an uncovered possible directed path from A to R such that R and B are  \n \n  not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R. Rio:      Suppose      Ao>      R,   \n \nB   \n \n+   \n \nR   \n \n«      D,      p;      is      an      uncovered      possible      directed      path      from   \n \nA      to      B,      and      pz      is      an      uncovered  \n \n  possible      directed      path      from   \n \nA      to      D."
            },
            {
              "id": 1875,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Let   \n \nU      be      the      vertex      adjacent      to   \n \nA      on      p;      (U      could      be      B),      and      W      be      the      vertex  \n \n  adjacent      to   \n \nA      on      pz      (W      could      be      D). If   \n \nU      and      W      are      distinct,      and      are      not      adjacent,      then      orient      Ao>      Ras   \n \nA   \n \n>      R."
            },
            {
              "id": 1876,
              "title": "A.2.      Preliminary      about      Orientation      Rules - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Ri:      If      (K,---   \n \n,      A,      B,      R)      is   \n \na      discriminating      path      between   \n \nK      and   \n \nR      for      B,      and   \n \nB      o-*      R,      then      orient      Bo-*«      Ras   \n \nB   \n \n>      R. Ri:      If      A-©B,      then   \n \nA   \n \n>      B."
            }
          ],
          "content": ""
        },
        {
          "id": 1877,
          "title": "A.3.      Preliminary      about      Causal      Effect      Estimation",
          "type": "section",
          "children": [
            {
              "id": 1878,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "A.3. Preliminary      about      Causal      Effect      Estimation\nDefinition   \n \n7      (Adjustment      set;      Pearl]      (2009);      /van      der      Zander      et      al|      (2014)."
            },
            {
              "id": 1879,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      DAG,      MAG,      or      PAG      G,,   \n \nZ      is      an      adjustment  \n \n  set      relative      to      (X,Y)      if      for      any      probability      density      f      compatible      with      G,      the      causal      effect      of   \n \nX      on   \n \nY (YX),      ifZ      =,  \n \n  P(Y|do(X))   \n \n=   \n \n|      poet      P(Y|Z,      X)P(Z)dZ,   \n \n_      otherwise."
            },
            {
              "id": 1880,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "©\n \n \n  Maathuis      et      al.|      (2015);      |Perkovic      et      al.|(2017b)      presented      the      necessary      and      sufficient      graphical      characterization      for      the      causal  \n \n  effect      identifiablility      via      covariate      adjustment      given   \n \na      DAG/CPDAG/MAG/PAG. We      show      them      in      Prop. 4]      See      Maathuis  \n \n  et      al.|      (2015)      for      the      notation      Gx."
            },
            {
              "id": 1881,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "At      first,      we      introduce      an      important      concept      D-SEP(X,      Y,      G)      in      Def.|8}      D-SEP(X,      Y,      G)  \n \n  is      essentially   \n \na      set      of      vertices. Definition   \n \n8      (D-SEP(X,      Y,      G);|Spirtes      et      al.|(2000)). Let   \n \nX      and   \n \nY      be      two      distinct      vertices      in   \n \na      mixed      graph      G."
            },
            {
              "id": 1882,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      say  \n \n  that   \n \nV   \n \n€      D-SEP(X,      Y,      G)      if   \n \nV   \n \n4      X,      and      there      is   \n \na      collider      path      between   \n \nX      and   \n \nV      in      G,      such      that      every      vertex      on      this      path  \n \n  (including      V)      is      an      ancestor      of   \n \nX      or   \n \nY      inG. Proposition   \n \n4      (Maathuis      et      al.|      (2015);      Perkovic      et      al.|(2017b))."
            },
            {
              "id": 1883,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Let      G      be   \n \na      MAG      or      PAG,      and   \n \nX      and   \n \nY      be      two      distinct  \n \n  vertices      in      G. There      exists      an      adjustment      set      relative      to      (X,Y)      in      G      ifand      only      ifY   \n \n¢      Adj(X,      Gx)      and      D-SEP(X,      Y,Gx)N  \n \n  PossDe(X,      G)   \n \n=      9."
            },
            {
              "id": 1884,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Moreover,      if      an      adjustment      set      exists,      then      D-SEP(X,      Y,      Gx)      is      such   \n \na      set. Denote      D-SEP(X,      Y,      Gx)  \n \n  by      D,      then f(V      |do(X      =f      f(D)      f(V|D,   \n \nX      =a)      dD. (2) B. A      Detailed      Introduction      to      PAGcauses      (Wang      et      al."
            },
            {
              "id": 1885,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "2023a)\n \n \n  In      this      part,      we      introduce      the      method      PAGcaused      to      determine      the      set      of      possible      causal      effects      given   \n \na      PAG,      which      is  \n \n  proposed      by      |Wang      et      al. (2023a). We      first      show      some      theoretical      results      of      Wang      et      al. (2023a). Some      of      these      results      are  \n \n  needed      in      our      proof."
            },
            {
              "id": 1886,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "The      first      important      result      is      Prop. 5}      It      provides   \n \na      graphical      characterization      for      the      adjustment      set      comprised      of      observable  \n \n  variables      in      all      the      DAGs      represented      by   \n \na      given      MAG."
            },
            {
              "id": 1887,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "It      implies      that      there      exists   \n \na      DAG      where      the      causal      effect      of   \n \nX       on   \n \nY      is      identifiable      by      covariate      adjustment      and      the      adjustment      set      is      comprised      of      some      observable      variables      if      and      only  \n \n  if      D-SEP(X,      Y,      Mx)      De(X,      M)   \n \n=      0,      and      D-SEP(X,      Y,      Mx)      is      the      adjustment      set."
            },
            {
              "id": 1888,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Hence,      given   \n \na      MAG      M,      we      can determine      whether      there      exists      some      DAG      where      the      causal      effect      is      identifiable      by      adjusting      for      observable      variables  \n \n  without      the      need      the      enumerate      the      DAGs. And      for      all      the      DAGs      above,      they      are      associated      with      the      same      causal      effect. Proposition      5."
            },
            {
              "id": 1889,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Suppose   \n \na      MAG      M      where   \n \nX   \n \n©      Anc(Y,      M). There      exists   \n \na      DAG      D      represented      by      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      in      D      can      be      identified      by      adjusting      for   \n \na      set      comprised      of      V(M)      if      and      only      if      D-SEP(X,      Y,      Mx)   \n \n9 De(X,      M)   \n \n=      @."
            },
            {
              "id": 1890,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      such   \n \na      set      exists,      D-SEP(X,      Y,      Mx)      is      an      adjustment      set."
            },
            {
              "id": 1891,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      the      following,      when we      say      an      adjustment      set      in      M,      it      means      the      adjustment      set      in      the      DAGs      represented      by      the      MAG      M      such      that      the      causal  \n \n  effect      of   \n \nX      on   \n \nY      can      be      identified      by      adjusting      for      this      adjustment      set. According      to      Prop."
            },
            {
              "id": 1892,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "5,      when      addressing      the      set      determination      task      for      the      causal      effect      of   \n \nX      on      Y,      we      only      need      to      consider  \n \n  the      MAG      in      the      MEC      presented      by      ?,      without      the      need      to      consider      the      DAGs."
            },
            {
              "id": 1893,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Considering      there      are      many      circles      ina      PAG  \n \n  P,      PAGcauses      considers      transforming      the      circles      of   \n \nX      at      first."
            },
            {
              "id": 1894,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "They      use   \n \na      set      of      vertices      C      to      represent   \n \na      local      transformation  \n \n  of      X,      i.e.,      transform   \n \nX      o*   \n \nV      to   \n \nX      <«V      if   \n \nV   \n \n€      C      and      transform   \n \nX      o*«   \n \nV      to   \n \nX      -*«V      if   \n \nV   \n \n€      {V   \n \n€      V(P)|X      o*   \n \nV      in      P}\\\\\\\\C."
            },
            {
              "id": 1895,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "An      important      problem      here      is      to      evaluate      the      validity      of      each      local      transformation,      i.e.,      whether      there      is   \n \na      MAG      consistent  \n \n  with      this      local      transformation      in      the      MEC      represented      by      ?."
            },
            {
              "id": 1896,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "For      this      purpose,      they      presented   \n \na      graphical      characterization  \n \n  for      the      valid      local      transformation      of   \n \nX      implied      by      C      given      the      PAG      P,      which      is      shown      in      Prop. 6,      The      three      conditions      in  \n \n  Prop. (6|      can      be      evaluated      in      O(d?),      where      d      denotes      the      number      of      vertices. In      Prop."
            },
            {
              "id": 1897,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "(6      the      concept      of      bridged      is      involved, which      is      shown      in      Def. 9       Definition   \n \n9      (Bridged      relative      to      V’      in      H;      |Wang      et      al.||2023a). Let      H      be   \n \na      partial      mixed      graph. Denote      H’   \n \na      subgraph  \n \n  of      H      induced      by   \n \na      set      of      vertices      K."
            },
            {
              "id": 1898,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      set      of      vertices      V’      in      H      that      is      disjoint      of      K,      two      vertices   \n \nA      and   \n \nB       in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V\\\\\\'      if      either   \n \nA   \n \n=   \n \nB      or      in      each      minimal      circle      path  \n \n  A(=      Vo)      o-0      Vj      o-0---      0-0      V,,      o-0      B(=      V,,41)      from   \n \nA      to   \n \nB      in      H’,      there      exists      one      vertex      V;,0   \n \n<      s   \n \n<      n+      1,      such      that  \n \n  Fy,   \n \n©      Fv,,,,0<i<s—land      Fy,,,      C      Fy,,s      <i      <n,      where      Fy,   \n \n=      {V   \n \n€      V’   \n \n|   \n \nV      +0      V;      or      Vx>      V;      in      H}."
            },
            {
              "id": 1899,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Further,  \n \n  H\\\\\\'      is      bridged      relative      to      V’      in      H      if      any      two      vertices      in   \n \na      connected      circle      component      of      H’      are      bridged      relative      to      V’. Proposition      6."
            },
            {
              "id": 1900,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      PAG      P,      for      any      set      of      vertices      C      C      {V   \n \n|   \n \nX      o-*   \n \nV      in      P},      there      exists   \n \na      MAG      M      consistent      with      P       with   \n \nX      +*V,      VV   \n \n€      Cand   \n \nX   \n \n>      V,VV   \n \n€      {V   \n \n|   \n \nX      o«V      in      P}\\\\\\\\C      ifand      only      if\n(1)      PossDe(X,      P{[—C])      N      Pa(C,      P)   \n \n=      0;\n(2)      the      subgraph      P|C]      of      P      induced      by      C      is   \n \na      complete      graph;\n(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P\n \n{   \n \nX      }]      is      bridged      relative      to      C   \n \nU      {X}      in      P."
            },
            {
              "id": 1901,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "After      incorporating   \n \na      valid      local      transformation      into      the      PAG      ?,      [Wang      et      al.|(2023a)      used      the      sound      and      complete      orientation  \n \n  rules      Ry   \n \n—      R3,R4,Rz   \n \n—      Rio,      R11      to      further      update      the      graph. And      the      obtained      graph      is      called      by      maximal      local      MAG,  \n \n  denoted      by      M."
            },
            {
              "id": 1902,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "By      incorporating      different      valid      local      transformations,      PAGcauses      can      obtain      different      maximal      local      MAGs. However,      determining   \n \na      maximal      local      MAG      M      is      not      sufficient      for      determining      the      only      adjustment      set      in      all      the      MAGs  \n \n  consistent      with      MI."
            },
            {
              "id": 1903,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      established      the      graphical      characterization      for      the      adjustment      set      in      the      MAGs      consistent  \n \n  with      M      in      Prop. 2)and      Prop. {7}      Both      Prop. [2]and      Prop."
            },
            {
              "id": 1904,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "[/]ensure      that      PAGcauses      can      find      the      same      set      of      causal      effects      given  \n \n  M      as      methods      to      enumerate      all      the      MAGs      consistent      with      M. Proposition      7. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y)."
            },
            {
              "id": 1905,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 1906,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Then      W      is   \n \na      potential      adjustment      set      in      M      and      there      exists   \n \na      block set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      V’      inM};\n(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M\nM."
            },
            {
              "id": 1907,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "With      the      results      above,      they      proposed      their      method      PAGcauses      in      Alg. A}  \n \n  In      the      proof      of      Prop. |2}      if      the      three      conditions      are      satisfied,      they      present      an      algorithm      to      construct   \n \na      MAG      consistent      with      M       such      that      the      adjustment      set      is      W. We      show      the      algorithm      in      Alg."
            },
            {
              "id": 1908,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "[5}  \n \n  3\nAlgorithm      4:      PAGcauses Input:      PAG      P,      X,Y  \n \n  AS(P)      =0)      //      Record      all      the      valid      adjustment      sets;\n      if      X      ¢      PossAn(Y,      ?)      then      return      No      causal      effects;       if      the      conditions      in      Prop.\\\\\\\\4      Hare      satisfied      for      P      then       |      return      AS(P)      +      {D-SEP(X,      Y,      Px)}      //      Prop."
            },
            {
              "id": 1909,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "[4       4       5       6       7       8       9       10       11 for      each      setC      C{V      |      V      «0      X      in      P}      do       if      the      three      conditions      in      Prop. (dare      satisfied      then       Obtain      a      maximal      local      MAG      M      based      on      P      and      C;       Find      all      potential      adjustment      sets      W,,      W2,---      given      M      according      to      Def."
            },
            {
              "id": 1910,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "for      each      potential      adjustment      set      W;,      do       for      each      block      set      S      do       if      the      three      conditions      in      Prop."
            },
            {
              "id": 1911,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "2Jare      satisfied      given      S      then AS(P)      +      AS(P)      U      {Wi}: 12       13 break      //      Break      the      loop      of      S;       Output:      Set      of      causal      effects      via      adjustment      in      the      given      PAG      P      identified      with      AS(P)      by      (i)\nAlgorithm      5:      Orient   \n \na      maximal      local      MAG      of   \n \nX      as   \n \na      MAG  \n \n  input:      Maximal      local      MAG      M,      potential      adjustment      set      W      and      corresponding      W      according      to      Def."
            },
            {
              "id": 1912,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "2}      PI      block      set      S       1:      for      VK   \n \n€      PossDe(W,      M[—S])      and      VT   \n \n€      S      such      that   \n \nK      o~*   \n \nT      in      M,      orient      it      as   \n \nK      <+*T\\\\\\'      (the      mark      at   \n \nT      remains);  \n \n  2:      update      the      subgraph      M[PossDe(W,      M[—S])]      as      follows      until      no      feasible      updates:      for      any      two      vertices      V;      and      V;      such  \n \n  that      V;      0-0      V;,      orient      itas      V;   \n \n+      V;      if      (1)      Fy,      \\\\\\\\Fv;   \n \n#      or      (2)      Fy,   \n \n=      Fy,      as      well      as      there      is   \n \na      vertex  \n \n  V;,   \n \n€      PossDe(W,      M[—S})      not      adjacent      to      V;      such      that      V;,   \n \n>      V;      o-o      V;,      where      Fy,   \n \n=      {V   \n \n€      S|   \n \nV      +0      V;      in      M};  \n \n  3:      orient      the      circles      on      the      remaining      o—      edges      as      tails;  \n \n  4:      in      subgraph      M[PossDe(W,      M[—S])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders;  \n \n  5:      in      subgraph      M[—PossDe(W,      M[-S]])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders."
            },
            {
              "id": 1913,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "output:   \n \nA      MAG      M\n[I]  \n \n  Suppose      there      are      m      edges      and      d      vertices      in      H. There      are      m      edges      that      can      be      transformed. Hence      the      round      of      loop      is  \n \n  O(m). In      each      round,      suppose      we      want      to      detect      whether   \n \nA      o-*«   \n \nB      can      be      transformed      by      Ry2      or      R13."
            },
            {
              "id": 1914,
              "title": "A.3.      Preliminary      about      Causal      Effect      Estimation - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  Line   \n \n2      and      Line   \n \n3      is      O(d). And      determining      the      set      Anc(S      4,      H)      takes   \n \na      O(md)      complexity. Executing      Line   \n \n7      and      Line   \n \n9       take   \n \na      O(m)      complexity. And      the      complexity      of      Line   \n \n8      is      O(m). Hence      the      complexity      of      Alg. [lis      O(m?3),. roof"
            }
          ],
          "content": ""
        },
        {
          "id": 1915,
          "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P",
          "type": "section",
          "children": [
            {
              "id": 1916,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P\n \n{   \n \nX      }]      is      bridged      relative      to      C   \n \nU      {X}      in      P."
            },
            {
              "id": 1917,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "After      incorporating   \n \na      valid      local      transformation      into      the      PAG      ?,      [Wang      et      al.|(2023a)      used      the      sound      and      complete      orientation  \n \n  rules      Ry   \n \n—      R3,R4,Rz   \n \n—      Rio,      R11      to      further      update      the      graph. And      the      obtained      graph      is      called      by      maximal      local      MAG,  \n \n  denoted      by      M."
            },
            {
              "id": 1918,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "By      incorporating      different      valid      local      transformations,      PAGcauses      can      obtain      different      maximal      local      MAGs. However,      determining   \n \na      maximal      local      MAG      M      is      not      sufficient      for      determining      the      only      adjustment      set      in      all      the      MAGs  \n \n  consistent      with      MI."
            },
            {
              "id": 1919,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Hence,      they      established      the      graphical      characterization      for      the      adjustment      set      in      the      MAGs      consistent  \n \n  with      M      in      Prop. 2)and      Prop. {7}      Both      Prop. [2]and      Prop."
            },
            {
              "id": 1920,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "[/]ensure      that      PAGcauses      can      find      the      same      set      of      causal      effects      given  \n \n  M      as      methods      to      enumerate      all      the      MAGs      consistent      with      M. Proposition      7. Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y)."
            },
            {
              "id": 1921,
              "title": "(3)      P[PossDe(X,      P[—C])\\\\\\\\      {      X      }]      is      bridged      relative      to      C      U      {X}      in      P - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Let      W      be      D-SEP(X,      Y,      Mx). Then      W      is   \n \na      potential      adjustment      set      in      M      and      there      exists   \n \na      block set      S      such      that\n(1)      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9;\n(2)      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      V’      inM};"
            }
          ],
          "content": ""
        },
        {
          "id": 1922,
          "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M",
          "type": "section",
          "children": [
            {
              "id": 1923,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M\nM. With      the      results      above,      they      proposed      their      method      PAGcauses      in      Alg. A}  \n \n  In      the      proof      of      Prop."
            },
            {
              "id": 1924,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "|2}      if      the      three      conditions      are      satisfied,      they      present      an      algorithm      to      construct   \n \na      MAG      consistent      with      M       such      that      the      adjustment      set      is      W. We      show      the      algorithm      in      Alg."
            },
            {
              "id": 1925,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "[5}  \n \n  3\nAlgorithm      4:      PAGcauses Input:      PAG      P,      X,Y  \n \n  AS(P)      =0)      //      Record      all      the      valid      adjustment      sets;\n      if      X      ¢      PossAn(Y,      ?)      then      return      No      causal      effects;       if      the      conditions      in      Prop.\\\\\\\\4      Hare      satisfied      for      P      then       |      return      AS(P)      +      {D-SEP(X,      Y,      Px)}      //      Prop."
            },
            {
              "id": 1926,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "[4       4       5       6       7       8       9       10       11 for      each      setC      C{V      |      V      «0      X      in      P}      do       if      the      three      conditions      in      Prop. (dare      satisfied      then       Obtain      a      maximal      local      MAG      M      based      on      P      and      C;       Find      all      potential      adjustment      sets      W,,      W2,---      given      M      according      to      Def."
            },
            {
              "id": 1927,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "for      each      potential      adjustment      set      W;,      do       for      each      block      set      S      do       if      the      three      conditions      in      Prop."
            },
            {
              "id": 1928,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "2Jare      satisfied      given      S      then AS(P)      +      AS(P)      U      {Wi}: 12       13 break      //      Break      the      loop      of      S;       Output:      Set      of      causal      effects      via      adjustment      in      the      given      PAG      P      identified      with      AS(P)      by      (i)\nAlgorithm      5:      Orient   \n \na      maximal      local      MAG      of   \n \nX      as   \n \na      MAG  \n \n  input:      Maximal      local      MAG      M,      potential      adjustment      set      W      and      corresponding      W      according      to      Def."
            },
            {
              "id": 1929,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "2}      PI      block      set      S       1:      for      VK   \n \n€      PossDe(W,      M[—S])      and      VT   \n \n€      S      such      that   \n \nK      o~*   \n \nT      in      M,      orient      it      as   \n \nK      <+*T\\\\\\'      (the      mark      at   \n \nT      remains);  \n \n  2:      update      the      subgraph      M[PossDe(W,      M[—S])]      as      follows      until      no      feasible      updates:      for      any      two      vertices      V;      and      V;      such  \n \n  that      V;      0-0      V;,      orient      itas      V;   \n \n+      V;      if      (1)      Fy,      \\\\\\\\Fv;   \n \n#      or      (2)      Fy,   \n \n=      Fy,      as      well      as      there      is   \n \na      vertex  \n \n  V;,   \n \n€      PossDe(W,      M[—S})      not      adjacent      to      V;      such      that      V;,   \n \n>      V;      o-o      V;,      where      Fy,   \n \n=      {V   \n \n€      S|   \n \nV      +0      V;      in      M};  \n \n  3:      orient      the      circles      on      the      remaining      o—      edges      as      tails;  \n \n  4:      in      subgraph      M[PossDe(W,      M[—S])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders;  \n \n  5:      in      subgraph      M[—PossDe(W,      M[-S]])],      orient      the      circle      component      into   \n \na      DAG      without      new      unshielded      colliders."
            },
            {
              "id": 1930,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "output:   \n \nA      MAG      M\n[I]  \n \n  Suppose      there      are      m      edges      and      d      vertices      in      H. There      are      m      edges      that      can      be      transformed. Hence      the      round      of      loop      is  \n \n  O(m). In      each      round,      suppose      we      want      to      detect      whether   \n \nA      o-*«   \n \nB      can      be      transformed      by      Ry2      or      R13."
            },
            {
              "id": 1931,
              "title": "(3)      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "The      complexity      of  \n \n  Line   \n \n2      and      Line   \n \n3      is      O(d). And      determining      the      set      Anc(S      4,      H)      takes   \n \na      O(md)      complexity. Executing      Line   \n \n7      and      Line   \n \n9       take   \n \na      O(m)      complexity. And      the      complexity      of      Line   \n \n8      is      O(m). Hence      the      complexity      of      Alg. [lis      O(m?3),. roof"
            }
          ],
          "content": ""
        },
        {
          "id": 1932,
          "title": "D.1.      Proof      of      Proposition",
          "type": "section",
          "children": [
            {
              "id": 1933,
              "title": "D.1.      Proof      of      Proposition - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.1. Proof      of      Proposition"
            }
          ],
          "content": ""
        },
        {
          "id": 1934,
          "title": "C.      Complexity      Analysis      of      Algorithm      [I]",
          "type": "section",
          "children": [
            {
              "id": 1935,
              "title": "C.      Complexity      Analysis      of      Algorithm      [I] - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "C. Complexity      Analysis      of      Algorithm      [I]\n[I]"
            }
          ],
          "content": ""
        },
        {
          "id": 1936,
          "title": "D.      Proof",
          "type": "section",
          "children": [
            {
              "id": 1937,
              "title": "D.      Proof - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D. Proof\nroof\n \n \n  Then      we      prove      that      if      Alg. [I]      transforms      an      edge   \n \nA      o-*«   \n \nB      to   \n \nA      +*B      on      Line      9,      then      R42      can      be      triggered. Since      the      rigorous  \n \n  proof      is      somewhat      tedious,      we      just      show   \n \na      proof      sketch      here. If      Alg."
            },
            {
              "id": 1938,
              "title": "D.      Proof - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "[I]transforms      an      edge   \n \nA      o-   \n \nB      to   \n \nA      +*B      on      Line      9,  \n \n  then      there      is      an      unshielded      collider      formed      in      H’      on      Line      8. In      this      case,      according      to      the      proof      idea      of      Lemma   \n \n5      of      [Wang  \n \n  et      al.|(2023a)),      we      can      prove      that      H[D]      is      not      bridged      relative      to      S4."
            },
            {
              "id": 1939,
              "title": "D.      Proof - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Then,      we      will      prove      that      there      is      an      unbridged      path      in  \n \n  H[D|      relative      to      S      4. Suppose      there      is   \n \na      minimal      path      p   \n \n=      Vo      o-0---o-o      V,,41      in      H[D]      where      there      is      not   \n \na      vertex      V,      such      that      Fy,      C      Fy,      yO  \n \n  i<s—landfy,,,      C      Fy,,8      <i      <n."
            },
            {
              "id": 1940,
              "title": "D.      Proof - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "As      Line   \n \n9      is      triggered,      no      vertex      in      D      belongs      to      Anc(S.,      H). Hence      if      there      is  \n \n  some      vertex   \n \nV   \n \n¢      Fy,,   \n \nV      is      not      adjacent      to      V;. Next,      we      consider      the      path      p. We      discuss      whether      Fy,      \\\\\\\\Fv,   \n \n=      0. If      empty,      we  \n \n  consider      whether      Fy,      \\\\\\\\Fy,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1941,
              "title": "D.      Proof - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process      above      until      we      find      the      first      index   \n \nj      such      that      Fy,\\\\\\\\Fv,,,   \n \n4      9."
            },
            {
              "id": 1942,
              "title": "D.      Proof - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Note      such   \n \n7      must      exist,      for      otherwise,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +:   \n \n©      Fy,,,,      in      which      case      there      is      s   \n \n=      n+1  \n \n  such      that      Fy,   \n \n©      Fy,,,,0      <7      <s—land      fy,,,   \n \n©      Fy,,8      <7   \n \n<      n,      contradiction. Then,      we      consider      the      sub-path  \n \n  V;      0-0      ---      0-0      V4."
            },
            {
              "id": 1943,
              "title": "D.      Proof - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Note      according      to      the      process      above,      there      is      Fy,      C      Fy,      C      Fy,   \n \n©      +++   \n \n©      Fy,      and      Fy,      \\\\\\\\FVja1      #. Then,      we      consider      whether      Fy,      ,,\\\\\\\\Fv,,   \n \n=      9. If      empty,      we      consider      whether      Fy,      \\\\\\\\Fy,,_,   \n \n=   \n \n@      instead."
            },
            {
              "id": 1944,
              "title": "D.      Proof - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "We      repeat      the      process  \n \n  above      until      we      find      the      first      index   \n \n&      such      that      Fy,      \\\\\\\\Fy,_,   \n \n4      @. Similar      to      the      proof      above,      such      index   \n \nk      must      exist. And       there      is      Fy,      D2      Fy,,,      2---   \n \n2      Fv,,,      and      Fy,_,   \n \n#      0. Next      we      discuss      the      relationship      between   \n \nj      and      k."
            },
            {
              "id": 1945,
              "title": "D.      Proof - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove  \n \n  the      impossibility      of   \n \nk   \n \n<      j. Suppose   \n \nk   \n \n<      7."
            },
            {
              "id": 1946,
              "title": "D.      Proof - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      result      above,      there      is      Fy,      C      Fy,   \n \n©      Fy,   \n \n©      +++   \n \n©      Fy,      and       Fv,      »)      F      Views      Des      D      F      Vina      Hence,      there      is      Fy,      C      Fy,      C      Fy,      rae      Fy,   \n \n=      FV      nas      See   \n \n=      Fy,      DD      FVngt:      In  \n \n  this      case,      there      is      s   \n \n=   \n \n7      such      that      Fy,      C      Fy,,,,0      <i<s—Jland      Fy,,,      C      Fy,,8      <i      <n,      contradiction."
            },
            {
              "id": 1947,
              "title": "D.      Proof - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is  \n \n  k   \n \n>   \n \nj      +1. In      this      case,      there      is   \n \na      minimal      path      V;      0-0      Vj,      0-0      ---      o-o      Vj,      such      that      Fy,\\\\\\\\Fy,,,   \n \n#   \n \nO      and      Fy,\\\\\\\\Fy,_,      #0  \n \n  in      H[D]. It      is      an      unbridged      path      relative      to      S.4      in      H[D]."
            },
            {
              "id": 1948,
              "title": "D.      Proof - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "And      since      there      are      an      uncovered      possible      directed      paths      from   \n \nA      to      any      vertice      in      D      and      at      the      same      time   \n \nB      is      the      vertex  \n \n  adjacent      to   \n \nA      in      the      paths,      7212      can      be      triggered      to      transform   \n \nA      o-«   \n \nB      to   \n \nA      +*B. The      proof      completes. O\nD.2. Proof      of      Theorem[I]\nProof."
            },
            {
              "id": 1949,
              "title": "D.      Proof - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      the      soundness      of      7213,      then      prove      the      soundness      of      R12. For      R13,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B. It      is      evident      that      the      uncovered      path      is   \n \nA   \n \n>   \n \nB   \n \n>      --. —      K."
            },
            {
              "id": 1950,
              "title": "D.      Proof - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "According  \n \n  to      the      definition      of      S   \n \n,      and      the      conditions      in      713,      there      must      be   \n \na      vertex      C\\\\\\'   \n \n€      Sy      such      that      thereis      C+>      A—>---K      >---C,  \n \n  which      contradicts      with      the      ancestral      property,      contradiction. For      R12,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B."
            },
            {
              "id": 1951,
              "title": "D.      Proof - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      condition      of      R12,      it      is      evident      that      for      each      vertex  \n \n  K;,1      <4      <m,      there      is   \n \na      minimal      directed      path   \n \nA   \n \n>   \n \nB   \n \n>      ---   \n \n+      K;      in      M."
            },
            {
              "id": 1952,
              "title": "D.      Proof - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "And      for      any   \n \nT   \n \n€      S,4      and      K;j,1      <<i<m  \n \n  such      that      there      is      an      edge      between   \n \nT      and      K;      in      the      PMG      H,      there      must      be      Tx—      K;      in      M,      for      otherwise      there      is  \n \n  A>      B-.-.—      K;   \n \n~      T*>      A,      contradicting      with      ancestral      property. According      to      Def."
            },
            {
              "id": 1953,
              "title": "D.      Proof - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "[I]      there      is      an      unbridged      path  \n \n  p:      K,      0-0      Ky      0-0---o-0      K,,,      such      that      Fx,      \\\\\\\\Fr,      #0      and      Fr,,\\\\\\\\Fr,,_,      #0. Suppose      Cy   \n \n€      Fx,\\\\\\\\F      x,      and      C2   \n \n€      Fx,,\\\\\\\\Fx,,,_,-      If      Ci      is      adjacent      to      Ko,      as      Cy   \n \n¢      Fx,,      there      is      Ky   \n \n—      C,      in      H."
            },
            {
              "id": 1954,
              "title": "D.      Proof - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "In      this  \n \n  case      there      must      be   \n \nA      +«*B      according      to      R43,      the      soundness      of      which      has      been      proven. Thus   \n \nA   \n \n—   \n \nB      and      that      C{      is      adjacent  \n \n  to      K2      are      impossible. In      the      following,      we      consider      the      case      that      C\\\\\\';      is      not      adjacent      to      K2      and      C2      is      not      adjacent      to      K,,_}."
            },
            {
              "id": 1955,
              "title": "D.      Proof - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "We      have      shown      before      that      if      there      is      an      edge   \n \nA   \n \n>   \n \nB      in      M,      there      must      be      C)*>      Ky      and      C2*—>      K,,      in      M."
            },
            {
              "id": 1956,
              "title": "D.      Proof - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,  \n \n  no      matter      how      we      transform      the      circles      in      C,+—3      Ky      0-0      Ky      0-0      ---      0-0      K,,      <+Co,      there      will      be   \n \na      new      unshielded      collider  \n \n  in      M,      which      contradicts      with      the      fact      that      M      is      consistent      with      H. O\nD.3."
            },
            {
              "id": 1957,
              "title": "D.      Proof - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Theorem      [Z|\n \n \n  Proof      of      Theorem{2|      Note      the      graph      M      is      updated      in      every      round      of      Alg. 2]      To      distinguish      them,      we      use      M,      to      denote  \n \n  the      graph      obtained      after      Line   \n \n5      of      Alg. /2}in      the      7-th      round. Denote      M      the      original      maximal      local      MAG."
            },
            {
              "id": 1958,
              "title": "D.      Proof - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the  \n \n  whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      i,      Anc(Y,M;)   \n \n=      Anc(Y,M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nT      rounds      in      Alg."
            },
            {
              "id": 1959,
              "title": "D.      Proof - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge      A;      «+S;      is      transformed      by      Rj2      on      Line   \n \n6      of      Alg. [2](A;      just      denotes      any   \n \na      vertex),      and      thus  \n \n  Anc(5;,      M;)   \n \n9   \n \nT      is      incorporated      to      S      on      Line   \n \n7      of      Alg."
            },
            {
              "id": 1960,
              "title": "D.      Proof - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "Since      the      algorithm      returns   \n \na      set      of      vertices      S      after      T’      rounds,      according      to      Line      4,      6,      and   \n \n9      of      Alg."
            },
            {
              "id": 1961,
              "title": "D.      Proof - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "2}      we      conclude  \n \n  that      (1)      M7[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V\\\\\\'   \n \n©      S|V      o-*      VlorV      <#V’      in      Mr},      (2)  \n \n  PossDe(W,      Mr[—S])   \n \n7      Pa(S,      Mr)   \n \n=      @,      (3)      there      is      no      unbridged      path      relative      to      S      in      M7|PossDe(W,      Mr[—S])]."
            },
            {
              "id": 1962,
              "title": "D.      Proof - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  will      prove      that      the      three      conditions      in      Prop. 2Jare      satisfied      given      the      set      S,      thus      we      can      conclude      the      desired      result      by      Prop."
            },
            {
              "id": 1963,
              "title": "D.      Proof - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "[2\n(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}\n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      Vor   \n \nV      ¢*V’      in      M}. In  \n \n  the      process      of      Alg."
            },
            {
              "id": 1964,
              "title": "D.      Proof - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "2}      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads,      hence      M[Sy]   \n \n=      M,[Sy]      for      any   \n \nV   \n \n€      W. Hence      given      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W."
            },
            {
              "id": 1965,
              "title": "D.      Proof - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "(2)      We      will      prove      that      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      0. Suppose   \n \nA   \n \n=      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)."
            },
            {
              "id": 1966,
              "title": "D.      Proof - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Without      loss  \n \n  of      generality,      suppose      there      is   \n \nV   \n \n€      W      and   \n \na      minimal      possible      directed      path      p   \n \n=      (V,      Ji,---   \n \n,      Jz,      A)      from   \n \nV      to   \n \nA      in      M      such  \n \n  that      each      non-endpoint      in      p      does      not      belong      to      W      (If      there      is      V’   \n \n€      W      in      the      path      p,      we      consider      V’      instead      of   \n \nV      and      the  \n \n  sub-path      from      V’      to   \n \nA      instead      of      p)."
            },
            {
              "id": 1967,
              "title": "D.      Proof - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the      process      of      Alg.|2|      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads  \n \n  on      the      edges      connecting      W      and      S. Hence,      since      p      is      not   \n \na      minimal      possible      directed      path      in      My,      and      each      non-endpoint  \n \n  does      not      belong      to      W,      there      must      be      J,   \n \n€      S."
            },
            {
              "id": 1968,
              "title": "D.      Proof - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "However,      in      this      case      the      path      p      is      not      in      M[—S]      since      J,   \n \n€      S,      contradiction. Hence      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9. (3)      We      will      prove      that      there      is      no      unbridged      path      relative      to      S      in      M[PossDe(W,      M[-—S])}. Note      in      the      process      of      Alg."
            },
            {
              "id": 1969,
              "title": "D.      Proof - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "2|      we\n \n \n  only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads      on      the      edges      connecting      W      and      S."
            },
            {
              "id": 1970,
              "title": "D.      Proof - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      there      is      an      unbridged  \n \n  path      relative      to      S      in      M,      this      path      still      exists      in      Mr      since      each      vertex      in      this      path      cannot      belong      to      S,      which      concludes      that  \n \n  M-[PossDe(W,      Mr[—S])]      is      not      bridged      relative      to      S      in      Mr,      contradiction."
            },
            {
              "id": 1971,
              "title": "D.      Proof - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is      no      unbridged      path      relative      to      S       in      M[PossDe(W,      M[—S})],      that      is,      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M      according      to      Def. (o}      0\nD.4. Proof      of      Theorem      B]\n \n \n  The      proof      relied      on      some      results      by      {Wang      et      al.|      (2023a))."
            },
            {
              "id": 1972,
              "title": "D.      Proof - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "We      first      present      two      supporting      results      in      Lemma[I]and      Lemma]  \n \n  Lemma      [2]      implies      that      if      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in   \n \na      maximal      local      MAG      M,      then      we      can      find   \n \na       minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma   \n \n1      (Wang      et      al.|(2023a))."
            },
            {
              "id": 1973,
              "title": "D.      Proof - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      obtained      from   \n \na      PAG      P      and   \n \na      valid      local      transformation  \n \n  of   \n \nX      represented      by      C,      the      following      properties      are      satisfied:\n(Invariant)      The      arrowheads      and      tails      in      M      are      invariant      in      all      the      MAGs      consistent      with      P      and      the      local      transformation  \n \n  of   \n \nX      represented      by      C;\n(Chordal)      the      circle      component      in      M      is      chordal;\n \n \n  (Balanced)      for      any      three      vertices      A,      B,C      in      M,      if      Ax—   \n \nB      o-*      C,      then      there      is      an      edge      between   \n \nA      and      C      with      an  \n \n  arrowhead      at      C’,      namely,      Ax      C."
            },
            {
              "id": 1974,
              "title": "D.      Proof - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      the      edge      between   \n \nA      and   \n \nB      is   \n \nA   \n \n—      B,      then      the      edge      between   \n \nA      and       C      is      either   \n \nA      C      or      Ao      C      (i.e,      itis      not      A&C);\n(Complete)      for      each      circle      at      vertex   \n \nA      on      any      edge   \n \nA      o-*   \n \nB      in      M,      there      exist      MAGs      M,      and      Mg      consistent      with      M       with   \n \nA      +*B   \n \n€      E(M,)      and      A>      BE      E(Mg);\n(P6)      we      can      always      obtain   \n \na      MAG      consistent      with      P      and      the      local      transformation      of   \n \nX      represented      by      C,      by  \n \n  transforming      the      circle      component      into   \n \na      DAG      without      unshielded      colliders      and      transforming      Ao>      Bas   \n \nA   \n \n>      B."
            },
            {
              "id": 1975,
              "title": "D.      Proof - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "Lemma   \n \n2      (Wang      et      al.|      (2023a)). Consider   \n \na      maximal      local      MAG      MA. If      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in      M,  \n \n  then      there      is   \n \na      minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma      3."
            },
            {
              "id": 1976,
              "title": "D.      Proof - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y). Let      W      be      D-SEP(X,Y,      Mx)."
            },
            {
              "id": 1977,
              "title": "D.      Proof - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (Jo(= V),      Ji,-:+      ,Js(=      T)      from   \n \nV   \n \n€      W      to   \n \na      vertex   \n \nT      in      M,      where      each      non-endpoint      in      p      does      not      belong      to      W      UW. If  \n \n  T   \n \n€      Anc(Y,      M),      then      p      can      only      be      as      Jyo>      Jy   \n \n>      +++   \n \n+      J,      in      M."
            },
            {
              "id": 1978,
              "title": "D.      Proof - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "And      there      exists   \n \na      collider      path      X(=      Fo)   \n \n&      Fi   \n \n& »   \n \n>      Fi      <*V      in      M      with      edges      F;   \n \n>      J,,0<i<n-1. Proof. According      to      Def. there      exists   \n \na      collider      path   \n \nX      (=      Fo)   \n \n@      Fy      +++      Fy_y      +#V      in      M,      where      F),---   \n \n,      Fy-1   \n \n€ W."
            },
            {
              "id": 1979,
              "title": "D.      Proof - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "There      cannot      be      an      edge      F;      <+*J;      in      M      for      any   \n \n0      <2   \n \n<   \n \nt   \n \n—      1,      for      otherwise      J,   \n \n©      WU      W. Since   \n \nV      is      not      an      ancestor      of   \n \nY      in      M      and      p      is   \n \na      minimal      possible      directed      path,      there      must      be      Fy_;   \n \n©   \n \nV      <+*J,      in      M."
            },
            {
              "id": 1980,
              "title": "D.      Proof - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Hence      F;_,      is      adjacent      to      J;,      for      otherwise      there      is   \n \na      new      unshielded      collider      in      M      relative      to      M."
            },
            {
              "id": 1981,
              "title": "D.      Proof - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Since      (1)      for      each  \n \n  F;,0      <i<t-—1,      there      cannot      be      F;      <+*.J,      in      M,      and      (2)      the      balanced      property      is      fulfilled      in      M,      we      can      conclude      that  \n \n  there      is      there      is      F;   \n \n>      J,      or      Fjo3      Jy,V1      <1      <n-—1      and   \n \nX   \n \n—      Jj,      otherwise      there      is      always   \n \na      discriminating      path      for Lemma      4."
            },
            {
              "id": 1982,
              "title": "D.      Proof - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment      set  \n \n  relative      to      (X,Y). Let      W      be      D-SEP(X,      Y,      Mx). For      any      S      incorporated      into      the      set      of      vertices      S      in      the      process      of      Alg."
            },
            {
              "id": 1983,
              "title": "D.      Proof - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "2) (on      Line      7),      there      is      S   \n \n€      Anc(Y,      M). V\n \n   which      leads      to   \n \na      non-circle      mark      at   \n \nV      on      the      edge      between   \n \nV      and      J;      in      P. Due      to      Vx—      F,,_;   \n \n—      J;      in      M      and      the  \n \n  balanced      property      of      M,      there      is      Vo—      J;."
            },
            {
              "id": 1984,
              "title": "D.      Proof - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "Since      the      path      p      is   \n \na      minimal      possible      directed      path,      the      path      can      only      be      as  \n \n  Vo      J,      7-3      Is. CI\n \n \n  Proof. Note      the      graph      M      is      updated      in      every      round      of      Alg.|2|      To      distinguish      them,      we      use      M1;      to      denote      the      graph      obtained  \n \n  after      Line   \n \n5      of      Alg."
            },
            {
              "id": 1985,
              "title": "D.      Proof - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "/2|/in      the      i-th      round. Denote      M      the      original      maximal      local      MAG. Note      in      the      whole      process,      there      are      no       new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      S   \n \n€      W,      since      W   \n \n=      D-SEP(X,      Y,      Mx),      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)      and      S   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1986,
              "title": "D.      Proof - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "For      S   \n \n€      So      defined  \n \n  in      Def. |4}      according      to      Lemma[3}      since      $\\\\\\'      is      the      vertex      adjacent      to   \n \na      vertex   \n \nV   \n \n€      W      ina      minimal      possible      directed      path  \n \n  from   \n \nV      to   \n \na      vertex      in      Anc(Y,      M),      there      is      S   \n \n€      Anc(Y,M)."
            },
            {
              "id": 1987,
              "title": "D.      Proof - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      are   \n \nT      rounds      in      Alg.|2)      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge   \n \nA      ++5S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2      and      thus      Anc(S;,      M,)      N   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg.|2|      For      brevity,      denote   \n \nT   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg."
            },
            {
              "id": 1988,
              "title": "D.      Proof - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      S;   \n \n€      Anc(Y,M). Since      R12      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (K1,---   \n \n,      Km)      relative      to      So  \n \n  and      there      exists      an      uncovered      possible      directed      path      (V,      S,,---   \n \n,      Kj)      for   \n \n1   \n \n<   \n \n7   \n \n<      min      M),      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1989,
              "title": "D.      Proof - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is      C_      *-o      Ky      0-0      ---      0-0      Ky,      o-*«      Din      M,  \n \n  where      C   \n \n€      Fx,\\\\\\\\Fr,,D   \n \n©      Fr,,\\\\\\\\Fr,_,»      Fk;   \n \n=      {V   \n \n€      VW’   \n \n|   \n \nV      +0      Kj      or      Vx      K;      in      My}."
            },
            {
              "id": 1990,
              "title": "D.      Proof - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "Next      we      prove      there      is  \n \n  not      kK;   \n \n+      Cin      M,. Suppose      kK,   \n \n—      C      in      M,      for      contradiction. As      in      the      process      of      Alg. 2]      we      never      add   \n \na      tail,      there      is  \n \n  K,      €—>      CinM. In      this      case,      there      is   \n \na      directed      path      S;   \n \n>      ---   \n \n—      kK,   \n \n>      CinMandC   \n \n€      So      C      Anc(WU      {Y},M)."
            },
            {
              "id": 1991,
              "title": "D.      Proof - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "Hence      S$,   \n \n€      Anc(W   \n \nU      {Y},M). Since   \n \nV   \n \n€      W      is      adjacent      to      91,      9;      should      belong      to      So,      contradiction. Hence      there  \n \n  cannot      be      an      edge      Ky   \n \n>      Cin      My."
            },
            {
              "id": 1992,
              "title": "D.      Proof - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      F’;,1   \n \n<   \n \n7   \n \n<      m,      it      is      easy      to      prove      that      F’;      is      an      ancestor      of      either      C      or      D,  \n \n  for      otherwise      there      will      be      an      unshielded      collider      in      the      path      (C,      Ky,---   \n \n,      Km,      D)      in      M."
            },
            {
              "id": 1993,
              "title": "D.      Proof - Chunk 57",
              "type": "chunk",
              "children": [],
              "content": "And      since      C,      D   \n \n€      So,      and      C,      D       are      ancestors      of   \n \nY      in      M,      it      holds      C,      D   \n \n€      Anc(Y,M). And      since      there      is      Vo>      5;   \n \n—      ---   \n \n+      K,      in      M,      5;      is      an      ancestor      of  \n \n  Y      in      M. Thus      S;   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1994,
              "title": "D.      Proof - Chunk 58",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      all      the      vertices      in      Anc(.S,,      My)      M   \n \nT      are      ancestors      of      Y. Next      we      prove      the      induction      result. Suppose      in      the      first   \n \ni      round,      each      vertex      in      So,      Anc(S;,M),---   \n \n,      Anc(.S;,      M1)      is      an  \n \n  ancestor      of   \n \nY      in      M. We      will      prove      S;,1   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 1995,
              "title": "D.      Proof - Chunk 59",
              "type": "chunk",
              "children": [],
              "content": "Since      R49      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (7,---   \n \n,      T\\\\\\')      relative      to      Sp      UU,      <,<;(Ane(Sq,      Mi)      N      T)      and      there  \n \n  exists      an      uncovered      possible      directed      path      (V,      $;41,---      ,7;)      forl   \n \n<      s   \n \n<      f      in      M,,1      where   \n \nV   \n \n€      W."
            },
            {
              "id": 1996,
              "title": "D.      Proof - Chunk 60",
              "type": "chunk",
              "children": [],
              "content": "Without      loss      of  \n \n  generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is   \n \nJ      *-o      T;      o-o      ---      0-0      Ty      o-*   \n \nK      in      M;41,      where  \n \n  J   \n \n€      Fr,\\\\\\\\Fr,,   \n \nK   \n \n€      Fr;      \\\\\\\\Frj_1:      Next      we      prove      there      is      not      T;   \n \n—   \n \nJ      in      M;,,."
            },
            {
              "id": 1997,
              "title": "D.      Proof - Chunk 61",
              "type": "chunk",
              "children": [],
              "content": "Suppose      J;   \n \n—   \n \nJ      in      M      for      contradiction. Note      in      the      whole      process      of      Alg. 2}      we      never      add   \n \na      tail,      hence      there      is      T;      —>   \n \nJ      in      M. In      this      case,      there      is   \n \na      directed      path  \n \n  Sig1      3-1:   \n \n>      T,   \n \n>      JinMand   \n \nJ   \n \n€      So      UU      <g<;(Ane(Sq,      Mg)      OT)."
            },
            {
              "id": 1998,
              "title": "D.      Proof - Chunk 62",
              "type": "chunk",
              "children": [],
              "content": "If   \n \nJ   \n \n€      So,      then      S341   \n \n€      Anc(WU{Y},M),      Sizi  \n \n  should      belong      to      So,      contradiction. If      5,4;   \n \n€      Anc(S,,M,)   \n \n7      T,1      <q      <3,      then      S;,1      should      have      been      incorporated      into  \n \n  S      in      the      g-round      of      Alg.|2}      contradiction. Hence      there      cannot      be      an      edge      T;   \n \n>   \n \nJ      in      M41."
            },
            {
              "id": 1999,
              "title": "D.      Proof - Chunk 63",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      T,,1   \n \n<      s   \n \n<      f,      itis      an      ancestor      of      either   \n \nJ      or      K,      for      otherwise      there      will  \n \n  be      an      unshielded      collider      in      the      path      (J,T1,---      ,T,      A)      in      M."
            },
            {
              "id": 2000,
              "title": "D.      Proof - Chunk 64",
              "type": "chunk",
              "children": [],
              "content": "And      since      J,   \n \n€      So      UUy<<;(Ane(Sq,M,)   \n \n9      T),      and       J,   \n \nK      are      ancestors      of   \n \nY      in      M,      it      holds      J,      kK   \n \n€      Anc(Y,M). And      since      there      is      Vo>      S;4;   \n \n>      ---   \n \n>      T,      in      M,      $;4,      is      an  \n \n  ancestor      of      Y. Thus      S;41;   \n \n€      Anc(Y,M)."
            },
            {
              "id": 2001,
              "title": "D.      Proof - Chunk 65",
              "type": "chunk",
              "children": [],
              "content": "Hence      all      the      vertices      in      Anc(.$;41,      M41)      M   \n \nT      are      ancestors      of   \n \nY      in      M. By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M. O\nTheorem.B]      Prop. {/has      implied      that      W   \n \n=      D-SEP(X,      Y,      M.x)      is   \n \na      potential      adjustment      set."
            },
            {
              "id": 2002,
              "title": "D.      Proof - Chunk 66",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      that   \n \na      set      of vertices      S$      will      be      returned      by      Alg. Note      the      graph      M      is      updated      in      every      round      of      Alg."
            },
            {
              "id": 2003,
              "title": "D.      Proof - Chunk 67",
              "type": "chunk",
              "children": [],
              "content": "[2|      To      distinguish      them,      we      use      M|;      to      denote      the      graph      obtained      after  \n \n  Line   \n \n5      of      Alg.2|in      the      i-th      round,      use      S;      to      denote      the      set      of      vertices      obtained      after      Line   \n \n7      of      Alg. [2|in      the      i-th      round. Denote  \n \n  M      the      original      maximal      local      MAG. For      S   \n \n€      So      in      Def."
            },
            {
              "id": 2004,
              "title": "D.      Proof - Chunk 68",
              "type": "chunk",
              "children": [],
              "content": "4}      there      must      be   \n \nV      <*S      in      M      if      there      is   \n \nV      o-*      S      in      M. Hence      the  \n \n  arrowheads      introduced      in      the      first      round      of      Alg. 2]      must      exist      in      /. And      due      to      the      soundness      of      Ri2      by      Thm. [I]      all      the  \n \n  arrowheads      introduced      in      Alg. RJexist      in      M."
            },
            {
              "id": 2005,
              "title": "D.      Proof - Chunk 69",
              "type": "chunk",
              "children": [],
              "content": "In      the      whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nJ      rounds      in      Alg."
            },
            {
              "id": 2006,
              "title": "D.      Proof - Chunk 70",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<J-—1,anedge   \n \nA      +S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2}      and      thus      Anc(S;,      M;)      M   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg. 2}      Hence      there      is      evidently      S;,;   \n \n=      S;   \n \nU      (Anc($;41,Mi41)      NT),      forO      <i<      J—1."
            },
            {
              "id": 2007,
              "title": "D.      Proof - Chunk 71",
              "type": "chunk",
              "children": [],
              "content": "It      suffices      to      show      that      in      the      i-th      round   \n \n1   \n \n<   \n \ni   \n \n<      J,      there      is      (1)      PossDe(W,      M;;[—S,])      N      Pa(S;,      Mi)   \n \n=      0,      (2)      M;      [Sy]      is   \n \na       complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S;|V      o«      V’or   \n \nV      ¢*V’      in      Mj},      and      (3)      there      is      not      an      unbridged      path  \n \n  relative      to      S;      in      M;[PossDe(W,      M;[—S,])]."
            },
            {
              "id": 2008,
              "title": "D.      Proof - Chunk 72",
              "type": "chunk",
              "children": [],
              "content": "As      when      these      three      conditions      are      satisfied      in      each      round,      Alg.|2|could      output a\n \n   set      of      vertices. Suppose      in      the   \n \n2      round,      the      algorithm      output      “No”. According      to      Alg.|2}      at      least      one      of      the      three      conditions  \n \n  is      violated."
            },
            {
              "id": 2009,
              "title": "D.      Proof - Chunk 73",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      the      impossibility      of      the      violations      of      the      three      conditions      in      the      following."
            },
            {
              "id": 2010,
              "title": "D.      Proof - Chunk 74",
              "type": "chunk",
              "children": [],
              "content": "If      PossDe(W,      M;[—S;])  \n \n  Pa(S;,M;)   \n \n4      T,      suppose      there      is   \n \na      minimal      possible      directed      path      p      from   \n \nV   \n \n€      W      to   \n \nT      in  \n \n  M;[—S,]      such      that      each      non-endpoint      does      not      belong      to      W,      and      there      is      an      edge   \n \nT   \n \n+      S      in      M;      for      S   \n \n€      S;. Hence  \n \n  T   \n \n€      Anc(S,M;)."
            },
            {
              "id": 2011,
              "title": "D.      Proof - Chunk 75",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma}      p      is      Vo>—      --. +   \n \nT      in      M. In      this      case,      if      S   \n \n€      So,      according      to      Def. 4]      and       Lemmaj}}      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)."
            },
            {
              "id": 2012,
              "title": "D.      Proof - Chunk 76",
              "type": "chunk",
              "children": [],
              "content": "Thus   \n \nT   \n \n€      Anc(W   \n \nU      {Y},      M),      which      implies      that      there      is   \n \na      minimal      possible  \n \n  directed      path      p\\\\\\'      from   \n \nV   \n \n€      W      to   \n \nT   \n \n€      Anc(W   \n \nU      {Y},M)      such      that      p’      is   \n \na      sub-path      of      p. However,      according      to      Def."
            },
            {
              "id": 2013,
              "title": "D.      Proof - Chunk 77",
              "type": "chunk",
              "children": [],
              "content": "in      the      case      above,      the      vertex      adjacent      to   \n \nV      in      p’      should      belong      to      So,      contradicting      with      the      fact      that      the      path      p      is      in  \n \n  M,[—S,]. If      S;      is      incorporated      into      S      in      Alg."
            },
            {
              "id": 2014,
              "title": "D.      Proof - Chunk 78",
              "type": "chunk",
              "children": [],
              "content": "Qin      the      7,7   \n \n<   \n \n7      round,      since      there      is   \n \nT   \n \n€      Anc(S,M),   \n \nT      should      belong      to  \n \n  S541,S;+42,:--      ,8;,      contradicting      with      the      fact      that      the      path      p      is      in      M;|—S,]. Hence      there      is      always   \n \na      contradiction      if      there  \n \n  is      PossDe(W,      M;;[—S;])      M      Pa(S;,M;)   \n \n4      0."
            },
            {
              "id": 2015,
              "title": "D.      Proof - Chunk 79",
              "type": "chunk",
              "children": [],
              "content": "Since      W   \n \n=      D-SEP(X,      Y,      Mx),      for      any   \n \nV   \n \n€      W,   \n \nV      is      not      an      ancestor      of   \n \nY      in      M. If      M,[Sy]      is      not   \n \na      complete      graph for      some   \n \nV   \n \n€      W,      there      must      be      an      edge   \n \nV   \n \n>      Sin      M,      for      otherwise      there      will      be      new      unshielded      collider      at      V."
            },
            {
              "id": 2016,
              "title": "D.      Proof - Chunk 80",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  Lemma}      S      is      an      ancestor      of      Y. Thus   \n \nV      is      an      ancestor      of      Y,      thus   \n \nV   \n \n€      WW,      contradicting      with      W   \n \n9      W   \n \n=      9. Finally,      we      prove      that      there      is      not      an      unbridged      path      relative      to      S;      in      M;[PossDe(W,M,[—S,])]."
            },
            {
              "id": 2017,
              "title": "D.      Proof - Chunk 81",
              "type": "chunk",
              "children": [],
              "content": "Suppose  \n \n  M;{[PossDe(W,      M[—S,])]      is      not      bridged      relative      to      S;      in      M. Since      M;[PossDe(W,M,{—S;])]      is      not      bridged      relative  \n \n  to      S;      in      M;,      without      loss      of      generality,      suppose      an      unbridged      path      Ky,      o—o      ---      o—o      K,,,      relative      to      S;,      and      there      is  \n \n  AE      W."
            },
            {
              "id": 2018,
              "title": "D.      Proof - Chunk 82",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma      4}      all      the      vertices      in      S;      are      ancestors      of   \n \nY      in      M. At      first,      we      prove      Ky,---   \n \n,      Ky      are  \n \n  ancestors      of   \n \nY      in      M."
            },
            {
              "id": 2019,
              "title": "D.      Proof - Chunk 83",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      vertices      S),.S_   \n \n€      S;      such      that      S$;   \n \n€      Fx,      \\\\\\\\Fr,      and      Sy   \n \n€      Fr,,\\\\\\\\Fr      where  \n \n  Fy      ={V\\\\\\'      €S,|V      o*      V’      or   \n \nV      «V’      in      M;}      as      Def. [I] m—1? If      S   \n \n€      So,      according      to      Def."
            },
            {
              "id": 2020,
              "title": "D.      Proof - Chunk 84",
              "type": "chunk",
              "children": [],
              "content": "|4}      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (V’,S,---      ,T)      from      V’   \n \n€      WtoT   \n \n€       Anc(W   \n \nU      {Y},M)      where      each      non-endpoint      does      not      belong      to      W      in      M;. According      to      Def. |2}      there      exists   \n \na      collider      path X\n \n   OF      O---&      Fy_   \n \n1      <V’      where      F\\\\\\\\,---   \n \n,      F;_1   \n \n€      W."
            },
            {
              "id": 2021,
              "title": "D.      Proof - Chunk 85",
              "type": "chunk",
              "children": [],
              "content": "And      according      to      the      result      (2)      above,      M;|Sy-]      is   \n \na      complete  \n \n  graph. Hence      F;_,      is      adjacent      to      S. In      this      case      if      there      is      an      edge      F;_;      «+S      in      Mj,      there      is      F;_;      «+S      in      M,      thus      there  \n \n  is      S   \n \n€      WUW. And      due      to      S   \n \n¢      W,      there      is      S   \n \n€      W."
            },
            {
              "id": 2022,
              "title": "D.      Proof - Chunk 86",
              "type": "chunk",
              "children": [],
              "content": "And      if      there      is      an      edge      F,_      o-*      S      or      F;_1   \n \n>      S\\\\\\'      in      Mj,      there      is\n \n \n  F,_,      o*      S      or      Fy_;   \n \n—      S      in      M,      there      must      be      Vo  \n \n  S      in      M."
            },
            {
              "id": 2023,
              "title": "D.      Proof - Chunk 87",
              "type": "chunk",
              "children": [],
              "content": "Due      the      p      is   \n \na      minimal      possible      directed      path      in      Mj,      p      is      also   \n \na       minimal      possible      directed      path      in      M,      pis      V’o>      S   \n \n>      ---   \n \n>      Tin      M,      thus      S   \n \n€      Anc(W   \n \nU      {Y},      M)."
            },
            {
              "id": 2024,
              "title": "D.      Proof - Chunk 88",
              "type": "chunk",
              "children": [],
              "content": "Hence,      no      matter      what  \n \n  the      edge      is      between      S      and      F;_1,      there      is      S   \n \n€      Anc(W   \n \nU      {Y},      M). In      this      case,      if      there      is      kK;   \n \n—      5S      in      M,      there      is      kK;   \n \n€      So  \n \n  due      to      S\\\\\\'   \n \n€      So,      contradicting      with      K;   \n \n€      PossDe(W,      M;[-S,])."
            },
            {
              "id": 2025,
              "title": "D.      Proof - Chunk 89",
              "type": "chunk",
              "children": [],
              "content": "If      S      is      incorporated      into      S      in      the      j,   \n \n7   \n \n<   \n \ni      round      on      Line   \n \n7      of  \n \n  Alg. [2|   \n \nK      is      also      incorporated      into      S      in      this      round      due      to   \n \nK   \n \n€      Anc(S,M),      contradicting      with      K;   \n \n€      PossDe(W,      M;[—S;]). Hence      for      any      K;,1      <j   \n \n<      mand      5S   \n \n€      §,      in      the      process      of      Alg."
            },
            {
              "id": 2026,
              "title": "D.      Proof - Chunk 90",
              "type": "chunk",
              "children": [],
              "content": "(2)      there      cannot      be      an      edge      S   \n \n+      K;. Hence,      consider      the      uncovered      path      py   \n \n=      ($1,      Ky,      Ko,--+   \n \n,      Km,      S2)      in      M;      where      the      sub-path      from      K,      to      K,,,      is   \n \na      circle  \n \n  path."
            },
            {
              "id": 2027,
              "title": "D.      Proof - Chunk 91",
              "type": "chunk",
              "children": [],
              "content": "Note      the      non-circle      marks      in      M;      also      exist      in      M      due      to      the      soundness      of   \n \nR   \n \n2      according      to      Thm. {i}      Since      M      cannot have      new      unshielded      colliders      relative      to      M;,      there      is      each      vertex      in      K,,      K2,---   \n \n,      Km      is      an      ancestor      of      either      S;      or      So      in M."
            },
            {
              "id": 2028,
              "title": "D.      Proof - Chunk 92",
              "type": "chunk",
              "children": [],
              "content": "Since      S;      and      S2      are      ancestors      of   \n \nY      according      to      Lemma      any      vertex      in      K,,---   \n \n,      Kj,      are      ancestors      of   \n \nY      in      M. Note      in      the      process      of      Alg."
            },
            {
              "id": 2029,
              "title": "D.      Proof - Chunk 93",
              "type": "chunk",
              "children": [],
              "content": "2)      we      only      add      arrowheads      at      W,      which      are      not      ancestors      of   \n \nY      in      M,      hence      we      will  \n \n  never      introduce      any      arrowheads      at      K;,V1   \n \n<   \n \nj   \n \n<      min      Alg."
            },
            {
              "id": 2030,
              "title": "D.      Proof - Chunk 94",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence      in      M;,      the      uncovered      path      p,      is      in      the      form      of S,      #0      Ky      0-0:      ++      0-0      Ky,      o-*      So,      that      is,      there      cannot      be      S$;   \n \n>      Ky,      or      Ky,      <*S>      in      M;."
            },
            {
              "id": 2031,
              "title": "D.      Proof - Chunk 95",
              "type": "chunk",
              "children": [],
              "content": "Next,      for      any      K;,1   \n \n<   \n \n7   \n \n<      _m,      consider      the      minimal      possible      directed      path      p   \n \n=      (A,      Bj,  \n \n  K      A)      from   \n \nA      to      K;. Note      we  \n \n  use      notation   \n \nB      to      denote      the      vertex      adjacent      to   \n \nA      in      the      minimal      possible      directed      path      from   \n \nA      to      K;,1      <7      <m."
            },
            {
              "id": 2032,
              "title": "D.      Proof - Chunk 96",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      we      suppose      each      non-endpoint      in      p      does      not      belong      to      W,      since      if      there      is      another      vertex      A’   \n \n€      W      in      p,  \n \n  we      can      consider      A’      instead      of      A,      it      is      evidently      that      K1,---   \n \n,      Ky,      are      possible      descendants      of      A’      as      well      since      there      is   \n \na       minimal      possible      directed      path      from      A’      to      A;      and      there      are      circle      paths      from      KX;      to      each      vertex      in      Ky,---   \n \n,      Km."
            },
            {
              "id": 2033,
              "title": "D.      Proof - Chunk 97",
              "type": "chunk",
              "children": [],
              "content": "Note      it      is      possible      that      there      are      many      minimal      possible      directed      paths      from   \n \nA      to      K;."
            },
            {
              "id": 2034,
              "title": "D.      Proof - Chunk 98",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      prove      that      for      any  \n \n  B;,B;,1<i<   \n \nJ      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;,      and      B;      is      adjacent      to      each  \n \n  vertex      in      S      in      M. Suppose      B;      is      not      adjacent      to      B;      or      S   \n \n€      S      in      M."
            },
            {
              "id": 2035,
              "title": "D.      Proof - Chunk 99",
              "type": "chunk",
              "children": [],
              "content": "Since      S      is      an      ancestor      of   \n \nY      in      any      MAG      M      consistent  \n \n  with      M      such      that      W   \n \n=      D-SEP(X,Y,      Mx),      and   \n \nA   \n \n€      W,      there      is   \n \nA      +*S      in      M. Since      there      is      not   \n \nA      +*B;      or   \n \nA      *B;      in  \n \n  M,      there      is      either   \n \nA   \n \n+      B;      or   \n \nA   \n \n>      B;      in      M."
            },
            {
              "id": 2036,
              "title": "D.      Proof - Chunk 100",
              "type": "chunk",
              "children": [],
              "content": "And      since      B;      and      B;      are      located      at      minimal      possible      directed      paths      from   \n \nA       to      K;      and      K;,      respectively,      there      must      be   \n \nA   \n \n€      Anc(.A;,      M)      or   \n \nA   \n \n€      Anc(;,      M)."
            },
            {
              "id": 2037,
              "title": "D.      Proof - Chunk 101",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      that      K;,.K;      are  \n \n  ancestors      of   \n \nY      in      M,   \n \nA      is      an      ancestors      of   \n \nY      in      M,      in      which      case      there      is   \n \nA   \n \n©      WNW,      contradicting      with      WM      W      =Oin  \n \n  Def."
            },
            {
              "id": 2038,
              "title": "D.      Proof - Chunk 102",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence,      for      any      B;,B;,1      <7   \n \n<   \n \n7      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;, and      B;      is      adjacent      to      each      vertex      in      S      in      M. Next,      we      prove      that      for      any   \n \n1   \n \n<   \n \nj   \n \n<      m,      there      is      not      B;   \n \n=      K,."
            },
            {
              "id": 2039,
              "title": "D.      Proof - Chunk 103",
              "type": "chunk",
              "children": [],
              "content": "That      is,      the      minimal      possible      directed      path      from   \n \nA      to  \n \n  kK;      cannot      be   \n \nA      o—*      Kk;      in      M;. Suppose      there      is   \n \nA      o-*      A’;      in      M;. According      to      the      result      above,      for      any      S   \n \n€      S,      K;      is  \n \n  adjacent      to      S."
            },
            {
              "id": 2040,
              "title": "D.      Proof - Chunk 104",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,      there      must      be      m   \n \n>      3,      for      otherwise      if      the      unbridged      path      is      just      Ky      o-o      K2,      suppose   \n \nj   \n \n=      1,  \n \n  then      there      must      be      Fx,      D      Fxx,,      contradicting      with      the      definition      of      unbridged      path      in      Def."
            },
            {
              "id": 2041,
              "title": "D.      Proof - Chunk 105",
              "type": "chunk",
              "children": [],
              "content": "[I]      We      consider      the      circle  \n \n  path      kK;      o-      Kj4,0~©---co-0      K,,      inM      (If   \n \n7      =>      m   \n \n—      1,      then      we      consider      the      circle      path      Ky      o-0      ---      K;      instead. And      it  \n \n  is      impossible      that      m   \n \n=   \n \n3      and   \n \nj   \n \n=      2,      for      otherwise      the      path      cannot      be      unbridged). There      is      Sy   \n \n€      Fx,,\\\\\\\\Fx,,_,."
            },
            {
              "id": 2042,
              "title": "D.      Proof - Chunk 106",
              "type": "chunk",
              "children": [],
              "content": "Since  \n \n  there      cannot      be      an      edge      K,,-1   \n \n—      52      in      M;      and      M,      which      we      have      proven      before,      and      S2   \n \n€      Fx,,      \\\\\\\\Fx,,_,,      52      cannot      be  \n \n  adjacent      to      K,,-1."
            },
            {
              "id": 2043,
              "title": "D.      Proof - Chunk 107",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      can      conclude      that      K,,,_2      is      not      adjacent      to      S2,      for      otherwise      in      the      substructure      comprised      of  \n \n  Km—2,      Km—1,      Km,      S2,      there      must      be      K,,   \n \n>      Sg   \n \n+      K,,—2      oriented      by      Rg      in      P,      which      leads      to      K,,-2   \n \n>      Sin      M      and      M,,  \n \n  contradiction."
            },
            {
              "id": 2044,
              "title": "D.      Proof - Chunk 108",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      conclude      that      no      vertices      in      K;,      Kj41,---   \n \n,      Km      is      adjacent      to      S. However,      we      have      proven  \n \n  that      K;      is      adjacent      to      S,      contradiction. Hence,      for      any      B;,1      <j      <_m,      Bj   \n \n4      K;."
            },
            {
              "id": 2045,
              "title": "D.      Proof - Chunk 109",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      will      prove      that      for      any      B;,1   \n \n<   \n \nj   \n \n<      m,      B;      is      also      in      the      minimal      possible      directed      path      from   \n \nA      to      Kj,  \n \n  where   \n \n1   \n \n<   \n \ni   \n \n<      mandi   \n \n¥      j. Without      loss      of      generality,      suppose   \n \n7   \n \n>      7."
            },
            {
              "id": 2046,
              "title": "D.      Proof - Chunk 110",
              "type": "chunk",
              "children": [],
              "content": "Consider      the      minimal      possible      directed      path  \n \n  (A,      By41,-+-   \n \n,      541)      from   \n \nA      to      Kj+41      in      M. We      will      prove      that      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible  \n \n  directed      path      from   \n \nA      to      Kj+1. If      Bj,      and      B;      denote      the      same      vertex,      the      result      evidently      holds."
            },
            {
              "id": 2047,
              "title": "D.      Proof - Chunk 111",
              "type": "chunk",
              "children": [],
              "content": "We      just      consider      the      case  \n \n  Bj41   \n \n4      B;. We      have      proven      that      B;      is      adjacent      to      B;+1      before. Note      each      vertex      in      Ky,---   \n \n,      Ky,      is      an      ancestor      of   \n \nY      in      M. According      to      Lemma      3}      there      must      be      p)   \n \n=      Ao      B;   \n \n>       -++      —>      Kj      and      po   \n \n=      Ao      By,   \n \n—      ---   \n \n—      Kj41."
            },
            {
              "id": 2048,
              "title": "D.      Proof - Chunk 112",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      Kj;   \n \n#      Bj,      above,   \n \nA      cannot      be      adjacent      to  \n \n  Kj+41,      for      otherwise      p      is      not   \n \na      minimal      possible      directed      path."
            },
            {
              "id": 2049,
              "title": "D.      Proof - Chunk 113",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      adjacent      to      Kj;      in      M,      it      is      evident      that      there      is   \n \na       minimal      possible      directed      path      (A,      B;,      Kj+1),      thus      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path  \n \n  from   \n \nA      to      K;41."
            },
            {
              "id": 2050,
              "title": "D.      Proof - Chunk 114",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      not      adjacent      to      K;+1,      due      to      the      possible      directed      path      B;   \n \n>      ---   \n \n>      K,;      o-0      Kj,      in      Mj,      the  \n \n  corresponding      path      in      M      is      also   \n \na      possible      directed      path,      there      must      be   \n \na      minimal      possible      directed      path      p’      from      B;      to      Kj41  \n \n  in      M      according      to      Lemma|2}      and      thus      the      corresponding      path      of      p’      in      M;      must      be      also   \n \na      minimal      possible      directed      path      since  \n \n  in      Alg."
            },
            {
              "id": 2051,
              "title": "D.      Proof - Chunk 115",
              "type": "chunk",
              "children": [],
              "content": "2|      we      only      transform      some      edge   \n \nV      o-*      S      to   \n \nV      <*S\\\\\\'      for   \n \nV   \n \n€      W      and      S   \n \n€      S;,      while      each      vertex      in      p’      does      not      belong  \n \n  to      S      since      it      is      in      M;[—S,]."
            },
            {
              "id": 2052,
              "title": "D.      Proof - Chunk 116",
              "type": "chunk",
              "children": [],
              "content": "And   \n \nA      is      not      adjacent      to      any      non-endpoint      in      p’      since      Ao      B;   \n \n>      ---   \n \n>      K;      is   \n \na      minimal  \n \n  possible      directed      path      and   \n \nA      is      not      adjacent      to      K;41."
            },
            {
              "id": 2053,
              "title": "D.      Proof - Chunk 117",
              "type": "chunk",
              "children": [],
              "content": "Hence,      we      have   \n \na      new      minimal      possible      directed      path      Ao>      B;      Op’,  \n \n  where      B,      is      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      A’;+1."
            },
            {
              "id": 2054,
              "title": "D.      Proof - Chunk 118",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      prove      that      B;      is  \n \n  also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      Kj42."
            },
            {
              "id": 2055,
              "title": "D.      Proof - Chunk 119",
              "type": "chunk",
              "children": [],
              "content": "Repeat      the      process,      we      can      prove      that      B;  \n \n  is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      K;,      for      any   \n \n1      <i   \n \n<      mandi      F      7."
            },
            {
              "id": 2056,
              "title": "D.      Proof - Chunk 120",
              "type": "chunk",
              "children": [],
              "content": "Till      now,      we      have      proven      that      there      exists   \n \na      minimal      possible      directed      path      from   \n \nA      to      each      vertex      in      Ky,---   \n \n,      Ky,      such      that  \n \n  B;      is      the      common      vertex      adjacent      to   \n \nA      in      all      paths. And      it      is      evidently      that      the      minimal      possible      directed      path      is      an      uncovered  \n \n  path."
            },
            {
              "id": 2057,
              "title": "D.      Proof - Chunk 121",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      B;   \n \n¢      S;,      the      edge   \n \nA      o-«      B;      should      be      transformed      by      R42      in      M;      on      Line   \n \n6      of      Alg. [2|      thus      the      algorithm      will enter the next loop, contradiction. Hence there is not an unbridged path relative to S; in M;[PossDe(W, M;[—S,])] O\nD.5. Proof      of      Proposition\nProof. We      prove      it      by      mathematical      induction."
            },
            {
              "id": 2058,
              "title": "D.      Proof - Chunk 122",
              "type": "chunk",
              "children": [],
              "content": "For      each   \n \nV   \n \n€      DD-SEP(X,      Y,      MLx      ),      we      consider      the      minimal      collider      path  \n \n  satisfying      the      three      conditions      of      Definition   \n \n|      in      M. If      the      length      is      1,      there      is   \n \nX      <-*V      in      My      since      there      cannot      be   \n \nX      -«V  \n \n  in      Mx      according      to      the      definition      of      Mx."
            },
            {
              "id": 2059,
              "title": "D.      Proof - Chunk 123",
              "type": "chunk",
              "children": [],
              "content": "If      there      is   \n \nV   \n \n¢      Anc(Y,      M),      it      trivially      concludes      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)  \n \n  according      to      the      definition. If      M[Qy]      is      not   \n \na      complete      graph,      evidently      there      are      at      least      two      vertices      in      Oy. Suppose  \n \n  S1,S2   \n \n€      Oy      are      not      adjacent."
            },
            {
              "id": 2060,
              "title": "D.      Proof - Chunk 124",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      there      is      either   \n \nV   \n \n>      5S;      or   \n \nV   \n \n—      S      in      M,      otherwise      there      is   \n \na      new      unshielded  \n \n  collider      in      M      relative      to      M      and      P,      which      contradicts      with      that      M      is      consistent      with      MI."
            },
            {
              "id": 2061,
              "title": "D.      Proof - Chunk 125",
              "type": "chunk",
              "children": [],
              "content": "Thus      there      is      also   \n \nV   \n \n€      Anc(Y,      M)  \n \n  such      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Hence      if      the      length      is      1,      there      is   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Suppose      the      result      holds  \n \n  when      the      length      of      the      minimal      collider      path      mentioned      above      is      k."
            },
            {
              "id": 2062,
              "title": "D.      Proof - Chunk 126",
              "type": "chunk",
              "children": [],
              "content": "For      the      vertex   \n \nV      with   \n \na      minimal      collider      path      satisfying  \n \n  the      three      conditions      of      Definition      [5]      whose      length      is   \n \nk   \n \n+      1,      suppose      the      path      is      comprised      of      X,V;,V2,-+-      ,Ve41. We  \n \n  have      Vi,      V2,---   \n \n,      Ve   \n \n€      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 2063,
              "title": "D.      Proof - Chunk 127",
              "type": "chunk",
              "children": [],
              "content": "For      Vi.41,      similar      to      the      proof      above,      no      matter      whether      V.+1   \n \n€      Anc(Y,      M) or      M[Qy,.,,]      is      not   \n \na      complete      graph,      there      is      always      Vii   \n \n€      Anc(Y,M),      thus      V4;   \n \n€      D-SEP(X,Y,      M4)      due      to      the collider      path      where      each      non-endpoint      belongs      to      D-SEP(X,      Y,      Mx). O\nD.6."
            },
            {
              "id": 2064,
              "title": "D.      Proof - Chunk 128",
              "type": "chunk",
              "children": [],
              "content": "Proof      of      Corollary      {I|\nProof. The      proof      follows      Thm. 4      of|Wang      et      al! (2023a)      based      on      Thm. 2]      and      Thm. 3}      Thm. 2)and      Thm. 3)can      ensure      that  \n \n  by      using      Alg."
            },
            {
              "id": 2065,
              "title": "D.      Proof - Chunk 129",
              "type": "chunk",
              "children": [],
              "content": "2]      for      each      potential      adjustment      set,      we      can      find      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the  \n \n  MAGs      consistent      with      M."
            },
            {
              "id": 2066,
              "title": "D.      Proof - Chunk 130",
              "type": "chunk",
              "children": [],
              "content": "And      since      in      PAGrules,      all      possible      local      transformation      are      considered      on      Line      5,      PAGrules      can  \n \n  return      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the      MAGs      consistent      with      P. C"
            }
          ],
          "content": ""
        },
        {
          "id": 2067,
          "title": "D.2.      Proof      of      Theorem[I]",
          "type": "section",
          "children": [
            {
              "id": 2068,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.2. Proof      of      Theorem[I]\nProof. We      first      prove      the      soundness      of      7213,      then      prove      the      soundness      of      R12. For      R13,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B. It      is      evident      that      the      uncovered      path      is   \n \nA   \n \n>   \n \nB   \n \n>      --. —      K."
            },
            {
              "id": 2069,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "According  \n \n  to      the      definition      of      S   \n \n,      and      the      conditions      in      713,      there      must      be   \n \na      vertex      C\\\\\\'   \n \n€      Sy      such      that      thereis      C+>      A—>---K      >---C,  \n \n  which      contradicts      with      the      ancestral      property,      contradiction. For      R12,      suppose      there      is      an      MAG      M      with   \n \nA   \n \n—      B."
            },
            {
              "id": 2070,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "According      to      the      condition      of      R12,      it      is      evident      that      for      each      vertex  \n \n  K;,1      <4      <m,      there      is   \n \na      minimal      directed      path   \n \nA   \n \n>   \n \nB   \n \n>      ---   \n \n+      K;      in      M."
            },
            {
              "id": 2071,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "And      for      any   \n \nT   \n \n€      S,4      and      K;j,1      <<i<m  \n \n  such      that      there      is      an      edge      between   \n \nT      and      K;      in      the      PMG      H,      there      must      be      Tx—      K;      in      M,      for      otherwise      there      is  \n \n  A>      B-.-.—      K;   \n \n~      T*>      A,      contradicting      with      ancestral      property. According      to      Def."
            },
            {
              "id": 2072,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "[I]      there      is      an      unbridged      path  \n \n  p:      K,      0-0      Ky      0-0---o-0      K,,,      such      that      Fx,      \\\\\\\\Fr,      #0      and      Fr,,\\\\\\\\Fr,,_,      #0. Suppose      Cy   \n \n€      Fx,\\\\\\\\F      x,      and      C2   \n \n€      Fx,,\\\\\\\\Fx,,,_,-      If      Ci      is      adjacent      to      Ko,      as      Cy   \n \n¢      Fx,,      there      is      Ky   \n \n—      C,      in      H."
            },
            {
              "id": 2073,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "In      this  \n \n  case      there      must      be   \n \nA      +«*B      according      to      R43,      the      soundness      of      which      has      been      proven. Thus   \n \nA   \n \n—   \n \nB      and      that      C{      is      adjacent  \n \n  to      K2      are      impossible. In      the      following,      we      consider      the      case      that      C\\\\\\';      is      not      adjacent      to      K2      and      C2      is      not      adjacent      to      K,,_}."
            },
            {
              "id": 2074,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "We      have      shown      before      that      if      there      is      an      edge   \n \nA   \n \n>   \n \nB      in      M,      there      must      be      C)*>      Ky      and      C2*—>      K,,      in      M."
            },
            {
              "id": 2075,
              "title": "D.2.      Proof      of      Theorem[I] - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,  \n \n  no      matter      how      we      transform      the      circles      in      C,+—3      Ky      0-0      Ky      0-0      ---      0-0      K,,      <+Co,      there      will      be   \n \na      new      unshielded      collider  \n \n  in      M,      which      contradicts      with      the      fact      that      M      is      consistent      with      H. O"
            }
          ],
          "content": ""
        },
        {
          "id": 2076,
          "title": "D.3.      Proof      of      Theorem      [Z|",
          "type": "section",
          "children": [
            {
              "id": 2077,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.3. Proof      of      Theorem      [Z|\n \n \n  Proof      of      Theorem{2|      Note      the      graph      M      is      updated      in      every      round      of      Alg. 2]      To      distinguish      them,      we      use      M,      to      denote  \n \n  the      graph      obtained      after      Line   \n \n5      of      Alg. /2}in      the      7-th      round. Denote      M      the      original      maximal      local      MAG."
            },
            {
              "id": 2078,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the  \n \n  whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      i,      Anc(Y,M;)   \n \n=      Anc(Y,M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nT      rounds      in      Alg."
            },
            {
              "id": 2079,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge      A;      «+S;      is      transformed      by      Rj2      on      Line   \n \n6      of      Alg. [2](A;      just      denotes      any   \n \na      vertex),      and      thus  \n \n  Anc(5;,      M;)   \n \n9   \n \nT      is      incorporated      to      S      on      Line   \n \n7      of      Alg."
            },
            {
              "id": 2080,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Since      the      algorithm      returns   \n \na      set      of      vertices      S      after      T’      rounds,      according      to      Line      4,      6,      and   \n \n9      of      Alg."
            },
            {
              "id": 2081,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "2}      we      conclude  \n \n  that      (1)      M7[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V\\\\\\'   \n \n©      S|V      o-*      VlorV      <#V’      in      Mr},      (2)  \n \n  PossDe(W,      Mr[—S])   \n \n7      Pa(S,      Mr)   \n \n=      @,      (3)      there      is      no      unbridged      path      relative      to      S      in      M7|PossDe(W,      Mr[—S])]."
            },
            {
              "id": 2082,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "We  \n \n  will      prove      that      the      three      conditions      in      Prop. 2Jare      satisfied      given      the      set      S,      thus      we      can      conclude      the      desired      result      by      Prop."
            },
            {
              "id": 2083,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "[2\n(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}\n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      Vor   \n \nV      ¢*V’      in      M}. In  \n \n  the      process      of      Alg."
            },
            {
              "id": 2084,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "2}      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads,      hence      M[Sy]   \n \n=      M,[Sy]      for      any   \n \nV   \n \n€      W. Hence      given      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W."
            },
            {
              "id": 2085,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "(2)      We      will      prove      that      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      0. Suppose   \n \nA   \n \n=      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)."
            },
            {
              "id": 2086,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Without      loss  \n \n  of      generality,      suppose      there      is   \n \nV   \n \n€      W      and   \n \na      minimal      possible      directed      path      p   \n \n=      (V,      Ji,---   \n \n,      Jz,      A)      from   \n \nV      to   \n \nA      in      M      such  \n \n  that      each      non-endpoint      in      p      does      not      belong      to      W      (If      there      is      V’   \n \n€      W      in      the      path      p,      we      consider      V’      instead      of   \n \nV      and      the  \n \n  sub-path      from      V’      to   \n \nA      instead      of      p)."
            },
            {
              "id": 2087,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the      process      of      Alg.|2|      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads  \n \n  on      the      edges      connecting      W      and      S. Hence,      since      p      is      not   \n \na      minimal      possible      directed      path      in      My,      and      each      non-endpoint  \n \n  does      not      belong      to      W,      there      must      be      J,   \n \n€      S."
            },
            {
              "id": 2088,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "However,      in      this      case      the      path      p      is      not      in      M[—S]      since      J,   \n \n€      S,      contradiction. Hence      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9. (3)      We      will      prove      that      there      is      no      unbridged      path      relative      to      S      in      M[PossDe(W,      M[-—S])}. Note      in      the      process      of      Alg."
            },
            {
              "id": 2089,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "2|      we\n \n \n  only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads      on      the      edges      connecting      W      and      S."
            },
            {
              "id": 2090,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      there      is      an      unbridged  \n \n  path      relative      to      S      in      M,      this      path      still      exists      in      Mr      since      each      vertex      in      this      path      cannot      belong      to      S,      which      concludes      that  \n \n  M-[PossDe(W,      Mr[—S])]      is      not      bridged      relative      to      S      in      Mr,      contradiction."
            },
            {
              "id": 2091,
              "title": "D.3.      Proof      of      Theorem      [Z| - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is      no      unbridged      path      relative      to      S       in      M[PossDe(W,      M[—S})],      that      is,      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M      according      to      Def. (o}      0"
            }
          ],
          "content": ""
        },
        {
          "id": 2092,
          "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}",
          "type": "section",
          "children": [
            {
              "id": 2093,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M}\n \na      complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S|V      o*      Vor   \n \nV      ¢*V’      in      M}. In  \n \n  the      process      of      Alg."
            },
            {
              "id": 2094,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "2}      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads,      hence      M[Sy]   \n \n=      M,[Sy]      for      any   \n \nV   \n \n€      W. Hence      given      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W,      M[Sy]      is   \n \na      complete      graph      for      any   \n \nV   \n \n€      W."
            },
            {
              "id": 2095,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "(2)      We      will      prove      that      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      0. Suppose   \n \nA   \n \n=      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)."
            },
            {
              "id": 2096,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Without      loss  \n \n  of      generality,      suppose      there      is   \n \nV   \n \n€      W      and   \n \na      minimal      possible      directed      path      p   \n \n=      (V,      Ji,---   \n \n,      Jz,      A)      from   \n \nV      to   \n \nA      in      M      such  \n \n  that      each      non-endpoint      in      p      does      not      belong      to      W      (If      there      is      V’   \n \n€      W      in      the      path      p,      we      consider      V’      instead      of   \n \nV      and      the  \n \n  sub-path      from      V’      to   \n \nA      instead      of      p)."
            },
            {
              "id": 2097,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Note      in      the      process      of      Alg.|2|      we      only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads  \n \n  on      the      edges      connecting      W      and      S. Hence,      since      p      is      not   \n \na      minimal      possible      directed      path      in      My,      and      each      non-endpoint  \n \n  does      not      belong      to      W,      there      must      be      J,   \n \n€      S."
            },
            {
              "id": 2098,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "However,      in      this      case      the      path      p      is      not      in      M[—S]      since      J,   \n \n€      S,      contradiction. Hence      PossDe(W,      M[—S])   \n \n9      Pa(S,      M)   \n \n=      9. (3)      We      will      prove      that      there      is      no      unbridged      path      relative      to      S      in      M[PossDe(W,      M[-—S])}. Note      in      the      process      of      Alg."
            },
            {
              "id": 2099,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "2|      we\n \n \n  only      transform      some      circles      at   \n \nV   \n \n€      W      to      arrowheads      on      the      edges      connecting      W      and      S."
            },
            {
              "id": 2100,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      there      is      an      unbridged  \n \n  path      relative      to      S      in      M,      this      path      still      exists      in      Mr      since      each      vertex      in      this      path      cannot      belong      to      S,      which      concludes      that  \n \n  M-[PossDe(W,      Mr[—S])]      is      not      bridged      relative      to      S      in      Mr,      contradiction."
            },
            {
              "id": 2101,
              "title": "(1)      We      will      prove      that      M[Sy]      is      a      complete      graph      for      any      V      €      W,      where      Sy      =      {V’      €      S|V      o*      Vor      V      ¢*V’      in      M} - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "Hence      there      is      no      unbridged      path      relative      to      S       in      M[PossDe(W,      M[—S})],      that      is,      M[PossDe(W,      M[—S])]      is      bridged      relative      to      S      in      M      according      to      Def. (o}      0"
            }
          ],
          "content": ""
        },
        {
          "id": 2102,
          "title": "D.4.      Proof      of      Theorem      B]",
          "type": "section",
          "children": [
            {
              "id": 2103,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.4. Proof      of      Theorem      B]\n \n \n  The      proof      relied      on      some      results      by      {Wang      et      al.|      (2023a))."
            },
            {
              "id": 2104,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "We      first      present      two      supporting      results      in      Lemma[I]and      Lemma]  \n \n  Lemma      [2]      implies      that      if      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in   \n \na      maximal      local      MAG      M,      then      we      can      find   \n \na       minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma   \n \n1      (Wang      et      al.|(2023a))."
            },
            {
              "id": 2105,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M      obtained      from   \n \na      PAG      P      and   \n \na      valid      local      transformation  \n \n  of   \n \nX      represented      by      C,      the      following      properties      are      satisfied:\n(Invariant)      The      arrowheads      and      tails      in      M      are      invariant      in      all      the      MAGs      consistent      with      P      and      the      local      transformation  \n \n  of   \n \nX      represented      by      C;\n(Chordal)      the      circle      component      in      M      is      chordal;\n \n \n  (Balanced)      for      any      three      vertices      A,      B,C      in      M,      if      Ax—   \n \nB      o-*      C,      then      there      is      an      edge      between   \n \nA      and      C      with      an  \n \n  arrowhead      at      C’,      namely,      Ax      C."
            },
            {
              "id": 2106,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "Furthermore,      if      the      edge      between   \n \nA      and   \n \nB      is   \n \nA   \n \n—      B,      then      the      edge      between   \n \nA      and       C      is      either   \n \nA      C      or      Ao      C      (i.e,      itis      not      A&C);\n(Complete)      for      each      circle      at      vertex   \n \nA      on      any      edge   \n \nA      o-*   \n \nB      in      M,      there      exist      MAGs      M,      and      Mg      consistent      with      M       with   \n \nA      +*B   \n \n€      E(M,)      and      A>      BE      E(Mg);\n(P6)      we      can      always      obtain   \n \na      MAG      consistent      with      P      and      the      local      transformation      of   \n \nX      represented      by      C,      by  \n \n  transforming      the      circle      component      into   \n \na      DAG      without      unshielded      colliders      and      transforming      Ao>      Bas   \n \nA   \n \n>      B."
            },
            {
              "id": 2107,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Lemma   \n \n2      (Wang      et      al.|      (2023a)). Consider   \n \na      maximal      local      MAG      MA. If      there      is   \n \na      possible      directed      path      from   \n \nA      to   \n \nB      in      M,  \n \n  then      there      is   \n \na      minimal      possible      directed      path      from   \n \nA      to   \n \nB      in      M. Lemma      3."
            },
            {
              "id": 2108,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment  \n \n  set      relative      to      (X,Y). Let      W      be      D-SEP(X,Y,      Mx)."
            },
            {
              "id": 2109,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (Jo(= V),      Ji,-:+      ,Js(=      T)      from   \n \nV   \n \n€      W      to   \n \na      vertex   \n \nT      in      M,      where      each      non-endpoint      in      p      does      not      belong      to      W      UW. If  \n \n  T   \n \n€      Anc(Y,      M),      then      p      can      only      be      as      Jyo>      Jy   \n \n>      +++   \n \n+      J,      in      M."
            },
            {
              "id": 2110,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "And      there      exists   \n \na      collider      path      X(=      Fo)   \n \n&      Fi   \n \n& »   \n \n>      Fi      <*V      in      M      with      edges      F;   \n \n>      J,,0<i<n-1. Proof. According      to      Def. there      exists   \n \na      collider      path   \n \nX      (=      Fo)   \n \n@      Fy      +++      Fy_y      +#V      in      M,      where      F),---   \n \n,      Fy-1   \n \n€ W."
            },
            {
              "id": 2111,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "There      cannot      be      an      edge      F;      <+*J;      in      M      for      any   \n \n0      <2   \n \n<   \n \nt   \n \n—      1,      for      otherwise      J,   \n \n©      WU      W. Since   \n \nV      is      not      an      ancestor      of   \n \nY      in      M      and      p      is   \n \na      minimal      possible      directed      path,      there      must      be      Fy_;   \n \n©   \n \nV      <+*J,      in      M."
            },
            {
              "id": 2112,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "Hence      F;_,      is      adjacent      to      J;,      for      otherwise      there      is   \n \na      new      unshielded      collider      in      M      relative      to      M."
            },
            {
              "id": 2113,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Since      (1)      for      each  \n \n  F;,0      <i<t-—1,      there      cannot      be      F;      <+*.J,      in      M,      and      (2)      the      balanced      property      is      fulfilled      in      M,      we      can      conclude      that  \n \n  there      is      there      is      F;   \n \n>      J,      or      Fjo3      Jy,V1      <1      <n-—1      and   \n \nX   \n \n—      Jj,      otherwise      there      is      always   \n \na      discriminating      path      for Lemma      4."
            },
            {
              "id": 2114,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "Given   \n \na      maximal      local      MAG      M,      suppose   \n \na      MAG      M      consistent      with      M      such      that      there      exists      an      adjustment      set  \n \n  relative      to      (X,Y). Let      W      be      D-SEP(X,      Y,      Mx). For      any      S      incorporated      into      the      set      of      vertices      S      in      the      process      of      Alg."
            },
            {
              "id": 2115,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "2) (on      Line      7),      there      is      S   \n \n€      Anc(Y,      M). V\n \n   which      leads      to   \n \na      non-circle      mark      at   \n \nV      on      the      edge      between   \n \nV      and      J;      in      P. Due      to      Vx—      F,,_;   \n \n—      J;      in      M      and      the  \n \n  balanced      property      of      M,      there      is      Vo—      J;."
            },
            {
              "id": 2116,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Since      the      path      p      is   \n \na      minimal      possible      directed      path,      the      path      can      only      be      as  \n \n  Vo      J,      7-3      Is. CI\n \n \n  Proof. Note      the      graph      M      is      updated      in      every      round      of      Alg.|2|      To      distinguish      them,      we      use      M1;      to      denote      the      graph      obtained  \n \n  after      Line   \n \n5      of      Alg."
            },
            {
              "id": 2117,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "/2|/in      the      i-th      round. Denote      M      the      original      maximal      local      MAG. Note      in      the      whole      process,      there      are      no       new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      S   \n \n€      W,      since      W   \n \n=      D-SEP(X,      Y,      Mx),      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)      and      S   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 2118,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "For      S   \n \n€      So      defined  \n \n  in      Def. |4}      according      to      Lemma[3}      since      $\\\\\\'      is      the      vertex      adjacent      to   \n \na      vertex   \n \nV   \n \n€      W      ina      minimal      possible      directed      path  \n \n  from   \n \nV      to   \n \na      vertex      in      Anc(Y,      M),      there      is      S   \n \n€      Anc(Y,M)."
            },
            {
              "id": 2119,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "Suppose      there      are   \n \nT      rounds      in      Alg.|2)      where      in      the      i-th      round,  \n \n  1<i<T-—1,anedge   \n \nA      ++5S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2      and      thus      Anc(S;,      M,)      N   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg.|2|      For      brevity,      denote   \n \nT   \n \n=      PossDe(W,      M[—S])\\\\\\\\W)      like      Line   \n \n2      of      Alg."
            },
            {
              "id": 2120,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "We      first      prove      S;   \n \n€      Anc(Y,M). Since      R12      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (K1,---   \n \n,      Km)      relative      to      So  \n \n  and      there      exists      an      uncovered      possible      directed      path      (V,      S,,---   \n \n,      Kj)      for   \n \n1   \n \n<   \n \n7   \n \n<      min      M),      where   \n \nV   \n \n€      W."
            },
            {
              "id": 2121,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is      C_      *-o      Ky      0-0      ---      0-0      Ky,      o-*«      Din      M,  \n \n  where      C   \n \n€      Fx,\\\\\\\\Fr,,D   \n \n©      Fr,,\\\\\\\\Fr,_,»      Fk;   \n \n=      {V   \n \n€      VW’   \n \n|   \n \nV      +0      Kj      or      Vx      K;      in      My}."
            },
            {
              "id": 2122,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "Next      we      prove      there      is  \n \n  not      kK;   \n \n+      Cin      M,. Suppose      kK,   \n \n—      C      in      M,      for      contradiction. As      in      the      process      of      Alg. 2]      we      never      add   \n \na      tail,      there      is  \n \n  K,      €—>      CinM. In      this      case,      there      is   \n \na      directed      path      S;   \n \n>      ---   \n \n—      kK,   \n \n>      CinMandC   \n \n€      So      C      Anc(WU      {Y},M)."
            },
            {
              "id": 2123,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "Hence      S$,   \n \n€      Anc(W   \n \nU      {Y},M). Since   \n \nV   \n \n€      W      is      adjacent      to      91,      9;      should      belong      to      So,      contradiction. Hence      there  \n \n  cannot      be      an      edge      Ky   \n \n>      Cin      My."
            },
            {
              "id": 2124,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      F’;,1   \n \n<   \n \n7   \n \n<      m,      it      is      easy      to      prove      that      F’;      is      an      ancestor      of      either      C      or      D,  \n \n  for      otherwise      there      will      be      an      unshielded      collider      in      the      path      (C,      Ky,---   \n \n,      Km,      D)      in      M."
            },
            {
              "id": 2125,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "And      since      C,      D   \n \n€      So,      and      C,      D       are      ancestors      of   \n \nY      in      M,      it      holds      C,      D   \n \n€      Anc(Y,M). And      since      there      is      Vo>      5;   \n \n—      ---   \n \n+      K,      in      M,      5;      is      an      ancestor      of  \n \n  Y      in      M. Thus      S;   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 2126,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      all      the      vertices      in      Anc(.S,,      My)      M   \n \nT      are      ancestors      of      Y. Next      we      prove      the      induction      result. Suppose      in      the      first   \n \ni      round,      each      vertex      in      So,      Anc(S;,M),---   \n \n,      Anc(.S;,      M1)      is      an  \n \n  ancestor      of   \n \nY      in      M. We      will      prove      S;,1   \n \n€      Anc(Y,      M)."
            },
            {
              "id": 2127,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "Since      R49      is      triggered,      there      is      an      unbridged      path      p   \n \n=      (7,---   \n \n,      T\\\\\\')      relative      to      Sp      UU,      <,<;(Ane(Sq,      Mi)      N      T)      and      there  \n \n  exists      an      uncovered      possible      directed      path      (V,      $;41,---      ,7;)      forl   \n \n<      s   \n \n<      f      in      M,,1      where   \n \nV   \n \n€      W."
            },
            {
              "id": 2128,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Without      loss      of  \n \n  generality,      suppose      p      is      an      unbridged      path. In      the      unbridged      path,      there      is   \n \nJ      *-o      T;      o-o      ---      0-0      Ty      o-*   \n \nK      in      M;41,      where  \n \n  J   \n \n€      Fr,\\\\\\\\Fr,,   \n \nK   \n \n€      Fr;      \\\\\\\\Frj_1:      Next      we      prove      there      is      not      T;   \n \n—   \n \nJ      in      M;,,."
            },
            {
              "id": 2129,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Suppose      J;   \n \n—   \n \nJ      in      M      for      contradiction. Note      in      the      whole      process      of      Alg. 2}      we      never      add   \n \na      tail,      hence      there      is      T;      —>   \n \nJ      in      M. In      this      case,      there      is   \n \na      directed      path  \n \n  Sig1      3-1:   \n \n>      T,   \n \n>      JinMand   \n \nJ   \n \n€      So      UU      <g<;(Ane(Sq,      Mg)      OT)."
            },
            {
              "id": 2130,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "If   \n \nJ   \n \n€      So,      then      S341   \n \n€      Anc(WU{Y},M),      Sizi  \n \n  should      belong      to      So,      contradiction. If      5,4;   \n \n€      Anc(S,,M,)   \n \n7      T,1      <q      <3,      then      S;,1      should      have      been      incorporated      into  \n \n  S      in      the      g-round      of      Alg.|2}      contradiction. Hence      there      cannot      be      an      edge      T;   \n \n>   \n \nJ      in      M41."
            },
            {
              "id": 2131,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "Hence,      in      M      consistent      with      M,      for      each      vertex      T,,1   \n \n<      s   \n \n<      f,      itis      an      ancestor      of      either   \n \nJ      or      K,      for      otherwise      there      will  \n \n  be      an      unshielded      collider      in      the      path      (J,T1,---      ,T,      A)      in      M."
            },
            {
              "id": 2132,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "And      since      J,   \n \n€      So      UUy<<;(Ane(Sq,M,)   \n \n9      T),      and       J,   \n \nK      are      ancestors      of   \n \nY      in      M,      it      holds      J,      kK   \n \n€      Anc(Y,M). And      since      there      is      Vo>      S;4;   \n \n>      ---   \n \n>      T,      in      M,      $;4,      is      an  \n \n  ancestor      of      Y. Thus      S;41;   \n \n€      Anc(Y,M)."
            },
            {
              "id": 2133,
              "title": "D.4.      Proof      of      Theorem      B] - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Hence      all      the      vertices      in      Anc(.$;41,      M41)      M   \n \nT      are      ancestors      of   \n \nY      in      M."
            }
          ],
          "content": ""
        },
        {
          "id": 2134,
          "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O",
          "type": "section",
          "children": [
            {
              "id": 2135,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M. O\nTheorem.B]      Prop. {/has      implied      that      W   \n \n=      D-SEP(X,      Y,      M.x)      is   \n \na      potential      adjustment      set. We      will      prove      that   \n \na      set      of vertices      S$      will      be      returned      by      Alg."
            },
            {
              "id": 2136,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "Note      the      graph      M      is      updated      in      every      round      of      Alg. [2|      To      distinguish      them,      we      use      M|;      to      denote      the      graph      obtained      after  \n \n  Line   \n \n5      of      Alg.2|in      the      i-th      round,      use      S;      to      denote      the      set      of      vertices      obtained      after      Line   \n \n7      of      Alg. [2|in      the      i-th      round."
            },
            {
              "id": 2137,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "Denote  \n \n  M      the      original      maximal      local      MAG. For      S   \n \n€      So      in      Def. 4}      there      must      be   \n \nV      <*S      in      M      if      there      is   \n \nV      o-*      S      in      M. Hence      the  \n \n  arrowheads      introduced      in      the      first      round      of      Alg. 2]      must      exist      in      /. And      due      to      the      soundness      of      Ri2      by      Thm."
            },
            {
              "id": 2138,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "[I]      all      the  \n \n  arrowheads      introduced      in      Alg. RJexist      in      M. In      the      whole      process,      there      are      no      new      tails      introduced. Hence,      for      any      7,      Anc(Y,      M;)   \n \n=      Anc(Y,      M). For      brevity,      denote  \n \n  T   \n \n=      PossDe(W,      M[—S])\\\\\\\\W      like      Line   \n \n2      of      Alg. {2}      Suppose      there      are   \n \nJ      rounds      in      Alg."
            },
            {
              "id": 2139,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "|2}      where      in      the      i-th      round,  \n \n  1<i<J-—1,anedge   \n \nA      +S;      is      transformed      by      R12      on      Line   \n \n6      of      Alg.|2}      and      thus      Anc(S;,      M;)      M   \n \nT      is      incorporated      to      S       on      Line   \n \n7      of      Alg. 2}      Hence      there      is      evidently      S;,;   \n \n=      S;   \n \nU      (Anc($;41,Mi41)      NT),      forO      <i<      J—1."
            },
            {
              "id": 2140,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "It      suffices      to      show      that      in      the      i-th      round   \n \n1   \n \n<   \n \ni   \n \n<      J,      there      is      (1)      PossDe(W,      M;;[—S,])      N      Pa(S;,      Mi)   \n \n=      0,      (2)      M;      [Sy]      is   \n \na       complete      graph      for      any   \n \nV   \n \n€      W,      where      Sy   \n \n=      {V’   \n \n€      S;|V      o«      V’or   \n \nV      ¢*V’      in      Mj},      and      (3)      there      is      not      an      unbridged      path  \n \n  relative      to      S;      in      M;[PossDe(W,      M;[—S,])]."
            },
            {
              "id": 2141,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "As      when      these      three      conditions      are      satisfied      in      each      round,      Alg.|2|could      output a\n \n   set      of      vertices. Suppose      in      the   \n \n2      round,      the      algorithm      output      “No”. According      to      Alg.|2}      at      least      one      of      the      three      conditions  \n \n  is      violated."
            },
            {
              "id": 2142,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 8",
              "type": "chunk",
              "children": [],
              "content": "We      will      prove      the      impossibility      of      the      violations      of      the      three      conditions      in      the      following."
            },
            {
              "id": 2143,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 9",
              "type": "chunk",
              "children": [],
              "content": "If      PossDe(W,      M;[—S;])  \n \n  Pa(S;,M;)   \n \n4      T,      suppose      there      is   \n \na      minimal      possible      directed      path      p      from   \n \nV   \n \n€      W      to   \n \nT      in  \n \n  M;[—S,]      such      that      each      non-endpoint      does      not      belong      to      W,      and      there      is      an      edge   \n \nT   \n \n+      S      in      M;      for      S   \n \n€      S;. Hence  \n \n  T   \n \n€      Anc(S,M;)."
            },
            {
              "id": 2144,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 10",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma}      p      is      Vo>—      --. +   \n \nT      in      M. In      this      case,      if      S   \n \n€      So,      according      to      Def. 4]      and       Lemmaj}}      there      is      S   \n \n€      Anc(W   \n \nU      {Y},M)."
            },
            {
              "id": 2145,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 11",
              "type": "chunk",
              "children": [],
              "content": "Thus   \n \nT   \n \n€      Anc(W   \n \nU      {Y},      M),      which      implies      that      there      is   \n \na      minimal      possible  \n \n  directed      path      p\\\\\\'      from   \n \nV   \n \n€      W      to   \n \nT   \n \n€      Anc(W   \n \nU      {Y},M)      such      that      p’      is   \n \na      sub-path      of      p. However,      according      to      Def."
            },
            {
              "id": 2146,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 12",
              "type": "chunk",
              "children": [],
              "content": "in      the      case      above,      the      vertex      adjacent      to   \n \nV      in      p’      should      belong      to      So,      contradicting      with      the      fact      that      the      path      p      is      in  \n \n  M,[—S,]. If      S;      is      incorporated      into      S      in      Alg."
            },
            {
              "id": 2147,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 13",
              "type": "chunk",
              "children": [],
              "content": "Qin      the      7,7   \n \n<   \n \n7      round,      since      there      is   \n \nT   \n \n€      Anc(S,M),   \n \nT      should      belong      to  \n \n  S541,S;+42,:--      ,8;,      contradicting      with      the      fact      that      the      path      p      is      in      M;|—S,]. Hence      there      is      always   \n \na      contradiction      if      there  \n \n  is      PossDe(W,      M;;[—S;])      M      Pa(S;,M;)   \n \n4      0."
            },
            {
              "id": 2148,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 14",
              "type": "chunk",
              "children": [],
              "content": "Since      W   \n \n=      D-SEP(X,      Y,      Mx),      for      any   \n \nV   \n \n€      W,   \n \nV      is      not      an      ancestor      of   \n \nY      in      M. If      M,[Sy]      is      not   \n \na      complete      graph for      some   \n \nV   \n \n€      W,      there      must      be      an      edge   \n \nV   \n \n>      Sin      M,      for      otherwise      there      will      be      new      unshielded      collider      at      V."
            },
            {
              "id": 2149,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 15",
              "type": "chunk",
              "children": [],
              "content": "Due      to  \n \n  Lemma}      S      is      an      ancestor      of      Y. Thus   \n \nV      is      an      ancestor      of      Y,      thus   \n \nV   \n \n€      WW,      contradicting      with      W   \n \n9      W   \n \n=      9. Finally,      we      prove      that      there      is      not      an      unbridged      path      relative      to      S;      in      M;[PossDe(W,M,[—S,])]."
            },
            {
              "id": 2150,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 16",
              "type": "chunk",
              "children": [],
              "content": "Suppose  \n \n  M;{[PossDe(W,      M[—S,])]      is      not      bridged      relative      to      S;      in      M. Since      M;[PossDe(W,M,{—S;])]      is      not      bridged      relative  \n \n  to      S;      in      M;,      without      loss      of      generality,      suppose      an      unbridged      path      Ky,      o—o      ---      o—o      K,,,      relative      to      S;,      and      there      is  \n \n  AE      W."
            },
            {
              "id": 2151,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 17",
              "type": "chunk",
              "children": [],
              "content": "According      to      Lemma      4}      all      the      vertices      in      S;      are      ancestors      of   \n \nY      in      M. At      first,      we      prove      Ky,---   \n \n,      Ky      are  \n \n  ancestors      of   \n \nY      in      M."
            },
            {
              "id": 2152,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 18",
              "type": "chunk",
              "children": [],
              "content": "As      there      are      vertices      S),.S_   \n \n€      S;      such      that      S$;   \n \n€      Fx,      \\\\\\\\Fr,      and      Sy   \n \n€      Fr,,\\\\\\\\Fr      where  \n \n  Fy      ={V\\\\\\'      €S,|V      o*      V’      or   \n \nV      «V’      in      M;}      as      Def. [I] m—1? If      S   \n \n€      So,      according      to      Def."
            },
            {
              "id": 2153,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 19",
              "type": "chunk",
              "children": [],
              "content": "|4}      there      is   \n \na      minimal      possible      directed      path      p   \n \n=      (V’,S,---      ,T)      from      V’   \n \n€      WtoT   \n \n€       Anc(W   \n \nU      {Y},M)      where      each      non-endpoint      does      not      belong      to      W      in      M;. According      to      Def. |2}      there      exists   \n \na      collider      path X\n \n   OF      O---&      Fy_   \n \n1      <V’      where      F\\\\\\\\,---   \n \n,      F;_1   \n \n€      W."
            },
            {
              "id": 2154,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 20",
              "type": "chunk",
              "children": [],
              "content": "And      according      to      the      result      (2)      above,      M;|Sy-]      is   \n \na      complete  \n \n  graph. Hence      F;_,      is      adjacent      to      S. In      this      case      if      there      is      an      edge      F;_;      «+S      in      Mj,      there      is      F;_;      «+S      in      M,      thus      there  \n \n  is      S   \n \n€      WUW. And      due      to      S   \n \n¢      W,      there      is      S   \n \n€      W."
            },
            {
              "id": 2155,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 21",
              "type": "chunk",
              "children": [],
              "content": "And      if      there      is      an      edge      F,_      o-*      S      or      F;_1   \n \n>      S\\\\\\'      in      Mj,      there      is\n \n \n  F,_,      o*      S      or      Fy_;   \n \n—      S      in      M,      there      must      be      Vo  \n \n  S      in      M."
            },
            {
              "id": 2156,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 22",
              "type": "chunk",
              "children": [],
              "content": "Due      the      p      is   \n \na      minimal      possible      directed      path      in      Mj,      p      is      also   \n \na       minimal      possible      directed      path      in      M,      pis      V’o>      S   \n \n>      ---   \n \n>      Tin      M,      thus      S   \n \n€      Anc(W   \n \nU      {Y},      M)."
            },
            {
              "id": 2157,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 23",
              "type": "chunk",
              "children": [],
              "content": "Hence,      no      matter      what  \n \n  the      edge      is      between      S      and      F;_1,      there      is      S   \n \n€      Anc(W   \n \nU      {Y},      M). In      this      case,      if      there      is      kK;   \n \n—      5S      in      M,      there      is      kK;   \n \n€      So  \n \n  due      to      S\\\\\\'   \n \n€      So,      contradicting      with      K;   \n \n€      PossDe(W,      M;[-S,])."
            },
            {
              "id": 2158,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 24",
              "type": "chunk",
              "children": [],
              "content": "If      S      is      incorporated      into      S      in      the      j,   \n \n7   \n \n<   \n \ni      round      on      Line   \n \n7      of  \n \n  Alg. [2|   \n \nK      is      also      incorporated      into      S      in      this      round      due      to   \n \nK   \n \n€      Anc(S,M),      contradicting      with      K;   \n \n€      PossDe(W,      M;[—S;]). Hence      for      any      K;,1      <j   \n \n<      mand      5S   \n \n€      §,      in      the      process      of      Alg."
            },
            {
              "id": 2159,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 25",
              "type": "chunk",
              "children": [],
              "content": "(2)      there      cannot      be      an      edge      S   \n \n+      K;. Hence,      consider      the      uncovered      path      py   \n \n=      ($1,      Ky,      Ko,--+   \n \n,      Km,      S2)      in      M;      where      the      sub-path      from      K,      to      K,,,      is   \n \na      circle  \n \n  path."
            },
            {
              "id": 2160,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 26",
              "type": "chunk",
              "children": [],
              "content": "Note      the      non-circle      marks      in      M;      also      exist      in      M      due      to      the      soundness      of   \n \nR   \n \n2      according      to      Thm. {i}      Since      M      cannot have      new      unshielded      colliders      relative      to      M;,      there      is      each      vertex      in      K,,      K2,---   \n \n,      Km      is      an      ancestor      of      either      S;      or      So      in M."
            },
            {
              "id": 2161,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 27",
              "type": "chunk",
              "children": [],
              "content": "Since      S;      and      S2      are      ancestors      of   \n \nY      according      to      Lemma      any      vertex      in      K,,---   \n \n,      Kj,      are      ancestors      of   \n \nY      in      M. Note      in      the      process      of      Alg."
            },
            {
              "id": 2162,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 28",
              "type": "chunk",
              "children": [],
              "content": "2)      we      only      add      arrowheads      at      W,      which      are      not      ancestors      of   \n \nY      in      M,      hence      we      will  \n \n  never      introduce      any      arrowheads      at      K;,V1   \n \n<   \n \nj   \n \n<      min      Alg."
            },
            {
              "id": 2163,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 29",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence      in      M;,      the      uncovered      path      p,      is      in      the      form      of S,      #0      Ky      0-0:      ++      0-0      Ky,      o-*      So,      that      is,      there      cannot      be      S$;   \n \n>      Ky,      or      Ky,      <*S>      in      M;."
            },
            {
              "id": 2164,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 30",
              "type": "chunk",
              "children": [],
              "content": "Next,      for      any      K;,1   \n \n<   \n \n7   \n \n<      _m,      consider      the      minimal      possible      directed      path      p   \n \n=      (A,      Bj,  \n \n  K      A)      from   \n \nA      to      K;. Note      we  \n \n  use      notation   \n \nB      to      denote      the      vertex      adjacent      to   \n \nA      in      the      minimal      possible      directed      path      from   \n \nA      to      K;,1      <7      <m."
            },
            {
              "id": 2165,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 31",
              "type": "chunk",
              "children": [],
              "content": "Without  \n \n  loss      of      generality,      we      suppose      each      non-endpoint      in      p      does      not      belong      to      W,      since      if      there      is      another      vertex      A’   \n \n€      W      in      p,  \n \n  we      can      consider      A’      instead      of      A,      it      is      evidently      that      K1,---   \n \n,      Ky,      are      possible      descendants      of      A’      as      well      since      there      is   \n \na       minimal      possible      directed      path      from      A’      to      A;      and      there      are      circle      paths      from      KX;      to      each      vertex      in      Ky,---   \n \n,      Km."
            },
            {
              "id": 2166,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 32",
              "type": "chunk",
              "children": [],
              "content": "Note      it      is      possible      that      there      are      many      minimal      possible      directed      paths      from   \n \nA      to      K;."
            },
            {
              "id": 2167,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 33",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      prove      that      for      any  \n \n  B;,B;,1<i<   \n \nJ      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;,      and      B;      is      adjacent      to      each  \n \n  vertex      in      S      in      M. Suppose      B;      is      not      adjacent      to      B;      or      S   \n \n€      S      in      M."
            },
            {
              "id": 2168,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 34",
              "type": "chunk",
              "children": [],
              "content": "Since      S      is      an      ancestor      of   \n \nY      in      any      MAG      M      consistent  \n \n  with      M      such      that      W   \n \n=      D-SEP(X,Y,      Mx),      and   \n \nA   \n \n€      W,      there      is   \n \nA      +*S      in      M. Since      there      is      not   \n \nA      +*B;      or   \n \nA      *B;      in  \n \n  M,      there      is      either   \n \nA   \n \n+      B;      or   \n \nA   \n \n>      B;      in      M."
            },
            {
              "id": 2169,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 35",
              "type": "chunk",
              "children": [],
              "content": "And      since      B;      and      B;      are      located      at      minimal      possible      directed      paths      from   \n \nA       to      K;      and      K;,      respectively,      there      must      be   \n \nA   \n \n€      Anc(.A;,      M)      or   \n \nA   \n \n€      Anc(;,      M)."
            },
            {
              "id": 2170,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 36",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      that      K;,.K;      are  \n \n  ancestors      of   \n \nY      in      M,   \n \nA      is      an      ancestors      of   \n \nY      in      M,      in      which      case      there      is   \n \nA   \n \n©      WNW,      contradicting      with      WM      W      =Oin  \n \n  Def."
            },
            {
              "id": 2171,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 37",
              "type": "chunk",
              "children": [],
              "content": "2}      Hence,      for      any      B;,B;,1      <7   \n \n<   \n \n7      <™m,      there      is      either      B;      and      B;      denote      the      same      vertex,      or      B;      is      adjacent      to      B;, and      B;      is      adjacent      to      each      vertex      in      S      in      M. Next,      we      prove      that      for      any   \n \n1   \n \n<   \n \nj   \n \n<      m,      there      is      not      B;   \n \n=      K,."
            },
            {
              "id": 2172,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 38",
              "type": "chunk",
              "children": [],
              "content": "That      is,      the      minimal      possible      directed      path      from   \n \nA      to  \n \n  kK;      cannot      be   \n \nA      o—*      Kk;      in      M;. Suppose      there      is   \n \nA      o-*      A’;      in      M;. According      to      the      result      above,      for      any      S   \n \n€      S,      K;      is  \n \n  adjacent      to      S."
            },
            {
              "id": 2173,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 39",
              "type": "chunk",
              "children": [],
              "content": "In      this      case,      there      must      be      m   \n \n>      3,      for      otherwise      if      the      unbridged      path      is      just      Ky      o-o      K2,      suppose   \n \nj   \n \n=      1,  \n \n  then      there      must      be      Fx,      D      Fxx,,      contradicting      with      the      definition      of      unbridged      path      in      Def."
            },
            {
              "id": 2174,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 40",
              "type": "chunk",
              "children": [],
              "content": "[I]      We      consider      the      circle  \n \n  path      kK;      o-      Kj4,0~©---co-0      K,,      inM      (If   \n \n7      =>      m   \n \n—      1,      then      we      consider      the      circle      path      Ky      o-0      ---      K;      instead. And      it  \n \n  is      impossible      that      m   \n \n=   \n \n3      and   \n \nj   \n \n=      2,      for      otherwise      the      path      cannot      be      unbridged). There      is      Sy   \n \n€      Fx,,\\\\\\\\Fx,,_,."
            },
            {
              "id": 2175,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 41",
              "type": "chunk",
              "children": [],
              "content": "Since  \n \n  there      cannot      be      an      edge      K,,-1   \n \n—      52      in      M;      and      M,      which      we      have      proven      before,      and      S2   \n \n€      Fx,,      \\\\\\\\Fx,,_,,      52      cannot      be  \n \n  adjacent      to      K,,-1."
            },
            {
              "id": 2176,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 42",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      can      conclude      that      K,,,_2      is      not      adjacent      to      S2,      for      otherwise      in      the      substructure      comprised      of  \n \n  Km—2,      Km—1,      Km,      S2,      there      must      be      K,,   \n \n>      Sg   \n \n+      K,,—2      oriented      by      Rg      in      P,      which      leads      to      K,,-2   \n \n>      Sin      M      and      M,,  \n \n  contradiction."
            },
            {
              "id": 2177,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 43",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      conclude      that      no      vertices      in      K;,      Kj41,---   \n \n,      Km      is      adjacent      to      S. However,      we      have      proven  \n \n  that      K;      is      adjacent      to      S,      contradiction. Hence,      for      any      B;,1      <j      <_m,      Bj   \n \n4      K;."
            },
            {
              "id": 2178,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 44",
              "type": "chunk",
              "children": [],
              "content": "Next,      we      will      prove      that      for      any      B;,1   \n \n<   \n \nj   \n \n<      m,      B;      is      also      in      the      minimal      possible      directed      path      from   \n \nA      to      Kj,  \n \n  where   \n \n1   \n \n<   \n \ni   \n \n<      mandi   \n \n¥      j. Without      loss      of      generality,      suppose   \n \n7   \n \n>      7."
            },
            {
              "id": 2179,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 45",
              "type": "chunk",
              "children": [],
              "content": "Consider      the      minimal      possible      directed      path  \n \n  (A,      By41,-+-   \n \n,      541)      from   \n \nA      to      Kj+41      in      M. We      will      prove      that      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible  \n \n  directed      path      from   \n \nA      to      Kj+1. If      Bj,      and      B;      denote      the      same      vertex,      the      result      evidently      holds."
            },
            {
              "id": 2180,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 46",
              "type": "chunk",
              "children": [],
              "content": "We      just      consider      the      case  \n \n  Bj41   \n \n4      B;. We      have      proven      that      B;      is      adjacent      to      B;+1      before. Note      each      vertex      in      Ky,---   \n \n,      Ky,      is      an      ancestor      of   \n \nY      in      M. According      to      Lemma      3}      there      must      be      p)   \n \n=      Ao      B;   \n \n>       -++      —>      Kj      and      po   \n \n=      Ao      By,   \n \n—      ---   \n \n—      Kj41."
            },
            {
              "id": 2181,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 47",
              "type": "chunk",
              "children": [],
              "content": "Since      we      have      proven      Kj;   \n \n#      Bj,      above,   \n \nA      cannot      be      adjacent      to  \n \n  Kj+41,      for      otherwise      p      is      not   \n \na      minimal      possible      directed      path."
            },
            {
              "id": 2182,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 48",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      adjacent      to      Kj;      in      M,      it      is      evident      that      there      is   \n \na       minimal      possible      directed      path      (A,      B;,      Kj+1),      thus      B;      is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path  \n \n  from   \n \nA      to      K;41."
            },
            {
              "id": 2183,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 49",
              "type": "chunk",
              "children": [],
              "content": "If      B;      is      not      adjacent      to      K;+1,      due      to      the      possible      directed      path      B;   \n \n>      ---   \n \n>      K,;      o-0      Kj,      in      Mj,      the  \n \n  corresponding      path      in      M      is      also   \n \na      possible      directed      path,      there      must      be   \n \na      minimal      possible      directed      path      p’      from      B;      to      Kj41  \n \n  in      M      according      to      Lemma|2}      and      thus      the      corresponding      path      of      p’      in      M;      must      be      also   \n \na      minimal      possible      directed      path      since  \n \n  in      Alg."
            },
            {
              "id": 2184,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 50",
              "type": "chunk",
              "children": [],
              "content": "2|      we      only      transform      some      edge   \n \nV      o-*      S      to   \n \nV      <*S\\\\\\'      for   \n \nV   \n \n€      W      and      S   \n \n€      S;,      while      each      vertex      in      p’      does      not      belong  \n \n  to      S      since      it      is      in      M;[—S,]."
            },
            {
              "id": 2185,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 51",
              "type": "chunk",
              "children": [],
              "content": "And   \n \nA      is      not      adjacent      to      any      non-endpoint      in      p’      since      Ao      B;   \n \n>      ---   \n \n>      K;      is   \n \na      minimal  \n \n  possible      directed      path      and   \n \nA      is      not      adjacent      to      K;41."
            },
            {
              "id": 2186,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 52",
              "type": "chunk",
              "children": [],
              "content": "Hence,      we      have   \n \na      new      minimal      possible      directed      path      Ao>      B;      Op’,  \n \n  where      B,      is      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      A’;+1."
            },
            {
              "id": 2187,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 53",
              "type": "chunk",
              "children": [],
              "content": "Similarly,      we      can      prove      that      B;      is  \n \n  also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      Kj42."
            },
            {
              "id": 2188,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 54",
              "type": "chunk",
              "children": [],
              "content": "Repeat      the      process,      we      can      prove      that      B;  \n \n  is      also      the      vertex      adjacent      to   \n \nA      in   \n \na      minimal      possible      directed      path      from   \n \nA      to      K;,      for      any   \n \n1      <i   \n \n<      mandi      F      7."
            },
            {
              "id": 2189,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 55",
              "type": "chunk",
              "children": [],
              "content": "Till      now,      we      have      proven      that      there      exists   \n \na      minimal      possible      directed      path      from   \n \nA      to      each      vertex      in      Ky,---   \n \n,      Ky,      such      that  \n \n  B;      is      the      common      vertex      adjacent      to   \n \nA      in      all      paths. And      it      is      evidently      that      the      minimal      possible      directed      path      is      an      uncovered  \n \n  path."
            },
            {
              "id": 2190,
              "title": "By      induction,      we      can      prove      that      all      the      incorporated      vertices      in      S      are      ancestors      of      Y      in      M.      O - Chunk 56",
              "type": "chunk",
              "children": [],
              "content": "Hence,      if      B;   \n \n¢      S;,      the      edge   \n \nA      o-«      B;      should      be      transformed      by      R42      in      M;      on      Line   \n \n6      of      Alg. [2|      thus      the      algorithm      will enter the next loop, contradiction. Hence there is not an unbridged path relative to S; in M;[PossDe(W, M;[—S,])] O"
            }
          ],
          "content": ""
        },
        {
          "id": 2191,
          "title": "D.5.      Proof      of      Proposition",
          "type": "section",
          "children": [
            {
              "id": 2192,
              "title": "D.5.      Proof      of      Proposition - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.5. Proof      of      Proposition\nProof. We      prove      it      by      mathematical      induction. For      each   \n \nV   \n \n€      DD-SEP(X,      Y,      MLx      ),      we      consider      the      minimal      collider      path  \n \n  satisfying      the      three      conditions      of      Definition   \n \n|      in      M."
            },
            {
              "id": 2193,
              "title": "D.5.      Proof      of      Proposition - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "If      the      length      is      1,      there      is   \n \nX      <-*V      in      My      since      there      cannot      be   \n \nX      -«V  \n \n  in      Mx      according      to      the      definition      of      Mx. If      there      is   \n \nV   \n \n¢      Anc(Y,      M),      it      trivially      concludes      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx)  \n \n  according      to      the      definition."
            },
            {
              "id": 2194,
              "title": "D.5.      Proof      of      Proposition - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "If      M[Qy]      is      not   \n \na      complete      graph,      evidently      there      are      at      least      two      vertices      in      Oy. Suppose  \n \n  S1,S2   \n \n€      Oy      are      not      adjacent."
            },
            {
              "id": 2195,
              "title": "D.5.      Proof      of      Proposition - Chunk 4",
              "type": "chunk",
              "children": [],
              "content": "It      is      evident      that      there      is      either   \n \nV   \n \n>      5S;      or   \n \nV   \n \n—      S      in      M,      otherwise      there      is   \n \na      new      unshielded  \n \n  collider      in      M      relative      to      M      and      P,      which      contradicts      with      that      M      is      consistent      with      MI."
            },
            {
              "id": 2196,
              "title": "D.5.      Proof      of      Proposition - Chunk 5",
              "type": "chunk",
              "children": [],
              "content": "Thus      there      is      also   \n \nV   \n \n€      Anc(Y,      M)  \n \n  such      that   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Hence      if      the      length      is      1,      there      is   \n \nV   \n \n€      D-SEP(X,      Y,      Mx). Suppose      the      result      holds  \n \n  when      the      length      of      the      minimal      collider      path      mentioned      above      is      k."
            },
            {
              "id": 2197,
              "title": "D.5.      Proof      of      Proposition - Chunk 6",
              "type": "chunk",
              "children": [],
              "content": "For      the      vertex   \n \nV      with   \n \na      minimal      collider      path      satisfying  \n \n  the      three      conditions      of      Definition      [5]      whose      length      is   \n \nk   \n \n+      1,      suppose      the      path      is      comprised      of      X,V;,V2,-+-      ,Ve41. We  \n \n  have      Vi,      V2,---   \n \n,      Ve   \n \n€      D-SEP(X,      Y,      Mx)."
            },
            {
              "id": 2198,
              "title": "D.5.      Proof      of      Proposition - Chunk 7",
              "type": "chunk",
              "children": [],
              "content": "For      Vi.41,      similar      to      the      proof      above,      no      matter      whether      V.+1   \n \n€      Anc(Y,      M) or      M[Qy,.,,]      is      not   \n \na      complete      graph,      there      is      always      Vii   \n \n€      Anc(Y,M),      thus      V4;   \n \n€      D-SEP(X,Y,      M4)      due      to      the collider      path      where      each      non-endpoint      belongs      to      D-SEP(X,      Y,      Mx). O"
            }
          ],
          "content": ""
        },
        {
          "id": 2199,
          "title": "D.6.      Proof      of      Corollary      {I|",
          "type": "section",
          "children": [
            {
              "id": 2200,
              "title": "D.6.      Proof      of      Corollary      {I| - Chunk 1",
              "type": "chunk",
              "children": [],
              "content": "D.6. Proof      of      Corollary      {I|\nProof. The      proof      follows      Thm. 4      of|Wang      et      al! (2023a)      based      on      Thm. 2]      and      Thm. 3}      Thm. 2)and      Thm. 3)can      ensure      that  \n \n  by      using      Alg."
            },
            {
              "id": 2201,
              "title": "D.6.      Proof      of      Corollary      {I| - Chunk 2",
              "type": "chunk",
              "children": [],
              "content": "2]      for      each      potential      adjustment      set,      we      can      find      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the  \n \n  MAGs      consistent      with      M."
            },
            {
              "id": 2202,
              "title": "D.6.      Proof      of      Corollary      {I| - Chunk 3",
              "type": "chunk",
              "children": [],
              "content": "And      since      in      PAGrules,      all      possible      local      transformation      are      considered      on      Line      5,      PAGrules      can  \n \n  return      the      set      of      causal      effects      in      all      the      DAGs      represented      by      the      MAGs      consistent      with      P. C"
            }
          ],
          "content": ""
        }
      ],
      "content": ""
    }
  ],
  "content": ""
}